{"http://act.cs.brown.edu/dynamic_allocation.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Long-Duration Deployments of Heterogeneous Teams of Robots Home Long-Duration Deployments of Heterogeneous Teams of Robots Description Many tasks require robots to operate in long-duration missions with minimal interruption for recharging or replenishing resources. However, robot power and resources are limited, and without a continuous supply of these resources, robots would have significant downtime for recharging or refreshing other resources, which could be severely disruptive to their mission. In this project, we are developing a theoretical framework to deploy teams of robots task robots for exploration and surveillance while taking into account their energy and resource requirements. We envision a distribution center with replenishable resources batteries, cameras etc. that receives or predicts requests for fresh resources from deployed robots, and dispatches agile delivery robots e.g., quadrotors to deliver them in a timely manner. We will address the scheduling and prediction problem underlying this distribution task and propose solutions which generate near-optimal schedules for resource redistribution with multiple incoming requests from deployed robots. The framework will incorporate priorities on task robots which can be changed over time, and allow a relaxed delivery schedule if there are not enough delivery robots available. Delivery robots can also be dynamically re-routed to make efficient use of time and resources to sustain long-duration missions for robotic teams operating in a given region. Investigators Jingyao Ren Nitin Kamra Ameer Hamza Nora Ayanian Related Publications N. Kamra, T. K. S. Kumar and N. Ayanian . Combinatorial Problems in Multirobot Battery Exchange Systems, in IEEE Trans. Automation Science and Engineering, vol. 15, no. 2, pp. 852-862, April 2018. PDF Preprint , DOI , DBLP A. Hamza . Predicting mission power requirement for mobile robots Masters Thesis. Viterbi School of Engineering, University of Southern California, 2015. Full Thesis N. Kamra and N. Ayanian . A Mixed Integer Programming Model for Timed Deliveries in Multirobot Systems, in IEEE Conf. on Automation Science and Engineering, Gothenburg, Sweden, August 2015. PDF Preprint , BibTeX Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:36+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Long-Duration Deployments of Heterogeneous Teams of Robots", ""], "word_count": 334, "token_count_estimate": 454}}, "http://act.cs.brown.edu/group.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Our Team Home Group Faculty and Graduate Students Prof. Nora Ayanian Director noraayanian at brown dot edu Eric Ewing Ph.D. Student Anoop Kiran Ph.D. Student Lishuo Pan Ph.D. Student Arjun Prakash Ph.D. Student Jingyao Ren Ph.D. Candidate at USC Kegan Strawn Ph.D. Student at USC M.S. Students Vikraman Sathiyanarayanan Undergraduate Students Laura Lytle Eric Yi Han Chen Andrew Opem Pilar Luiz Natalie Abreu Former Lab Members Elizabeth Boroson, Graduate Research Assistant Connie Zhang, Graduate Research Assistant Baskin enbalar, Graduate Research Assistant Wolfgang Hnig, Graduate Research Assistant Alp Cevikel, Masters Student Researcher Trevor Nielsen, Undergraduate Researcher Mark Debord, Masters Student Researcher John Zeiders, Undergraduate Researcher Barbara Boyajian, Undergraduate Researcher Jillian Khoo, Undergraduate Researcher Colin Heath, Undergraduate Researcher Virginia Dudley, Undergraduate Researcher Alex Colello, Undergraduate Researcher Sarthak Arora, Masters Student Researcher Chotiwat Chawannakul, Masters Student Researcher Pavle Medvidovic, Undergraduate Researcher Minzhi Xue, Masters Student Researcher Kim Luong, Undergraduate Researcher Joao Victor Cordeiro Coutinho, Visiting Researcher Nitin Kamra, Graduate Research Assistant Arash Tavakoli, Graduate Research Assistant Lindsay White, Undergraduate Researcher Chirag Sanghvi, Student Worker Abishek Hariharan, Masters Student Researcher U Chun Lao, Masters Student Researcher Kristen Morse, Masters Student Researcher Vishwa Theja, Masters Student Researcher Christina Milanes, Undergraduate Researcher Haig Nalbandian, Undergraduate Researcher Lisa Scaria, Undergraduate Researcher Luis Servn, Visiting Researcher Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:37+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Our Team", "Former Lab Members"], "word_count": 221, "token_count_estimate": 407}}, "http://act.cs.brown.edu/crazyswarm.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Crazyswarm Home Crazyswarm Description The Crazyswarm is a swarm of miniature quadcopters Crazyflie 2.0 that can fly together in close proximity. Our approach has the goal to make research in multi-robot systems safer, cheaper, and easier to reproduce. The Crazyswarm has the following features amongst others Safe operation near humans Small footprint allows to fly many vehicles in small lab spaces Good crash resistance because of low inertia Fully open-source Off-the-shelf hardware The system currently requires a motion capture system e.g. VICON, OptiTrack, or PhaseSpace. More information, including tutorials on how to setup the Crazyswarm, can be found on its webpage . A video demonstrating the swarms capabilities is shown below. We used the Crazyswarm to experimentally validate our trajectory planning approach for large quadrotor teams see related publications below. In the future, we are looking at other applications, including distributed algorithms. Investigators In collaboration with the Robotic Embedded Systems Laboratory RESL. Wolfgang Hnig Summer 2016 - James Preiss RESL Summer 2016 - Gaurav Sukhatme RESL Summer 2016 - Nora Ayanian Summer 2016 - Daniel Lytle Fall 2016 - Trevor Nielsen Fall 2016 - Eric Yi Han Chen Fall 2016 - Alex Colello Fall 2017 - Barbara Boyajian Fall 2017 - Jillian Khoo Fall 2017 - Minzhi Xue Fall 2015 - Spring 2016 Chotiwat Chawannakul Summer 2016 - Summer 2017 Related Publications M. Debord , W. Hnig , and N. Ayanian . Trajectory Planning for Heterogeneous Robot Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Madrid, Spain, October 2018. PDF Preprint , Video , Blog Post M. Debord , W. Hnig , and N. Ayanian . Trajectory Planning for Heterogeneous Robot Teams, in 2nd International Symposium on Aerial Robotics ISAR, Philadelphia, USA, June 2018. PDF Preprint , Video W. Hnig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . Trajectory Planning for Quadrotor Swarms, in IEEE Transactions on Robotics T-RO, Special Issue Aerial Swarm Robotics. To Appear. PDF Preprint , Video J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Large Quadrotor Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Vancouver, BC, Canada, September 2017. PDF Preprint , Video J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Quadrotor Swarms, in International Symposium on Aerial Robotics, Philadelphia, PA, USA, June 2017. PDF Preprint J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Large Quadcopter Teams, in Southern California Robotics Symposium SCR, Los Angeles, CA, April 2017. PDF Preprint J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Crazyswarm A Large Nano-Quadcopter Swarm, in Proc. IEEE International Conference on Robotics and Automation, Singapore, 2017. PDF Preprint , Video J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Crazyswarm A Large Nano-Quadcopter Swarm Extended Abstract, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS Late Breaking, Daejeon, Korea, October 2016. PDF Preprint , Video Media Coverage USA Today Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:36+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Crazyswarm", ""], "word_count": 527, "token_count_estimate": 893}}, "http://act.cs.brown.edu/heterogeneous-mapping.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Mapping with Heterogeneous Robots Home Mapping with Heterogeneous Robots Description When robots operate in unknown environments like search and rescue or planetary exploration by rovers, it is important for them to build a map that can be used for localization, planning, and identifying science or search targets. Heterogeneous robots with different kinds of sensors are beneficial for exploration because they have different capabilities and may be able to search the area in different ways. However, it is extremely challenging to combine these measurements from different kinds of sensors. This project focuses on combining data from different kinds of sensors to build better maps, and on building maps that can be used by robots with different capabilities. Initially, we have focused on finding ways to represent information which is shared between different kinds of measurements, such as features which appear in point clouds created from different types of sensors, like LIDAR and stereo camera. We plan to do multi-robot SLAM and build maps with these features. We also plan additional work on improving map-building in groups of heterogeneous robots. Investigators Elizabeth Boroson Nora Ayanian Funding Elizabeth Boroson is funded by the NASA Space Technology Research Fellowship . Related Publications E.R. Boroson , R. Hewitt, N. Ayanian , and J.-P. de la Croix. Inter-Robot Range Measurements in Pose Graph Optimization, in IEEERSJ International Conference on Intelligent Robots and Systems IROS, October 2020. E.R. Boroson and N. Ayanian . 3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM, in IEEE International Conference on Robotics and Automation ICRA, Montral, Canada, May 2019. PDF Preprint Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:37+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Mapping with Heterogeneous Robots", ""], "word_count": 271, "token_count_estimate": 369}}, "http://act.cs.brown.edu/admission.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Get Involved Home Admission Joining ACT Lab Interested Ph.D. students should contact Prof. Ayanian and apply to Brown University Department of Computer Science or School of Engineering. ACT Lab is now at Brown University In January 2022, the ACT Lab moved from the University of Southern California to Brown University. Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:36+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Get Involved", ""], "word_count": 63, "token_count_estimate": 83}}, "http://act.cs.brown.edu/actbot.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT ACTBot Home ACTBot Description Development of a differential-drive robot platform. The platform was successfuly created and is now in the software development and testing phase. We intend to create a public repository and plan on making both the hardware and software design files freely available in the near future. Investigators Luis Servn Jacob Swanson Lindsay White Vishwa Theja Arash Tavakoli Nora Ayanian Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:36+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["ACTBot", ""], "word_count": 75, "token_count_estimate": 100}}, "http://act.cs.brown.edu/contact.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Contact Home Contact Email Nora Ayanian E noraayanian at brown dot edu Offices Department of Computer Science 115 Waterman St Providence, Rhode Island 02906 Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:36+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Contact", ""], "word_count": 37, "token_count_estimate": 55}}, "http://act.cs.brown.edu": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Welcome About Us The Automatic Coordination of Teams ACT Lab at Brown University. ACT Lab conducts research in the area of coordinated multi-robot systems. The common theme behind our different research threads is that we provide theoretically sound solutions to practically motivated problems. The research of ACT is supported by Office of Naval Research ONR , Army Research Laboratory ARL , and National Science Foundation NSF . Media Follow Us On Learn More About Brown Robotics Recent Highlights Our paper Inter-Robot Range Measurements in Pose Graph Optimization was accepted to IROS 2020. June 2020 Connie Zhang was awarded the NSF Graduate Research Fellowship beginning Fall 2020. April 2020 Eric Ewing was awarded the NSF Graduate Research Fellowship Honorable Mention. April 2020 Our paper 3-Dimensional Keypoint Repeatability for Heterogeneous Multi-Robot SLAM was accepted to ICRA 2019. January 2019 Our paper Persistent and Robust Execution of MAPF Schedules in Warehouses was accepted to IEEE RA-L 2019. December 2018 Elizabeth Boroson was awarded the NASA Space Technology Research Fellowship beginning Fall 2018. August 2018 Our paper Trajectory Planning for Heterogeneous Robot Teams was accepted to IROS 2018. June 2018 Our paper Conflict-Based Search with Optimal Task Assignment was accepted to AAMAS 2018 joint work with Amazon Robotics. January 2018 Older Highlights... We are seeking multiple Ph.D. students to work on multiple federally funded projects in multi-robot systems. November 2017 Our paper Downwash-Aware Trajectory Planning for Large Quadrotor Teams was accepted to IROS 2017 June 2017 Our Crazyswarm research is featured at USA Today March 2017 Our paper Crazyswarm A Large Nano-Quadcopter Swarm was accepted to IEEE ICRA 2017 January 2017 Our paper Seamless Robot Simulation Integration for Education A Case Study has been accepted at the workshop on the Role of Simulation in Robot Programming at SIMPAR 2016. November 2016 Our book chapter Flying Multiple UAVs Using ROS will appear in the Springer Book on Robot Operating System ROS 2017 November 2016 Our Crazyswarm was Accepted to Appear in IEEE IROS 2016 Late Breaking August 2016 Dr. Ayanian Selected by MIT Technology Review as a TR35 Top Innovator August 2016 Two of our submissions were accepted to IROS July 2016 Our paper Multi-Agent Path Finding with Kinematic Contraints wins Best Paper in Robotics Track at ICAPS March 2016 Our paper Multi-Agent Path Finding with Kinematic Contraints was accepted to ICAPS January 2016 ACT Lab featured in the inside cover of the USC Viterbi magazine November 2015 Paper Accepted to Appear in IEEE IROS 2015 July 2015 Dr. Ayanian Honored in Inaugural Mic 50 June 2015 Our Paper is Accepted to Appear in IEEE CASE 2015 May 2015 Dr. Ayanian wins the Hanna Reisler Mentorship Award April 2015 Undergrads in the ACT Lab Receive WiSE Research Awards April 2015 Winning the Best Demo Award in the Annual Research Review March 2015 Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Welcome"], "word_count": 480, "token_count_estimate": 687}}, "http://act.cs.brown.edu/mixed-reality.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Mixed Reality for Robotics Home Mixed Reality for Robotics Description When robots operate in shared environments with humans, they are expected to behave predictably, operate safely, and complete the task even with the uncertainty inherent with human interaction. Preparing such a system for deployment often requires testing the robots in an environment shared with humans in order to resolve any unanticipated robot behaviors or reactions, which could be potentially dangerous to the human.In the case of a multi-robot system, uncertainty compounds and opportunities for error multiply, increasing the need for exhaustive testing in the shared environment but at the same time increasing the possibility of harm to both the robots and the human. As the number of components of the system humans, robots, etc. increases, controlling and debugging the system becomes more difficult. Allowing system components to operate in a combination of physical and virtual environments can provide a safer and simpler way to test these interactions, not only by separating the system components, but also by allowing a gradual transition of the system components into shared physical environments. Such a Mixed Reality platform is a powerful tool for testing that can address these issues and has been used to varying degrees in robotics and other fields. We present Mixed Reality as a tool for multi-robot research and discuss the necessary components for effective use. Furthermore, we present practical applications with different robots Crazyflie 2 and TurtleBot 2 and simulation platforms Gazebo, V-REP, and Unity 3D. Investigators In collaboration with the Mixed Reality Laboratory MxR. Wolfgang Hnig Christina Milanes Lisa Scaria Thai Phan MxR Mark Bolas MxR Nora Ayanian Related Publications Thai Phan, W. Hnig , and N. Ayanian . Mixed Reality Collaboration between Human-Agent Teams Extended Abstract, in Proc. IEEE Conference on Virtual Reality and 3D User Interfaces IEEE VR Poster, Reutlingen, Germany, March 2018. PDF Preprint , Video W. Hnig , C. Milanes , L. Scaria , T. Phan, M. Bolas, and N. Ayanian . Mixed Reality for Robotics, in IEEERSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. PDF Preprint , Video , Code , BibTeX Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Mixed Reality for Robotics", ""], "word_count": 365, "token_count_estimate": 481}}, "http://act.cs.brown.edu/mapfast.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Algorithm Selection for Multi-Agent PathfindingMAPF Problems Home Algorithm Selection for Multi-Agent PathfindingMAPF Problems Description Solving the Multi-Agent Path Finding MAPF problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we build deep learning network which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. We improve the performance of our model by including single-agent shortest paths in the instance embedding given to our model and by utilizing supplemental loss functions in addition to a classification loss. We evaluate our model on a large and diverse dataset of MAPF instances, showing that it outperforms all individual algorithms in its portfolio as well as the state-of-the-art optimal MAPF algorithm selector. We also provide an analysis of algorithm behavior in our dataset to gain a deeper understanding of optimal MAPF algorithms strengths and weaknesses to help other researchers leverage different heuristics in algorithm designs. Investigators Jingyao Ren Eric Ewing Baskin Senbaslar Vikraman Sathiyanarayanan Nora Ayanian Funding This research was supported by NSF awards IIS-1553726, IIS-1724392, IIS-1724399, and CNS-1837779 as well as a gift from Amazon. Related Publications Ren J, Sathiyanarayanan V, Ewing E, Senbaslar B, Ayanian N. MAPFAST A Deep Algorithm Selector for Multi Agent Path Finding using Shortest Path Embeddings. In Proceedings of the 20th International Conference on Autonomous Agents and Multi-Agent Systems AAMAS-21 2021 May 3 pp. 1055-1063. PDF Ren J, Sathiyanarayanan V, Ewing E, Senbaslar B, Ayanian N. Automatic Optimal Multi-Agent Path Finding Algorithm Selector Student Abstract. In Proceedings of the AAAI Conference on Artificial Intelligence 2021 May 18 Vol. 35, No. 18, pp. 15877-15878. PDF Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:47+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Algorithm Selection for Multi-Agent Pathfinding(MAPF) Problems", ""], "word_count": 323, "token_count_estimate": 480}}, "http://act.cs.brown.edu/motion-coordination.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Motion Coordination for Multi-Robot Systems Home Motion Coordination for Multi-Robot Systems Description Planning is a crucial component in robotic systems. Nevertheless, the state-of-the art algorithms do not perform well in realistic conditions for robot groups. On the one hand, sampling or graph based methods which operate in joint space suffer from the dimensionality explosion. On the other hand, planners which try to avoid that effect make simplifying assumptions, limiting its practical applications. We investigate planning algorithms which work in realistic conditions that is kinematic constraints and imperfect plan execution for robot groups. Because there is always the possibility that a single robot fails, such plans need to be either be computable in a very short amount of time or it needs to be possible to update them online. The following video shows an example of a motion planning problem. The robots need to swap sides, but there is only a small corridor available. Nevertheless, we want to find a motion plan for each robot such that the overal swapping time is minimal or within a specifiable factor away from the optimum. Investigators In collaboration with the Intelligent Decision Making Laboratory IDM Lab. Wolfgang Hnig B. enbalar M. Debord T. K. Satish Kumar Liron Cohen IDM Lab Hang Ma IDM Lab Hong Xu IDM Lab Sven Koenig IDM Lab Nora Ayanian Funding This project is supported by NSF IIS-1724392 and NSF CNS-1837779 . Related Publications W. Hnig , S. Kiesel, A. Tinka, J. W. Durham,, and N. Ayanian . Persistent and Robust Execution of MAPF Schedules in Warehouses, in IEEE Robotics and Automation Letters RA-L, Accepted, To Appear, 2019. PDF Preprint , Video , DOI B. enbalar , W. Hnig , and N. Ayanian . Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning Extended Abstract, in IEEERSJ International Conference on Intelligent Robots and Systems IROS Poster, Madrid, Spain, October 2018. PDF Preprint , Video B. enbalar , W. Hnig , and N. Ayanian . Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning, in Int. Symp. on Distributed Autonomous Robotic Systems DARS, Boulder, CO, USA, October 2018. PDF Preprint , Video W. Hnig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . Trajectory Planning for Quadrotor Swarms, in IEEE Transactions on Robotics T-RO, Special Issue Aerial Swarm Robotics, vol. 34, no. 4, pp. 856-869, August 2018. PDF Preprint , Video , DOI M. Debord , W. Hnig , and N. Ayanian . Trajectory Planning for Heterogeneous Robot Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Madrid, Spain, October 2018. PDF Preprint , Video , Blog Post W. Hnig , S. Kiesel, A. Tinka, J. W. Durham, and N. Ayanian . Conflict-Based Search with Optimal Task Assignment, In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems AAMAS, Stockholm, Sweden, July 2018. PDF Preprint , ACM , DBLP J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Large Quadrotor Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Vancouver, BC, Canada, September 2017. PDF Preprint , Video , DOI , DBLP H. Ma, W. Hnig , L. Cohen, T. Uras, H. Xu, T. K. S. Kumar, N. Ayanian and S. Koenig. Overview A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems, in IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12, NovemberDecember 2017. PDF Preprint , Video , DOI , DBLP W. Hnig , T. K. S. Kumar, L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. Summary Multi-Agent Path Finding with Kinematic Contraints, in International Joint Conferences on Artificial Intelligence, Melbourne, Australia, August 2017. PDF , Video , DBLP W. Hnig , T. K. S. Kumar , H. Ma, S. Koenig, and N. Ayanian Formation change for robot groups in occluded environments, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Daejeon, Korea, October 2016. PDF Preprint , Video , BibTeX H. Ma, S. Koenig, N. Ayanian , L. Cohen, W. Hnig , T. K. S. Kumar , T. Uras, H. Xu, C. Tovey, and G. Sharon. Overview Generalizations of Multi-Agent Path Finding to Real-World Scenarios, in IJCAI-16 Workshop on Multi-Agent Path Finding WOMPF, New York City, NY, July 2016. PDF Preprint W. Hnig , T. K. S. Kumar , L. Cohen, H. Ma, S. Koenig, and N. Ayanian . Path Planning With Kinematic Constraints For Robot Groups, in Southern California Robotics Symposium SCR, San Diego, CA, April 2016. PDF Preprint W. Hnig , T. K. S. Kumar , L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. Multi-Agent Path Finding with Kinematic Contraints, in International Conference on Automated Planning and Scheduling, London, U.K., June 2016. AWARDED BEST PAPER IN ROBOTICS TRACK. PDF Preprint , Video , BibTeX Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Motion Coordination for Multi-Robot Systems", ""], "word_count": 817, "token_count_estimate": 1328}}, "http://act.cs.brown.edu/human-inspired.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Human-Inspired Multirobot Coordination Home Human-Inspired Multirobot Coordination Description Tasks requiring tight coordination between groups of robots are very challenging. Typical approaches use groups with fixed hierarchies or the same simple algorithms on all robots, which may not work for unknown environments and complex problems. However, humans are very good at coordinating and adapting to changes in the environment. A major reason for this is their diversity. In a group, humans take different roles and work together to reach a better solution than they would individually. To understand the behaviors humans use to cooperate, we have developed an online multiplayer game in which a group of players must arrange themselves in a formation using only a limited view of their immediate surroundings, simulating a robot with a lidar sensor. We have observed that humans learn to complete this task efficiently, and take on diverse roles to ensure group success. Every group has some players who take a leading role and direct others into place, some who collaborate by joining groups and forming lines, and some who create anchors for the group to form around. Over several consecutive games, players maintain the same roles, and the group learns to tightly coordinate their actions. We plan to train diverse groups of autonomous agents and robots to use these same behaviors to coordinate on shape formation and other complex tasks. The video below shows a group playing the cooperative game with instructions to form a rectangle. Each participant has only the neighborhood view so can only see the area directly around their position. The players initially form several parts of shapes before finding the rest of the group, and show different roles and communication as they coordinate to form the final rectangle. Investigators Elizabeth Boroson Sarthak Arora John Zeiders Nora Ayanian Funding This project is supported by NSF CAREER IIS-1553726 . Related Publications Refereed Conference Papers and Abstracts E. Boroson , F. Sha, and N. Ayanian . Model-Free Policy Gradients for Multi-Agent ShapeFormation Extended Abstract, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS Poster, Vancouver, BC, Canada, September 2017. PDF Preprint A. Tavakoli , H. Nalbandian , and N. Ayanian . Crowdsourced Coordination Through Online Games, in ACMIEEE Intl Conf. on Human Robot Interaction Late Breaking Reports, 2016. PDF Preprint , BibTeX Workshop Papers A. Tavakoli and N. Ayanian . Multirobot Coordination by Multiplayer Games, in International Conference on Robotics and Automation ICRA Fielded Multi-Robot Systems Operating On Land, Sea, and Air Workshop, 2016. Preprints and Papers Under Review A. Tavakoli , H. Nalbandian , and N. Ayanian . Multiplayer Games for Learning Multirobot Coordination Algorithms. arXiv preprint arXiv1604.05942. 2016. PDF Preprint , arXiv , BibTeX Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:37+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Human-Inspired Multirobot Coordination", ""], "word_count": 458, "token_count_estimate": 625}}, "http://act.cs.brown.edu/index.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Welcome About Us The Automatic Coordination of Teams ACT Lab at Brown University. ACT Lab conducts research in the area of coordinated multi-robot systems. The common theme behind our different research threads is that we provide theoretically sound solutions to practically motivated problems. The research of ACT is supported by Office of Naval Research ONR , Army Research Laboratory ARL , and National Science Foundation NSF . Media Follow Us On Learn More About Brown Robotics Recent Highlights Our paper Inter-Robot Range Measurements in Pose Graph Optimization was accepted to IROS 2020. June 2020 Connie Zhang was awarded the NSF Graduate Research Fellowship beginning Fall 2020. April 2020 Eric Ewing was awarded the NSF Graduate Research Fellowship Honorable Mention. April 2020 Our paper 3-Dimensional Keypoint Repeatability for Heterogeneous Multi-Robot SLAM was accepted to ICRA 2019. January 2019 Our paper Persistent and Robust Execution of MAPF Schedules in Warehouses was accepted to IEEE RA-L 2019. December 2018 Elizabeth Boroson was awarded the NASA Space Technology Research Fellowship beginning Fall 2018. August 2018 Our paper Trajectory Planning for Heterogeneous Robot Teams was accepted to IROS 2018. June 2018 Our paper Conflict-Based Search with Optimal Task Assignment was accepted to AAMAS 2018 joint work with Amazon Robotics. January 2018 Older Highlights... We are seeking multiple Ph.D. students to work on multiple federally funded projects in multi-robot systems. November 2017 Our paper Downwash-Aware Trajectory Planning for Large Quadrotor Teams was accepted to IROS 2017 June 2017 Our Crazyswarm research is featured at USA Today March 2017 Our paper Crazyswarm A Large Nano-Quadcopter Swarm was accepted to IEEE ICRA 2017 January 2017 Our paper Seamless Robot Simulation Integration for Education A Case Study has been accepted at the workshop on the Role of Simulation in Robot Programming at SIMPAR 2016. November 2016 Our book chapter Flying Multiple UAVs Using ROS will appear in the Springer Book on Robot Operating System ROS 2017 November 2016 Our Crazyswarm was Accepted to Appear in IEEE IROS 2016 Late Breaking August 2016 Dr. Ayanian Selected by MIT Technology Review as a TR35 Top Innovator August 2016 Two of our submissions were accepted to IROS July 2016 Our paper Multi-Agent Path Finding with Kinematic Contraints wins Best Paper in Robotics Track at ICAPS March 2016 Our paper Multi-Agent Path Finding with Kinematic Contraints was accepted to ICAPS January 2016 ACT Lab featured in the inside cover of the USC Viterbi magazine November 2015 Paper Accepted to Appear in IEEE IROS 2015 July 2015 Dr. Ayanian Honored in Inaugural Mic 50 June 2015 Our Paper is Accepted to Appear in IEEE CASE 2015 May 2015 Dr. Ayanian wins the Hanna Reisler Mentorship Award April 2015 Undergrads in the ACT Lab Receive WiSE Research Awards April 2015 Winning the Best Demo Award in the Annual Research Review March 2015 Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Welcome"], "word_count": 480, "token_count_estimate": 687}}, "http://act.cs.brown.edu/multi-target-tracking.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Heterogeneous Multi-Target Tracking Home Heterogeneous Multi-Target Tracking Description Tracking multiple moving targets in a dynamic environment has many applications. For example, it can be used in surveillance, in sports events to keep track on where the players are, or for tracking the position of animals. Furthermore, if cameras are used for tracking, it is beneficial to maximize the visual coverage of the targets. This can be used in post-processing, for example in case of sports events to give detailed feedback about the players, or in case of animals to create 3D-Animations. To achieve both tracking and maximum visual coverage, the robots must collaborate and share sensor information. Moreover, planed paths need to take the limited fields of operation, occlusion, and obstacles into account. A video for the 2D-case is shown below. Assume there are cameras placed on differential drive robots. All robots collaborate to maximize the coverage marked as green edges and minimize the surface area which is not visible red edges. Dynamic path planning is used to find a path to better configuration blue lines. Investigators Wolfgang Hnig Nora Ayanian Related Publications W. Hnig and N. Ayanian . Dynamic multi-target coverage with robotic cameras, in Proc. IEEERSJ Int. Conf. Intell. Robots Syst., 2016. Accepted, to appear. PDF Preprint , Video , BibTeX Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Heterogeneous Multi-Target Tracking", ""], "word_count": 226, "token_count_estimate": 302}}, "http://act.cs.brown.edu/mrhi.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Multi-Robot-Human Interaction Home Multi-Robot-Human Interaction Description Coming soon. Investigators Kegan Strawn Funding Related Publications Workshop Papers K. J. Strawn and N. Ayanian . Symmetry Agnostic Learning for Multi-Robot Zero-Shot Coordination, in AAMAS Workshop on Autonomous and Multi-Robot Systems, May 2022. PDF Preprint Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Multi-Robot-Human Interaction", ""], "word_count": 55, "token_count_estimate": 97}}, "http://act.cs.brown.edu/research.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Research Projects Home Research Algorithm Selection for Multi-Agent PathfindingMAPF Problems Solving the Multi-Agent Path Finding MAPF problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we build deep learning network which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. View Project Mapping with Heterogeneous Robots This project focuses on combining data from different kinds of sensors to build better maps, and on building maps that can be used by robots with different capabilities. View Project Motion Coordination for Multi-Robot Systems Traditional single-robot algorithms tend to be slow if applied to groups of robots due to the increased dimensionality of the state space. On the other hands, multi-agent solutions from the artificial intelligence community can often not be directly applied to robots because they make invalid, simplifying assumptions. We investigate solutions that bridge the gap between AI and robotics, allowing to plan for large multi-robot systems. View Project Long-Duration Deployments of Heterogeneous Teams We develop both a theoretical framework and empirical models for extended autonomy in multirobot teams. Long-duration deployments require replenished resources, such as batteries and sensors. Our framework deals with both predicting when those resources will be needed, as well as ensuring that they are delivered in a timely manner to reduce robot down-time. View Project Crazyswarm The Crazyswarm is a swarm of miniature quadcopters Crazyflie 2.0 that can fly together in close proximity. The size of the quadrotors allows safe operations near humans and indoor experiments with many vehicles even in tight lab spaces. The hardware is commercially available and the software including ROS support is available as open source. We use and maintain the Crazyswarm for research in multi-robot coordination. View Project Human-Inspired Multirobot Coordination We use a cooperative online multiplayer games to observe the behaviors and algorithms humans use to work together. By applying learning techniques to data from humans, we plan to create an ensemble of diverse controllers for robots that can be used together to complete complex tasks. View Project Multi-Robot-Human Interaction We focus on developing safer and more efficient interaction between multiple robots and humans. We apply reinforcement learning, verification, and human-robot interaction techniques to multiple different interaction scenarios and applications. View Project Mixed Reality for Robotics Mixed Reality can be a valuable tool for research and development in robotics. Specifically, our approach reduces the gap between simulation and implementation, and can eliminate safety concerns with human-robot interaction. View Project Old Projects... Heterogeneous Multi-Target Tracking We investigate algorithms for mobile robotic cameras to maximize the visual coverage of multiple moving targets in dynamic environments including obstacles. This approach has a variety of applications, including for surveillance, sports events, training, and documentation of endangered animals. View Project ACTBot Development of a differential-drive robot platform. View Project 1 Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:47+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Research Projects", ""], "word_count": 521, "token_count_estimate": 647}}, "http://aireu.cs.brown.edu": {"text_content": "Welcome How to Apply About the Program Faculty Mentors Recent Research Projects Review Criteria Applications for Summer 24 closed on Februrary 2nd. Review of applications is currently ongoing. Welcome Brown Computer Science is proud to present Artificial Intelligence for Computational Creativity, an NSF Summer REU Site. This is a 9-week, fully-funded, summer residential program which brings students to the Brown University campus June 3 -- August 2 2024 to conduct original research with computer science faculty and graduate students. Our intellectual focus is creative applications of artificial intelligence potential research topics include creative generative models of visual and textual content, detecting fake generated content, AI for game playing, user experience design for creative AI systems, and more. Research in this field is poised to revolutionize the means of personal expression for everyone in writing, photography, design, architecture, and more. Our REU Site is a partnership with The Leadership Alliance , a national consortium of more than 30 PhD-granting and Minority-Serving Institutions MSIs dedicated to training students from diverse cultural and academic backgrounds for graduate programs and professional research-based careers. We encourage applications from students from historically-underrepresented groups, which includes but is not limited to students that identify as women, underrepresented minority URM, having a disability, first-generation college, low-income, andor LGBTQ. In addition to conducting original research, students at our site will participate in Alliance-led career development activities, professional networking opportunities, and social events. Apply to join us in Providence, Rhode Island this summer How to Apply To apply for the program, submit an application via NSF ETAP httpsetap.nsf.govaward238opportunity6337 You will also need to submit an application to The Leadership Alliances Summer Research Early Identification Program SR-EIP httpsapp.theleadershipalliance.org Please submit the same materials statements, recommendation letters, etc. to both applications. The application deadline is February 2, 2024 . Admission offers will be sent out on a rolling basis after the application deadline. About the Program Who is eligible to apply US citizens or permanent residents who are enrolled in a degree program leading to a baccalaureate or associate degree. Students who are transferring from one college or university to another and are enrolled at neither institution during the summer may participate. High school graduates who have been accepted at an undergraduate institution but who have not yet started their undergraduate study are also eligible to participate. Students who have received their bachelors degrees and are no longer enrolled as undergraduates are generally not eligible to participate. Experience needed Prospective students should at minimum have completed an introductory computer science course sequence as well as mathematics courses covering calculus, linear algebra, and probability. Additional advanced coursework in areas related to the Sites theme e.g. computer vision, machine learning are helpful but not strictly required. Prior research experience is helpful but also not strictly required. Research activities Participants will be paired with a faculty mentor and a graduate student mentor who will help guide them through a 9-week research project. This includes a weekly study group which walks students through the process of conceiving, developing, and presenting an original research proposal. In addition, the summer begins with crash courses on research methods, artificial intelligence and machine learning principles, and working with modern software tools for AIML. Other activities In addition to their research projects, students will also have the opportunity to participate in Leadership Alliance-sponsored events including faculty and alumni panels on careers in research, graduate student panels on pathways to graduate school, group dinners, and more. We also plan to organize extracurricular social activities in the local area, such as visits to the RISD museum, excursions to Newport and Rhode Islands beaches, and Saturday night visits to Providences Waterfire celebration. Time commitment The program runs 9 weeks, from June 3 through August 2, 2024. You can expect to spend 35 hours a week on your research and an additional 5 hours a week in other required program activities. Most research and activities will take place between 9-5 Monday - Friday. Optional weekend social activities will also be included. Funding Participating students will receive a stipend of 6,480 for the summer, in three installments. Students will live in Brown campus housing with other members of the REU Site cohort for the duration of the program housing and travel costs to and from the campus will be covered by the program. Faculty Mentors Students who participate in our Site will be mentored by one or more of the following Brown CS faculty members Daniel Ritchie Creating, editing, and analyzing 3D structures James Tompkin Creating, editing, and manipulating images and video Nora Ayanian How can we enable almost anyone to use teams of robots Chen Sun Multimodal machine learning for computer vision to help language understanding, robotics, and social science Srinath Sridhar 3D vision machine learning for understanding human physical interactions Recent Research Projects Here are just a few examples of research projects recently carried out by our faculty A data-driven generative model that can synthesize new virtual bedrooms and other types of 3D indoor scenes. Learn more Reconstructing time-varying 4D objects with unsupervised segmentation. Learn more A neural network to reverse engineer CAD modeling sequences for 3D shapes. Learn more A system for creating new 3D floor plans by automatically recombining rooms from existing floor plans. Learn more A neural network to transmogrify images of animals without altering the image background. Learn more A neural network to write programs that generate structured 3D shapes, such as chairs. Learn more High-resolution text-to-shape synthesis without any text labels at training time. Learn more A neural network to insert images of objects into new environments. Learn more A neural generative model that can learn to write in your handwriting and represent all kinds of different styles. Learn more Building high-quality models of objects from only a few images. Learn more Previous Next Review Criteria When we review applicants to the program, we are looking for the following qualities Students with strong technical skills, as evidenced by grades in computer science and math courses, prior research projects, or other relevant experience. Students who write thoughtful, compelling statements about why they want to pursue research in creative applications of AI. Students who have limited opportunities to engage in CS research at their own college or university. Students who will contribute to a diverse cohort with a variety of backgrounds, experience levels, and perspectives.", "metadata": {"last_modified": "2024-02-19T16:46:38+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": [], "word_count": 1054, "token_count_estimate": 1303}}, "http://act.cs.brown.edu/publications.html": {"text_content": "Toggle navigation ACT LAB RESEARCH PUBLICATIONS GROUP ADMISSION CONTACT Publications Home Publications Book Chapters and Journal Publications W. Hnig , S. Kiesel, A. Tinka, J. W. Durham,, and N. Ayanian . Persistent and Robust Execution of MAPF Schedules in Warehouses, in IEEE Robotics and Automation Letters RA-L, vol. 4, no. 2, pp. 1125-1131, April 2019. PDF Preprint , Video , DOI N. Ayanian . DART Diversity-enhanced autonomy in robot teams, in International Journal of Robotics Research IJRR, March 2019. DOI T. Abdelzaher, N. Ayanian , T. Basar, S. Diggavi, J. Diesner, D. Ganesan, R. Govindan, S. Jha, T. Lepoint, B. Marlin, K. Nahrstedt, D. Nicol, R. Rajkumar, S. Russell, S. Seshia, F. Sha, P. Shenoy, M. Srivastava, G. Sukhatme, A. Swami, P. Tabuada, D. Towsley, N. Vaidya and V. Veeravalli. Toward an internet of battlefield things A resilience perspective, in Computer, vol. 51, no. 11, pp. 24-36, Nov 2018. DOI W. Hnig , J. A. Preiss, T. K. S. Kumar, G. S. Sukhatme, and N. Ayanian . Trajectory Planning for Quadrotor Swarms, in IEEE Transactions on Robotics T-RO, Special Issue Aerial Swarm Robotics, vol. 34, no. 4, pp. 856-869, August 2018. PDF Preprint , Video , DOI N. Kamra, T. K. S. Kumar and N. Ayanian . Combinatorial Problems in Multirobot Battery Exchange Systems, in IEEE Trans. Automation Science and Engineering, vol. 15, no. 2, pp. 852-862, April 2018. PDF Preprint , DOI , DBLP H. Ma, W. Hnig , L. Cohen, T. Uras, H. Xu, T. K. S. Kumar, N. Ayanian and S. Koenig. Overview A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems, in IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12, NovemberDecember 2017. PDF Preprint , Video , DOI , DBLP W. Hnig and N. Ayanian . Flying Multiple UAVs Using ROS, Chapter in Robot Operating System ROS The Complete Reference Volume 2, Springer, 2017. PDF Preprint This is a pre-print of a contribution published in Robot Operating System ROSThe Complete Reference Volume 2 Editor Koubaa, Anis published by Springer. The definitive authenticated version is available online via DOI . K. Hausman, J. Mller, A. Hariharan , N. Ayanian and G. Sukhatme. Cooperative Control for Target Tracking with Onboard Sensing, in International Journal of Robotics Research, vol. 34, no. 13, pp. 1660-1677, Nov. 2015. PDF Preprint , BibTeX Refereed Conference Publications K. Strawn and N. Ayanian . Byzantine Fault Tolerant Consensus for Multi-Robot Pickup and Delivery , in International Symposium on Distributed Autonomous Robotic Systems DARS, June 2021. PDF Preprint J. Ren , V. Sathiyanarayanan , E. Ewing , B. enbalar , and N. Ayanian . Automatic Optimal Multi-Agent Path Finding Algorithm Selector Extended Abstract, in AAAI Conference on Artificial Intelligence AAAI, Accepted, to appear February 2021. PDF Preprint E.R. Boroson , R. Hewitt, N. Ayanian , and J.-P. de la Croix. Inter-Robot Range Measurements in Pose Graph Optimization, in IEEERSJ International Conference on Intelligent Robots and Systems IROS, October 2020. A. Molchanov, T. Chen, W. Hnig , J.A. Preiss, N. Ayanian , and G.S. Sukhatme. Sim- to-Multi- Real Transfer of Low-Level Robust Control Policies to Multiple Quadrotors, in IEEERSJ International Conference on Intelligent Robots and Systems IROS, Macau, China, November 2019. E. R. Boroson and N. Ayanian . 3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM, in IEEE International Conference on Robotics and Automation ICRA, Montral, Canada, May 2019. PDF Preprint D. Albani , W. Hnig , N. Ayanian , D. Nardi, and V. Trianni. Summary Distributed Task Assignment and Path Planningwith Limited Communication for Robot Teams Short Paper, in International Conference on Autonomous Agents and Multiagent Systems AAMAS 2019. PDF Preprint H. Ma, W. Hnig , S. Kumar, N. Ayanian , and S. Koenig. Lifelong Path Planning with Kinematic Constraints for Multi-Agent Pickup and Delivery, Proceedings of the AAAI Conference on Artificial Intelligence AAAI 2019. PDF Preprint , Appendix , Video 1 , Video 2 , Video 3 , Video 4 , Video 5 , Video 6 B. enbalar , W. Hnig , and N. Ayanian . Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning Extended Abstract, in IEEERSJ International Conference on Intelligent Robots and Systems IROS Poster, Madrid, Spain, October 2018. PDF Preprint , Video B. enbalar , W. Hnig , and N. Ayanian . Robust Trajectory Execution for Multi-Robot Teams Using Distributed Real-time Replanning, in Int. Symp. on Distributed Autonomous Robotic Systems DARS, Boulder, CO, USA, October 2018. PDF Preprint , Video , Code M. Debord , W. Hnig , and N. Ayanian . Trajectory Planning for Heterogeneous Robot Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Madrid, Spain, October 2018. PDF Preprint , Video , Blog Post W. Hnig , S. Kiesel, A. Tinka, J. W. Durham, and N. Ayanian . Conflict-Based Search with Optimal Task Assignment, In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems AAMAS, Stockholm, Sweden, July 2018. PDF Preprint , ACM , DBLP T. Phan, W. Hnig , and N. Ayanian . Mixed Reality Collaboration between Human-Agent Teams Extended Abstract, in Proc. IEEE Conference on Virtual Reality and 3D User Interfaces IEEE VR Poster, Reutlingen, Germany, March 2018. PDF Preprint , Video , DOI , DBLP N. Ayanian . DART Diversity-enhanced autonomy in robot teams, In International Symposium of Robotics Research ISRR, Chile, Dec 2017. Talk available online , DOI J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Large Quadrotor Teams, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Vancouver, BC, Canada, September 2017. PDF Preprint , Video , DOI , DBLP E. Boroson , F. Sha, and N. Ayanian . Model-Free Policy Gradients for Multi-Agent ShapeFormation Extended Abstract, in IEEERSJ International Conference on Intelligent Robots and Systems IROS Poster, Vancouver, BC, Canada, September 2017. PDF Preprint W. Hnig , T. K. S. Kumar, L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. Summary Multi-Agent Path Finding with Kinematic Contraints, in International Joint Conferences on Artificial Intelligence, Melbourne, Australia, August 2017. PDF , Video , DOI , DBLP J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Crazyswarm A Large Nano-Quadcopter Swarm, in Proc. IEEE International Conference on Robotics and Automation, Singapore, 2017. PDF Preprint , Video J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Crazyswarm A Large Nano-Quadcopter Swarm Extended Abstract, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS Late Breaking, Daejeon, Korea, October 2016. PDF Preprint , Video W. Hnig and N. Ayanian . Dynamic multi-target coverage with robotic cameras, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Daejeon, Korea, October 2016. PDF Preprint , Video , BibTeX W. Hnig , T. K. S. Kumar , H. Ma, S. Koenig, and N. Ayanian Formation change for robot groups in occluded environments, in Proc. IEEERSJ International Conference on Intelligent Robots and Systems IROS, Daejeon, Korea, October 2016. PDF Preprint , Video , BibTeX L. Cohen, T. K. S. Kumar , T. Uras, H. Xu, S. Koenig, and N. Ayanian . Improved Bounded-Suboptimal Multi-Agent Path Finding Solvers, in Proc. International Joint Conference on Artificial Intelligence, New York, NY, July 2016. PDF , BibTeX W. Hnig , T. K. S. Kumar , L. Cohen, H. Ma, H. Xu, N. Ayanian , and S. Koenig. Multi-Agent Path Finding with Kinematic Contraints, in International Conference on Automated Planning and Scheduling, London, U.K., June 2016. AWARDED BEST PAPER IN ROBOTICS TRACK. PDF Preprint , Video , BibTeX T. Cai, D. Zhang, T. K. S. Kumar , S. Koenig, and N. Ayanian . Local search on trees and a framework for automated construction using multiple identical robots, in International Conference on Autonomous Agents and Multiagent Systems, Extended Abstract, Singapore, May 2016. PDF Preprint , BibTeX A. Tavakoli , H. Nalbandian , and N. Ayanian . Crowdsourced Coordination Through Online Games, in ACMIEEE Intl Conf. on Human Robot Interaction Late Breaking Reports, 2016. PDF Preprint , BibTeX W. Hnig , C. Milanes , L. Scaria , T. Phan, M. Bolas, and N. Ayanian . Mixed Reality for Robotics, in IEEERSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. PDF Preprint , Video , Code , BibTeX S. Wang, B. Krishnamachari, and N. Ayanian . The Optimism Principle A Unified Framework for Optimal Robotic Network Deployment in An Unknown Obstructed Environment, IEEERSJ Intl Conf. on Intelligent Robots and Systems, Hamburg, Germany, September 2015. PDF Preprint , BibTeX N. Kamra and N. Ayanian . A Mixed Integer Programming Model for Timed Deliveries in Multirobot Systems, in IEEE Conf. on Automation Science and Engineering, Gothenburg, Sweden, August 2015. PDF Preprint , BibTeX S. Garg and N. Ayanian . Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a Small Team of Robots, in Robotics Science and Systems X, Berkeley, CA, July 2014. PDF Preprint , BibTeX K. Hausman, J. Mller, A. Hariharan , N. Ayanian , and G. Sukhatme. Cooperative Control for Target Tracking with Onboard Sensing, in Proceedings of the Intl Symposium on Experimental Robotics, Morrocco, June 2014. PDF Preprint , BibTeX Masters Thesis A. Hamza . Predicting mission power requirement for mobile robots Masters Thesis. Viterbi School of Engineering, University of Southern California, 2015. Full Thesis Workshops and Symposia K. J. Strawn and N. Ayanian . Symmetry Agnostic Learning for Multi-Robot Zero-Shot Coordination, in International Conference on Autonomous Agents and Multiagent Systems AAMAS, Auckland, New Zealand, May 2022. PDF Preprint M. Debord , W. Hnig , and N. Ayanian . Trajectory Planning for Heterogeneous Robot Teams, in 2nd International Symposium on Aerial Robotics ISAR, Philadelphia, USA, June 2018. PDF Preprint , Video W. Hnig . Scalable Task and Motion Planning for Multi-Robot Systems in Obstacle-Rich Environments Doctoral Consortium, In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems AAMAS, Stockholm, Sweden, July 2018. PDF Preprint , ACM , DBLP E. Boroson , F. Sha, and N. Ayanian . Model-Free Policy Gradients for Multi-Agent ShapeFormation, in IEEE International Symposium on Multi-Robot and Multi-Agent Systems MRS, Los Angeles, CA, December 2017. PDF Preprint J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Quadrotor Swarms, in International Symposium on Aerial Robotics, Philadelphia, PA, USA, June 2017. PDF Preprint J. A. Preiss, W. Hnig , G. S. Sukhatme, and N. Ayanian . Downwash-Aware Trajectory Planning for Large Quadcopter Teams, in Southern California Robotics Symposium SCR, Los Angeles, CA, April 2017. PDF Preprint W. Hnig , A. Tavakoli , and N. Ayanian . Seamless Robot Simulation Integration for Education A Case Study, Workshop on the Role of Simulation in Robot Programming at SIMPAR 2016, San Francisco, CA, December 2016. PDF Preprint , Code H. Ma, S. Koenig, N. Ayanian , L. Cohen, W. Hnig , T. K. S. Kumar , T. Uras, H. Xu, C. Tovey, and G. Sharon. Overview Generalizations of Multi-Agent Path Finding to Real-World Scenarios, in IJCAI-16 Workshop on Multi-Agent Path Finding WOMPF, New York City, NY, July 2016. PDF Preprint W. Hnig , T. K. S. Kumar , L. Cohen, H. Ma, S. Koenig, and N. Ayanian . Path Planning With Kinematic Constraints For Robot Groups, in Southern California Robotics Symposium SCR, San Diego, CA, April 2016. PDF Preprint Copyright ACT Lab 2018", "metadata": {"last_modified": "2022-10-18T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Publications", ""], "word_count": 1871, "token_count_estimate": 3294}}, "https://awards.cs.brown.edu/2015/07/02/four-brown-cs-students-recognized-2015-google-scholars/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Four Brown CS Students Recognized As 2015 Google Scholars Posted by Jesse Polhemus on July 2, 2015 in Awards Four students from Brown University s Department of Computer Science attended Googles Scholars Retreat in Mountain View, California this past week, where they each accepted highly selective Google scholarships. Together with an incoming student who was also chosen and one who was recognized as a finalist, they received recognition and support toward their education for the 2015-16 academic year as they become part of the next generation of diverse tech leaders. The students were awarded scholarships in several categories, achieving a level of representation that few Brown CS rivals matched Sharon Lo 16 and Dana Metaxa-Kakavouli 15 incoming Stanford PhD student won the Google Anita Borg Memorial Scholarship, awarded to 20 women students and leaders in CS Paige Selby M16 and Eli White 18 won the Google Lime Award, awarded to 12 high-achieving CS students with disabilities Luis Aguirre 19 was one of 20 winners of the Generation Google Scholarship for incoming CS college students from underrepresented backgrounds Ebube Chuba 19 was also recognized as one of ten finalists for the Generation Google Scholarship. During the four-day retreat in Mountain View the scholars attended tech talks, networked with Google employees, participated in developmental activities and sessions, and attended social activities with the other Google scholars. I personally would say I left the retreat really appreciative that I get to be part of the Brown community, Sharon says. During the retreat, we had a talk from a program manager from Google X, one of Googles most innovative teams aimed at creating major moonshot technological advancements and surprise, but almost no surprise at all she was a Brown alum.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Information for:", "Awards", "Four Brown CS Students Recognized As 2015 Google Scholars"], "word_count": 299, "token_count_estimate": 369}}, "https://awards.cs.brown.edu/2016/05/06/krishna-chaitanya-aluru-wins-ycombinator-fellowship/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Krishna Chaitanya Aluru Wins A Y Combinator Fellowship Posted by Jesse Polhemus on May 6, 2016 in Awards The YC Fellowship, an experiment from Y Combinator in helping create startups, has just put a Brown University student on the path toward using computing to significantly improve lives on a global scale. Krishna Chaitanya Aluru of the Department of Computer Science Brown CS and his collaborators Akshat Goenka Wharton and Vamsee Chamakura IIIT have just been admitted to the program for their DocTalk project, earning 20,000 and eight weeks of advice from the Y Combinator community to transform their idea into an actual startup. Currently, a single doctor in India serves an astonishing 1,800 patients. DocTalk, which features an app co-developed with Brown University student Justin Brower, will enable doctors to maximize the number of patients they can consult with by solving some of the inefficiencies in the current healthcare ecosystem in India. Further details will remain proprietary until launch. Interviewing with YC was an incredible experience, Krishna says. We felt so lucky to be able to sit across the table from people who founded and funded insanely successful companies and talk to them about our idea. YC calls you the same day of the interview to let you know whether you got in. We actually decided to watch Zootopia that evening to take our minds off of it. It was barely ten minutes into the movie when we got the phone call from one of the partners saying that we were accepted into the fellowship. Being accepted is the best motivation we could have asked for as we work on DocTalk over the next few months. Were incredibly grateful and cannot wait to be a part of YC. For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:04+00:00", "headings": ["Information for:", "Awards", "Krishna Chaitanya Aluru Wins A Y Combinator Fellowship"], "word_count": 321, "token_count_estimate": 397}}, "https://awards.cs.brown.edu/2014/07/22/layla-oespser-wins-ismb-workshop-best-presentation-award/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Layla Oesper Wins ISMB Workshop Best Presentation Award Posted by Jesse Polhemus on July 22, 2014 in Awards Last weekin Boston, Brown University s Department of Computer Science BrownCS and Centerfor Computational Molecular Biology CCMB managed to put a capstone ontheir achievement of giving a recordnumber of talks at one of the most prominent conferences in ComputationalBiology . Atthe twenty-second annual International Conference on Intelligent Systems forMolecular Biology ISMB 2014, PhD candidate Layla Oesper s talk Quantifying TumorHeterogeneity in Whole-Genome and Whole-Exome Sequencing Data received theBest Presentation Award, accompanied by a cash prize of 250, for the HitSeq2014 High-Throughput Sequencing Algorithms and Applications workshop. Reachedfor comment, Layla says, I definitely want to acknowledge my co-authors, Gryteand Ben, on the work that was presented at HitSeq.This project is part of a team effort and itwouldnt have been possible without them.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Layla Oesper Wins ISMB Workshop Best Presentation Award"], "word_count": 152, "token_count_estimate": 225}}, "https://awards.cs.brown.edu/2015/10/07/mace-roelke-and-fonseca-win-best-paper-award-sosp-2015/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Posted by Jesse Polhemus on Oct. 7, 2015 in Awards Brown University Computer Science Brown CS PhD Candidate Jonathan Mace , Ryan Roelke 15 now at Vertica, and Brown CS Assistant Professor Rodrigo Fonseca have just received one of three Best Paper Awards at the 25th Association for Computing Machinery ACM Symposium on Operating Systems Principles SOSP 2015, currently being held in Monterey, California. SOSP is often considered the leading forum for researchers and developers of computer operating systems, and their research compared favorably with more than two dozen entries selected from over 300 global submissions, covering a wide range of theory and practice. Jonathan, Ryan, and Rodrigos work Pivot Tracing Dynamic Causal Monitoring for Distributed Systems addresses the challenge of monitoring and troubleshooting distributing systems with a monitoring framework that combines techniques from both the dynamic instrumentation and causal tracing literature. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, alter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. The result is a dynamic and extensible solution that enables cross-tier analysis between inter-operating applications with low execution overhead. This is the first framework we are aware of, Rodrigo says, that allows you to ask questions about a system as it runs, while causally combining metrics across its distributed components.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015"], "word_count": 259, "token_count_estimate": 327}}, "https://awards.cs.brown.edu/2015/06/02/esha-ghosh-olya-ohrimenko-and-roberto-tamassia-win-acns-2015-best-student-paper-award/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Posted by Jesse Polhemus on June 2, 2015 in Awards PhD candidate Esha Ghosh , PhD alumna Olya Ohrimenko, and professor Roberto Tamassia of Brown University s Computer Science Department have been selected for the Best Student Paper Award at the 13th International Conference on Applied Cryptography and Network Security ACNS 2015, to be held in New York on June 2-5, 2015. With the advent of cloud computing, Esha explains, a huge amount of sensitive data gets outsourced. While integrity is essential in accessing outsourced data, privacy is a very important aspect too. Most importantly, since many of the clients accessing this data are small computing devices, efficiency is crucial. There have been attempts to address these issues separately in the past. In this work, we address these issues comprehensively, propose a formal model, and give a very efficient construction for supporting order queries and order statistics on list data. Their work Zero-Knowledge Authenticated Order Queries and Order Statistics on a List, which Esha will present on the afternoon of June 3, shares the honor with one other paper. In addition to the competitive nature of ACNS, which has a historical acceptance rate in the range of 12-23, the Best Student Paper Award is the only award given by the conference, chosen from all accepted papers with a student among the authors. I am delighted by the recognition given to our paper, says Roberto, which is part of an ambitious project aimed at providing an unprecedented level of security and privacy to cloud computing applications. This project began, says Olya, when Esha and I were sharing an office, and its continued across the Atlantic after I moved to Microsoft Research. Its a great example of both close and remote collaboration.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award"], "word_count": 318, "token_count_estimate": 409}}, "https://awards.cs.brown.edu/2014/09/25/molly-long-and-layla-oesper-win-google-anita-borg-memorial-scholarship/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Molly Long And Layla Oesper Win Google Anita Borg Memorial Scholarship Posted by Jesse Polhemus on Sept. 25, 2014 in Diversity , Awards Brown Universitys Molly Long and Layla Oesper have just won the Google Anita Borg Memorial Scholarship for their excellence in computing and technology and their status as activerole models and leaders in the field. Its accompanied by an award in theexpected amount of 10,000 and an invitation to the Annual Google ScholarsRetreat. Layla and Molly and fellow Brown University student, Eden Weizmanjoin multiple previous BrownCS recipients ofthe scholarship, including Tess Avitabile in 2010. The more I learn about Anita Borg, Layla shares, the moreI admire her and the work she did to help promote diversity in computing. I thinkthis is the third time Ive applied for this scholarship, so Im justabsolutely thrilled to have been chosen as a recipient this year. A key qualification for the scholarship is leadership in thecommunity and proven experience with inspiring other women to enter the field.Perhaps Mollys most notable success in this area is the creation of Brownsfirst annual hackathon, an event in which programmers and others collaboratedover the course of a weekend to create new software. Working with Molly was amazing, comments Mackenzie Clark,a co-founder of the event. She is incredibly hard-working, responsible, anddedicated to everything she does. I cant think of anyone more deserving ofthis award. A few numbers support these accolades 35 of hackathon attendeesidentified as female, 75 had never been to a hackathon before, and 100 saidthat they would return next year. Professor Tom Doeppner agrees. Im delighted to hear aboutMollys award, he says. Shes been extremely enthusiastic in pretty mucheverything she does, acting as a role model not only for women, but for all CSstudents. Shes served as a UTA, she was the co-organizer of HackBrown, andnow shes the co-organizer of a CS senior yearbook. When asked to describe Laylas achievements, Associate Professor Amy Greenwald mentionsher work on the BrownCS Diversity Committee, her efforts to improve recruitmentof women, and both the design and implementation of key departmental diversityinitiatives. Citing Anita Borgs ambition of creating malefemale parity in thefield by 2020, Amy says, If we had 1000 Laylas all working toward this goalin their spare time like she does I honestly believe we could do it Associate Professor BenRaphael is equally enthusiastic Im delighted that Laylas accomplishments are beingrecognized by the Google Anita Borg Memorial Scholarship. Layla is a first-rateresearcher and teacher of computer science and computational biology. Shealso works tirelessly to promote women in computer science, spearheadingdiversity initiatives in the department and in our research group. Theseexemplary qualities would make Anita Borg proud. Thescholarship will only enhance the already remarkable work of the two women. Thisaward was so competitive and it brings so many opportunities with it, Mollyconcludes. Im ecstatic Her efforts and Laylas will no doubt provideopportunities for an entire generation of colleagues present and future.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Molly Long And Layla Oesper Win Google Anita Borg Memorial Scholarship"], "word_count": 494, "token_count_estimate": 668}}, "https://awards.cs.brown.edu/2015/11/20/alexandra-papoutsaki-and-multiple-brown-cs-collaborators-win-best-paper-award-runner-hcomp-2015/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 Posted by Jesse Polhemus on Nov. 20, 2015 in Awards The Conference on Human Computation and Crowdsourcing HCOMP, held this year in San Diego, is one of the most prominent conferences on the subject of human cooperation, computation, and crowdsourcing, and Brown University s Department of Computer Science Brown CS made a strong showing this year. Two different groups of students and faculty have been declared Best Paper Award Runner Up at the recent HCOMP 2015 Tropel Crowdsourcing Detectors with Minimal Training Genevieve Patterson Brown CS PhD student, Grant Van Horn California Institute of Technology, Serge Belongie Cornell University and Cornell Tech, and James Hays former Brown CS faculty member received the award for research Tropel Crowdsourcing Detectors with Minimal Training named after the word for noisy crowd in Spanish. Genevieve would also like to thank Ben Bauer Brown CS undergraduate student, who contributed software to the project. It was a big help and a pleasure to work with him, she says. Tropel is a system that enables non-technical users to create arbitrary visual detectors without first annotating a training set. Our primary contribution, the researchers explain, is a crowd active learning pipeline that is seeded with only a single positive example and an unlabeled set of training images. We examine the crowds ability to train visual detectors given severely limited training themselves. This paper presents a series of experiments that reveal the relationship between worker training, worker consensus and the average precision of detectors trained by crowd-in-the-loop active learning. In order to verify the efficacy of our system, we train detectors for bird species that work nearly as well as those trained on the exhaustively labeled CUB 200 dataset at significantly lower cost and with little effort from the end user. To further illustrate the usefulness of our pipeline, we demonstrate qualitative results on unlabeled datasets containing fashion images and street- level photographs of Paris. Anyone interested in using Tropel should click the link that follows to contact Genevieve . Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki , Brown CS PhD student, and collaborators Hua Guo Brown CS PhD student, Danae Metaxa-Kakavouli Brown CS alum, Connor Gramazio Brown CS PhD student, Jeff Rasley Brown CS PhD student, Wenting Xie Brown University alum, Guan Wang Brown CS PhD student, and Jeff Huang Brown CS Assistant Professor received the award for research Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters that became something of an Internet sensation, attracting more than 20,000 views in a single week and 100,000 unique visitors to date, including academics, researchers, and potential graduate students. Its the result of a class assignment from the CS2951-L HCI seminar as taught by Jeff in Spring 2014 . All the other authors attended the class as students and were able to see an assignment turn into a peer-reviewed publication. For the undergraduates of the group Danae and Wenting, it was their first in what will undoubtedly be a long line of publications. To determine how novice requesters design crowdsourcing tasks, the group conducted an experiment with a class of 19 students, each of whom tried their hand at crowdsourcing a real data collection task with a fixed budget and realistic time constraint. Students used Amazon Mechanical Turk to gather information about the academic careers of over 2,000 professors from 50 top Computer Science departments in America. In addition to curating this dataset, they classified the strategies which emerged, discussed design choices students made on task dimensions, and compared these novice strategies to best practices identified in crowdsourcing literature. Their work culminates in a summary of design pitfalls and effective strategies observed to provide guidelines for novice requesters. The data is publicly accessible, and the researchers are still allowing the public to help improve its accuracy at httpjeffhuang.comcomputerscienceprofessors.html . The Human-Computer Interaction HCI group will also continue working and expanding both the dataset including more universities across North America and the research contributions. You can read more about this project, Drafty, here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015"], "word_count": 701, "token_count_estimate": 887}}, "https://awards.cs.brown.edu/2016/05/26/andrew-crotty-wins-google-phd-fellowship/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Andrew Crotty Wins A Google PhD Fellowship Posted by Jesse Polhemus on May 26, 2016 in Awards Andrew Crotty of Brown University s Department of Computer Science Brown CS has just received a Google PhD Fellowship for his research in data management, particularly the design of big data analytics systems. His current work focuses on developing a new high-performance analytics platform, Tupleware , which is geared toward complex computations like machine learning. The fellowship, first launched in 2009, recognizes and supports outstanding graduate students doing exceptional research in computer science and related disciplines. It includes a monetary award and assigns each student a Google Research Mentor to serve as a resource. This year, there were 39 recipients from three different continents Andrew is one of three winners in the Systems and Networking category, joining colleagues from the University of Cambridge and the University of California, Berkeley. This was by far the most accomplished group of students weve seen, and each and every nominee should be proud, says Michael Rennaker of Google University Relations. Andrews research, he explains, is predicated on the fact that data analytics has grown to include increasingly sophisticated techniques, such as machine learning and advanced statistics. Frequently, he says, users express these complex analytics tasks as workflows of user-defined functions UDFs that specify each algorithmic step. However, given typical hardware configurations and dataset sizes, the core challenge of complex analytics is no longer sheer data volume but rather the computation itself, and the next generation of analytics frameworks must focus on optimizing for this computation bottleneck. While query compilation has gained widespread popularity as a way to tackle the computation bottleneck for traditional SQL workloads, relatively little work addresses UDF-centric workflows in the domain of complex analytics. Crottys research has primarily focused on the creation of a novel architecture for automatically compiling workflows of UDFs and co-developing several related optimizations that consider properties of the data, UDFs, and hardware together in order to generate different code on a case-by-case basis. These techniques are currently being implemented in Tupleware, a new high-performance distributed analytics system whose benchmarks show performance improvements of up to three orders of magnitude compared to alternative systems. The fellowship is the latest recognition in a busy year for Andrew hes recently published papers on a variety of topics from compiling UDF-centric workflows to redesigning traditional data management algorithms for high-performance networks to providing interactive analytics through pen and touch. He and other Brown CS colleagues also won a Best Demo Award at VLDB 2015 . Its a big honor to be awarded the Google fellowship, Andrew says, especially this year being included among so many other outstanding recipients. Im really looking forward to continuing the exciting work weve been doing with Tupleware and exploring applications to new areas, including interactive data analysis and genomics pipelines.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Andrew Crotty Wins A Google PhD Fellowship"], "word_count": 484, "token_count_estimate": 576}}, "https://awards.cs.brown.edu/2017/05/10/geopipe-co-founded-thomas-dickerson-wins-100k-nyu-entrepreneurs-challenge/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Geopipe, Co-Founded By Thomas Dickerson, Wins 100K At The NYU 300K Entrepreneurs Challenge Posted by Jesse Polhemus on May 10, 2017 Click the links that follow for more Brown CS content about Thomas Dickerson and entrepreneurship . Could anything be more valuable to a young startup than expert-led coaching sessions on how to identify opportunities and design business models, or the chance to pitch ideas to industry leaders Probably not much, but a check for 100,000 might be a close contender. NYU Sterns W. R. Berkley Innovation Labs 300K Entrepreneurs Challenge, held at New York Universitys Stern School of Business, offers all those things. Last week, PhD Candidate Thomas Dickerson of Brown University s Department of Computer Science Brown CS returned from the competition with some valuable experience and one of those comically-oversized checks that are almost too big for one person to carry. After months of workshops, coaching sessions, and deliverables, his startup, Geopipe, was selected for its potential for great impact, challenging assumed boundaries, and inspiring a sense of whats possible. It won the top prize of 100,000 in the Challenges Technology Venture Competition. Co-founded last year with Dr. Christopher Mitchell, a New York University alum, Geopipe builds algorithms to turn 2D and 3D data into highly detailed 3D virtual models. Their system ingests and analyzes data, including satellite photos, maps, laser scans, and much more. It then combines machine learning with a distributed systems approach to rapidly correlate data sources, understand structure, and produce complete 3D models at many different scales. One of Geopipes strengths is that it offers more semantic modeling than competing solutions with massive amounts of content while coupling models to real-world data without a great deal of manual effort. It puts models in the hands of customers, who can use them in their own software suites with automatic customization options at a consistently high level of visual quality. This is an extremely important moment for Geopipe, says Thomas, and well put the money to good use. We have a pretty extensive RD road-map for the next 12 months, and were looking to balance pushing that with getting hands-on feedback through pilot programs with customers in the architecture market. The image above is NYU Photo Bureau Hollenshead and used with permission. For more information about this story, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Geopipe, Co-Founded By Thomas Dickerson, Wins $100K At The NYU $300K Entrepreneurs Challenge"], "word_count": 412, "token_count_estimate": 528}}, "http://bigai.cs.brown.edu": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Brown Integrative, General Artificial Intelligence About Learn about bigAI. Blog read about recent work. People Meet the professors and students. Press read about bigai in the press. Publications Robots Meet the robots. Welcome to bigAI BrownCS View our Mission Tweets by BrownBigAI Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["", "Welcome to bigAI @ BrownCS!"], "word_count": 56, "token_count_estimate": 69}}, "http://bigai.cs.brown.edu/2019/08/28/deepmellow.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In DeepMellow - Removing the Need for Target Networks in Deep Q-Learning Seungchan Kim August 12, 2019 In this paper, we proposed an approach to remove the need for a target network from Deep Q-learning. Our DeepMellow algorithm, the combination of Mellowmax operator and DQN, can learn stably without a target network when tuned with specific temperature parameter . We proved novel theoretical properties convexity, monotonic increase, and overestimation bias reduction of Mellowmax operator, and empirically showed that Mellowmax operator can obviate the need for a target network in multiple domains. To learn more, see the full blog post , or read the IJCAI paper . Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["DeepMellow - Removing the Need for Target Networks in Deep Q-Learning"], "word_count": 119, "token_count_estimate": 159}}, "http://bigai.cs.brown.edu/2019/09/03/hac.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Learning Multi-Level Hierarchies with Hindsight Andrew Levy September 4, 2019 Hierarchical Reinforcement Learning HRL has the potential to accelerate learning in sequential decision making tasks like the inverted pendulum domain shown in Figure 1 where the agent needs to learn a sequence of joint torques to balance the pendulum. HRL methods can accelerate learning because they enable agents to break down a task that may require a relatively long sequence of decisions into a set of subtasks that only require short sequences of decisions. HRL methods enable agents to decompose problems into simpler subproblems because HRL approaches train agents to learn multiple levels of policies that each specialize in making decisions at different time scales. Figure 1 shows an example of how hierarchy can shorten the lengths of the sequences of actions that an agent needs to learn. While a non-hierarchical agent left side of Figure 1 must learn the full sequence of joint torques needed to swing up and balance the pole, a task that is often prohibitively difficult to learn, the 2-level agent right side of Figure 1 only needs to learn relatively short sequences. The high-level of the agent only needs to learn a sequence of subgoals purple cubes to achieve the task goal yellow cube, and the low-level of the agent only needs to learn the sequences of joint torques to achieve each subgoal. Figure 1 Video compares the actions sequences that need to be learned by a non-hierarchical agent left and a 2-level hierarchical agent right in order to complete the task. While the non-hierarchical agent needs to learn the full sequence of joint torques that move the agent from its initial state to the goal state i.e., yellow cube, the 2-level agent only needs to learn relatively short sequences of decisions. The high-level of the agent just needs to learn the short sequence of subgoals i.e., purple cubes needed to achieve the goal. The low-level only needs to learn the short sequences of joint torques needed to achieve each subgoal i.e., purple cube. Yet, in order for hierarchical agents to take advantage of these short decision sequences and realize the potential of faster learning, hierarchical agents need to be able to learn their multiple levels of policies in parallel. That is, at the same time one level in the hierarchy is learning the sequence of subtasks needed to solve a task, the level below should be learning the sequence of shorter time scale actions needed to solve each subtask. The alternative is to learn the hierarchy of policies one level at a time in a bottom-up fashion, but this strategy both may forfeit the sample efficiency gains hierarchy offers and can be difficult to implement. Learning multiple levels of policies in parallel, however, is hard because it is inherently unstable. Changes in a policy at one level of the hierarchy may cause changes in the transition and reward functions at higher levels in the hierarchy, making it difficult to jointly learn multiple levels of policies. In this post, we present a new Hierarchical Reinforcement Learning framework, Hierarchical Actor-Critic HAC , that enables hierarchical agents to efficiently learn multiple levels of policies in parallel. The main idea behind HAC is to train each level of the hierarchy independently of the lower levels by training each level as if the lower levels are already optimal. This strategy yields stable transition and reward functions at all levels and thus makes it easier to learn multiple levels of policies simultaneously. The HAC framework is able to simulate optimal lower level policy hierarchies as a result of two components i a particular hierarchical policy architecture and ii three types of transitions that take advantage of hindsight. Our empirical results in a variety of discrete and continuous domains show that hierarchical agents trained with HAC can learn tasks significantly faster than both non-hierarchical agents and hierarchical agents trained with another leading HRL approach. Further, to the best of our knowledge, our results include the first 3-level agents trained in tasks with continuous state and action spaces. The remainder of the post is structured as follows. In the first section, we describe in more detail the instability issues that arise when agents try to learn to make decisions at multiple time scales. In the second section, we present our HRL framework and show how it can reduce this instability and thereby help agents to learn multiple levels of policies simultaneously. In the third section, we discuss the experiments we implemented and the results obtained. In final section of the post, we provide some concluding remarks. For a more detailed description of our approach and experiments, please see our ICLR 2019 paper . For open-sourced software to implement our framework, please check out our GitHub repository . In addition, for the video presentation of our experiments, please see the following video . Instability in Hierarchical RL Learning multiple levels of policies simultaneously is problematic due to non-stationary transition and reward functions that naturally emerge. Hierarchical policies almost always use some sort of nested structure. Beginning with the top level, each level will propose a temporally extended action and the level below has a certain number of attempts to try to execute that temporally extended action. Thus, for any temporally extended action from any level above the base level, the next state that action results in and potentially the reward of that action depend on the policies below that level. As a result, when all levels in the hierarchy are learned simultaneously, the transition function and potentially the reward function for any level above the base level may continue to change as long as the policies below that level continue to change. For an example of non-stationary transition functions in hierarchical policies, consider the 2-level toy robot in the video in Figure 2 below. The high-level of this agent attempts to break down the task by setting subgoals for the low-level to achieve. The video shows four different occasions in which the high-level of the agent proposes state B as a subgoal when the agent is currently in state A . Yet due to the nested structure of the 2-level agent, the next state that this high-level action results in after a certain number of attempts in this case 5 by the low-level will depend on the policy of the low-level. But since the low-level should be improving and likely also exploring over time, the next state that this subgoal action results in will change over time. Iteration State Action Next State 1 A B C 2 A B D 3 A B E 4 A B B Figure 2 Example of non-stationary transition functions that arise when learning hierarchical policies. In this example, when the robot proposes subgoal state B when in state A, the next state that this action results in changes over time as the low-level policy changes. Similarly, non-stationary reward functions can also arise when trying to learning multiple levels of policies simultaneously. Figure 3 shows an example in which a 2-level robot proposes and achieves the same subgoal on two different occasions, but receives transitions with different rewards because the agent follows different paths to the subgoal. Iteration State Action Reward Next State 1 A B -13 B 2 A B -4 B Figure 3 Example of non-stationary reward functions that arise when learning hierarchical policies. In this example, even though in both iterations the agent is able to achieve subgoal B, the low-level takes different paths so the same subgoal action may yield different rewards. In this case, the reward function is assumed to be -1 for any primitive action that does not achieve the goal of task not shown and 0 otherwise. Non-stationary transition and reward functions are a significant concern because they make it difficult to learn effective policies. RL algorithms typically estimate the expected long-term value of action in state i.e., as the sum of the immediate reward and the discounted value of the current policy in the succeeding state i.e., QTargetst, at rt1 gamma Vpist1. If and do not have stationary distributions for the same state-action pair, Q-values will not stabilize and it will be difficult to value individual actions, which in turn will make it difficult to learn effective policies. Thus, in order for the hierarchical agent to learn all of its policies in parallel and realize the sample efficiency benefits of HRL, the non-stationary transition and reward functions that occur at all levels above the base level will need to be overcome. Hierarchical Actor-Critic HAC The key problem described above is that if all of the levels of the hierarchy are to be trained in parallel, the temporally extended actions from any level cannot be evaluated with respect to the current hierarchy of policies below that level. This lower level hierarchy will continue to change as long as these lower level policies both learn from experience and explore. Changes in lower level policies in turn will cause non-stationary transitions and rewards functions at higher levels that will make it difficult to learn effective policies at those higher levels. The central idea of our approach, Hierarchical Actor-Critic HAC, is that instead of evaluating the temporally extended actions with respect to the current lower level hierarchy of policies, evaluate the temporally extended actions with respect to where the lower level hierarchy is headed an optimal lower level hierarchy. The optimal lower level hierarchy, which consists of optimal versions of all lower level policies, does not change over time. As a result, the distribution of succeeding states and rewards for any temporally extended action will be stable, enabling the hierarchical agent to learn its multiple levels of policies in parallel. Agents that learn with the HAC framework are able to train each non-base level of the hierarchy with respect to optimal versions of lower level policies without actually needing the optimal lower level policy hierarchy as a result of the frameworks two major components i the particular architecture of the hierarchical policy HAC agents learn and ii three types of transitions that the agent uses to evaluate actions. Hierarchical Policy Architecture Agents trained with HAC learn hierarchical policies with the following structural properties. Deterministic, Goal-Conditioned Policies HAC agents learn -level hierarchical policies that consist of deterministic, goal-conditioned policies. The number of levels, , is a hyperparameter chosen by the user. Thus, at each level , the agent learns a policy that maps the current state and goal of the level to an action . The goal will typically be an individual state or a set of states. The space of goals for the highest level of the hierarchy is determined by the user. The goals for all other levels are determined by the actions from the level above. Action Space State Space for Non-Base Levels HAC agents divide tasks into shorter horizon subtasks using the state space. That is, each policy above the base level attempts to decompose the task of achieving its goal state into a short sequence subgoal states to achieve along the way. Setting the action space of the non-base levels of the hierarchy to be the state space is critical because it makes it simple for the agent to create transitions that simulate an optimal lower level policy hierarchy, which will ultimately help the agent learn multiple levels of policies in parallel. We will explain in more detail why this is the case during our discussion of the three types of transitions HAC agents use to evaluate actions. In addition, the action space for the base level of the hierarchy is the set of primitive actions available to the agent. Nested Policies The hierarchical policies learned by HAC agents are also nested in order to make it easier for higher levels in the hierarchy to learn to act at longer time scales. When a non-base level outputs a subgoal state, this subgoal is passed down to level as its next goal. Level then has at most attempts to achieve this goal state, in which is a hyperparameter set by the user. Figure 4 shows the architecture of a 3-level agent trained with HAC. Figure 4 Architecture of a 3-level hierarchical policy using HAC. Each of the three policies is deterministic and goal-conditioned as each policy takes an input the current state and goal state. The top two levels have an action space equal to the state space as these policies will output subgoal states for lower levels to achieve. The bottom level will output primitive actions. Further, each level has H actions to achieve its goal state before another goal is provided. Three Types of Transitions In addition to the structure of the hierarchical policy, HAC agents are able to efficiently learn multiple levels of policies simultaneously as a result of three types of transitions HAC agents use to evaluate actions. We describe each of these transitions next. In order to make these transitions easier to understand, we will make use of the example episode shown in Figure 5 below, in which a 2-level robot is trying to move from its initial state to the yellow flag. Figure 5 Example episode of a 2-level agent trying to move from the initial state to the yellow flag. The pink circles with the label represent the original subgoal state proposed by the high-level of the agent at step The gray circles with the label indicate the state of the agent after primitive actions by the low-level policy following the proposal of subgoal Hindsight Action Transitions In order to efficiently learn multiple policies in parallel, the non-base levels of the hierarchy need transitions that evaluate actions as if the lower level policies are already optimal. This is the purpose of the first set of HAC transitions, which we refer to as hindsight action transitions. Hindsight action transitions are implemented using a simple procedure replace the proposed action with the action that was actually executed in hindsight. For non-base levels of the agent that propose subgoals, this means that whenever a level proposes some subgoal state but the level below misses that subgoal state and ends in some other state after attempts, the hindsight action transition will use the state the agent ended in as the original subgoal action. With this change, the action and next state components in the transition will be the same and thus hindsight action transitions can simulate how an optimal lower level policy hierarchy would act. In addition, for the reward component of the transition, the reward will only depend on i the state reached after attempts and ii the goal state for the level in consideration. The reward will not take into consideration the exact path taken to the state reached after attempts because the goal is to create transitions that simulate an optimal lower level policy hierarchy and it is not known what path an optimal lower level policy hierarchy would take. The reward will also be sparse and binary to avoid the issues that arise when reward functions are manually engineered. Specifically, the reward for each level, will be 0 for any action in which and -1 otherwise. Figure 6 shows the hindsight action transitions that would be created for the high-level of the agent in the example episode in Figure 5. Note that had the high-level had access to the optimal version of the low-level policy, the transition would look the same. Iteration State Action Reward Next State Goal Discount Rate 1 s 0 s 1 -1 s 1 Yellow Flag 2 s 1 s 2 -1 s 2 Yellow Flag 3 s 2 s 3 -1 s 3 Yellow Flag 4 s 3 s 4 -1 s 4 Yellow Flag 5 s 4 s 5 -1 s 5 Yellow Flag Figure 6 High-level hindsight action transitions created in the example episode shown in Figure 5. For the low-level of the agent, the hindsight action transitions will be the typical transitions created for flat agents. Hindsight Goal Transitions Although hindsight action transitions help hierarchical agents jointly learn multiple levels of policies by reducing the non-stationary transition and reward function issues, they introduce another problem how to learn multiple levels of policies with only sparse reward functions. The HAC framework attempts to overcome this problem by supplementing agents with a second type of transition, which we refer to as hindsight goal transitions . Hindsight goal transitions make it easier to learn multiple level of policies in sparse reward settings by essentially extending the idea of Hindsight Experience Replay HER Andrychowicz et al., 2017 to the hierarchical setting. HER helps agents learn to reach different goal states in sparse reward domains by generalizing from the agents experience achieving other goal states. HER is implemented by creating copies of the original transitions and replacing the original goal state with a state that was actually achieved during the episode. The original reward is also replaced with the appropriate reward given the new goal state. Hindsight goal transitions are implemented in the same manner as HER transitions except that in non-base levels of the hierarchy, hindsight goal transitions are made from copies of the hindsight action transitions. Figure 7 lists the hindsight goal transitions created for the high-level after the example episode in Figure 5 assuming the last state that was reached, , is used as the new goal state. Figure 8 lists the hindsight goal transitions created for the low-level after the 5 attempts to try to achieve the first subgoal assuming the state is used as the new subgoal. Note that the last transition in these tables now includes the sparse reward of 0 and a discount rate of 0. Each level of the agent can now use this knowledge of how to reach these goal states to generalize to other goal states. Iteration State Action Reward Next State Goal Discount Rate 1 s 0 s 1 -1 s 1 s 5 2 s 1 s 2 -1 s 2 s 5 3 s 2 s 3 -1 s 3 s 5 4 s 3 s 4 -1 s 4 s 5 5 s 4 s 5 0 s 5 s 5 0 Figure 7 High-level hindsight goal transitions created in the example episode shown in Figure 5. Iteration State Action Reward Next State Goal Discount Rate 1 s 0 Joint Torques -1 1st Tick Mark s 1 2 1st Tick Mark Joint Torques -1 2nd Tick Mark s 1 3 2nd Tick Mark Joint Torques -1 3rd Tick Mark s 1 4 3rd Tick Mark Joint Torques -1 4th Tick Mark s 1 5 4th Tick Mark Joint Torques 0 s 1 s 1 0 Figure 8 Low-level hindsight goal transitions created when the low-level attempted to achieve the first subgoal. Subgoal Testing Transitions Hindsight action and hindsight goal transitions help agents learning multiple levels of policies in parallel using only sparse reward functions, yet a significant problem still remains. These transitions only enable non-base levels to learn Q-values for subgoal states that can actually be achieved within steps by the level below. They ignore subgoal states that cannot be reached in actions. Ignoring a region of the subgoal action space is problematic because the critic function may assign relatively high Q-values to these actions, which may then incentivize the levels policy to output these unrealistic subgoals. For discrete domains, HAC overcomes this issue with pessimistic Q-value initializations. For continuous domains, HAC supplements agents with a third type of transition, which we refer to as subgoal testing transitions . Subgoal testing transitions help agents overcome this issue by penalizing subgoal actions that cannot be achieved with the current lower level policy hierarchy. Subgoal testing transitions are implemented as follows. After a non-base level proposes a subgoal, a certain fraction of the time that level will decide to test whether the policy hierarchy below that level can achieve the proposed subgoal. All lower levels then must greedily follow their policy and not add exploration noise. If the level below is not able to achieve the proposed subgoal in actions, the level that proposed the subgoal is penalized with a subgoal testing transition that contains some low reward value. In our experiments, we used a reward value of for this penalty. As an example of a subgoal testing transition, assume that when the 2-level robot in Figure 5 was in state , the high-level of the robot decided to test whether the low-level could achieve the proposed subgoal . The low-level policy then had to follow its policy exactly for steps. Because the low-level policy failed to achieve , the high-level would receive the subgoal testing transition below. Note that this transition uses a discount rate of 0 to avoid any non-stationary transition function issues. Subgoal testing transitions thus help agents assign low Q-values to unrealistic subgoals because these subgoal actions will be penalized during subgoal testing. Using these three types of transitions, the policy at each level of the hierarchy can then be trained with an off-policy Reinforcement Learning algorithm e.g., Deep Deterministic Policy Gradient DDPG Lillicrap et al., 2015 . The critic or Q-function at each level will take the form of a Universal Value Function Approximator Schaul et al., 2015 that maps states, goals, and actions to the real number space . The hierarchical architecture and the three types of transitions constitute the bulk of the HAC framework. For the full HAC algorithm, please see our ICLR 2019 paper . For open-sourced software to implement our approach, please see our GitHub repository . Experiments We evaluated our approach on both i discrete state and action space and ii continuous state and action space environments. The discrete tasks consisted on two grid world tasks i 10x10 grid world and ii four rooms. The continuous domains consisted of the following four tasks built in MuJoCo Todorov et al., 2012 i inverted pendulum, ii UR5 reacher, iii ant reacher, and iv ant four rooms. Using these environments, we performed two comparisons. The first comparison we implemented compared agents using 1 i.e., flat, 2, and 3 levels. The purpose of this comparison was to evaluate our hypothesis that HAC agents with more levels of hierarchy could learn new tasks with better sample efficiency as they can divide tasks into shorter horizon subtasks and solve these simpler subtasks in parallel. In this experiment, the flat agents used Q-Learning HER in the discrete tasks and DDPG HER in the continuous domains. Figure 9 below compares the performance of each agent type in all of the tasks listed above. The green, blue, and red lines represent the performance of 1, 2, and 3-level agents, respectively. In all tasks, hierarchical agents significantly outperformed the 1-level agents. Further, in all tasks, the 3-level agents outperformed, often significantly, the 2-level agents. Figure 9 Results of 1 vs. 2 vs. 3-Level Agent Comparison. Below we show two short videos from our ant experiments. For the full video presentation showing all of our experiments, please see our YouTube video . 2-Level Ant Reacher Figure 10 2-Level HAC agent in the ant reacher task. The task goal is the yellow cube. Subgoal actions from the high-level policy are represented by the purple cubes. Low-level policy outputs joint torques. 3-Level Ant Four Rooms Figure 11 3-Level HAC agent in the ant four rooms task. The task goal is the yellow cube. Subgoal actions from the high-level and mid-level policies are represented by the green and purple cubes, respectively. Low-level policy outputs joint torques. The second comparison we implemented compared HAC to another leading HRL algorithm, HIRO HIerarchical Reinforcement learning with Off-policy correction Nachum et al, 2018 . HIRO, which was developed simultaneously and independently to our approach, trains 2-level agents with a similar architecture to our approach and can also learn off-policy as in our approach. However, HIRO does not use either of our hindsight transitions, and therefore should not be able to learn multiple levels of policies in parallel as efficiently as our approach can. We compared 2-Level HAC with HIRO in the inverted pendulum, UR reacher, and ant reacher tasks. The results are shown in Figure 12 below. The green and blue lines represent the performance of HIRO and 2-Level HAC, respectively. In all tasks, 2-level HAC significantly outperforms HIRO. Figure 12 Comparison of 2-Level HAC vs HIRO in the left inverted pendulum, middle UR5 reacher, and right ant reacher tasks. Conclusion Hierarchy has the potential to accelerate learning but in order to realize this potential, hierarchical agents need to be able to learn their multiple levels of policies in parallel. In this post, we present a new HRL framework that can efficiently learn multiple levels of policies simultaneously. HAC can overcome the instability issues that arise when agents try to learn to make decisions at multiple time scales because the framework primarily trains each level of the hierarchy as if the lower levels are already optimal. Our results in several discrete and continuous domains, which include the first 3-level agents in tasks with continuous state and action spaces, confirm that HAC can significantly improve sample efficiency. Thank you Kate Saenko, George Konidaris, Robert Platt, and Ben Abbatematteo for your helpful feedback on this post. Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Learning Multi-Level Hierarchies with Hindsight", "Instability in Hierarchical RL", "Hierarchical Actor-Critic (HAC)", "Experiments", "Conclusion"], "word_count": 4211, "token_count_estimate": 5082}}, "http://bigai.cs.brown.edu/2019/11/04/kinematics.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Learning to Generalize Kinematic Models to Novel Objects Ben Abbatematteo November 4, 2019 Objects with articulated parts are ubiquitous in household tasks. Putting items in a drawer, opening a door, and retrieving a frosty beverage from a refrigerator are just a few examples of the tasks wed like our domestic robots to be capable of. However, this is a difficult problem for todays robots refrigerators, for example, come in different shapes, sizes, and colors, are in different locations, etc, so control policies trained on individual objects do not readily generalize to new instances of the same class. Humans, on the other hand, learn to manipulate household objects with remarkable efficiency. As a child, we learn to interact with our refrigerator, then readily manipulate the refrigerators we encounter in the houses of our friends and relatives. This is because humans recognize the underlying task structure these objects almost always consist of the same kinds of parts, despite looking a bit different each time. In order for our robots to achieve generalizable manipulation, they require similar priors. This post details our recent work towards this end, training robots to generalize kinematic models to novel objects. After identifying kinematic structures for many examples of an object class, our model learns to predict kinematic model parameters, articulated pose, and object geometry for novel instances of that class, ultimately enabling manipulation from only a handful of observations of a static object. Kinematic Models Kinematic models are commonly used to represent the relative motion of two rigid bodies. In particular, they describe a bodys forward kinematics the position and orientation of an articulated part as a function of the state of a joint the angle of a door or the displacement of a drawer, for example. The most common model types are revolute like a door or prismatic like a drawer, but others exist as well rigid, spherical, screw, etc. These models are parameterized by their position and orientation in space for example, in the revolute model, the parameters consist of a the axis about which the door rotates and b the spatial relationship between the axis and the origin of the door. A kinematic graph represents all of an objects parts and the kinematic models between them. Nodes in the graph represent the objects parts, and edges encode model types and model parameters. For example, in Figure 1, the cabinet pictured can be abstracted into three nodes and two edges, with the rotation between the body and the door encoded in the edge between the respective parts. Figure 1 An example object and its corresponding kinematic graph, annotated with the pose of the axis of rotation. To summarize, each node in the graph represents a part, and each edge in the graph consists of Model type, denoted , between a part and its parent revolute, prismatic, . Kinematic model parameters, , the axis of rotationtranslation and the resting pose of that part. The state or configuration of the joint, denoted , an angle in revolute models and a displacement in prismatic models. These quantities enable the robot to simulate how the object parts move about each other. If a robot can identify them, it can begin to reason about how to manipulate an object. A large body of literature explores fitting kinematic models to individual objects, requiring part motion generated by either a human demonstrator or by the robot itself. Critically, these approaches fit models to each object from scratch a demonstration is required for every new object, no matter how similar each is to those experienced previously. This results in a robot which has to deliberately explore every object it encounters, without ever learning the underlying structure in its experiences with those objects. This is insufficient for a robot operating autonomously in a new household environment, where every object it sees will be new. Generalizing to New Objects In contrast, our models are trained to predict kinematic model parameters from observations of static objects, providing the agent with a useful prior over a novel objects articulation. We choose to categorize objects according to their part connectivity once we do so, if our agent can recognize objects, it can identify the kinematic graph structure which represents a novel object. In particular, it will have the same connectivity as all other instances of that class. This enables us to define a template for each object class, then train neural network models which regress from depth images to the parameters of the kinematic model between each pair of parts, as well as the state of each of the objects joints and a simple parameterization of the objects geometry. After being trained in simulation, the models are capable of predicting kinematic model parameters for real, novel objects from individual observations. We show that this is sufficient for manipulating new instances of familiar object classes without first seeing a demonstration. Model The task of our neural network models is to predict the parameters of the kinematic model specified by the objects class, , the objects present articulated pose, , and a parameterization of the objects geometry, , given the objects class label, denoted , and a depth image of the object at time , . In order to enable the agent to express confidence in its estimates and reason about sequential observations in a principled way, we trained mixture density networks for each object class, which parameterize a mixture of Gaussian distributions over , , and . The mixture density networks consist of three neural networks, , , and , which represent the means, covariances, and weights of the mixture components, respectively. We trained ResNet backbones jointly with the mixture density networks. The resulting estimate of the joint distribution over model parameters, articulated pose, and object geometry has the following form pphi, qt, theta mid xt, c sumim piicxt mathcalN phi, qt, theta mid muicxt, sigmaicxt . In order to train the models, we require annotated depth images of articulated objects. Given the labels, the models are trained by maximizing the probability of the true labels under the parameterized mixture of gaussians mathcalL - mathbbEleft log pphi, qt, theta xt, c right. Dataset In the absence of an annotated collection of real articulated objects, we procedurally generated objects from geometric primitives, simulated them in Mujoco, rendered synthetic depth images, and recorded ground truth parameters. We did so for six object classes cabinet, drawer, microwave, toaster oven, two-door cabinet, and refrigerator. Note that we need to classify cabinets into two categories according to the number of articulated parts due to our classification scheme described above. Ongoing work seeks to relax this by learning to identify part connectivity from pointclouds, too. Some samples from the dataset are shown in Figure 2. Figure 2 Sample simulated objects. The models are trained on many examples of a class, then tested on novel instances. Categories from the top cabinet, drawer, microwave, toaster oven, cabinet2, refrigerator. Manipulating Novel Objects Once our models are trained, they enable a robot to estimate kinematic models for novel objects without first seeing demonstrations of their part mobility.Using an estimated kinematic model, after obtaining a grasp on the object, the agent is able to compute a path of its end-effector through space that sets the objects degree of freedom to a desired setting while obeying the constraints imposed by the objects joints. We demonstrated this with two real objects that the robot was not previously trained on a microwave, and a drawer. Please see the video below for footage of the demonstrations. Conclusion Its critical that a robot operating autonomously in new environments be capable of interacting with novel articulated objects.Existing approaches demonstrate how an agent might acquire a model of a novel object through exploration, but they fail to provide the agent with a useful prior over how the object might move.As such, the resulting exploration is time consuming and must be repeated from scratch for every object.Our work presented here provides a framework for learning to generalize these models to new objects, ultimately enabling zero-shot manipulation of novel instances of familiar object classes. For more detail, see the paper , the code for the dataset , or the code for the model . Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Learning to Generalize Kinematic Models to Novel Objects", "Kinematic Models", "Generalizing to New Objects", "Manipulating Novel Objects", "Conclusion"], "word_count": 1379, "token_count_estimate": 1632}}, "http://bigai.cs.brown.edu/2020/05/18/dsc.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Deep Skill Chaining Akhil Bagaria May 18, 2020 Figure 1 Top Combined value function learned by deep skill chaining. Bottom Value functions learned by discovered skills. In this U-shaped maze, the goal state is in the top-left and the start state is in the bottom-left While modern RL algorithms have achieved impressive results on hard problems, they have struggled in long-horizon problems with sparse rewards. Hierarchical reinforcement learning is a promising approach to overcome these challenges. While the benefit of using hierarchies has been known for a long time, the question of how useful hierarchies can be discovered autonomously has remained largely unanswered. In this work, we present an algorithm that can construct temporally extended, higher level actions called skills from the set of primitive actions already available to the RL agent. Not only is the ability to break down complex problems into simpler sub-problems a hallmark of intelligence, it is also the missing piece from traditionalflat reinforcement learning techniques. By constructing useful hierarchies, RL agents will be able to combine modular solutions to easy sub-problems to reliably solve hard real-world problems. We propose Deep Skill Chaining as a step towards realizing the goal of autonomous skill discovery in high-dimensional problems with continuous state and action spaces. To learn more, see the full blog post , read the ICLR paper , or check out the code . Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Deep Skill Chaining"], "word_count": 241, "token_count_estimate": 290}}, "https://awards.cs.brown.edu/2019/05/09/evgenios-kornaropoulos-wins-joukowsky-family-foundation-outstanding-dissertation-award/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Evgenios Kornaropoulos Wins The Joukowsky Family Foundation Outstanding Dissertation Award Posted by Jesse Polhemus on May 9, 2019 in Awards Click the link that follows for more news about other Brown CS winners of the Joukowsky Family Foundation Outstanding Dissertation Award and other recent accomplishments by our students . Every year, Brown University s Graduate School recognizes four students who are receiving doctoral degrees for superior achievements in research one each in the humanities, life sciences, physical sciences, and social sciences. This year, one of the recipients of the Joukowsky Family Foundation Outstanding Dissertation Award is Evgenios Kornaropoulos of Brown CS , who successfully defended his thesis two weeks ago. He is the Department of Computer Sciences second winner of this prestigious award, following Stefan Roth . The award and an honorarium will be given out at the Graduate School Commencement ceremony on Sunday, May 26. As the volume and complexity of generated data grow, Evgenios explains, users would like to maintain the ability to issue expressive queries on their data without sacrificing privacy. Encrypted databases are one of the most promising approaches towards this direction. However, this efficiency comes with the price of leaking information about the plaintext data. In my thesis, we use an algorithmic approach to develop rigorous attacks on encrypted databases and secure protocols. Specifically, Evgenioss work addresses the limitation of standard leakage profiles in encrypted databases under widely-used expressive queries such as range queries and k-nearest neighbor queries. In the works published from my thesis, he says, we show that even though we have cryptographic proofs that guarantee that the interaction between a client and a server leaks nothing more than a well-defined piece of information, we are still discovering what an adversary can infer from the leaked information. Using a plethora of algorithmic tools from areas such as computational geometry, statistics, learning theory, probabilistic analysis, and optimization, we devise new attacks that recover the plaintext values of encrypted databases under minimal assumptions about the query and the data distribution. Hopefully, our findings will pave the way towards new efficient cryptographic designs that defend against our attacks. When asked about the experience of doing a PhD at Brown CS, Evgenios says, I am thrilled to call Prof. Roberto Tamassia my academic father. His experience, rigor, and patience helped me sharpen my technical skills as well as my research taste. I also feel very fortunate to interact frequently with our professors that lead by example such as Prof. Vasileios Kemerlis and the rest of our Security Group . Finally, a big part of my thesis came out of my interaction with my academic sibling Prof. Charalampos Papamanthou from University of Maryland who is doing outstanding research and always sets the bar high. It is an honor to receive this prestigious award from our Graduate School and I am thankful for our professors and staff for making my graduate studies such a rewarding experience A full list of winners is available here . The image above is 2019 by Kirtley Righi and used with permission. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Evgenios Kornaropoulos Wins The Joukowsky Family Foundation Outstanding Dissertation Award"], "word_count": 540, "token_count_estimate": 654}}, "http://bigai.cs.brown.edu/about.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In About The mission of the Brown Integrative, General Artificial Intelligence project is to develop agents with human-level problem-solving ability and communication skills. We believe that these fully integrated, generally intelligent agents should be robots embodied systems which perceive the world through their sensors, affect the world through their actuators, and interact with humans in complex environments. In order to build these agents, we are drawing on our facultys expertise in machine learning, artificial intelligence, and natural language processing, and applying cutting-edge ideas to the full AI problem building machines that learn, reason, and communicate about the natural world. It is our hope that together we can build the worlds first truly generally intelligent robot. Welcome to bigAI Brown. Lets get started Meet us Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["About"], "word_count": 137, "token_count_estimate": 159}}, "http://bigai.cs.brown.edu/people.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In People Professors Several of our faculty members and their students are working together to realize our dream of intelligent robots. Stefanie Tellex Professor Tellex is the director of the Humans To Robots Lab. Learn More George Konidaris Professor Konidaris is the director of the Intelligent Robot Lab. Learn More Michael Littman Professor Littman leads the Reinforcement Learning Adaptive Behavior group RLAB, as well as serving as Co-Director of the Humanity Centered Robotics initiative . Learn more Ellie Pavlick Professor Pavlick studies computational models of natural language semantics and pragmatics. She leads the Language Understanding And Representation LUNAR Lab. Learn more Eugene Charniak Professor Charniak directs the Brown Laboratory for Linguistic Information Processing BLLIP. Learn more Students Meet the students coming soon Thats all, folks. Meet the robots, check out bigAI in the press, and see our publications. Robots Press Publications Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["People", "Professors", "Students", "That's all, folks."], "word_count": 154, "token_count_estimate": 200}}, "http://bigai.cs.brown.edu/blog.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Deep Skill Chaining Akhil Bagaria May 18, 2020 Figure 1 Top Combined value function learned by deep skill chaining. Bottom Value functions learned by discovered skills. In this U-shaped maze, the goal state is in the top-left and the start state is in the bottom-left While modern RL algorithms have achieved impressive results on hard problems, they have struggled in long-horizon problems with sparse rewards. Hierarchical reinforcement learning is a promising approach to overcome these challenges. While the benefit of using hierarchies has been known for a long time, the question of how useful hierarchies can be discovered autonomously has remained largely unanswered. In this work, we present an algorithm that can construct temporally extended, higher level actions called skills from the set of primitive actions already available to the RL agent. Not only is the ability to break down complex problems into simpler sub-problems a hallmark of intelligence, it is also the missing piece from traditionalflat reinforcement learning techniques. By constructing useful hierarchies, RL agents will be able to combine modular solutions to easy sub-problems to reliably solve hard real-world problems. We propose Deep Skill Chaining as a step towards realizing the goal of autonomous skill discovery in high-dimensional problems with continuous state and action spaces. To learn more, see the full blog post , read the ICLR paper , or check out the code . Continue reading Learning to Generalize Kinematic Models to Novel Objects Ben Abbatematteo November 4, 2019 Objects with articulated parts are ubiquitous in household tasks. Putting items in a drawer, opening a door, and retrieving a frosty beverage from a refrigerator are just a few examples of the tasks wed like our domestic robots to be capable of. However, this is a difficult problem for todays robots refrigerators, for example, come in different shapes, sizes, and colors, are in different locations, etc, so control policies trained on individual objects do not readily generalize to new instances of the same class. Humans, on the other hand, learn to manipulate household objects with remarkable efficiency. As a child, we learn to interact with our refrigerator, then readily manipulate the refrigerators we encounter in the houses of our friends and relatives. This is because humans recognize the underlying task structure these objects almost always consist of the same kinds of parts, despite looking a bit different each time. In order for our robots to achieve generalizable manipulation, they require similar priors. This post details our recent work towards this end, training robots to generalize kinematic models to novel objects. After identifying kinematic structures for many examples of an object class, our model learns to predict kinematic model parameters, articulated pose, and object geometry for novel instances of that class, ultimately enabling manipulation from only a handful of observations of a static object. Continue reading Learning Multi-Level Hierarchies with Hindsight Andrew Levy September 4, 2019 Hierarchical Reinforcement Learning HRL has the potential to accelerate learning in sequential decision making tasks like the inverted pendulum domain shown in Figure 1 where the agent needs to learn a sequence of joint torques to balance the pendulum. HRL methods can accelerate learning because they enable agents to break down a task that may require a relatively long sequence of decisions into a set of subtasks that only require short sequences of decisions. HRL methods enable agents to decompose problems into simpler subproblems because HRL approaches train agents to learn multiple levels of policies that each specialize in making decisions at different time scales. Figure 1 shows an example of how hierarchy can shorten the lengths of the sequences of actions that an agent needs to learn. While a non-hierarchical agent left side of Figure 1 must learn the full sequence of joint torques needed to swing up and balance the pole, a task that is often prohibitively difficult to learn, the 2-level agent right side of Figure 1 only needs to learn relatively short sequences. The high-level of the agent only needs to learn a sequence of subgoals purple cubes to achieve the task goal yellow cube, and the low-level of the agent only needs to learn the sequences of joint torques to achieve each subgoal. Figure 1 Video compares the actions sequences that need to be learned by a non-hierarchical agent left and a 2-level hierarchical agent right in order to complete the task. While the non-hierarchical agent needs to learn the full sequence of joint torques that move the agent from its initial state to the goal state i.e., yellow cube, the 2-level agent only needs to learn relatively short sequences of decisions. The high-level of the agent just needs to learn the short sequence of subgoals i.e., purple cubes needed to achieve the goal. The low-level only needs to learn the short sequences of joint torques needed to achieve each subgoal i.e., purple cube. Continue reading DeepMellow - Removing the Need for Target Networks in Deep Q-Learning Seungchan Kim August 12, 2019 In this paper, we proposed an approach to remove the need for a target network from Deep Q-learning. Our DeepMellow algorithm, the combination of Mellowmax operator and DQN, can learn stably without a target network when tuned with specific temperature parameter . We proved novel theoretical properties convexity, monotonic increase, and overestimation bias reduction of Mellowmax operator, and empirically showed that Mellowmax operator can obviate the need for a target network in multiple domains. To learn more, see the full blog post , or read the IJCAI paper . Continue reading Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": [], "word_count": 929, "token_count_estimate": 1137}}, "http://bigai.cs.brown.edu/press.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Press 2019 Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing , June 18, 2019 . Retrieved at httpcs.brown.edunews20190618brown-cs-undergraduate-atsunobu-kotani-teaches-robots-handwriting-and-drawing Michael Littman Has Been Named An ACM Fellow , June 17, 2019. Retrieved at httpcs.brown.edunews20190617michael-littman-has-been-named-acm-fellow . See also httpswww.acm.orgmedia-center2018decemberfellows-2018 David Abel Wins A Presidential Award For Excellence In Teaching , May 20, 2019. Retrieved at httpcs.brown.edunews20190520david-abel-wins-presidential-award-excellence-teaching George Konidaris Wins An NSF CAREER Award For Autonomous Robotic Learning , April 18, 2019 . Retrieved at httpcs.brown.edunews20190418george-konidaris-wins-nsf-career-award-autonomous-robotic-learning Rhode Island Robot Block Party Returns On April 13 , March 6, 2019. Retrieved at httpcs.brown.edunews20190306rhode-island-robot-block-party-returns-april-13 Evan Cater Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award , February 28, 2019. Retrieved at httpcs.brown.edunews20190228evan-cater-wins-randy-f-pausch-computer-science-undergraduate-summer-research-award Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyundai Visionary Challenge , January 18, 2019. Retrieved at httpcs.brown.edunews20190118nakul-gopalan-eric-rosen-daniel-ullman-david-whitney-win-hyundai-visionary-challenge 2018 Michael Littman Receives Browns Presidential Faculty Award , October 5, 2018. Retrieved at httpcs.brown.edunews20181005michael-littman-receives-browns-presidential-faculty-award The Serious Security Problem Looming Over Robotics , August 24, 2018. Retrieved at httpswww.wired.comstorysecurity-robotics Undergraduate team helps to develop drone-based intro robotics course , August 17, 2018. Retrieved at httpsnews.brown.eduarticles201808droneutra Tellexs Outreach Inspires A High School Student To Study CS, Then Teach , August 2, 2018. Retrieved at httpcs.brown.edunews20180802tellexs-outreach-inspires-high-school-student-study-robotics-then-teach Hordes of Research Robots Could be Hijacked for Fun and Sabotage , July 24, 2018. Retrieved at httpswww.technologyreview.coms611704hordes-of-research-robots-could-be-hijacked-for-fun-and-sabotage Seeing the Mind of a Robot in Augmented Reality , June 4, 2018. Retrieved at httpswww.technologyreview.coms611296seeing-the-mind-of-a-robot-in-augmented-reality Meet Realtime Robotics CEO Peter Howard and Chief Roboticist George Konidaris , May 22, 2018.Retrieved at httpsmedium.comtoyota-ai-venturesmeet-realtime-robotics-ceo-peter-howard-and-chief-roboticist-george-konidaris-a6359ceb117c Stefanie Tellex Wins An Early Career Research Achievement Award , April 19, 2018.Retrieved at httpscs.brown.edunews20180419stefanie-tellex-wins-early-career-research-achievement-award George Konidaris Helps Robots Think And Plan In The Abstract , February 9, 2018.Retrieved at httpscs.brown.edunews20180209george-konidaris-helps-robots-think-and-plan-abstract 2017 David Abels Research Matters Talk , December 12, 2017.Retrieved at httpswww.youtube.comwatchvrNFP2OC4NYM How I Learned to Stop Worrying and Be Realistic About AI Michael L. Littman TEDxProvidence , November 8, 2017.Retrieved at httpswww.youtube.comwatchvLFTqdrPXj8A A Cooperative Path to Artificial Intelligence Michael Littman TEDxBoston , October 24, 2017.Retrieved at httpswww.youtube.comwatchvuMdHGOhSIJY George Konidaris And Stefanie Tellex Earn DARPA Directors Fellowships , October 13, 2017.Retrieved at httpscs.brown.edunews20171013konidaris-and-tellex-earn-darpa-directors-fellowships This Robot Knows When Its Confused and Asks for Help , April 25, 2017.Retrieved at httpswww.technologyreview.coms604031this-robot-knows-when-its-confused-and-asks-for-help Meet Iorek, The Robot That Communicates In A Remarkable Way , March 20, 2017.Retrieved at httpswww.wired.com201703meet-lorek-robot-communicates-remarkable-way Robot Knows The Right Question To Ask When Its Confused , March 15, 2017.Retrieved at httpspectrum.ieee.orgautomatonroboticsartificial-intelligencerobot-knows-the-right-question-to-ask-when-its-confused 2016 George Konidaris Wins An AFOSR Young Investigator Research Award , November 17, 2016.Retrieved at httpscs.brown.edunews20161117george-konidaris-wins-afosr-young-investigator-research-award Robots Can Now Teach Each Other New Tricks , October 27, 2016. Retrieved at httpswww.technologyreview.coms542821robots-can-now-teach-each-other-new-tricks Robot, Get The Fork Out Of My Sink , October 18, 2016. Retrieved at httpswww.technologyreview.coms602626robot-get-the-fork-out-of-my-sinkset602614 Robotic Motion Planning in Real-Time , June 20, 2016.Retrieved at httpspratt.duke.eduaboutnewsrobotic-motion-planning-real-time Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Press", "2019", "2018", "2017", "2016"], "word_count": 460, "token_count_estimate": 1358}}, "http://bigai.cs.brown.edu/pubs.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Publications Please find the publications of each PI on their respective pages below George Konidaris httpirl.cs.brown.edupublications.php Stefanie Tellex httph2r.cs.brown.edupublications Michael Littman httpsdblp.uni-trier.depershdlLittmanMichaelL.html Ellie Pavlick httpscs.brown.edupeopleepavlickpubs.html Eugene Charniak httpcs.brown.edupeopleecharnia Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Publications"], "word_count": 42, "token_count_estimate": 105}}, "http://bigai.cs.brown.edu/robots.html": {"text_content": "Menu Home About Blog People Press Publications Robots Get Started Log In Robots Robots Meet the robots Miss Tick, the Movo The Movo is our mobile manipulation platform from Kinova Robotics. Miss Tick is quite impressive she can play the ukulele and knows how to write several alphabets Winnie, the Baxter Winnie is shy, but shes an expert at pick and place, and has learned to understand natural language task specifications. Iorek, the Baxter Iorek is a proud Baxter, but knows when to ask for help Detritus, the KUKA iiwa7 Detritus is learning to manipulate objects. Dorfl, the KUKA iiwa7 Dorfl is learning motor skills with imitation learning. Kuri Our Kuri robots are learning to recognize human activities and answer queries about them. In the meantime, they sing pancake songs, meow with pleasure, and constantly drive into things. Brown University", "metadata": {"last_modified": "2020-05-18T15:00:42+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Robots", "Robots"], "word_count": 140, "token_count_estimate": 189}}, "https://awards.cs.brown.edu/2016/12/12/foreign-policy-magazine-names-tellex-and-oberlin-2016-global-thinkers/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers Posted by Jesse Polhemus on Dec. 12, 2016 When we consider as we do each year the work of the worlds leading thinkers, writes David Rothkopf, CEO and Editor of the FP Group, which publishes Foreign Policy Magazine, we find that the vast majority of them in science, technology, business, culture and government are actually moving us forward and helping to solve the problems of the past. Thats encouraging...and thats what we are acknowledging with this issue. This year, Foreign Policy included Assistant Professor Stefanie Tellex and PhD candidate John Oberlin of Brown University s Department of Computer Science Brown CS in their 2016 list of Leading Global Thinkers, placing them in the Innovators category. Their work in robotic grasping, human-robot collaboration, and robot-to-robot learning puts them among a small group of only 100 peers, whose accomplishments range from founding a political party in Hong Kong to fighting the Zika virus to exposing lead levels in the tap water of Flint, Michigan. You can read John and Stefanies profile here and the full article here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Information for:", "Awards", "Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers"], "word_count": 219, "token_count_estimate": 277}}, "http://bigdata.cs.brown.edu/vctutorial/": {"text_content": "Abstract Slides Instructors Bibliography Acknowledgements Abstract Random sampling is a naturaltechnique to speed up the execution of algorithms on very largedatasets. The results obtained by analyzing only a random sample of thedataset are an approximation of the exact solution. When onlya single value must be computed, the trade-off between the size of thesample and the accuracy of the approximation can be studied throughprobabilistic bounds e.g., the Chernoff-Hoeffding bounds for thedeviation of the quantity of interest in the sample from its exactvalue in the dataset. In many classical data mining problems, thenumber of quantities of interest can be extremely large e.g.,betweenness centrality requires to compute one value for each node in agraph. In these cases, uniform i.e., simultaneous bounds to thedeviations of all quantities are needed. Classical techniques likethe Union bound are insufficient because excessively loose due totheir worst-case assumptions that do not hold in many data miningproblems. Rademacher Averages and theVapnik-Chervonenkis dimension have been developed to overcome this issue they obtain much stricteruniform deviation bounds by taking into account the nature of theproblem and properties of the dataset and of the sampling process. Theyhave been used with success in the analysis of sampling algorithms fordata and graph analysis problems on very large datasets. In this tutorial, we survey the use ofRademacher Averages and VC-dimension for developing sampling-basedalgorithms for graph analysis and pattern mining. We start fromtheir theoretical foundations at the core of machine learning theory , thenshow a generic recipe for formulating data mining problems in a way thatallows using these concepts in the analysis of efficient randomizedalgorithms for those problems. Finally, we show examples of theapplication of this recipe to graph problems connectivity, shortestpaths, betweenness centrality and pattern mining . Our goal is to show how these techniques can be avaluable addition to the toolkit of the data mining researcher, and toencourage further research in the area. Slides Slides presented at ECML PKDD Updated September 11 Slides presented at KDD Updated August 11 Instructors Matteo Riondato is aresearch scientist in the Labs group at TwoSigma . Previously he was a postdoc at Brown University and atStanford University. He received his Ph.D. from Brown in May 2014,where he was advised by Eli Upfal, with a dissertation onsampling-based randomized algorithms for data analytics, which receivedthe Best Student Poster Award at SIAM SDM 2014. He presented a nectartalk about modern sampling algorithms at ECML PKDD 2014. His researchfocuses on exploiting theoretical results for practical algorithms inpattern and graph mining. Eli Upfal is a professor ofcomputer science at Brown University, where he was also the departmentchair from 2002 to 2007. Prior to joining Brown in 1998, he was aresearcher and project manager at the IBM Almaden Research Center inCalifornia, and a professor of Applied Mathematics and Computer Scienceat the Weizmann Institute of Science in Israel. Upfals researchfocuses on the design and analysis of algorithms. In particular he isinterested in randomized algorithms, probabilistic analysis ofalgorithms, and computational statistics, with applications rangingfrom combinatorial and stochastic optimization to routing andcommunication networks, computational biology, and computationalfinance. Upfal is a fellow of the IEEE and the ACM. He received the IBMOutstanding Innovation Award, and the IBM Research Division Award. Hiswork at Brown has been funded in part by the National ScienceFoundation NSF, the Defense Advanced Research Projects AgencyDARPA, the Office of Naval Research ONR, and the National Instituteof Health NIH. He is co-author of a popular textbook Probability andComputing Randomized Algorithms and Probabilistic Analysis with M.Mitzenmacher, Cambridge University Press 2005. Bibliography A BibTeX bibliography of the main publications about VC-dimension and Rademacher averages vcrade.bib . Acknowledgements This tutorial is part of Project BIGDATA at Brown CS . This work is supported in part by NSF grant IIS-1247581 and NIH grant R01-CA180776. Any opinions, findings, and conclusions orrecommendations expressed in this material are those of the authorsand do not necessarily reflect the views of the National ScienceFoundation.", "metadata": {"last_modified": "2015-09-11T07:55:53+00:00", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["VC-Dimension and Rademacher Averages:", "From Statistical Learning Theory to Sampling Algorithms", "A Tutorial by", "and", "Abstract", "Slides", "Instructors", "Bibliography", "Acknowledgements"], "word_count": 638, "token_count_estimate": 887}}, "http://bllip.cs.brown.edu": {"text_content": "Brown Laboratory for Linguistic Information Processing BLLIP BLLIP Home People Publications Resources Photos People Faculty Graduate students Undergraduate Students Alumni Publications 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 and earlier Resources Software Corpora Departments Computer Science Cognitive Linguistic Sciences Applied Mathematics Other Pages of Interest BLLIP Listserv Machine Learning Reading Group Pattern Theory Group Assoc. for Computational Linguistics ACL Anthology ACL Wiki elsewhere Computation and Language at arXiv Linguistic Data Consortium Last update Friday, May 27 2016, 0756 PM", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:05+00:00", "headings": ["Brown Laboratory for Linguistic Information Processing (BLLIP)", "Departments", "Other Pages of Interest"], "word_count": 88, "token_count_estimate": 142}}, "http://mlrg.cs.brown.edu/": {"text_content": "Announcement The MLRG is no longer actively maintained, if you are interested in leading the group, please contact Brown CS for authorization. About We meet weekly to discuss active projects and recent papers. Participants hail from many disciplines, including applied math, neuroscience, computer science, and cognitive science. Please join us MLRG announcements happen on theML-READING-GROUP list. Click here to subscribe . TheMLRG leader this semester Fall 2016 is Zhile Ren . Contact renATcs.brown.edu Schedule During fall 2016, well meet at CIT Library on Mondays 4-5pm . The CIT library is a meeting roomgrad lounge at the fourth floor of the building. Schedule Date Topic 919 Organizational Meeting 926 Practice Talk DKs Thesis Proposal 103 No meeting 1010 No meeting Columbus Day 1017 Ren Research update on segmentationstereoflow 1024 Gabe Introduction to Bayesian Optimization. link 1031 Canceled. 117 Leah Stochastic Variational Inference. link 1114 No meeting CVPR Deadline 1121 No meeting New England Vision Workshop link 1128 Ren Practice talk of IVC seminar See last springs schedule here .", "metadata": {"last_modified": "2019-07-22T19:43:53+00:00", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["", "Announcement", "About", "Schedule", "Schedule"], "word_count": 168, "token_count_estimate": 239}}, "http://bllip.cs.brown.edu/publications/": {"text_content": "Brown Laboratory for Linguistic Information Processing BLLIP BLLIP Home People Publications Resources Photos Lab Publications By Year 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 1996 1995 1994 1993 1992 By Author Eugene Charniak Micha Elsner Heidi Fox Stuart Geman Will Headden Mark Johnson Matt Lease David McClosky Rebecca Mason Ben Swanson Do Kook Choe Chris Tanner 2016 2015 Byron C. Wallace, Do Kook Choe, and Eugene Charniak. Sparse, Contextually Informed Models for Irony Detection Exploiting User Communities, Entities and Sentiment . In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing Volume 1 Long Papers , pages 1035-1044, Beijing, China, July 2015. Association for Computational Linguistics. bib .pdf Do Kook Choe and David McClosky. Parsing Paraphrases with Joint Inference . In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing Volume 1 Long Papers , pages 1223-1233, Beijing, China, July 2015. Association for Computational Linguistics. bib .pdf Do Kook Choe, David McClosky, and Eugene Charniak. Syntactic Parse Fusion . In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 1360-1366, Lisbon, Portugal, September 2015. Association for Computational Linguistics. bib .pdf Chris Tanner and Eugene Charniak. A Hybrid GenerativeDiscriminative Approach To Citation Prediction . In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologies , pages 75-83, Denver, Colorado, May-June 2015. Association for Computational Linguistics. bib .pdf 2014 Rebecca Mason and Eugene Charniak. Domain-Specific Image Captioning . In Proceedings of the Eighteenth Conference on Computational Natural Language Learning , pages 11-20, Ann Arbor, Michigan, June 2014. Association for Computational Linguistics. bib .pdf Rebecca Mason and Eugene Charniak. Nonparametric Method for Data-driven Image Captioning . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics Volume 2 Short Papers , pages 592-598, Baltimore, Maryland, June 2014. Association for Computational Linguistics. bib .pdf Byron C. Wallace, Do Kook Choe, Laura Kertz, and Eugene Charniak. Humans Require Context to Infer Ironic Intent so Computers Probably do, too . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics Volume 2 Short Papers , pages 512-516, Baltimore, Maryland, June 2014. Association for Computational Linguistics. bib .pdf Ben Swanson and Eugene Charniak. Data Driven Language Transfer Hypotheses . In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, volume 2 Short Papers , pages 169-173, Gothenburg, Sweden, April 2014. Association for Computational Linguistics. bib .pdf 2013 Rebecca Mason. Domain-Independent Captioning of Domain-Specific Images . In Proceedings of the 2013 NAACL HLT Student Research Workshop , pages 69-76, Atlanta, Georgia, June 2013. Association for Computational Linguistics. bib .pdf Rebecca Mason and Eugene Charniak. Annotation of Online Shopping Images without Labeled Training Examples . In Proceedings of Workshop on Vision and Language , Atlanta, Georgia, June 2013. Association for Computational Linguistics. bib .pdf Do Kook Choe and Eugene Charniak. Naive Bayes Word Sense Induction . In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing , pages 1433-1437, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. bib .pdf Ben Swanson and Eugene Charniak. Extracting the Native Language Signal for Second Language Acquisition . In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologies , pages 85-94, Atlanta, Georgia, June 2013. Association for Computational Linguistics. bib .pdf Ben Swanson, Elif Yamangil, Eugene Charniak, and Stuart Shieber. A Context Free TAG Variant . In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics Volume 1 Long Papers , pages 302-310, Sofia, Bulgaria, August 2013. Association for Computational Linguistics. bib .pdf 2012 Rebecca Mason and Eugene Charniak. Apples to Oranges Evaluating Image Annotations from Natural Language Processing Systems . In NAACL-2012 Main Proceedings , Montreal, Canada, 2012. Association for Computational Linguistics. bib .pdf Ben Swanson and Eugene Charniak. Native language detection with tree substitution grammars . In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics Short Papers - Volume 2 , ACL 12, pages 193-197, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics. bib .pdf Ben Swanson and Elif Yamangil. Correction detection and error type selection as an ESL educational aid . In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologies , NAACL HLT 12, pages 357-361, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics. bib .pdf 2011 Micha Elsner and Eugene Charniak. Disentangling chat with local coherence models . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics Human Language Technologies - Volume 1 , HLT 11, pages 1179-1189, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics. bib .pdf Micha Elsner and Deepak Santhanam. Learning to fuse disparate sentences . In Proceedings of the Workshop on Monolingual Text-To-Text Generation , MTTG 11, pages 54-63, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics. bib .pdf Micha Eisner and Eugene Charniak. Extending the entity grid with entity-specific features . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics Human Language Technologies short papers - Volume 2 , HLT 11, pages 125-129, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics. bib .pdf Rebecca Mason and Eugene Charniak. Extractive Multi-Document Summaries Should Explicitly Not Contain Document-Specific Content . In Proceedings of the ACL 2011 Workshop on Automatic Summarization for Different Genres, Media, and Languages , Portland, Oregon, 2011. Association for Computational Linguistics. bib .pdf Rebecca Mason and Eugene Charniak. BLLIP at TAC 2011 A General Summarization System for a Guided Summarization Task . In Proceedings of TAC 2011 , 2011. bib .pdf 2010 Eugene Charniak. Top-down nearly-context-sensitive parsing . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , EMNLP 10, pages 674-683, Stroudsburg, PA, USA, 2010. Association for Computational Linguistics. bib .pdf Micha Elsner and Eugene Charniak. The Same-head Heuristic for Coreference . In Proceedings of ACL 10 , Uppsala, Sweden, July 2010. Association for Computational Linguistics. bib .pdf David McClosky, Eugene Charniak, and Mark Johnson. Automatic domain adaptation for parsing . In Human Language Technologies The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , HLT 10, pages 28-36, Stroudsburg, PA, USA, 2010. Association for Computational Linguistics. bib .pdf 2009 Eugene Charniak and Micha Elsner. EM Works for Pronoun Anaphora Resolution . In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics EACL-09 , Athens, Greece, 2009. bib .pdf Micha Elsner and Warren Schudy. Bounding and Comparing Methods for Correlation Clustering Beyond ILP . In Proceedings of the NAACLHLT 2009 Workshop on Integer Linear Programming for Natural Language Processing ILP-NLP 09 , Boulder, Colorado, June 2009. bib .pdf Micha Elsner, Eugene Charniak, and Mark Johnson. Structured Generative Models for Unsupervised Named-Entity Clustering . In Proceedings of NAACL-09 HLT , Boulder, Colorado, June 2009. Association for Computational Linguistics. bib .pdf William P. Headden III, Mark Johnson, and David McClosky. Improving Unsupervised Dependency Parsing with Richer Contexts and Smoothing . In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference to appear , Boulder, Colorado, May 2009. bib Matthew Lease. An Improved Markov Random Field Model for Supporting Verbose Queries . In Proceedings of the 32nd Annual ACM SIGIR Conference , 2009. 16 acceptance rate, to appear. bib Abstract Matthew Lease, James Allan, and W. Bruce Croft. Regression Rank Learning to Meet the Opportunity of Descriptive Queries . In Proceedings of the 31st European Conference on Information Retrieval ECIR , pages 90-101, 2009. 22 acceptance rate. bib .pdf Abstract 2008 Micha Elsner and Eugene Charniak. You Talking to Me A Corpus and Algorithm for Conversation Disentanglement . In Proceedings of ACL-08 HLT , pages 834-842, Columbus, Ohio, June 2008. Association for Computational Linguistics. bib .pdf slides Micha Elsner and Eugene Charniak. Coreference-inspired Coherence Modeling . In Proceedings of ACL-08 HLT, Short Papers , pages 41-44, Columbus, Ohio, June 2008. Association for Computational Linguistics. bib .pdf poster William P. Headden III, David McClosky, and Eugene Charniak. Evaluating Unsupervised Part-of-Speech Tagging for Grammar Induction . In Proceedings of the 22nd International Conference on Computational Linguistics COLING08 , Manchester, UK, August 2008. bib .pdf .ps Matthew Lease. Incorporating Relevance and Psuedo-relevance Feedback in the Markov Random Field Model Brown at the TREC08 Relevance Feedback Track . In Proceedings of the 17th Text Retrieval Conference TREC08 , 2008. Best results in track. This paper supersedes an earlier version appearing in conferences Working Notes. bib .pdf Abstract Matthew Lease and Eugene Charniak. A Dirichlet-smoothed Bigram Model for Retrieving Spontaneous Speech . In Advances in Multilingual and Multimodal Information Retrieval 8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007, Revised Selected Papers , volume 5152 of Lecture Notes in Computer Science . Springer-Verlag, 2008. bib .pdf David McClosky and Eugene Charniak. Self-Training for Biomedical Parsing . In Proceedings of ACL-08 HLT, Short Papers , pages 101-104, Columbus, Ohio, June 2008. Association for Computational Linguistics. bib .pdf David McClosky, Eugene Charniak, and Mark Johnson. When is Self-training Effective for Parsing In Proceedings of the 22nd International Conference on Computational Linguistics COLING08 , Manchester, UK, August 2008. bib .pdf .ps David McClosky. Modeling Valence Effects in Unsupervised Grammar Induction . Technical Report CS-09-01, Brown University, Providence, RI, USA, 2008. bib tech-report Abstract 2007 Micha Elsner, Joseph Austerweil, and Eugene Charniak. A Unified Local and Global Model for Discourse Coherence . In Proceedings of HLT-NAACL 07 , Rochester, New York, April 2007. Association for Computational Linguistics. bib .pdf slides Micha Elsner and Eugene Charniak. A Generative Discourse-New Model for Text Coherence . Technical Report CS-07-04, Brown University, Providence, RI, USA, 2007. bib .pdf Abstract Jianfeng Gao, Galen Andrew, Mark Johnson, and Kristina Toutanova. A Comparative Study of Parameter Estimation Methods for Statistical Natural Language Processing . In Proceedings of the Association for Computational Linguistics ACL07 , 2007. bib Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. Distributional Cues to Word Segmentation Context is Important . In Proceedings of the 31st Boston University Conference on Language Development , 2007. bib .pdf Mark Johnson. Why Doesnt EM Find Good HMM POS-Taggers In Proceedings of Empirical Methods in Natural Language Processing EMNLP07 , 2007. bib Mark Johnson. Transforming Projective Bilexical Dependency Grammars into Efficiently-Parsable CFGs with Unfold-Fold . In Proceedings of the Association for Computational Linguistics ACL07 , 2007. bib Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater. Bayesian inference for PCFGs via Markov chain Monte Carlo . In Proceedings of the North American Conference on Computational Linguistics NAACL07 , 2007. bib .pdf Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater. Adaptor Grammars a Framework for Specifying Compositional Nonparametric Bayesian Models . In Advances in Neural Information Processing Systems 19 , 2007. bib .pdf Matthew Lease and Eugene Charniak. Brown at CL-SR07 Retrieving Conversational Speech in English and Czech . In Working Notes of the Cross-Language Evaluation Forum CLEF Cross-Language Speech Retrieval CL-SR track , 2007. Corrected version. bib .pdf Matthew Lease. Natural Language Processing for Information Retrieval the time is ripe again . In Proceedings of the 1st Ph.D. Workshop at the ACM Conference on Information and Knowledge Management PIKM , 2007. Best Paper award. bib .pdf Abstract Jenine Turner and Eugene Charniak. Language Modeling for Determiner Selection . In Human Language Technologies 2007 The Conference of the North American Chapter of the Association for Computational Linguistics Companion Volume, Short Papers , pages 177-180, Rochester, New York, April 2007. Association for Computational Linguistics. bib .pdf 2006 Ann Bies, Stephanie Strassel, Haejoong Lee, Kazuaki Maeda, Seth Kulick, Yang Liu, Mary Harper, and Matthew Lease. Linguistic Resources for Speech Parsing . In Fifth International Conference on Language Resources and Evaluation LREC06 , Genoa, Italy, 2006. bib .pdf Eugene Charniak, Mark Johnson, Micha Elsner, Joseph Austerweil, David Ellis, Isaac Haxton, Catherine Hill, R. Shrivaths, Jeremy Moore, Michael Pozar, and Theresa Vu. Multilevel Coarse-to-Fine PCFG Parsing . In Proceedings of the Human Language Technology Conference of the NAACL HLT-NAACL06 , pages 168-175, New York City, USA, June 2006. Association for Computational Linguistics. bib .pdf slides Sharon Goldwater, Tom Griffiths, and Mark Johnson. Interpolating between types and tokens by estimating power-law generators . In Y. Weiss, B. Schlkopf, and J. Platt, editors, Advances in Neural Information Processing Systems 18 , pages 459-466, Cambridge, MA, 2006. MIT Press. bib .pdf Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson. Contextual Dependencies in Unsupervised Word Segmentation . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association or Computational Linguistics COLINGACL06 , pages 673-680, Sydney, Australia, July 2006. Association for Computational Linguistics. bib .pdf John Hale, Izhak Shafran, Lisa Yung, Bonnie J. Dorr, Mary Harper, Anna Krasnyanskaya, Matthew Lease, Yang Liu, Brian Roark, Matthew Snover, and Robin Stewart. PCFGs with Syntactic and Prosodic Indicators of Speech Repairs . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics COLING-ACL06 , pages 161-168, Sydney, Australia, July 2006. Association for Computational Linguistics. bib .pdf William P. Headden III, Eugene Charniak, and Mark Johnson. Learning Phrasal Categories . In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing , pages 301-307, Sydney, Australia, July 2006. Association for Computational Linguistics. bib .pdf Matthew Lease, Mark Johnson, and Eugene Charniak. Recognizing disfluencies in conversational speech . IEEE Transactions on Audio, Speech and Language Processing , 1451566-1573, September 2006. bib .pdf Abstract Matthew Lease, Eugene Charniak, Mark Johnson, and David McClosky. A Look At Parsing and Its Applications . In Proceedings of the Twenty-First National Conference on Artificial Intelligence AAAI-06 , 16-20 July 2006. bib .pdf Matthew Lease and Mark Johnson. Early Deletion of Fillers In Processing Conversational Speech . In Proceedings of the Human Language Technology Conference of the NAACL HLT-NAACL06, Companion Volume Short Papers , pages 73-76, New York City, USA, June 2006. Association for Computational Linguistics. Version here corrects Table 2 in published version. bib .pdf David McClosky, Eugene Charniak, and Mark Johnson. Reranking and Self-Training for Parser Adaptation . In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ACL06 , pages 337-344, Sydney, Australia, July 2006. Association for Computational Linguistics. bib .pdf .ps David McClosky, Eugene Charniak, and Mark Johnson. Effective Self-Training for Parsing . In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference , pages 152-159, New York City, USA, June 2006. Association for Computational Linguistics. bib .pdf slides .ps B. Roark, Yang Liu, M. Harper, R. Stewart, M. Lease, M. Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyanskaya, and L. Yung. Reranking for Sentence Boundary Detection in Conversational Speech . In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing ICASSP06 , pages 545-548, May 14-19 2006. bib .pdf Abstract Brian Roark, Mary Harper, Eugene Charniak, Bonnie Dorr, Mark Johnson, Jeremy G. Kahn, Yang Liu, Mari Ostendorf, John Hale, Anna Krasnyanskaya, Matthew Lease, Izhak Shafran, Matthew Snover, Robin Stewart, and Lisa Yung. SParseval Evaluation Metrics for Parsing Speech . In Fifth International Conference on Language Resources and Evaluation LREC06 , Genoa, Italy, 2006. bib .pdf 2005 Eugene Charniak and Mark Johnson. Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking . In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ACL05 , pages 173-180, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics. bib .pdf Micha Elsner, Mary Swift, James Allen, and Daniel Gildea. Online Statistics for a Unification-Based Dialogue Parser . In Proceedings of the Ninth International Workshop on Parsing Technology IWPT05 , pages 198-199, Vancouver, British Columbia, October 2005. Association for Computational Linguistics. bib .pdf poster Heidi Fox. Dependency-Based Statistical Machine Translation . In Proceedings of the ACL Student Research Workshop , pages 91-96, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics. bib .pdf Dmitriy Genzel. Inducing a Multilingual Dictionary from a Parallel Multitext in Related Languages . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing , pages 875-882, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics. bib .pdf Sharon Goldwater and David McClosky. Improving Statistical MT through Morphological Analysis . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing HLT-EMNLP05 , pages 676-683, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics. bib .pdf .ps Sharon Goldwater and Mark Johnson. Representational Bias in Unsupervised Learning of Syllable Structure . In Proceedings of the Ninth Conference on Computational Natural Language Learning CoNLL-2005 , pages 112-119, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics. bib .pdf Jeremy G. Kahn, Matthew Lease, Eugene Charniak, Mark Johnson, and Mari Ostendorf. Effective Use of Prosody in Parsing Conversational Speech . In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing EMNLP05 , pages 233-240, Vancouver, British Columbia, Canada, October 2005. Association for Computational Linguistics. bib .pdf Matthew Lease. Parsing and Disfluency Modeling . Technical Report CS-05-15, Brown University Department of Computer Science, 2005. bib tech-report Matthew Lease, Eugene Charniak, and Mark Johnson. Parsing and its applications for conversational speech . In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing ICASSP05 , volume 5, pages 961-964, March 18 - March 23 2005. bib .pdf Abstract Matthew Lease and Eugene Charniak. Parsing Biomedical Literature . In R. Dale, K.-F. Wong, J. Su, and O. Kwong, editors, Proceedings of the 2nd International Joint Conference on Natural Language Processing IJCNLP05 , volume 3651 of Lecture Notes in Computer Science , pages 58 - 69, Jeju Island, Korea, October 11 - October 13 2005. Springer-Verlag. bib .pdf Abstract Heng Lian. Chinese Language Parsing with Maximum-Entropy-Inspired Parser . Masters thesis, Brown University, Providence, RI, 2005. bib .pdf Abstract Jenine Turner and Eugene Charniak. Supervised and Unsupervised Learning for Sentence Compression . In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ACL05 , pages 290-297, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics. bib .pdf 2004 Massimiliano Ciaramita and Mark Johnson. Multi-component Word Sense Disambiguation . In Rada Mihalcea and Phil Edmonds, editors, Senseval-3 Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text , pages 97-100, Barcelona, Spain, July 2004. Association for Computational Linguistics. bib .pdf Sharon Goldwater and Mark Johnson. Priors in Bayesian Learning of Phonological Rules . In Proceedings of the Seventh Meeting of the ACL Special Interest Group in Computational Phonology , pages 35-42, Barcelona, Spain, July 2004. Association for Computational Linguistics. bib .pdf Michelle Gregory and Yasemin Altun. Using Conditional Random Fields to Predict Pitch Accents in Conversational Speech . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics ACL04, Main Volume , pages 677-683, Barcelona, Spain, July 2004. bib .pdf Michelle Gregory, Mark Johnson, and Eugene Charniak. Sentence-Internal Prosody Does not Help Parsing the Way Punctuation Does . In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004 Main Proceedings , pages 81-88, Boston, Massachusetts, USA, May 2 - May 7 2004. Association for Computational Linguistics. bib .pdf Keith B. Hall and Mark Johnson. Attention Shifting for Parsing Speech . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics ACL04, Main Volume , pages 40-46, Barcelona, Spain, July 2004. bib .pdf Mark Johnson and Eugene Charniak. A TAG-based noisy-channel model of speech repairs . In Proceedings of the 42nd Meeting of the Association for Computational Linguistics ACL04 , pages 33-39, Barcelona, Spain, July 2004. bib .pdf Mark Johnson, Eugene Charniak, and Matthew Lease. An Improved Model For Recognizing Disfluencies in Conversational Speech . In Rich Transcription 2004 Fall Workshop RT-04F , 2004. bib .pdf Ron Kaplan, Stefan Riezler, Tracy H King, John T Maxwell III, Alex Vasserman, and Richard Crouch. Speed and Accuracy in Shallow and Deep Stochastic Parsing . In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004 Main Proceedings , pages 97-104, Boston, Massachusetts, USA, May 2 - May 7 2004. Association for Computational Linguistics. bib .ps .pdf Brian Roark, Murat Saraclar, Michael Collins, and Mark Johnson. Discriminative Language Modeling with Conditional Random Fields and the Perceptron Algorithm. In ACL , pages 47-54, 2004. bib 2003 Yasemin Altun, Mark Johnson, and Thomas Hofmann. Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences . In Michael Collins and Mark Steedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing , pages 145-152, 2003. bib .pdf Yasemin Altun and Thomas Hofmann. Large Margin Methods for Label Sequence Learning . In Proceedings of the Eighth European Conference on Speech Communication and Technology EuroSpeech03 , 2003. bib .pdf Abstract Eugene Charniak, Kevin Knight, and Kenji Yamada. Syntax-based Language Models for Statistical Machine Translation . In Proceedings of the Ninth Machine Translation Summit of the International Association for Machine Translation , New Orleans, Louisiana, September 2003. bib .pdf Massimiliano Ciaramita, Thomas Hofmann, and Mark Johnson. Hierarchical Semantic Classification Word Sense Disambiguation with World Knowledge . In Georg Gottlob and Toby Walsh, editors, IJCAI-03, Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence, Acapulco, Mexico, August 9-15, 2003 , pages 817-822. Morgan Kaufmann, 2003. bib .pdf .ps Massimiliano Ciaramita and Mark Johnson. Supersense Tagging of Unknown Nouns in WordNet . In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing EMNLP-03 , pages 168-175, 2003. bib .pdf Stuart Geman and Mark Johnson. Probability and statistics in computational linguistics, a brief review . Mathematical foundations of speech and language processing , 1381-26, 2003. bib .pdf Dmitriy Genzel and Eugene Charniak. Variation of Entropy and Parse Trees of Sentences as a Function of the Sentence Number . In Michael Collins and Mark Steedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing EMNLP03 , pages 65-72, 2003. bib .pdf Sharon Goldwater and Mark Johnson. Learning OT Constraint Rankings Using a Maximum Entropy Model . In Proceedings of the Workshop on Variation within Optimality Theory , Stockholm University, 2003. bib .pdf .ps Keith Hall and Mark Johnson. Language modelling using efficient best-first bottom-up parsing . In Automatic Speech Recognition and Understanding Workshop ASRU . IEEE ASRU 2003, 2003. bib .pdf Thomas Hofmann, Lijuan Cai, and Massimiliano Ciaramita. Learning with taxonomies Classifying documents and words . In Workshop on Syntax, Semantics and Statistics NIPS-03. , 2003. bib .pdf Mark Johnson. Learning and Parsing Stochastic Unification-Based Grammars . In Bernhard Schlkopf and Manfred K. Warmuth, editors, Computational Learning Theory and Kernel Machines, 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, COLTKernel 2003, Washington, DC, USA, August 24-27, 2003, Proceedings , volume 2777 of Lecture Notes in Computer Science , pages 671-683. Springer, 2003. bib .pdf 2002 Yasemin Altun, Thomas Hofmann, and Mark Johnson. Discriminative Learning for Label Sequences via Boosting . In Proceedings of Neural Information Processing Systems NIPS02 , 2002. bib .pdf Don Blaheta. Handling noisy training and testing data . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing , Philadelpha, Pennsylvania, July 2002. bib .pdf Massimiliano Ciaramita. Boosting automatic lexical acquisition with morphological information . In Unsupervised Lexical Acquisition Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon SIGLEX , pages 17-25, Philadelphia, July 2002. Association for Computational Linguistics. bib .ps .pdf Donald Engel, Eugene Charniak, and Mark Johnson. Parsing and Disfluency Placement . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing EMNLP 2002 , pages 49-54, 2002. bib .pdf Heidi Fox. Phrasal Cohesion and Statistical Machine Translation . In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing EMNLP 2002 , pages 304-311, Philadelphia, Pennsylvania, July 2002. Association for Computational Linguistics. bib .pdf Stuart Geman and Mark Johnson. Dynamic programming for parsing and estimation of stochastic unification-based grammars . In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics ACL02 , pages 279-286, Morristown, NJ, USA, 2002. Association for Computational Linguistics. bib .pdf Stuart Geman and Mark Johnson. Probabilistic Grammars and their Applications . In N.J. Smelser and P.B. Baltes, editors, International Encyclopedia of the Social Behavioral Sciences , pages 12075-12082, Pergamon, Oxford, 2002. bib .pdf Dmitriy Genzel and Eugene Charniak. Entropy Rate Constancy in Text . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics ACL-02 , pages 00-00, 2002. bib .pdf Mark Johnson. The DOP Estimation Method is Biased and Inconsistent . Computational Linguistics , 28171-76, 2002. bib .pdf Mark Johnson. A Simple Pattern-matching Algorithm for Recovering Empty Nodes and their Antecedents . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics ACL , pages 136-143, 2002. bib .pdf .ps Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. III Maxwell, and Mark Johnson. Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics ACL-02 , pages 271-278, 2002. bib .pdf 2001 Yasemin Altun and Mark Johnson. Inducing SFA with Epsilon-Translations Using Minimum Description Length . In Finite State Methods in Natural Language Processing Workshop, ESSLLI 2001 , 2001. bib .pdf Don Blaheta and Mark Johnson. Unsupervised learning of multi-word verbs . In Proceedings of the 2001 ACL Workshop on Collocation , 2001. bib .pdf Eugene Charniak and Mark Johnson. Edit Detection and Parsing for Transcribed Speech . In Proceedings of the Second Conference of the North American chapter of the Association for Computational Linguistics NAACL 01 , 2001. bib .pdf Eugene Charniak. Immediate-Head Parsing for Language Models . In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics , pages 124-131, 2001. bib .pdf .ps Eugene Charniak. Unsupervised Learning of Name Structure From Coreference Data . In Second Meeting of the North American Chapter of the Association for Computational Linguistics NACL-01 , 2001. bib .pdf Keith Hall. A Statistical Model of Nominal Anaphora . Masters thesis, Brown University, Providence, RI, 2001. bib .pdf Mark Johnson. Joint and Conditional Estimation of Tagging and Parsing Models . In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics ACL-01 , 2001. bib .pdf Brian Roark. Probabilistic top-down parsing and language modeling . Computational Linguistics , 272249-276, 2001. bib .pdf 2000 Don Blaheta and Eugene Charniak. Assigning function tags to parsed text . In Proceedings of the First Conference of the North American chapter of the Association for Computational Linguistics NAACL 00 , pages 234-240, 2000. bib .pdf Eugene Charniak. Parsing to Meaning, Statistically. In Canadian Conference on AI , page 442, 2000. bib .pdf Eugene Charniak. A maximum-entropy-inspired parser . In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics , pages 132-139, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc. bib .pdf tech-report Eugene Charniak, Yasemin Altun, Rodrigo de Salvo Braz, Benjamin Garrett, Margaret Kosmala, Tomer Moscovich, Lixin Pang, Changbee Pyo, Ye Sun, Wei Wy, Z. Yang, S. Zeller, and L. Zorn. Reading Comprehension Programs in a Statistical-Language-Processing Class . In In ANLPNAACL Workshop on Reading Comprehension Tests as Evaluation for Computer-Based Language Understanding Systems ANLPNAACL-00 , 2000. bib .pdf Massimiliano Ciaramita and Mark Johnson. Explaining away ambiguity Learning verb selectional preference with Bayesian networks . In Proceedings of the 18th International Conference on Computational Linguistics , 2000. bib .pdf Keith Hall and Thomas Hofmann. Learning Curved Multinomial Subfamilies for Natural Language Processing and Information Retrieval . In Pat Langley, editor, Proceedings of the Seventeenth International Conference on Machine Learning ICML 2000, Stanford University, Stanford, CA, USA, June 29 - July 2, 2000 , pages 351-358. Morgan Kaufmann, 2000. bib .pdf Mark Johnson and Brian Roark. Compact non-left-recursive grammars using the selective left-corner transform and factoring . In Proceedings of the 18th conference on Computational linguistics COLING 00 , pages 355-361, 2000. bib .pdf Mark Johnson and Stefan Riezler. Exploiting auxiliary distributions in stochastic unification-based grammars . In 1st Meeting of the North American Chapter of the Association for Computational Linguistics NACL-00 , pages 154-161, 2000. bib .pdf Scott Miller, Heidi Fox, Lance Ramshaw, and Ralph Weischedel. A novel use of statistical parsing to extract information from text . In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics NAACL00 , pages 226-233, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc. bib .pdf Stefan Riezler, Detlef Prescher, Jonas Kuhn, and Mark Johnson. Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training . In In Proceedings of 38th Annual Meeting of the Association for Compuational Linguistics ACL-00 , 2000. bib .pdf Brian Roark and Eugene Charniak. Measuring efficiency in high-accuracy, broad-coverage statistical parsing . In Proceedings of the COLING00 Workshop on Efficiency in Large-scale Parsing Systems , pages 29-36, 2000. bib .pdf 1999 Matthew Berland and Eugene Charniak. Finding parts in very large corpora . In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics ACL 99 , pages 57-64, 1999. bib .pdf tech-report Don Blaheta and Eugene Charniak. Automatic compensation for parser figure-of-merit flaws . In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics ACL99 , pages 513-518, Morristown, NJ, 1999. Association for Computational Linguistics. bib .pdf Sharon A. Caraballo and Eugene Charniak. Determining the Specificity of Nouns from Text . In Proceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP-99 , 1999. bib .ps Mark Johnson. Type-driven semantic interpretation and Feature dependencies in R-LFG . Semantics and Syntax in Lexical Functional Grammar , pages 359-388, 1999. bib .pdf Mark Johnson. A Resource Sensitive Interpretation of Lexical Functional Grammar . Journal of Logic, Language and Information , 8145-81, 1999. bib .pdf .ps Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. Estimators for Stochastic Unification-Based Grammars . In 37th Annual Meeting of the Association for Computational Linguistics ACL-99 , pages 535-541, 1999. bib .pdf Brian Roark and Mark Johnson. Efficient probabilistic top-down and left-corner parsing . In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics ACL 99 , pages 421-428, 1999. bib .pdf 1998 Sharon Caraballo and Eugene Charniak. New Figures of Merit for Best-First Probabalistic Chart Parsing . Computational Linguistics , 242275-298, 1998. bib .pdf Eugene Charniak, Sharon Goldwater, and Mark Johnson. Edge-Based Best-First Chart Parsing . In Sixth Workshop on Very Large Corpora , pages 127-133, 1998. bib .pdf Zhiyi Chi and Stuart Geman. Estimation of probabilistic context-free grammars . Computational Linguistics , 242299-305, 1998. bib .pdf Niyu Ge, John Hale, and Eugene Charniak. A statistical approach to anaphora resolution . In Proceedings of the Sixth Workshop on Very Large Corpora , Orlando, Florida, 1998. Harcourt Brace. bib .pdf Abstract John Hale and Eugene Charniak. Getting Useful Gender Statistics from English Text . Technical Report CS-98-06, Brown University, Providence, RI, 1998. bib .ps.Z .html Abstract Mark Johnson. Proof Nets and the Complexity of Processing Center Embedded Constructions . Journal of Logic, Language and Information , 74433-447, 1998. bib .pdf Mark Johnson. The Effect of Alternative Tree Representations on Tree Bank Grammars . In David M. W. Powers, editor, Proceedings of the Joint Conference on New Methods in Language Processing and Computational Natural Language Learning NeMLaP3CoNLL98 , pages 39-48, Somerset, New Jersey, 1998. Association for Computational Linguistics. bib .pdf Mark Johnson. PCFG Models of Linguistic Tree Representations . Computational Linguistics , 244613-632, 1998. bib .pdf .ps.gz Mark Johnson. Finite-state Approximation of Constraint-based Grammars using Left-corner Grammar Transforms . In COLING-ACL , pages 619-623, 1998. bib .pdf .ps 1997 Eugene Charniak. Statistical Techniques for Natural Language Parsing . AI Magazine , 18433-44, 1997. bib .pdf .ps Eugene Charniak. Statistical Parsing with a Context-Free Grammar and Word Statistics . In Proceedings of AAAI , pages 598-603, 1997. bib .pdf tech-report .ps Abstract Mark Johnson. Features as resources in R-LFG . In Proceedings of the 1997 LFG Conference , 1997. bib .ps 1996 Sharon Caraballo and Eugene Charniak. Figures of Merit for Best-First Probabilistic Parsing . In Proceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP96 , pages 127-132, 1996. bib tech-report .pdf Abstract Eugene Charniak. Tree-bank Grammars . In Proceedings of the Eleventh National Conference on Artificial Intelligence AAAI-96 , 1996. bib tech-report Abstract Eugene Charniak, Glenn Carroll, John Adcock, Anthony R. Cassandra, Yoshihiko Gotoh, Jeremy Katz, Michael L. Littman, and John McCann. Taggers for Parsers . Artificial Intelligence , 851-245-57, 1996. bib tech-report .ps Abstract Eugene Charniak. Expected-Frequency Interpolation . Technical Report CS-96-37, Brown University, Providence, RI, 1996. bib .html Abstract Mark Johnson. Resource-sensitivity in Lexical-Functional Grammar . Proceedings of the 1996 Roma Workshop , 1996. bib 1995 Sam Bayer and Mark Johnson. Features and Agreement . In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ACL-95 , pages 70-76, 1995. bib .pdf Abstract Eugene Charniak. Parsing with context-free grammars and word statistics . Technical Report CS-95-28, Brown University, Providence, RI, 1995. bib .ps.Z Abstract Murat Ersan and Eugene Charniak. A statistical syntactic disambiguation program and what it learns . In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors, Symbolic, Connectionist, and Statistical Approaches to Learning for Natural Language Processing , 1995. bib tech-report Mark Johnson. Memorization in Top-Down Parsing . Computational Linguistics , 213405-415, 1995. bib .pdf Mark Johnson and Sam Bayer. Features and Agreement in Lambek Categorial Grammar . In Proceedings of the 1995 ESSLLI Formal Grammar Workshop , pages 123-137, 1995. bib .ps.Z Mark Johnson and Jochen Dorre. Memoization of coroutined constraints . In Proceedings of the 33rd annual meeting on Association for Computational Linguistics , pages 100-107, Morristown, NJ, USA, 1995. Association for Computational Linguistics. bib .pdf 1994 Glenn Carroll and Eugene Charniak. Combining Grammars For Improved Learning . Technical Report CS-94-08, Department of Computer Science, Brown University, February 1994. bib .pdf .ps .html Abstract Eugene Charniak, Glenn Carroll, John Adcock, Antony Cassandra, Yoshihiko Gotoh, Jeremy Katz, Michael Littman, and John McCann. Expected-Frequency Interpolation . Technical Report CS-94-06, Brown University, Providence, RI, 1994. bib .ps.Z Eugene Charniak and Glenn Carroll. Context-Sensitive Statistics for Improved Grammatical Language Models . Technical Report CS-94-07, Brown University, Providence, RI, 1994. bib .ps.Z .html Abstract Mark Johnson. Computing with Features as Formulae . Computational Linguistics , 2011-25, 1994. bib .pdf 1993 Eugene Charniak, Curtis Hendrickson, Neil Jacobson, and Mike Perkowitz. Equations for Part-of-Speech Tagging . In National Conference on Artificial Intelligence , pages 784-789, 1993. bib .ps Abstract Eugene Charniak. Statistical Language Learning . The MIT Press, Cambridge, Massachusetts, 1993. bib http 1992 Glenn Carroll and Eugene Charniak. Two Experiments on Learning Probabilistic Dependency Grammars from Corpora . Technical Report CS-92-16, Brown University, Providence, RI, USA, 1992. bib .pdf Abstract Last update Friday, May 27 2016, 0427 PM", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Brown Laboratory for Linguistic Information Processing (BLLIP)", "Lab Publications", "2016", "2015", "2014", "2013", "2012", "2011", "2010", "2009", "2008", "2007", "2006", "2005", "2004", "2003", "2002", "2001", "2000", "1999", "1998", "1997", "1996", "1995", "1994", "1993", "1992"], "word_count": 5803, "token_count_estimate": 9625}}, "https://awards.cs.brown.edu/2019/03/12/alum-adventures-brown-cs-alums-david-simons-daniel-wilk-and-michael-natkin-have-won-academy-award-work-adobe-after-effects/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Alum Adventures Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects Posted by Rujul Singh on March 12, 2019 in Awards Click the links that follow for more news items about awards won by Brown CS alums. In the days since we went to press with the story below, Brown CS alums Dave Simons 90 and Daniel Wilk 92 have won yet another award for their work on Adobe Character Animator. The National Academy of Television Arts and Sciences has recognized the tool as a Pioneering System for Live Performance-Based Animation Using Facial Recognition. Developed by Daves team, Character Animator allows artists to animate characters in real time via live tracking and has changed the landscape of character animation. We are honored to work on software that allows artists to tell their stories in new ways, says Dave when asked about his motivations for the project. The tool was used for the first-ever live episode of The Simpsons, live cartoon interviews on The Late Show with Stephen Colbert, and the quick-turnaround production of Our Cartoon President, and will undoubtedly continue to make waves in the animation industry. We knew the odds were against us, laughs Brown CS alum Dave Simons 90, but the idealism of four recent college graduates trumped the 90 failure rate we were warned about. Nearly 30 years later, it seems this idealism may not have been misplaced, as Dave, along with fellow Brown CS alums Daniel Wilk 92 and Michael Natkin 89, have just won an Academy Award in scientific and technical achievement for their work on Adobe After Effects. Awarded to those who provide extraordinary contributions to the science of filmmaking and a proven record of contributing significant value to the process of making motion pictures, the honor truly recognized the critical role that After Effects has come to play in the motion graphics industry. What motivated Dave to begin his work on this pioneering project Well, it all started in the graphics group of Brown CS Professor Andy van Dam many years ago, at a time when undergraduate contributions to research were far less common. Michael also mentioned both Andy and his group in his acceptance speech, thanking van Dam for giving me a chance and a first introduction to graphics. When I first began my work in this field, all the tools were command-line tools, explains Dave, and I actually did my senior thesis on distribution ray-tracing. Friendships at Brown naturally led to the birth of The Company of Science Art, otherwise known as CoSA for short. Founded by Dave and three other Brown graduates in June of 1990 Greg Deocampo 88, David Foster DaveF 90, and David Herbstman DaveH 90 the company planned to become the next world-class content provider for the new electronic age. After searching all around Providence, DaveF found a great place near downtown, he remembers. DaveH negotiated the rent down to 1000 a month, and we were in business. With such lofty expectations, it was no surprise that the fledgling company inevitably faced a myriad of setbacks in its early years. The original plan was to have artists and programmers working side by side to produce multimedia content, and CD-ROM production was the first task. Named Connections The CoSA Journal, this first hypermedia publication was designed to show off the new medium, but garnered little interest. This was followed by PACo PICS Animation Compiler, which allowed platform-independent low-bandwidth streaming animation playback with synched sound. What initially seemed like a promising idea, however, quickly changed as Apple announced QuickTime a mere few months later. Running low on funds, the team knew that they needed to come up with something fast. And it was from this that Egg the first codename for After Effects was born. This is where Daves graphics-group training would really start to pay off. With Egg development in full swing, it was at this point that Dan Wilk 92 joined the team, helping to write effect plug-ins. The first press demos of the brand-new software were held in a private suite at MacWorld Boston. After receiving positive reviews from the public, the team quickly realized that the project needed a real name After Effects. Showing After Effects 1.0 to the public for the first time was an exhilarating experience, remembers Dave, We had a tiny booth and people were packed ten-deep at times trying to get a glimpse. The software exploded in popularity, and CoSA was bought out a mere six months later by Aldus Corporation, followed by another merger of Aldus into Adobe Systems a year later. This set into motion the chain of events that led to After Effects becoming the dominant motion graphics and visual effects application used in the post-production process of film and television production. Its easily the most common tool now to do motion graphics in the film industry, explains Dave, and it really lets you create anything you want in this field. Brown CS has certainly left its mark on the industry, as over 15 Brown graduates worked at CoSA or were involved in the After Effects project. Used for most of the iconic Pixar movies opening and closing credits, After Effects has quickly become an indispensable tool in the artists toolkit. With such an accomplished career, what does Dave believe prepared him best from his years at Brown Well, it may very well have been his experiences TAing a myriad of classes in Brown CS. I was a head TA for Andy van Dam in CS 11 and CS 192, he remembers, and Andys high bar and criticalness made me learn a lot. Dave has certainly come a long way from the old, refurbished apartment in which the project first began, and his work has undoubtedly made it possible for countless artists to enable their dreams. For more information on the history of CoSA and the teams Academy Award acceptance speeches, see the following link . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Alum Adventures: Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects"], "word_count": 1031, "token_count_estimate": 1225}}, "https://awards.cs.brown.edu/2016/08/15/de-stefani-epasto-riondato-and-upfal-win-best-student-paper-award-sigkdd-2016/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles De Stefani, Epasto, Riondato, And Upfal Win A Best Student Paper Award At KDD 2016 Posted by Jesse Polhemus on Aug. 15, 2016 in Awards Professor Eli Upfal of Brown University s Department of Computer Science Brown CS and his research group continue to distinguish themselves in the Big Data research community. Shortly after two of their full papers and one poster paper were accepted at the 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD 2016, a prominent Big Data conference, one of the papers has won the conferences Best Student Paper Award for the Research Track. TRIEST Counting Local and Global Triangles in Fully-dynamic Streams with Fixed Memory Size was a joint publication between Lead Researcher and PhD Candidate Lorenzo De Stefani, former Postdoctoral Research Associate Alessandro Epasto now at Google, Visiting Assistant Professor of Computer Science Matteo Riondato , and Eli. The paper tackles the problem of triangle counting in large massive graphs. Their work proposes a new algorithm based on adaptive sampling, which provides high quality approximations of the number of triangles in large networks with probabilistic guarantees. Two Sigma Labs, where Matteo works as a research scientist, has also published a news article on TRIEST thats available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus . The image above is 2016 by the Association for Computing Machinery.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "De Stefani, Epasto, Riondato, And Upfal Win A Best Student Paper Award At KDD 2016"], "word_count": 250, "token_count_estimate": 319}}, "https://awards.cs.brown.edu/2019/05/20/david-abel-wins-presidential-award-excellence-teaching/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles David Abel Wins A Presidential Award For Excellence In Teaching Posted by Rujul Singh on May 20, 2019 in Awards Click the links that follow for more news items about David Abel , other winners of the Presidential Award , and other awards won by our students. PhD candidate David Abel of Brown CS , who just recently proposed his thesis and expects to graduate with a PhD in Computer Science and a Masters in Philosophy next spring, has been recognized for an accomplishment beyond his achievements in research. Chosen out of hundreds of graduate students with teaching appointments, Dave was one of only four to win the Presidential Award for Excellence in Teaching. The award, given annually at the University Awards ceremony, recognizes outstanding pedagogical achievement. Its criteria span from teaching that influences and inspires students to learn to development of curriculum and resources that promote student learning. Dave began his teaching journey in 2014 as a TA for Stefanie Tellex, teaching CS 1410 an undergraduate Artificial Intelligence class. After being nominated as a great TA by the students in the class, he became a TA for CS 8 A First Byte of Computer Science, an introductory computer science class for non-majors taught by Professor Michael Littman with enrollment of 109 students. During his semester of teaching the course, Dave was consistently praised by his students, with many citing his energy, availability, and thoughtfulness as being key to fostering an environment for intellectual curiosity. Dave was instrumental in implementing an optional python unit in the class that gave students the opportunity to learn a language used widely in industry. As a testament to his teaching abilities, a full 98.5 of respondents rated the class as effective or very effective when Michael took a sabbatical and Dave ran the class on his own. Not limited to the classroom, Dave has been involved in a variety of activities that may very well have had an even greater impact on the Brown community. Along with fellow CS PhD students Nediyana Daskalova and Amariah Becker, Dave has been heavily involved in designing and running peer mentorship program in the department. His initiative pairs up post-candidacy PhD students with first year PhD students, ensuring that new students have proper guidance regarding finding research, working with their advisor, and establishing work-life balance. Keeping with the spirit of mentorship, Dave has been a primary research advisor for several Brown undergraduates as well. Over the past few years, he has co-authored 11 papers with many undergraduate students, guiding them through the research process. Dave has clearly shown himself to be a remarkable teacher, both in and outside the classroom. As he finishes up his graduate studies, its evident that his work has made a personal impact on the many dozens of students with whom he has worked. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "David Abel Wins A Presidential Award For Excellence In Teaching"], "word_count": 500, "token_count_estimate": 592}}, "https://blog.cs.brown.edu/2013/07/26/moocs-overview/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles MOOCs An Overview Posted by Rosemary Simpson on July 26, 2013 MOOCs Massive Open OnlineCourse are interactive online courses that typically are free and open toanyone with an Internet connection. Likeearlier free online course offerings, e.g., MITs OCW Open CourseWareinitiative, they provide resources such as videos, recommended readings, and problemsets. They differ from these earlieronline courses in two major ways the courses are designed for online useinstead of being copies of on-site existing courses, and they are structuredaround interactive social networks, called user forums. Currently there are three major MOOCvendors Coursera www.coursera.org, edX www.edx.org, and Udacitywww.udacity.com. While the format forthe three is similar, Udacity differs from Coursera and edX in that it does nothave a calendar-based schedule students may start a course at any time. The figure below fromStanford httpwww.stanforddaily.com20130205a-look-at-online-education-coursera-edx-and-udacityonline-education-page-1 summarizes keycomponents history, number of universities, number of courses, number ofstudents, and whether they are for-profit or non-profit.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "MOOCs: An Overview"], "word_count": 163, "token_count_estimate": 275}}, "https://blog.cs.brown.edu/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown Alumni Monthly Looks At Suresh Venkatasubramanians New Course, CSCI 1951-Z Fairness In Automated Decision-Making Posted by Jesse Polhemus on March 13, 2024 in Socially Responsible Computing Once you you get people on board with the idea that we should do something about making sure our systems are fair and unbiased and accountable, the next obvious question is how do you do that says Professor Suresh Venkatasubramanian, who premiered CSCI 1951z, Fairness in Automated Decision-Making, last fall. This class is really trying to answer that. read more Diverse Career Paths Brown CS Alum Lisa Gelobter Focuses Her Career On Technology For Equitable Workplaces And Doing Good Posted by Robayet Hossain on March 12, 2024 in Socially Responsible Computing , Diversity A member of Brown CS entered class of 1991, graduated class of 2011, Lisa Gelobter is the CEO and the founder of a tech startup called tEQuitable that uses technology to make workplaces more equitable. tEQuitables mission is to help companies create a safe, inclusive and equitable workplace. They provide a confidential sounding board for employees to address and resolve interpersonal conflict, specializing in micro-aggressions and micro-inequities, and they provide data and insights to companies to identify and improve systemic workplace culture issues. read more The Telepresence Of Furniture In Extended Reality Posted by Jesse Polhemus on March 4, 2024 in Socially Responsible Computing In the current issue of ACM Interactions Magazine , Assistant Professor of Practice Ian Gonsher presents a collection of prototypes developed at the intersection of robotics, ubiquitous computing, mixed reality, and furniture design. These design research projects also call attention to inequalities between local and remote telepresence users, and offer viable alternatives away from the dominant paradigm of personal devices towards the development of extended reality infrastructure as a public good. read more The Computer History Museums 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS Posted by Jesse Polhemus on Feb. 27, 2024 On January 24 of 2024, I attended the Computer History Museum CHMs huge celebration in Silicon Valley for the 40th anniversary of the launch of the Apple Macintosh, where Brown CS got a shout-out during the two-hour program. Why would that be I thought it would be interesting to those who werent around to learn about how universities Brown in particular were instrumental to the success of the computer that many now take for granted. read more Brown CS UTAs Start The Semester With A Dodgeball Tournament Posted by Jesse Polhemus on Feb. 2, 2024 read more The Brown Daily Herald Meets CSCI 0150s New AI-Powered Chatbot Teaching Assistant Posted by Jesse Polhemus on Feb. 1, 2024 read more John Hughes Ranks In The Top 0.21 Of Stack Exchanges Math Users Posted by Robayet Hossain on Jan. 29, 2024 in Awards Stack Exchange is a network of question-and-answer websites on subjects in diverse fields, with each site covering a specific topic where users questions and answers are input into an online reputation award process. Stack Exchange website areas include knitting, electronics, and especially programming, and users are able to upvote questions and answers that feel relevant and right for them. Brown CS faculty member John Hughes was recently ranked in the top 0.21 of Stack Exchange users in the Mathematics stack exchange for his reputation in answering questions posted online. read more Research Associate Tom Sgouros And Brown CS Students Use Sound And AI To Make NASA Imagery Accessible Posted by Jesse Polhemus on Dec. 18, 2023 in Diversity , Socially Responsible Computing Pivoting is a lot of what I do, Brown CS Research Associate Tom Sgouros says of a current project. It began in a familiar research area, virtual reality, and evolved in two different directions, resulting in work that offered unexpected depths along the route to an important and often neglected goal aiding the visually impaired. read more Diverse Career Paths Jonah Kagan Discusses Meaningful Impact Through CS Posted by Robayet Hossain on Dec. 3, 2023 in Socially Responsible Computing , Diversity A member of the Brown CS class of 2013, Jonah Kagan is a software engineer at VotingWorks , a small nonprofit organization dedicated to building reliable, open-source election technology like voting machines, ballot scanners, and election-auditing software. When asked about the skills he uses for his career, Kagan explained that the knowledge learned in his very first computer science class, CSCI 0190 Accelerated Introduction to Computer Science , has helped him in his day-to-day life. read more The New York Times Recommends Rhode Island In The Fall Posted by Jesse Polhemus on Oct. 19, 2023 A recent New York Times describes Rhode Islands East Bay as a beautiful, bountiful autumn destination. Just 30 minutes from Providence, writes Christine Chitnis, over an hour from Boston and four hours from New York City, the Easty Bay towns of Warren, Bristol, Tiverton and Little Compton offer an idyllic fall weekend getaway. read more Page 1 of 45 next", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", ""], "word_count": 835, "token_count_estimate": 1110}}, "https://awards.cs.brown.edu/2022/03/21/brown-cs-alum-david-abel-acm-sigai-dissertation-award-runner/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Brown CS Alum David Abel Is A Joint AAAIACM SIGAI Doctoral Dissertation Award Runner-Up Posted by Jesse Polhemus on March 21, 2022 in Awards Click the links that follow for more news about David Abel and other recent accomplishments by our alums . The Association for the Advancement for Artificial Intelligence AAAI is a nonprofit scientific society devoted to advancing the scientific understanding of the mechanisms underlying thought and intelligent behavior and their embodiment in machines, and ACM SIGAI is the Association for Computing Machinerys Special Interest Group on Artificial Intelligence. Working in concert, they present the Joint AAAIACM SIGAI Doctoral Dissertation Award annually to recognize and encourage superior research and writing by doctoral candidates in artificial intelligence, and Brown CS alum David Abel has just been announced as one of only two runners-up for the 2020 prize. Advised by Brown CS Professor Michael Littman , Davids thesis A Theory of Abstraction in Reinforcement Learning explores the use of abstraction to reduce the complexity of effective reinforcement learning. Reinforcement learning, he explains, defines the problem facing agents that learn to make good decisions through action and observation alone. To be effective problem solvers, such agents must efficiently explore vast worlds, assign credit from delayed feedback, and generalize to new experiences, all while making use of limited data, computational resources, and perceptual bandwidth. Abstraction is essential to all of these endeavors. Through abstraction, agents can form concise models of their environment that support the many practices required of a rational, adaptive decision maker. In his dissertation, David starts with three desiderata for functions that carry out the process of abstraction they should preserve representation of near-optimal behavior, be learned and constructed efficiently, and lower planning or learning time. Abel then presents a suite of new algorithms and analysis that clarify how agents can learn to abstract according to these desiderata. Collectively, he says, these results provide a partial path toward the discovery and use of abstraction that minimizes the complexity of effective reinforcement learning. For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Brown CS Alum David Abel Is A Joint AAAI/ACM SIGAI Doctoral Dissertation Award Runner-Up"], "word_count": 366, "token_count_estimate": 447}}, "https://awards.cs.brown.edu/2021/05/26/eli-upfal-and-collaborators-receive-acms-paris-kanellakis-theory-and-practice-award/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Eli Upfal And Collaborators Receive ACMs Paris Kanellakis Theory And Practice Award Posted by Jesse Polhemus on May 26, 2021 in Awards Click the links that follow for more news about Eli Upfal and other recent accomplishments by our faculty . This week, Professor Eli Upfal of Brown CS and his collaborators received one of theoretical computer sciences highest honors, an award that also pays tribute to Elis predecessor at Brown University . Together with Yossi Azar Tel Aviv University, Andrei Broder Google Research, Anna Karlin University of Washington, and Michael Mitzenmacher Harvard University, Upfal has won the Association for Computing Machinery ACM Paris Kanellakis Theory and Practice Award for the discovery and analysis of balanced allocations, known as the power of two choices, and their extensive applications to practice. The ACM is the worlds largest educational and scientific computing society, and Eli is the first Brown CS recipient of this accolade, which is given annually to recognize specific theoretical accomplishments that have had a significant and demonstrable effect on the practice of computing. Its accompanied by a prize of 10,000. In a 1994 paper , Eli and his colleagues introduced the balanced allocations framework, also known as the power of two choices paradigm, a theoretical work that has had widespread practical impact. It can be explained as follows when n balls are thrown into n bins chosen uniformly at random, its known with high probability that the maximum load on any bin is bounded by lg nlg lg n 1o1. The researchers proved that adding a little bit of choice makes a big difference. When throwing each ball, instead of choosing one bin at random, the thrower should choose two bins at random, then place the ball in the bin with the lesser load. This minor change brings an exponential improvement now, with high probability, the maximal load in any bin is bounded by lg lg nlg 2O1. In the same work, they show that if each ball has d choices, the maximum load drops with high probability to ln ln n ln dO1. Since bins and balls are the basic model for analyzing data structures such as hashing or processes like load balancing of jobs in servers, its not surprising that the power of two choices, which requires only a local decision rather than global coordination, has led to a wide range of practical applications. Just a few examples include Googles web index, Akamais overlay routing network, and highly reliable distributed data storage systems used by Microsoft and Dropbox, all based on variants of the power of two choices paradigm. The Balanced Allocations paper and the follow-up work on the power of two choices, the ACM writes, are elegant theoretical results, and their content had, and will surely continue to have, a demonstrable effect on the practice of computing. Paris Kanellakis was a distinguished computer scientist who was an esteemed and beloved member of the Brown CS community. His research area was theoretical computer science, with emphasis on the principles of database systems, logic in computer science, the principles of distributed computing, and combinatorial optimization. Winning this award is special for me, says Eli. Ive always been proud to be Pariss successor at Brown, and being recognized as someone who has had a similar impact on computing practice is really an honor. Bringing an award named for Paris Kanellakis back to Brown feels like closing a circle. The full ACM press release is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Eli Upfal And Collaborators Receive ACM's Paris Kanellakis Theory And Practice Award"], "word_count": 610, "token_count_estimate": 730}}, "https://blog.cs.brown.edu/2013/07/26/why-coursera/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Why Coursera Posted by Rosemary Simpson on July 26, 2013 What sets Coursera apart from myother experiences with distance learning MITs OCW, Stanfords video courses,Khan Academy 1 All previous venues shared the essential qualities of being free, providingrich video resources, being available on demand, and not being restricted byprerequisites or tied to a syllabus although Khan does supply a context graphof recommended relationships. Coursera courses provide, in addition to all ofthis, a focus on interaction among all participants that pervades the structureand experience of the course. UserForums These are the primary mechanism through which students interactwith each other, the community TAs, and the professors. They provide a chanceto ask questions and engage interactively with the answers. In addition, forumusers frequently volunteer their expertise by recommending resources andproviding insights that can be both surprising and very helpful. This is thekey difference between the Coursera student experience and the experience ofwatching videos in other, non-interactive online courses MIT-OCW and Stanford Video lectures provide nointeraction, no community, while Khan Academy, with its very different focusand granularity, has some minor interactive responses to specific videos.Courseras user forums are relevant to the entire course and comprise manythousands of highly engaged participants. In the beginning I was interested just in the videos andtended to ignore the forums, feeling I didnt want to waste my time with othersas ignorant as I. However, I found that I was very, very mistaken the Courseraforums have become a resource that is unique in my experience and has providedboth guidance and enriching ongoing dialoguedebate Ive never beforeexperienced. Some forum members have become friends with whom I continue to expandmy understanding. StudyGroups These provide a second interaction mechanism, and may be online anddistributed or co-located. At the beginning of each course students arestrongly encouraged to form study groups based on whatever criteria they findcongenial. The study groups become in effect small cohesive communities whereideas are explored in a safe space and people get to know each other. Again,initially I scorned the study groups, thinking I preferred to work things outon my own, and again I was wrong. This time around, in Keith DevlinsIntroduction to Mathematical Thinking, the study group Ive formed with afriend who is also taking the course is turning out to be enormously helpful heand I debate our differing reasons for assignment answers, egg each other on tosupport our positions, and uncover new resources, which we then post to theforum. PeerReview This is a third form of interaction, one which justifiably in myopinion is very controversial. My experience is that while doing a peer review is quite valuable inthe same way that attempting to teach is a very powerful way to learn, peerreview responses are not so useful. My opinion was unfortunately reinforcedearly on by a disastrous experience with idiotic peer reviews, or non-reviews,of an essay Id spent a week researching and writing. However, engaging inrebuttal and the subsequent interactive dialogue is quite useful. ISSUES From my perspective as a student, themajor problems involve structural inadequacies in search, forums, andresources. Searches The most critical defect in Coursera is the brain-dead search facility, whichis a simple string-only search over the titles and text of the forum. Youcannot search on the names of posters e.g., you cannot find all posts by aparticular person you cannot search the rest of the course site, and youcannot do simple Booleans such as find this but not that, much lesstake advantage of regular expression patterns. Many subject-specific userforums use Google search, which while not perfect is much more useful than thecurrent Coursera search Coursera should do the same. Searches should be faceted, e.g.,search on post author, date, ..., the scope should be the full course website, andthey should be able to be saved and then used for search refinements. The same automatic visualization tools thatshould illustrate the evolving forum graph structure see below could be usedto visualize the results of searches and sub-searches. Structurerelationshipvisualization is a key tool in gaining deep understanding. ForumsStructure Issues and possible solutions include the following points. 1. It is currently impossible to trackall threads. Forum software needs to automatically assign author-editable tagsto entries, and from that develop an emergent substructure among the threads.Threads should be sortable by tag, creation and modification date, author, andtitle. 2. The current structure is like arigid class hierarchy and needs cross-cutting views it should be a graphstructure to reflect the emerging multiple POV point-of-views and LODlevel-of-details. 3. The community TAs need a tool fortraversing the forums effectively and adding intermediate structure as needed,beyond the automatic evolution suggested in Point 1. 4. There should be a topics forumthat is independent of lecture and assignment and could have automatic linksinto relevant lectures and other forum threads. Obviously, the topics forumneeds to evolve deep structure as the course proceeds. 5. An evolving linked visualizationof the interacting threads graph would be extremely valuable. The NSDL ScienceLiteracy Maps httpstrandmaps.nsdl.org illustrate one possibility.StrandMaps would be a great addition to the courses. In sum, what is needed is acombination of full-faceted search plus an evolving forum structure withmultiple points of view. Resources In general, the resources are a fairly traditional set of lectures andrecommended readings. The videos Ive seen tend to be straightforward, high-qualitylectures the exception to this pattern is a modern poetry course with videos ofhour-long close reading discussions by the professor and several graduatestudents sitting around a conference table. However, in the courses Ive takenso far there is no metalevel visualization of context, no use of 2D or 3Dvisualization of the dynamics of the material, much less the forum threads, noset of relationship graphs among themes, no real integration or connectionswith the larger domain. In short, there is no reference to or exploration ofthe ecology of which the subject is part. It is as if hypertext had never beeninvented. Finally, while forums can be a rich source of recommendations forbooks, people, and websites, they too lack this awareness of any larger frameof reference. STRATEGIES Whypeople take the courses Reasons for taking the courses, which are especiallydiverse with Coursera due to its heterogeneity and interactivity, include testingthe waters, curiosity, need for community, opportunity to get questionsanswered, and gaining perspective, as well as a serious intent to complete allthe material.Further, as theCoursera courses have progressed, professors are realizing that their targetaudience is primarily adults, often adults with many other obligations. Thus,the current tendency is to close a course to new enrollments at the end of thecourse but to keep it accessible to those who did enroll at least until thenext time the course is given.Prof.Devlin, for example, has decided to keep the fall 2012 site of his mathematicalthinking course open. It would be nice if Coursera established a policy ofkeeping the course materials on a persistent basis, like the MIT OCW, Stanfordvideo, and Khan Academy materials. Working with the forumsto counteract rigidity As mentioned above, the forum structures are rigid,like a rigid class structure, and badly need cross-cutting and refactoringcapabilities. In the absence of facilities for doing this, Ive developedworkaround strategies that help compensate for and manage the sometimesoverwhelming chaos of thousands of unstructured threads. First of all, from the beginning of a course in which I intendto be seriously involved, I take advantage of the forums latest posts list onthe forum home page. This lets me track new threads of interest, as well asinteresting people and community TAs remember that it is not possible tosearch on names. I then subscribe to threads that seem promising and capturecontent I want to save and work with on my local system. In addition, in the General Discussion forum Ive establishedthreads for topics, experts, and resources I think are important and keep thesethreads foregrounded by periodically posting to them and providing links torelated forum posts Ive discovered during my daily prowls of the forum. Search Unfortunately, there is little that can be donewith the brain-dead search facility. Afurther frustration is that when you subscribe to a thread and an email arriveswith a new post or comment, clicking on the link takes you not to the post butto the top of the thread, and because you cant search on the name of the poster,you are reduced to attempting to discover where the comment is coming from byeither scrolling down the thread or trying to enter a string from the commentinto the search engine. 1 Coursera is one of three major vendors of MOOC Massive Open Online Coursecourseware that have come to prominence in the last year. Since I have direct experience with justCoursera, I have only referenced it in this article. For a brief overview and comparison of threevendors - Coursera, EdX, and Udacity - see the article MOOC vendors A Comparison Overview", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "Why Coursera"], "word_count": 1451, "token_count_estimate": 1917}}, "https://blog.cs.brown.edu/2013/07/29/experiences-line-course-offering/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Experiences from an Online Course Offering Posted by Shriram Krishnamurthi on July 29, 2013 In Fall2012, I offered my course CSCI 1730. This is a junior-, senior-, andbeginning-graduate-level course in programming languages not in how toprogram, but rather in linguistic mechanisms. Together with my PhD studentand graduate TA Joe Politz, I decided to offer it on-line in addition toin-class. My primarygoal was to understand this new teaching medium. As someone who runs veryinteractive classes and teaches solely by writing on a board, I had long beenconvinced that my teaching methods would simply never work with a remoteaudience. Having maintained this position for many years, I felt it importantto experiment and learn how to adapt everyone of a certain age or pop culturesensibility recognizes the phrase, video killed the radio star. I did not do it for the reasons that thefounders of Coursera have proclaimed that they had almost no studentengagement in their classes, they were tired of telling the same old jokes, andso on. One might conclude from their narrative that teaching and learning atStanford must be a terrible experience though a more charitable and much morelikely reading is that they are exaggerating for corporate effect. Hype andexaggeration apart, I do believe higher education is at a potentially criticaljuncture. Against this backdrop, Brown is engaging in a large planning effort, investingsignificant energy and resources on campus space. We are fortunate to be havingthis discussion after the MOOC Massive Open On-Line Course, the idea ofteaching courses through electronic media to large numbers of studentsaspersonified by courses on Coursera, Udacity, EdX, and other organizationsphenomenon has begun it would be unfortunate if it did not significantlyaffect these conversations, especially due to the impact on the classroomwhich I think is likely to be enormous. THE ONLINE COURSE, AND BROWNS VALUE ADDITION It was always clear that we could not offer exactly the samecourse as we gave Brown students. One of the important parts of my course is aset of open-ended written assignments. I consider these extremely important inmeasuring student understanding of the material, but we almost certainly lackedthe resources to grade them for the on-line students. Nor were we willing, asmany MOOCs are, to grade using simple computer-driven textual analysis wewanted to read the responses in depth. Thus the courses differed, and we wereable to point to tangible differencesbeyond the evident intangiblesbetweenthe Brown and on-line offerings. CERTIFICATION LEVELS Because we were not offering Browns course in full, we werefree to customize our course to different on-line clientele. Instead of gradeswhich would suggest having done the equivalent of the Brown course, we publicizedthree different certification levels Lite Completing a sufficient number of daily quizzes but no more Mezzanine Beyond Lite, completing the minor project that occupies the first month Ninja BeyondMezzanine, completing the major project that occupies the remaining two months When we noticed that many of our initial sign-ups wereprofessional programmers, we added a fourth Sprint Theminor project, and quizzes during its duration The Sprint option enabled people to engage intensively forone month, and then disengage fully from the course and return to theirprofessional and other lives. The completion numbers indicate that this was a wiseaddition. BY THE NUMBERS We hadabout 1650 signups initially. In keeping with all other MOOCs, attendancedropped off rapidly especially after we made the opening assignment especiallyhard. Our completion ratio was about what one might expect for an upper-leveltechnical course 80 students finished, distributed as follows Lite 23 Sprint 23 Mezzanine 32 Ninja 2 The distribution of sign-ups looked like a heat-map ofcomputer science large clusters in the US Northeast, the Pacific Northwest,and Northern and Southern California a strong showing in the London area andan especially strong cluster in Indias technology hub and my hometown,Bangalore now known as Bengalooru. We were surprised by the relative lack ofsignups from China, Japan, and Korea, but attributed this to our publicitymethods and to potential language difficulties. The distribution of finishers was not at all the same. Wehad one each from Argentina, Australia, Tanzania a Dutchman who has livedthere for a long time doing missionary work with his doctor wife, Thailand,China, Finland, Belarus, Hungary, Romania, Belgium, Spain, and Portugal. OnlyRussia, Germany, Canada, Japan, and India, other than the US, provided multiplefinishers the Indians were distributed around the country, in no way matchingthe distribution of signups. The American finishers also did not correspond tothe signup distribution, with a very strong showing from the Midwest andNortheast, nobody from the US Pacific Northwest, and one each from Northern andSouthern California. In general, therefore, tech hubs seem to offer masses ofenthusiasts whose initial interest does not translate into completion. To ourdelight, though, we had at least one person on each settled continent I also analyzed the finishers by self-described occupation.IT means anyone in the computing industry student could mean anywhere fromhigh-school upwards, though I dont believe any of the high-schoolers whoenrolled got very far. Note that some people did not provide this information. Lite IT 6students 8 mathematician 1 Sprint IT13 students graduate-level 2 finance 1 Mezzanine IT14 students 3 research scientist 1 stay-at-home dad 1 associateprofessor 1 Ninja IT 2 IN TERMS OF PRIOR EDUCATIONAL EXPERIENCE High school Bachelors degree Post-bachelor degree Lite 4 5 3 Sprint 9 8 Mezzanine 8 9 7 Ninja 2 The ageswere distributed as follows though we had several in the 13-18 age range signup, none of them survived the course 19-25 26-34 35-50 Over 50 Lite 5 3 3 1 Sprint 3 8 5 1 Mezzanine 5 12 7 Ninja 1 1 Atsign-up, we also asked people what their likelihood was of finishing each ofthe certification levels. Suffice it to say these expectations greatly outstrippedreality not least because roughly 1500 participants failed to complete anylevel. THE BOTTOM LINE I expectedmy in-class experience would remain largely unchanged, while I would learn mostfrom the on-line component. The exact reverse was true. The on-line componentwent along mostly predictable lines, with few surprises. In contrast, theprovision of videos had a dramatic and in my mind undesirable effect on thein-class experience of sixty students, only about twenty attended class regularly. Many studentsattributed their lack of attendance to the early hour of the class 10am onMWF. As a card-carrying computer scientist, Im guilty of having had similarviews as an undergraduate. However, the same course has been offered at 10amfor years, and attendance was always close to perfect, and this years classdidnt seem especially different in constitution. In short, there is the potential that the provision of videos will havea significant impact on class attendance, even in relatively interactive,discussion-oriented classes. PUBLICITY We madeour decision during the summer preceding the course, well before BrownsCoursera announcement. We therefore had to do all publicity ourselves. We madeannouncements on some mailing lists, and on our own social media pages. We didnot employ any other means of advertisement, such as purchasing Google ads. Itwas never our goal to bulk up with large numbers of students we were franklysurprised when signups first crossed 100, so other means of advertising madeno sense. FORMAT I normally put all my course material on-line, without anyfirewall like the abominable Blackboard and its siblings. What changed isthat we created mechanisms for grading on-line student work more on thislater, and also published videos of all the classes. Rather than createoff-line video snippets as used in flipped classrooms, we simply recordedclass and published it in full. Some on-line students reported that theyenjoyed the sense this gave of actually being in the class. To avoid visibility problems, I changed from writing on theboard to writing on a tablet computer projected on a screen nearly the samewriting experience for me, but with perfect visibility on video. Indeed, thetablet offered some advantages a whiteboard does not, such as the ability tomove a block of text from one location to another. To protect the privacy ofstudents, we recorded from the back of the room so their faces were not seen. After every class, we converted the videos and publishedthem on YouTube. On-line student discussion took place on Piazza, where Brownstudents were welcome but most did not actively participate, at least not byname. PLATFORMS Instead ofsticking with one packaged platform, we used a variety of on-line media GooglePlus, Google Documents, Google Groups, Batchgeo to make maps, Dropbox toshare videos, Piazza for discussion, JotForm for uploading solutions,Brown Computer Science facilities, and software we wrote. We chose to do thisso we could better understand from scratch what tools such an effort needs, andnot be hemmed in by one platform. Because I had a staff of world-class problemsolvers, I was confident we could fight our way out of any tight corners, andthis approach indeed worked well. STUDY GROUPS We felt itwas important to help people form local study groups, and many students wereinterested in this, too. Lacking a platform to do this for us, we created anopen Google Map that any participant could edit, so they could drop pins indicatingwhere they were and find one another. This worked well enough, and severalstudy groups sprang up around the world. ONLINE STUDENT BEHAVIOR Theon-line students generally behaved in exemplary fashion. Once we had weeded outthe tourists my term for those who were never going to be serious studentsin the class, the remainder were often genuinely grateful for the classexperience, and were far less demanding than I expected. Indeed, I think theywere undemanding to the point of hurting their educational experience. I was especiallyafraid of being pestered with email messages of the i dont know how to installur software variety. These never materialized. The few people who contacted usby email had good reasons and kept it brief and on point. We would actuallyhave enjoyed more interaction with some of the on-line students. Thebeginning of the semester was problematic on Piazza. Because there was nothingmuch to do, the on-line students turned it into yet another Web discussion siteperhaps to shake out their anxieties, holding forth vapidly on the coursetopic and much else. I believe this turned off many Brown students, in responseto which we created a Brown-only announcement mailing list. Perhaps if we hadperformed better crowd control initially, Piazza would have remained the singleforum everyone used. Iencountered only one moment of angst when a male on-line student made aninappropriate remark responding to a female on-line student. I caught thiswithin an hour of its appearance during which time it had received fewer thantwenty views, deleted it immediately, and posted a chastising comment on thediscussion site. Happily, the female student stayed with the course until thevery end, and remained a strong contributor. Therewas just one sense in which on-line students were very demanding in digitalformats. We initially expected we would simply upload our videos to YouTube.But some students complained they couldnt easily access YouTube, or wanted thevideo for off-line viewing e.g., while commuting to and from work, so we hadto make a direct link also accessible. Some wanted low-resolution versions ofthe video due to weak Internet access. Some wanted access to the digitalversion of what I wrote on the board. Some even wanted only audio access to thelectures. Keeping all these different needs satisfied was a significant andconstant burden. Surveys suggested each of these formats was useful to justenough students to be worth continuing to provide, and once we had begun tooffer one we couldnt take it away. Thetiming of our home works had an interesting and unintended consequence. BecauseI was redesigning the course from scratch, many of the projects were brand newand needed debugging. We put out assignments on Fridays. Most of the on-linestudents, being working professionals, did them immediately, and helped us findand fix most of the problems. Thus, by the time most Brown students got to theassignments, they encountered much better versions of them. STAFFING I did not have any additional resources to teach the on-lineoffering. My regular course staff consisted of my grad TA and six undergradTAs. I informed the undergrad TAs that, because this was a project being run bymy grad TA and me, they were under no obligation to participate. Though they largelydid not help with Piazza, the video recording and publication was handledalmost entirely by them. These videos obviously benefited the undergrads also,but without them there would have been no on-line course at all, so in thatsense the UTAs were indispensable. To wit, Id like to thank Liam Elberty,Jonah Kagan, Peter Kaufman, Scott Newman, Jon Sailor, and Varun Singh. COMPARISON TO COURSE GRADES Several people have asked me how these certification levelscorrespond to letter grades. They dont at all, because the Brown students hadto do additional work the written home works. However, very loosely, doing areasonable job on the written home works, combined with completing the Sprintrequirements, earned a C doing better on the written home works and completingthe Ninja requirements at a reasonable level earned a B and doing well on boththe written home works and the Ninja requirements earned an A. In short, thegrade requirements for Brown students were much higher than for on-linestudents which is why we created entirely different names rather than usingletter grades. Despite this, Brown students did much better than the on-linestudents 40 As, 7 Bs, 8 Cs, and 8 NCs in a non-required course. GRADING Because we only graded the programming-related assignmentsfor on-line students, all their grading could be automated. Most on-lineprogramming courses have students upload programs that are run by gradingscripts. We decided that we didnt want the headache of dealing withpotentially malicious programs it may helpor hurtthat Joe and I both docomputer security research, nor the expense of running these programs on acloud provider. We therefore instead handed out a binary program for eachassignment that would run the same checks on the students own machine, andreport the results back to us. As Joe pointed out, this puts the trustrelationship in the right direction we have no reason to trust them, but ifthey dont trust us enough to run our program, why are they taking a coursefrom us Of course, when the students are reporting their answers tous, its too easy for them to cheat. We therefore embedded a little ad hoccryptographic protocolJoe appositely labeled it craptographyin the gradingprograms to make this difficult. Our goal was not to create somethingimpregnable, but rather to prevent casual and, indeed, all but determined cheating.This process worked well in retrospect. WHO GAINED FROM THIS EXERCISE I gained the most. I got to experiment with what is clearlyan upcoming challenge to our profession. I got the opportunity to reach out towhole new segments of the computing population. We already have a new mastersstudent applicant from this on-line audience, and I wouldnt be surprised ifsome of the participants end up becoming PhD applicants down the road. Joe and the other course staff also learned a lot about theneeds and demands of on-line teaching platforms. One TA, in particular, has adeep interest in MOOCs, and has been considering job offers from companies suchas Coursera and Khan Academy. For these students it was a valuable real-worldsoftware requirements-gathering experience. The benefits for Brown students were probably fewer, butthat is also because we worked to insulate them from the on-line crowd. I dothink the students benefited some from interactions, especially withprofessionals. For instance, they got to see some important differences betweenhow they and professionals tackled some tasks, and at least some students foundthis thought-provoking. My wife pointed out one subtle benefit for Brown.Overthe years, Ive found it difficult to explain the chasm between our courses andthose almost everywhere else in the world. Offerings like this give the worlda window into what we do, and let them judge just how demanding and good ourcourses are. This raises the profile of our students with potential employersand others who need to evaluate them. By not only being uncompromising in thequality of our courses but by also showing that theres more to a Brown coursethan what is offered on-line, we also signal to the best students worldwidethat we are a place where they might feel at home.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "Experiences from an Online Course Offering"], "word_count": 2648, "token_count_estimate": 3531}}, "https://awards.cs.brown.edu/2020/02/17/michael-littman-has-been-named-aaas-leshner-fellow/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Michael Littman Has Been Named An AAAS Leshner Fellow Posted by Rujul Singh on Feb. 17, 2020 in Awards Click the links that follow for more news items about Michael Littman and other recent accomplishments by Brown CS faculty Brown CS Professor Michael Littman has just been named a Leshner Fellow focusing on Artificial Intelligence by the American Association for the Advancement of Science. Each year, the AAAS selects leaders from disciplines at the forefront of important science-society issues, recognizing them for their contributions and commitment to public engagement in the field. Fellows are provided with the opportunity to convene for a week of intensive public-engagement and science-communication collaboration with the rest of the cohort, with the goal of increasing public engagement and enacting institutional change during the fellowship year. I am most interested in helping people whose lives are being impacted by computing technology, Michael explains, to understand how that technology works and how we can best enhance its ability to empower us while minimizing its risks. As a founding member of AI Hub an organization with the goal of providing free, high-quality information about AI to the public, and co-host of the monthly podcast Computing Up , Michael continues to be a pioneer in sharing the wonders of AI and computing with the public. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Michael Littman Has Been Named An AAAS Leshner Fellow"], "word_count": 247, "token_count_estimate": 298}}, "https://awards.cs.brown.edu/2020/04/13/nishanth-kumar-has-been-named-2020-barry-m-goldwater-scholar/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Nishanth Kumar Has Been Named A 2020 Barry M. Goldwater Scholar Posted by Rujul Singh on April 13, 2020 Click the links that follow for more news about Nishanth Kumar and other recent accomplishments by Brown CS students and researchers . Brown University undergraduate Nishanth Kumar, a Computer Engineering concentrator and Brown CS researcher, has recently received the Barry Goldwater Scholarship for his research into Learning from Demonstration LfD. The scholarship was established by Congress in 1986 to identify and support the next generation of research leaders, and is widely regarded as one of the most prestigious undergraduate scholarships in the natural sciences, mathematics, and engineering in America. Nishanth joins fellow Brown students Adam Tropper Physics and Astronomy concentrator and Lucas Sanchez Chemistry concentrator this year as a scholarship recipient. Nishanths research focuses on teaching robots to learn real-world skills directly from observing demonstrations. LfD allows non-expert operators to program skills simply by demonstrating them many times, he explains, and these learned skills are more general they are able to handle slight variations of a task, such as if an object to be placed is slightly misplaced. The issue with current LfD techniques, however, is that they train skills that are unable to target specific goals from many possible choices i.e. targeting a specific button within a grid without copious amounts of training data. To combat this issue, I helped propose a method that learns skills that are parameterized by a goal parameter, Nishanth says, such that altering this parameter correctly alters the skill. In the button pressing scenario, instead of training a new skill for each button, we train one general skill that adapts itself depending on where the button is. Looking forward, Nishanth is ready to continue solving some of the most practical problems in Artificial Intelligence After winning the scholarship, Ive felt a deep responsibility and motivation to continue my research into AI and robotics. I believe the advent of intelligent, collaborative robots can massively change the world for the better and I hope to play some part in making this dream a reality. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Nishanth Kumar Has Been Named A 2020 Barry M. Goldwater Scholar"], "word_count": 377, "token_count_estimate": 461}}, "https://blog.cs.brown.edu/2013/08/05/pay-you-go-or-how-can-we-get-private-secure-and-efficient-payments-public-transportation/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles PAY-AS-YOU-GO or How can we get private, secure and efficient payments in public transportation Posted by Foteini Baldimtsi on Aug. 5, 2013 In a large metropolitan area such as NYC, the public transportation system is a vital part of the citys day-to-day operation. But transportation systems do not work for free each of the millions of passengers they serve must pay for their rides. Lets take a look at their underlying payment systems. The simplest, and oldest, payment system is with actual cash, tokens, or tickets. One of its advantages is that the passengers do not leave behind an electronic trail of their comings and goings. However, it also has severe limitations physical payments require cashiers or customized payment booths or turnstiles it is hard to adapt the system to variable pricing or to collect statistics that lead to better services, As a result, pre-paid or monthly cards those that need to be swiped, or sometimes contactless cards such as MetroCards in NYC and Charlie Cards in Boston have replaced the physical tokens. Contactless devices have also made paying highway tolls easier systems such as E-ZPass give drivers a device that automatically pays their tolls as they drive through the toll booth. These convenient systems raise concerns about the privacy of their customers. Ones MetroCard or Charlie Card is a persistent identier, and the MTA in New York, or MBTA in Boston, has the ability to locate an individual in a large metropolis based on where theyve used their card. These devices do not necessarily offer security for the transportation authorities either for example, the Charlie Card was shown vulnerable to forgery by three MIT students doing a class project. Thus, current practices are the worst of both worlds since there are no guarantees for either private or secure payments. One may argue that giving up ones privacy is a small price to pay for such important benets as ease and convenience, not to mention the fact that the information collected can facilitate advanced traveler information dissemination, trafc management, travel time estimation, emergency management, congestion pricing, carbon emissions control, and environmental justice assessments. But is it possible to get the best of both worlds Can we get the ease and convenience of Metrocards as well as the benefits of data collection without sacrificing privacy In theory, there exist cryptographic techniques that make this possible. Electronic cash schemes e-cash have all the privacy benets of actual physical cash. But how can we implement them on constrained devices such as a MetroCard How do we make them work with the same speed and convenience as non-privacy-preserving MetroCards How do we preserve the ability to collect the same useful information about trafc patterns, without sacrificing the privacy of individuals Pay-As-You-Go PAYG is a multi-disciplinary research project funded by the NSF 1 that started in 2010 and seeks to answer these questions. The project includes a diverse team of computer scientists, cryptographers, electrical and computer engineers, and transportation systems researchers from Brown University and the University of Massachusetts. The goal of PAYG is to bridge the gap between theoretical constructions and practical implementations on RFID devices. Starting on the crypto side, we want to construct efficient and provable secure e-cash schemes. On the other end, we want to achieve highly efcient implementations of e-cash in RFID devices that would be appropriate for the transportation scenario. Working from both ends of the problem, the goal of PAYG is to obtain a solution that offers speed and convenience on the one hand, and cryptographic guarantees of security and privacy on the other. By incorporating additional cryptographic techniques, we can derive additional benets, such as variable pricing and privacy-preserving data collection. The results of the PAYG project are very promising On the crypto end we managed to construct a new e-cash scheme 1, to be presented at ACM-CCS 2013, that perfectly suits the purpose of payments in public transportation systems. It is very efficient, has a formal proof of security, and allows the encoding of a users attributes such as age, address, etc. on the coinstokens withdrawn which is essential for the transportation setting. Encoding users attributes in the coinstokens allows us to implement additional features in our system such as variable pricing e.g. reduced fare for senior customers and privacy-preserving data collection. Our new e-cash scheme is a very exciting development in the e-cash research previous schemes were either not provably secure or too computationally expensive for scenarios where lightweight devices are used and efficiency is crucial. On the implementation end, the biggest challenge is the processing time constraints of transportation payment systems. To avoid congestion in front of turnstiles, a payment transaction should take approximately 300 ms which is a considerable challenge given the computational complexity of advanced payment protocols. The efciency of loading money on ones payment device is less critical but should also not take longer than a few seconds. Another set of challenges are related to the payment device itself. First, it should be based on inexpensive hardware due to the potentially very high volume and the need to replace payment cards frequently. Second, it should be able to communicate and work contactlessly and without a battery. These two conditions are seemingly in conict with the need to run very complex cryptographic operations. The results of the PAYG project on the implementation side are also very encouraging. In a work that was recently presented at Privacy Enhancing Technology Symposium PETS13 we implemented our new e-cash scheme using an NFC enabled smartphone 2. We managed to take advantage of certain elements of the smartphones API in order to speed up our implementation. We implemented loading in 300 milliseconds including terminal, communication and smartphone execution time and payment in about 380 milliseconds when two attributes are revealed less if no attributes were revealed. In conclusion, our work on the PAYG project shows that private and cryptographically secure payments in public transportation systems are a practical possibility. We managed to use cryptographic techniques that were previously considered prohibitively inefficient for such an application. But, are transportation systems the only possible application area of our results How can we extend our results to be used in other scenarios where private and efficient transactions are required ----------------------------------- 1 NSF grant numbers 096464, 0964379. 1 Anonymous Credentials Light , Foteini Baldimtsi, Anna Lysyanskaya, ACM Conference on Computer and Communications Security ACM-CCS, 2013. 2 Efficient E-cash in Practice NFC-based Payments for Intelligent Transportation Systems , Gesine Hinterwlder, Christian T. Zenger, Foteini Baldimtsi, Anna Lysyanskaya, Christof Paar and Wayne P. Burleson, Privacy Enhancing Technologies Symposium - PETS, 2013.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "PAY-AS-YOU-GO  or How can we get private, secure and efficient payments in public transportation"], "word_count": 1113, "token_count_estimate": 1385}}, "https://blog.cs.brown.edu/2013/08/01/new-edition-computer-graphics-principles-and-practice/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles New Edition of Computer Graphics Principles and Practice Posted by John Hughes on Aug. 1, 2013 Nearly a decade in the writing, the new edition of Computer Graphics Principles and Practice has finally been published the first copy is shown here sitting on my somewhat messy desk. The book is 1209 pages, which is slightly shorter than the second edition, but its in a larger format, which more than compensates for the difference. Several topics the extensive discussion of user interfaces, the long chapters on spline curves and surfaces have been substantially trimmed down, since there are now whole fields computer-human interaction, computer-aided design in which these topics find their natural home. The discussion of rendering -- especially Monte Carlo methods -- has been enlarged a good deal. Theres a big Brown CS representation in the book -- Andy van Dam and I here at Brown, my former Ph.D. student Morgan McGuire of Williams, former adjunct faculty member David Sklar of Vizify, Andys former Ph.D. student Steve Feiner of Columbia -- along with Jim Foley of Georgia Tech and Kurt Akeley of Lytro. As the lead author on this edition, Im a exhausted, and b very happy with the final product. The text is almost entirely new, although its strongly influenced, of course, by the presentation and order of the earlier editions. Whats Different Hardware by a world expert The third edition contains a chapter on Modern Graphics Hardware by Kurt Akeley, the cofounder of Silicon Graphics, designer of the Reality Engine and GLOpenGL, and now CTO of Lytro. Kurt uses a recent NVIDIA GPU as a model for analyzing the tradeoffs involved in designing a graphics processor, including the costbenefit choices involved in parallelizing graphics tasks, and extensive discussion of memory, concentrating on locality of reference and its relationship to caching, and the consequences of the differing constants in the Moores-Law-like improvements in memory, computation, and bandwidth. He also discusses the tradeoff between implementation simplicity and power provided to the user, and identifies a principle --- The art of architecture design includes identifying conflicts between the interests of implementors and users, and making the best tradeoffs --- early in the chapter, and then illustrates it with numerous examples. Principles galore That design tradeoff principle illustrates something about the book as well as we designed and revised chapters, we found ourselves repeatedly explaining a single idea in multiple contexts, and began to extract principles that weve found ourselves using over the years. These principles range over many levels of detail. The average height principle says that the average height of a point on the upper hemisphere of the unit sphere is 12, for example. That seems pretty specific, but its remarkable how often it comes up in discussing rendering topics. At the other extreme, the meaning principle --- which says that for every number that appears in a graphics program, you need to know the semantics, the meaning, of that number --- applies very widely. This principle might seem completely obvious to you -- of course you need to know what numbers mean If youre thinking that, let me ask you this suppose the top left pixel of your color image has colors r, g, b 245, 13, 11. What does that 245 mean If you think the pixel values are describing light as a physical phenomenon, what are the units Writing a book in a new century The worlds changed a lot since our last edition. Students are used to grabbing code from the internet. The language of choice has changed from Pascal andor C to well, to what C Scheme Java C Haskell OCaml The great thing is that it doesnt really matter. If you want to learn about, say, ray-intersect-plane computations, you can probably find implementations in any of those languages. That meant two things for us as authors We dont actually have to include code for many algorithms. The student can grab code from the web in whatever language works best for him or her. When we do write code, we can feel free to do it in almost any language. In the book, theres C, C, C, GLSL, pseudocode, and possibly some others Ive forgotten. The C-like languages are all similar enough that a student who knows one can generally read the others. Much of the early part of the book introduces 2D and basic 3D graphics via Windows Presentation Foundation WPF, a graphics library accessible through an XML-like format and via C code, but essentially the same ideas are usable via other libraries. These two mean that if the main ideas are explained simply and clearly enough which is, after all, our strength then the student can make the most of them. Structure The second edition started with 2D graphics in great detail, including extensive coverage of low-level topics like scan-conversion. Since the modern version of scan-conversion, rasterization, is now generally done in the GPU, its no longer the central topic it once was. Its also usually based on spatial subdivision approaches, which are most naturally delayed until later in the book. In the new edition, weve taken a different approach, briefly describing in the first chapter many of the main ideas of graphics, which are then treated in successively greater detail and mathematical sophistication in multiple later chapters. A clock modeled in WPF in Chapter 2 The Durer engraving used in Chapter 3 Pictures early We start with WPFs 2D features, which gives students a chance to make pictures indeed animated pictures in the second chapter, and learn about hierarchical modeling as they build a model of a clock-face. This same 2D foundation is used, in Chapter 3, to produce output for a very basic raytracer based on the famous Durer etching shown above. Almost immediately the student then learns about WPF 3D, and its basic Blinn-Phong shading model, after which we describe a couple of test-bed programs in WPF that the student can use to perform exercises throughout the book. Onion peeling At the end of the introduction we lay out a few basic facts about light, a little mathematics, and something about representation of shape in graphics just enough to let a student make a first renderer. As we work through the first several chapters, topics like clipping and transformations arise naturally, and efficiency considerations lead to discussion of how best to represent shapes with meshes. A few chapters further along, we revisit many of these ideas with greater sophistication. Morgan McGuire provides a wonderful mid-book chapter that summarizes the main current representations of light, of shape, and of light-transport, covering each in enough detail to let the student begin to see the big picture of how efficiency in one area may complicate another, etc. Its the most computer-sciency chapter the students have seen at this point. It goes into detail on fixed- and floating-point representations of numbers, memory structure in Z-buffers and other buffers, precomputation and caching for geometric models, etc. The next chapter puts much of this information to use in building a slightly more sophisticated but not recursive raytracer, a rasterizing renderer, and a hardware-based renderer, and showing how the three produce identical results, thus emphasizing the critical difference between raytracing and rasterization in the reordering of two main loops, and the consequences this has on caching, memory access patterns, etc. In later chapters, we return to raytracing in its recursive form, together with more sophisticated scattering models for light-surface interaction, and develop a path-tracer and photon-mapping renderer. And in the final chapter, on graphics hardware, we return to hardware-based rendering. This repeated treatment of the same topic allows the student to develop sophistication before facing the full complexities of the topic in its greatest generality. It also lets a teacher select how deeply to address a topic by including some chapters in the syllabus and omitting others. The Fourier transform of a box is a sinc Extramaterial Another feature of writing a book in the internet age isthat we can provide lots more to our readers. Were working on releasing sourcecode for many of the illustrations in the book, many of which like the oneillustrating that the Fourier transform of a box-filter is a sinc-function,shamelessly adapted from Bracewells Fourier Analysis book were generated byprograms in Matlab and other environments. We also provide example programs for download, and the basic ideas inWPF are explained using Browser Apps created by David Sklar in which thestudent can edit, in a browser, WPF2D XAML code and get instant feedback on theresults without every installing any software on hisher computer at all. Andy hard at work signing books McGuire, Sklar, Hughes, Akeley, van Dam, Foley, Feiner at SIGGRAPH 2013 book-signing event. Launching the book The new edition was launched at SIGGRAPH 2013, with a launchparty followed by a book-signing on the show floor. Judging from the lines atthe signing, people seem eager to have the book, and our first review on Amazongave us five starswere off to a good start", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "New Edition of Computer Graphics: Principles and Practice", "What's Different?", "Hardware by a world expert", "Principles galore", "Writing a book in a new century", "Pictures early!", "Onion peeling"], "word_count": 1513, "token_count_estimate": 1856}}, "https://awards.cs.brown.edu/2021/12/20/brown-cs-alum-guillaume-marceau-and-professors-fisler-and-krishnamurthi-win-onward-2011-most-notable-paper-award/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Brown CS Alum Guillaume Marceau And Professors Fisler And Krishnamurthi Win The Onward 2011 Most Notable Paper Award Posted by Eli Pullaro on Dec. 20, 2021 in Awards Click the links that follow for more news about Kathi Fisler , Guillaume Marceau , Shriram Krishnamurthi , and other recent accomplishments by our faculty and alums . Brown CS alum Guillaume Marceau, Professor Kathi Fisler , and Professor Shriram Krishnamurthi have just received the Onward 2011 Most Notable Paper Award. This honor is given annually to the authors of a paper that was presented at the Onward conference, an international event focusing on everything to do with programming and software. The papers are judged based on the influence they have had and their impact over the last ten years. The paper, Mind Your Language On Novices Interactions with Error Messages, explored beginning students reaction to error messages. Error messages can provide guidance to programmers while working and at the same time frustrate them because of the difficulty that comes with deciphering these messages. Using the programming language DrRacket, the paper studied how students respond to the vocabulary used in error messages. The paper found several problems with the understandability of messages, and presented recommendations to language developers and educators that have since had a significant impact on error message presentation. The paper was originally inspired by a talk-aloud study and in particular, one students remark on the confusing error messages they inevitably come across. Guillaume, Kathi, and Shrirams research on error messages offered valuable insights into one of the most critical user experience elements for programmers, according to their paper. To read the full paper, click here . For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Brown CS Alum Guillaume Marceau And Professors Fisler And Krishnamurthi Win The Onward! 2011 Most Notable Paper Award"], "word_count": 309, "token_count_estimate": 404}}, "https://awards.cs.brown.edu/2024/01/19/brown-cs-student-mattie-ji-runner-schafer-prize-excellence-mathematics-undergraduate-woman/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Posted by Jesse Polhemus on Jan. 19, 2024 in Awards , Diversity Click the link that follows for more news about other recent accomplishments by our students . Founded in 1971, the Association for Women in Mathematics AWM aims to create a community in which women and girls can thrive in their mathematical endeavors, and to promote equitable opportunity and treatment of women and others of marginalized genders and gender identities across the mathematical sciences. Almost twenty-five years ago, they established the Alice T. Schafer Mathematics Prize , named for one of their founding members, to be awarded to an undergraduate woman for excellence in mathematics. This year, Brown CS student Mattie Ji , a senior majoring in Mathematics, Applied Mathematics, and Computer Science, was the prizes runner-up. Mattie describes her interests as wide, and her knowledge of algebraic geometry and topology has allowed her participation in several Research Experience for Undergraduates programs where she contributed to projects that included an investigation into the relationship between the concepts of Euler characteristic transform ECT and smooth ECT, fake projective planes, and the study of a class of conic bundle threefolds. She has a keen interest in coding complex problems and has a repository set up on GitHub displaying her work . Mattie is consistently described, the AWM writes, as an outstanding student with the initiative to develop her knowledge and understanding and has an infectious passion for mathematics, with a remarkable record of co-authored papers and conference presentations. While this is an award in mathematics, Mattie says, I would not have gotten this award without the education and experience I have had within the Department of Computer Science. Many of my research projects that helped me garner this award involved various aspects of computational and data science, and I believe that my background and education in Computer Science were very critical for this award. A full list of this years winners is available here . For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman"], "word_count": 375, "token_count_estimate": 442}}, "https://blog.cs.brown.edu/2014/05/02/students-bootstrap-algebra-video-games/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Students Bootstrap Algebra From Video Games Posted by Jesse Polhemus on May 2, 2014 in Diversity by Kevin Stacey Science News Officer, Physical Sciences Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Middle school teacher Adam Newall calls it the eternal question of introductory algebra. As students tread water in a sea of variables, functions, and graphs, theyre bound to ask it When are we ever going to use any of this But Newall, who teaches at Pembroke Community Middle School in Pembroke, Mass., is hearing that question a lot less often lately. Hes using a new curriculum in his seventh and eighth grade math classes that answers it right off the bat and in a way that kids find hard to resist. The curriculum, called Bootstrap, teaches students to program their own video games a task that just happens to require understanding and applying fundamental concepts of algebra. Newall says the approach does wonders, engaging students in a subject from which they might otherwise shy away. The idea of making a video game is the allure, he said. But it opens students to the idea that they can learn math, and its not something thats meant to torture people. They learn that math is something that is real and relevant and that they can use it. Bootstrap is a group effort of Emmanuel Schanzer, a former computer programmer turned math teacher and now a Ph.D. student in the Harvard Graduate School of Education Kathi Fisler, professor of computer science at Worcester Polytechnic Institute and Shriram Krishnamurthi, professor of computer science at Brown. It builds on two decades of work done at Northeastern, Brown, and other universities. Middle school kids go from saying, Math is hard, to saying, I cant do math. ... Wed like to get to them before they make that decision. The curriculum started as a 10-week after-school program, which has been taught successfully around the country for six years. Now, based on the success of the after-school experience, Bootstrap is transitioning into an in-school program. The Bootstrap organization has set up training seminars for teachers around the country, and a few schools like Newalls Pembroke Community Middle School are already using the curriculum. Two new partnerships promise to bring Bootstrap to many more schools. Code.org , a national nonprofit that aims to expand computer science instruction in public schools, recently named Bootstrap as its official middle school math curriculum. CSNYC, a New York City-based group with similar goals, has adopted Bootstrap as well. This summer, as Code.org rolls out its national curriculum, the Bootstrap team will give additional training seminars to teachers all over the country interested in trying Bootstrap. More than just fun and games While the educators are mostly interested in the underlying math concepts, for the students, its the games they create that are the stars of the show. The whole curriculum is a sequence of steps that get you to the point where you have a working game at the end, Krishnamurthi said. Once we tell them theyre going to make their own game, the motivation is done. We dont have to say any more. Conceptually the games are fairly simple though surprisingly addictive. Students choose a main character, a goal for that character to reach, and a danger to avoid. Then the students learn a simple programming language to put it all in motion. And thats where algebra comes in. For example, in order for the program to know if a character has reached her goal or been stymied by an obstacle, the relative positions of objects must be plotted on a Cartesian grid. To do that, were going to need to know the Pythagorean theorem, Newall said. To understand the Pythagorean theorem we need to know square roots and squares. And the students will follow a lesson on how those things work in order to make it work in their game. Theyre so eager to own that. When all is said and done, each student has a game to show off to friends and a working understanding of variables, functions, and other fundamental algebra concepts that align with Common Core math standards. Right skills, right time One of the reasons Krishnamurthi is so eager to get the curriculum into more middle school classes is that it catches kids at a crucial time. Research has found that kids change the way they talk about math right around this age, he said. They go from saying, math is hard, to saying, I cant do math. And thats the point where kids make the decision to drop out of algebra. When they do, theyve actually made a career decision without even knowing it, because theres nothing you can do in a STEM field without algebra. Wed like to get to them before they make that decision to drop out, so they at least have they can keep their options open. But algebra isnt the only thing students learn through Bootstrap. They also become familiar with ins and outs of coding, a crucial skill in an increasingly digital world. When students present their games to their classmates, theyre also expected to stand up and explain the code that makes it work an exercise software engineers call a code review. I do code reviews with my college students, Krishnamurthi said. They are one of the most challenging experiences a college student can have. Its a hard-core professional skill. We teach it to middle schoolers as a natural part of our curricular design. The first time Newall taught the class, those code reviews were given at a launch party at semesters end. The superintendent came parents came. Just the amount of celebration from kids making a one-screen, side scrolling video game was more than I had ever anticipated, Newall said. And as for that eternal math class question, Newall says his Bootstrap students are now asking a new question. They go from, What are we going to use this for to What are we going to use this for next", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "Students \"Bootstrap\" Algebra From Video Games"], "word_count": 1041, "token_count_estimate": 1228}}, "https://blog.cs.brown.edu/2013/09/18/artemis-2013/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Artemis 2013 Posted by Angel Murakami on Sept. 18, 2013 in Diversity by Karishma Bhatia and April Tran Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . On the surface, Artemis is a summer program geared towards teaching young girls computer skills, programming, and computer science concepts through a challenging curriculum. Yet to the individuals that actually go through the Artemis experience, we learn that Artemis is much, much more. Yes, the program is about learning the science behind the modern machines we use everyday, but perhaps just as important, it helps the amazing young ladies that attend Artemis to build confidence in themselves, in their ability to build relationships with others, and their capacity to self learn. Though we can only possibly glimpse a portion of what the Artemis experience is like for its students, as directors we have learned life lessons and gleaned inspiration from our young students. As college undergraduates, in the midst of juggling multiple exams, papers, and projects, we often forget what it means to learn. Gone are the days in which making a small mistake for the sake of learning doesnt cost you a letter grade. Many of us no longer have the privilege or courage to test a teachers or parents patience with question upon question. We may never again have the opportunity or time to take complete advantage of our curiosity by letting our minds wander for hours or even days. Looking back, we realize just how valuable and precious such experiences were in our growth as students, innovators, and individuals. More broadly, we realize how important it is for our society---especially in academic institutions---to create such learning environments for youth in the community while continuing to encourage them to pursue their interests. Artemis started as a program for inner-city girls entering ninth grade to learn computer science. This year, we focused on making Artemis a program that helped students not only discover computer science, but discover a creative way to use the concepts they learned in their own hobbies and interests. Sometimes that meant a student realizing she had a knack for web-design and building a website featuring the work of her favorite artist--other times it meant a student realizing she was a poet and building a website featuring her own work. Artemis helped these girls build confidence in their own skills and talents while adding to them. How can we put into words the beauty of Iris glowing smile when her friends praised the personal works she put on her website The sense of accomplishment Jamie had watching the game she built in Scratch run perfectly Or the surge of confidence Desiree felt presenting her final project to a crowd of parents How can we describe the satisfaction of seeing the understanding on our girls faces after we explained a difficult concept By creating a positive association to computer science for our Artemis students, we ensure that they will not shy away from using technology to build creative solutions to relevant problems. They will not forgo their passions, they will not forget that they are capable of finding friends in the most unlikely people, and most importantly, they will not fear the challenge of learning something new.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Brown CS Blog", "Artemis 2013"], "word_count": 573, "token_count_estimate": 656}}, "https://awards.cs.brown.edu/2024/01/29/john-hughes-ranks-in-the-top-021-of-stack-exchanges-math-users/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles John Hughes Ranks In The Top 0.21 Of Stack Exchanges Math Users Posted by Robayet Hossain on Jan. 29, 2024 in Awards Click the links that follow for more news about John Hughes and other recent accomplishments by our faculty . Stack Exchange is a network of question-and-answer websites on subjects in diverse fields, with each site covering a specific topic where users questions and answers are input into an online reputation award process. Stack Exchange website areas include knitting, electronics, and especially programming, and users are able to upvote questions and answers that feel relevant and right for them. Brown CS faculty member John Hughes was recently ranked in the top 0.21 of Stack Exchange users in the Mathematics stack exchange for his reputation in answering questions posted online. When someone upvotes the answer, you get 10 magical internet points that are of no value to anyone at all, except you get a little reputation, and when someone accepts your answer, you get 15 points, John states. Those of us who like explaining things and showing off how much we know often answer a couple questions on this website now and then. Hughes explains that he would answer a few questions every morning as a way of practicing exposition and developing the skill of reading a question well enough to fully understand the users requests. He first became involved in the Stack Exchange network more than 10 years ago when he used the Computing stack exchange to ask questions regarding Windows for help in writing a graphics book, as well as the Electronics network to ask questions regarding characteristics of certain transistors. The Math stack exchange appealed to me because I used to be a mathematician, and I still love doing it, and because there was a sweet spot between the number of questions and the number of answers, John says. If you go and find information about your Android phone on the Android stack exchange, there are 8 billion questions and most of them never get an answer, so the math site is much better about that. The thing I enjoy most is divided into two things one is helping out someone where I think my help is actually useful to them. Thats very satisfying, knowing that someone is in need, and at the cost of asking them a few leading questions about the problem, I am able to get them on their way, and that is part of the reason why I like teaching, John says. The other thing I really enjoy is this business of learning to read questions carefully, learning to figure out what someone is asking and where they are confused. When asked about his favorite experiences with answering a question, Hughes referenced a few fond memories. There was one case where a Stack Exchange question thread resulted in him writing a joint paper about combinatorics with the user that eventually was posted to arXiv and became useful for future users. There are some things that arent worth doing financially the free market isnt going to make them happen. But if those are things that I like doing, Ive gotta make them happen, John says. If you like going to parties, youd better throw one now and then, and so part of public service for me is self-interest. I like talking about math with people, so I should contribute some time to that. Hughes believes it is valuable for faculty members to have interesting sidelights such as hes had throughout the last decade, telling a story of Browns old lecture series called Twisted Paths, where faculty in STEM gave talks about the diverse path they took to be doing what they are doing currently. I think about my former colleague Tom Dean, who was hand-carving parts for furniture, John says, adding that Dean became interested in selling refurbished metalworking machinery and started wondering about automatically controlling machines for this task, but did not have the necessary knowledge or money to delve into the work with these electronic parts. Thats when his wife Jo discovered that the local community college had affordable classes that would give him the education he needed and from there, his career as a scientist got launched, John says. He ended up working on some really fascinating projects at Google, working towards mapping parts of real brains to understand how they worked. So thats a pretty twisted path a guy who was carving table-legs ends up being a top AI researcher. John states that the most interesting scientists he has known have followed a very twisted path and that their former interests informed how they think about what theyre doing now. Theres plenty of fuel out there in the world there just arent enough sparks, John says. So I think of public service as one of the ways of being a spark, and thats why I do it. For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:06+00:00", "headings": ["Information for:", "Awards", "John Hughes Ranks In The Top 0.21% Of Stack Exchange\u2019s Math Users"], "word_count": 848, "token_count_estimate": 968}}, "https://awards.cs.brown.edu/2024/02/07/four-brown-cs-students-receive-cra-outstanding-undergraduate-researcher-honors/": {"text_content": "Awards Categories Awards 194 articles Diversity 11 articles Socially Responsible Computing 4 articles Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Posted by Jesse Polhemus on Feb. 7, 2024 in Awards Click the links that follow for more news about previous recipients of honors for this award and other recent accomplishments by our students . The Computing Research Association CRA is a coalition of more than 200 organizations with the mission of enhancing innovation by joining with industry, government, and academia to strengthen research and advance education in computing. Every year, they recognize North American students who show phenomenal research potential with their Outstanding Undergraduate Researcher Award, and for 2023-2024, four Brown CS students received honors Megan Frisella Finalist and Anh Truong, Qiuhong Anna Wei, and Carolyn Zech Honorable Mention. Megan Frisella My main research project, Megan says, is about soft memory, a new form of flexible memory that helps increase server utilization in datacenters. The work is done in the ETOS group under the advising of Assistant Professor Malte Schwarzkopf . Traditional memory is inflexible once memory is allocated to an application, it cannot be reallocated until the application terminates or explicitly frees it. This incentivizes datacenter operators to evict low-priority jobs and run at low memory utilization. Soft memory is a software level abstraction on top of DRAM that makes memory revocable under memory pressure, for reallocation elsewhere. Our system avoids out-of-memory terminations because soft memory can always be reclaimed from an application to fulfill a request elsewhere. We published a paper on Soft Memory at HotOS 2023 . In addition to systems research, I am also interested in programming languages. Last summer, I joined the RiSE group at Microsoft Research where I worked on a domain-specific language in F, called Pulse, for proof-oriented imperative programming. While most proof-oriented languages are functional, Pulse enables developers to write programs with proofs in a Rust-like syntax. Pulse extends F with proof automation, custom proof syntax, and imperative programming paradigms like loops. We have a Pulse tutorial in POPL 2024 TutorialFest . Anh Truong My research, Anh tells us, lies at the intersection of computer graphics and machine learning. Ive been working on a project with Eliot Horowitz Assistant Professor of Computer Science Daniel Ritchie that aims to achieve few-shot synthesis of 3D shapes our goal is to help novice users easily generate novel 3D models which borrow geometric features from a small set of example models they may have readily available. Such a system could allow designers to easily populate virtual worlds with varied geometry or iterate by generating many candidate models from which the most desirable can be expanded upon. A highlight of the project for me has been exploring the interface between geometry processing and machine learning and seeing how creatively ideas from these two seemingly unrelated fields have mingled. I am immensely grateful to have been able to work with Daniel and my wonderful labmates, and I look forward to exploring much more of computer graphics. Qiuhong Anna Wei Annas research, she explains, centers around building visual reasoning methods and making technology more trustworthy. Ive been working, she says, with Assistant Professor Srinath Sridhar at Brown IVL and Professor Leonidas Guibas from Stanford University on 3D vision and learning, specifically canonicalization of collections of objects, in the setting of indoor furniture rearrangement when given relatively extensive or limited information. Ive also worked with Daniel Ritchie recently in exploring the differences and similarities in human and machine understanding of layouts and regularity, as part of a larger project on open-universe scene generation with LLM program synthesis. On the other front, I have been working with Assistant Professor Peihan Miao and James A. and Julie N. Brown Professor of Computer Science Anna Lysyanskaya on private computing on set intersection in cryptography. Were especially interested in how the key component, oblivious shuffle realized via switching networks, may be optimized to achieve better efficiency or adapted to different frameworks or security settings. Carolyn Zech Paralegal, Carolyn explains, is a static analyzer that verifies Rust applications for compliance with user-specified policies. If an application fails to abide by a policy, Paralegal identifies the problematic code segments. Developers leverage Paralegal to prevent vulnerabilities from reaching production. Currently, developers write their Paralegal policies as graph queries, which makes policy-writing laborious and error-prone. My research focuses on developing a natural language interface for Paralegal, so that developers can specify high-level, intuitive policies for example, all users are authorized before accessing application data and receive quick notification of whether their code is compliant. Anh, Anna, Carolyn, and Megan join numerous prior Brown CS recipients of Outstanding Undergraduate Researcher Award honors. Most recently, they include Rachel Ma Honorable Mention, 2022 , Jiaju Ma Finalist, 2021, Wasu Piriyakulkij Honorable Mention, 2021, Nitya Thakkar Honorable Mention, 2021 , Sarah Bawabe Honorable Mention, 2020, Nishanth Kumar Finalist, 2020, Dylan Sam Honorable Mention, 2020, and Homer Walke Honorable Mention, 2020 . The full list of Outstanding Undergraduate Researcher Award recipients and honorees is available here . For more information, click the link that follows to contact Brown CS Communications Manager Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Awards", "Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors"], "word_count": 855, "token_count_estimate": 1118}}, "https://blog.cs.brown.edu/2014/01/09/hackbrown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles HackBrown Posted by Lauren Clarke on Jan. 9, 2014 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . A group of Brown CS and RISD students are hosting HackBrown, the first annual Brown University hackathon J anuary 24-25 in Alumnae Hall 250 students from BrownRISD and other schools in the northeast plus engineers from Dropbox, Google, Venmo and more will form teams and build a project in 24 hours. Teams will demo their projects for judges and win prizes. Students of all skill levels, interests, and backgrounds are all extremely welcome and encouraged to participate For more information and to register, visit the HackBrown website . Be sure to like us on Facebook and follow us on Twitter to get the latest information", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Hack@Brown"], "word_count": 148, "token_count_estimate": 188}}, "https://blog.cs.brown.edu/2014/04/16/sorin-istrail-receives-nsf-grant/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Sorin Istrail Receives NSF Grant For Haplotype Reconstruction Algorithms Posted by Sorin Istrail on April 16, 2014 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Sorin Istrail has received funding for the NSF grant Genome-Wide Algorithms for Haplotype Reconstruction and Beyond A Combined Haplotype Assembly and Identical-by-Descent Tracts Approach. Human genomes are diploids, which means that each human has two haplotypes, one inherited from the mother and one inherited by the father each haplotype is a set chromosomes of sequences of about 3.2 billions of A, C, G, and T. These haplotypes are mosaics of haplotype regions inherited from ancestors as a result of two major forces of evolution recombination and mutation. When two or more individuals inherit the same haplotype region from a common ancestor, the shared region is called a tract and it is said to be inherited identical-by-descent IBD. Tracts have the same start and end coordinates on genomes sharing them. The logic of detection of disease associations is rooted in the inference of tracts. For example, if a set of autistic patients is found to share a tract, and a certain gene is found part of this tract, this gene becomes a candidate gene for an ancestral model of autism inheritance. Preliminary work together with his PhD student Derek Aguiar succeeded in solving a major open problem of the influential Li-Stephens statistical framework 2003 for modeling linkage disequilibrium, recombination hotspots and haplotype phasing this framework enabled some of the most practical genome-wide association study GWAS software tools to date. A major bottleneck was the failure of exchangeability of the statistical process the output of the algorithm depended on the order in which the input was processed. The combinatorial solution that achieved exchangeability led to the first exact sub-quadratic close to linear and practical algorithm, Tractatus, for detecting the complete multi-shared identical-by-descent tracts in a GWAS sample of individuals current GWAS input size is a matrix with several billions entries. The name of the algorithm was inspired by Ludwig Wittgenstein s Tractatus Logico-Philosophicus. The grant proposes a comprehensive algorithmic framework for haplotype reconstruction using haplotype assembly the HapCompass framework, haplotype phasing and generalizations of Tractatus to address the problem of haplotype reconstruction in polyploidy organisms and medical aneuploidy.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Sorin Istrail Receives NSF Grant For Haplotype Reconstruction Algorithms"], "word_count": 396, "token_count_estimate": 543}}, "https://blog.cs.brown.edu/2014/03/06/browncs-students-win-best-teamwork-award/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles BrownCS Students Win Best Teamwork Award Posted by John Savage on March 6, 2014 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . On Friday and Saturday, February 7 and 8, the Atlantic Council hosted their second annual Cyber 912 Student Competition in Washington DC. It is an event designed to give students a taste of the challenges that face White House policy makers when responding to national cybersecurity threats. Twenty-two teams participated in the event representing twenty-four universities from as far away as Turkey and Estonia. A team of four Brown sophomores made an excellent showing. They not only advanced to the semifinal stage, they won the prize for Best Teamwork against much older teams. The Brown Secure team consisted of Samuel Brebner, Jason Ginsberg, Dan Meyers, and Jared Schober. I was faculty coach. Brown Secure was the youngest team to advance to the semifinal round and probably the youngest team in the competition. The competition consisted of three rounds in which students formulated four alternative responses to a crisis described in an intelligence brief. In each case teams had ten minutes to describe their responses and took ten minutes of questions. Preparation time for the first round lasted one week, the second twelve hours overnight, and the third thirty minutes. The Brown students benefited greatly from the trip, met prominent national security experts, and established a strong reputation for Brown at this event.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "BrownCS Students Win Best Teamwork Award"], "word_count": 260, "token_count_estimate": 311}}, "https://blog.cs.brown.edu/2014/03/17/middle-schoolers-get-tour-robotics-lab-brown-250-celebrations/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Middle Schoolers get tour of Robotics Lab for Brown 250 Celebrations Posted by John Raiti on March 17, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The robotics open house was hosted by the Brown Robotics Lab on first floor of the CIT Building. Visitors were greeted in the lobby by Morgan Jenkins using a telepresence robot. Through the telepresence robot, Morgan answered questions about the robotics lab and accompanied visitors to one of two rooms 1 CIT 121 where Dr. John Raiti demonstrated flight of quad rotor helicopters through web technologies developed at Brown. This project is enabling quadriplegics around the world to fly helicopters around campus. Recent talks by Prof. Chad Jenkins for TED and National Geographic has more information about this project. 2 CIT 134 where Prof. Jenkins demonstrated the PR2 robot recognizing and grasping household objects in an experimental domestic environment. This work is aimed to assist senior citizens and the physically disabled in their activities of daily living e.g., cleaning, food preparation and consumption. We eventually want to enable more people to live independently at home without requiring institutionalization in assisted living facilities. The Providence Journal has some good pictures of these demonstrations httpwww.providencejournal.combreaking-newscontent20140307-r.i.-middle-school-students-get-peek-into-the-brown-experience.ece Our continued goal is to advance robotic technology to meet the needs of society towards improving productivity and quality of life across the socioeconomic spectrum. This goal requires perspectives and interdisciplinary collaborations from across the academy, as well as engagement with the community and larger society. Participating in the 250th provided an excellent opportunity to raise awareness about the promise of robotics, engage broader perspectives, and help Brown celebrate an incredible moment in its history.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Middle Schoolers get tour of Robotics Lab for Brown 250+ Celebrations"], "word_count": 314, "token_count_estimate": 397}}, "https://blog.cs.brown.edu/2014/06/09/cs-student-work-habits-revealed-possibly-dangerously-normal/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles CS Student WorkSleep Habits Revealed As Possibly Dangerously Normal Posted by Jesse Polhemus on June 9, 2014 Imaginea first-year computer science concentrator lets call him Luis e-mailingfriends and family back home after a few weeks with Brown Computer Science BrownCS. Everything heexpected to be challenging is even tougher than anticipated generative recursion,writing specifications instead of implementations, learning how to test his codeinstead of just writing it. Worst of all is the workload. On any given night, hesaveraging this seems too cruel to be possible no more than eight or ninehours of sleep. Wait,what Everyone knows that CS students dont get any sleep, so eight ornine hours is out of the question. Or is it Recent findings from PhD student Joseph Gibbs Politz , adjunct professor Kathi Fisler , and professor Shriram Krishnamurthi analyze whenstudents completed tasks in two different BrownCS classes, shedding interestinglight on an age-old question when do our students work, and when if ever dothey sleep The question calls to mind a popular conception of the computerscientist that Luis has likely seen in countless movies and books Hours are late. A recent poster to boardgameslists.cs.brown.edu requests a 2 PM start time in order to avoid being ridiculouslyearly for prospective players. Sleep is minimal. BrownCS alumnus AndyHertzfeld, writing about the early days of Apple Computer in Revolution inthe Valley, describes the gigantic bag of chocolate-covered espressobeans and medicinal quantities of caffeinated beverages that allowed days ofuninterrupted coding. Part 1 Deadline Experiments Thestory begins a few years before Luiss arrival, when Shriram would routinely schedulehis assignments to be due at the 1100 AM start of class. Students lookedexhausted, he remembers. They were clearly staying up all night in order tocomplete the assignment just prior to class. Initially,he moved the deadline to 200 AM, figuring that night owl students would finishwork in the early hours of the morning and then get some sleep. This waseffective, but someone pointed out that it was unfair to other professors whotaught earlier classes and were forced to deal with tired students who hadfinished Shrirams assignment but not slept sufficiently. Myfinal step, he explains, was to change deadlines to midnight. I also beganpenalizing late assignments on a 24-hour basis instead of an hourly one. Thisencourages students to get a full nights sleep even if they miss a deadline. Thiswas the situation when Luis arrives. The next task was to start measuring theresults. Part2 Tracking Events Shriram,Kathi, and Joe analyzed two of Shrirams classes, CS 019 and CS 1730. For eachclass, Luis must submit test suites at any time he chooses, then read reviewsof his work from fellow students. He then continues working on the solution,eventually producing a final implementation that must be submitted prior to themidnight deadline. Part3 Reality And Mythology Giventhese parameters, what work and sleep patterns would you expect We asked professorTom Doeppner to reflect on Luis and share his experience of working closelywith students as Director of Undergraduate Studies and Director of the MastersProgram. Do students work late I know I get e-mail from students at all hoursof the night, he says, and I found out quickly that morning classes areunpopular, which is why I teach in the afternoon. Maybe its associated withage I liked to work late when I was young, but I got out of the habit in mythirties. Askedabout the possible mythologizing of late nights and sleeplessness, Tom tells astory from his own teaching Before we broke up CS 169 into two classes, thestudents had t-shirts made CS 169 Because There Are Only 168 Hours In AWeek. I think theres definitely a widespread belief that youre not really workinghard unless youre pulling multiple all-nighters. Thisdoesnt exactly sound like Luiss sleep habits Take a look at the graphs belowto see how mythology and reality compare. Part4 Results And Conclusions Thegraphs below depict test suite submissions, with time displayed in six-hoursegments. For example, between 6 PM and the midnight deadline 6-M, 50 CS173 students are submitting tests. Thisgraph is hypothetical, showing Joe, Kathi, and Shrirams expectations forsubmission activity. They expected activity to be slow and increase steadily,culminating in frantic late-night activity just before the deadline. Generallytaller M-6 midnightto 6 AM bars indicate late-night work and a corresponding flurryof submissions, followed by generally shorter 6-N 6 AM to noon bars whenstudents tried to get a few winks in. Cumulatively, these two trends depict thepopular conception of the computer science student who favors late hours andperpetually lacks sleep. Thesegraphs show actual submissions. Asexpected, activity generally increases over time and the last day contains themajority of submissions. However, unexpectedly, the N-6 noon to 6 PM and 6-M6 PM to midnight segments are universally the most active. In the case of the CS173 graph, this morning segment contains far more submissions than any other ofthe days three segments. In both of these graphs, the M-6 midnight to 6 AM segmentsare universally the least active, even the day the assignment is due. For example, the final segment of this type,which represents the last available span of early morning hours, is among thelowest of all segments, with only ten submissions occurring. In contrast, thecorresponding 6-N 6 AM to noon shows more than four times as manysubmissions, suggesting that most students do their work before or after thepre-dawn hours but not during them. Iwouldnt have expected that, Joe comments. I think of the stories folks tellof when they work not lining up with that, in terms of staying up late and gettingup just in time for class. Our students have something important to do atmidnight other than work they cut off their work before midnight and dosomething else. For the majority its probably sleep, but it could just besocial time or other coursework. Either way, its an interestingacross-the-board behavior. Ifword of these results gets out, what can Luis and his fellow students expectPeople will realize, Shriram says, that despite what everyone likes toclaim, students even in challenging courses really are getting sleep, so itsokay for them to, too. Joe agrees There isnt so much work in CS that youhave to sacrifice normal sleeping hours for it. Luis,his family, and his well-rested classmates will undoubtedly be glad to hear it.The only question is will their own descriptions of their worksleep habitschange to match reality, or are tales of hyper-caffeinated heroics too temptingto resist", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "CS Student Work/Sleep Habits Revealed As Possibly Dangerously Normal"], "word_count": 1058, "token_count_estimate": 1429}}, "https://blog.cs.brown.edu/2014/06/19/genevieve-patterson-helps-organize-ldv-vision-summit-sees-opportunity-undergrads/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Genevieve Patterson Helps Organize LDV Vision Summit, Sees Opportunity For Undergrads Posted by Jesse Polhemus on June 19, 2014 Brown University Department of Computer Science Brown CS PhDstudent Genevieve Patterson has justhelped organize the LDV Vision Summit, a start-up conference held in New YorkCity to address trends and technologies in digital imaging and video technology.Founded by Evan Nisselson of LDV Capital, an investment group interested in technology-focusedprojects across the imagingvideo spectrum, the summit brought together top technologistsand investors with the purpose of shaping the future of imaging and video. Genevievesprevious work with professor Serge Belongie of Cornell Tech, one of Nisselsonscollaborators, made her a natural choice to help run competitions and pre-judgeentrants for a vibrant and diverse conference. The summit featured anincredible variety of startups from all over the world, she explains. Theyrecreating state-of-the-art solutions for emerging topics, from wearable camerasto object detection to human tracking. Some of the solutions are extremelyhigh-tech, while others are simple and consumer-facing. Thesummit included multiple keynote addresses Jan Erik Solem of Mapillary on CrowdsourcingMap Photos and Rob Fergus of NYU and Facebook AI on Recent Progress InComputer Vision Using Deep Learning as just two examples, panels on such topicsas the future of cameras and image recognition, and two competitions. Thefirst, an entrepreneurial computer vision challenge, allowed experts todemonstrate solutions for problems such as summarizing video, detecting and recognizingwords in YouTube video frames, and predicting the relative attributes for pairsof men and womens shoes. Thesecond, a startup pitch competition, was won by Alexandre Alahi of VisioSafe,whose company uses networked cameras to analyze human behavior in physicalspaces. They went up against some impressive challengers and won, saysGenevieve. What theyre able to do is anonymously collect patterns of movementand then provide metrics, so their clients can make better use of any location,from malls to public parks. Theyre already working with Swiss Rail to improvetheir stations. Its an exciting example of the opportunities that this fieldhas to offer. Inparticular, Genevieve wants to point out th at undergraduatecomputer science students are poised to take advantage of the considerableopportunities that are being created. The fundamental challenges of computervision are still new to industry, she says, and that requires researchers.The dozens of startups seen at LDV Vision Summit need employees. They want studentsto get interested in the field today. The problems are still open, and theproducts that we have yet to see are going to create radical change in so manyaspects of everyday life. Anyoneinterested in the LDV Vision Summit can click here to follow them on Twitter,click here to go to theirWeb page, or click here to sign up for their newsletter for details on next years conference.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Genevieve Patterson Helps Organize LDV Vision Summit, Sees Opportunity For Undergrads"], "word_count": 453, "token_count_estimate": 616}}, "https://blog.cs.brown.edu/2014/10/01/brown-cs-finds-unique-way-celebrate-impressive-heidelberg-laureate-forum-representation/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS Finds A Unique Way To Celebrate Impressive Heidelberg Laureate Forum Representation Posted by Jesse Polhemus on Oct. 1, 2014 in Diversity In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Thirty-five years after the founding of the department, Brown CS attendance at international conferences is anything but uncommon strong representation and participation are the norm. But the three students who flew to last weeks Heidelberg Laureate Forum HLF took an unusual step to bring Brown CS spirit to the event, expanding departmental tradition and proving themselves right at home in a world-class environment where collaboration thrives. Now in its second year, the HLF provides an annual gathering in which Abel, Fields, and Turing laureates interact with 200 of the worlds best young minds, divided evenly between computer scientists and mathematicians. Irina Calciu , Max Leiserson , and Layla Oesper were selected from a pool of more than 2000 applicants, and they were joined by alumnus Matthew Lease PhD 10, providing Brown with an impressive 4 of worldwide CS attendees at the conference and 20 of American ones. They were also accompanied by a chicken. If youre not familiar with the rubber chicken tradition at Brown CS, click here . It just seemed like a good idea laughs Layla. We were so excited about meeting the laureates and the incredible diversity of researchers. There were students from six different continents We decided it would be fun to take pictures of a Brown CS rubber chicken traveling the world, meeting people, and showing our pride at having four attendees. The chicken complied, dutifully posing for pictures with Vint Cerf and John Hopcroft, atop castles, on a boat trip, and even during an Oktoberfest celebration. A selection of photos is available here . Structured as a mix of presentations and social events, the Forums informal talks included sometimes unexpected advice Leslie Lamport told listeners that since they spend more time sending e-mail than doing anything else, they should edit each message as if looking to publish them and frequently had a galvanizing effect. After hearing John Hopcroft talk about changes in theory needed to support changes in our field, Max remembers, the whole room was energized, and he was swarmed by people. But wed already met him when he sat down to have lunch with us the day before, possibly because we were carrying a rubber chicken All three students note that while they were interested in finding peers with similar scientific interests Layla mentions that a new friend may soon be using an algorithm developed by Ben Raphaels group, delving deeper into ones own research area wasnt the conferences true rationale. HLF gives you a high-level perspective on worldwide research that you hadnt known was going on, and how the two disciplines benefit each other, such as computer simulations of mathematical work, notes Max. But the socialization and interaction are what makes it all approachable. Its where the real learning happens. Bringing a chicken everywhere also had some unexpected and positive consequences. Not only did the chicken start conversations, says Irina, It caused people to tell us stories about traditions at their universities. That made me proud that tradition is so strong here at Brown CS. It defines us. We have a real commitment to getting to know everybody in the department and collaborating, and we brought that spirit to the Heidelberg Laureate Forum. The next time you attend a conference, bring a chicken with you, take a picture, and send it to Jesse Polhemus jcpcs.brown.edu. Wed be glad to tweet about it with the BrownCSConferenceChicken hashtag", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS Finds A Unique Way To Celebrate Impressive Heidelberg Laureate Forum Representation"], "word_count": 639, "token_count_estimate": 773}}, "https://blog.cs.brown.edu/2014/06/04/michael-littmans-cs-music-videos-go-viral-receive-50000-views/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Michael Littmans CS Music Videos Go Viral, Receive 50,000 Views Posted by Jesse Polhemus on June 4, 2014 So awesome writes oneenthusiastic YouTube commenter. Way too much fun for machinelearning, adds another. For the past several years, Brown University Departmentof Computer Science professor Michael Littman has beenextending a family tradition of writing spoof songs by making music videos toreinforce concepts taught in his classes. I was always a big fan of Weird AlYankovic, Michael says, His gift for wordplay and ear for rhythm areunmatched. While teaching a class on artificial intelligence back in 2001,Billy Joels We Didnt Start The Fire provided Littman with inspiration tosummarize class topics XOR, learning rate, squash the sum and integrate andthe string of videos began. Theyre rapidly becoming a viralphenomenon. One frequently-retweeted video features Michael, professor CharlesIsbell of Georgia Tech, and a Georgia Tech vocal group. Its based on MichaelJacksons Thriller and focuses on the problem of overfitting in machinelearning. Its available here ,and is unique in that it was made with the help of a video editor. Most of mysongs have been weekend hacks with just me, Garage Band, iMovie, and Keynote,Michael explains. Another video available here , for CS 8, spoofsthe Queen song Flash and teaches about the programming language Scratch. Itfeatures the undergraduate teaching assistants from the class and a cameo fromMichael. Neither of them are as popular as his The Sorter video, which hasreceived 54, 225 views and is still climbing. Most of what I know about Englishgrammar and the U.S. Constitution comes from watching Schoolhouse Rock songsas a kid, Michael says. The experience taught me that some concepts stickbetter if theyre put to music. Why not computer science The full collection of videos can befound here .Take a look, share them with friends, and as anothercommenter says, Let your geek fly", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Michael Littman\u2019s CS Music Videos Go Viral, Receive 50,000+ Views"], "word_count": 316, "token_count_estimate": 436}}, "https://blog.cs.brown.edu/2014/07/22/anna-lysyanskaya-offers-ukraine-commentary-wpri/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Anna Lysyanskaya Offers Ukraine Commentary On WPRI Posted by Jesse Polhemus on July 22, 2014 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown CS Professor Anna Lysyanskaya was again interviewed by WPRIs Dan Yorke and offered a commentary on the situation in Ukraine. Video of the interview can be found at WPRIs web site .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Anna Lysyanskaya Offers Ukraine Commentary On WPRI"], "word_count": 99, "token_count_estimate": 127}}, "https://blog.cs.brown.edu/2014/10/21/brown-university-hosts-northeast-robotics-colloquium-nerc-delights-scientists-industry-and-children/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown University Hosts Northeast Robotics Colloquium NERC, Delights Scientists, Industry, And Children Posted by David Whitney on Oct. 21, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The Brown University Humans To Robots Lab, headed by Professor Stefanie Tellex, hosted the 2014 Northeast Robotics Colloquium last week. Drones that can deliver packages bumped up against robots that have already moved millions of greenhouse plants, and aerospace resins met 3D printers. The event was part conference, part trade-show, with a large poster session for academic groups, and booths for private robotic firms. Keynote speakers were Holly Yanco UMass Lowell, Bertram Malle Brown University, Joe Jones Harvest Automation, and Nicholas Roy MIT, Google. Each speaker covered a different aspect of moving robotics forward in terms of theoretical ability and practical integration in society. Holly Yanco described the NERVE Center, a 10,000 square-foot indoor testing center for mobile robots. The Center contains a National Institute of Standards and Technology NIST compliant course as well as proprietary water and indoor rain environments. Nicholas Roy spoke about accurate SLAM simultaneous localization and mapping with small drones, and his practical implementation of such techniques during his stay at Google X. While there, he lead Project Wing, a drone delivery program. Joe Jones, a veteran of both MIT and iRobot the company behind Roomba, described his new company, Harvest Automation, and its goal to automate jobs in the worlds greenhouses and nurseries. Specifically, they address the nurseries need to evenly spread thousands of potted plants across a surface. Where this job is considered to be one of the nurserys most unpleasant, Harvest Automations fleet of HV-100s have moved over 7 million plants without complaint. Attendees prepare for the next speaker Event sponsors were private robotics firms interested in facilitating skill transfer between groups, and recruiting students and researchers looking to move to industry. Turn-out was larger than expected, with over 150 people interacting at the venue, Browns Alumnae Hall. The space was amazing, said volunteer coordinator John Oberlin. It really allowed for a diversity of research interests to intermingle. His favorite moment My favorite demo was a group who were 3D printing using aerospace resins. Brown student Miles Eldon shows off his gesture and speech interpreter Overall, the hosts were very pleased with the strong response. I think it was really fun, said Stefanie. I think its good for undergrads and new graduate students to experience a conference, before theyve necessarily published a paper. It shows what research is all about, gets them plugged in. Many attendees were also pleased that children and families were invited. Stefanies two-year old son, Jay, had a great time at the conference. Im so excited that hes excited about robots. He loved seeing Keepon and Dragonbot, and he got to drive Kinovas Jaco arm. Keynote speaker Nicholas Roy, one of several attendees who wouldnt have come if families hadnt been invited, brought his wife and three kids to NERC. Their whole family really enjoyed the event. The kids now believe that all robots come from Rhode Island, he said later. A Keepon robot, which teaches empathy to children, lost in thought as it ruminates on the human condition", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:07+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown University Hosts Northeast Robotics Colloquium (NERC), Delights Scientists, Industry, And Children"], "word_count": 567, "token_count_estimate": 717}}, "https://blog.cs.brown.edu/2014/07/08/brown-cs-and-ccmb-enjoy-record-participation-ismb-2014/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS And CCMB To Enjoy Record Participation At ISMB 2014 Posted by Jesse Polhemus on July 8, 2014 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown University s Department of Computer Science Brown CS and Center for Computational Molecular Biology CCMB are looking forward to giving a record number of talks at one of the most prominent conferences in computational biology. Current and former students and post-docs of professor Ben Raphael presenting at the twenty-second annual International Conference on Intelligent Systems for Molecular Biology ISMB 2014 in Boston include Iman Hajirasouliha , Max Leiserson , Layla Oesper , Anna Ritz , and Hsin-Ta Wu , featuring work co-authored with Ahmad Mahmoody , Gryte Satas , and Suzanne Sindi . Ben credits the strong Brown CS representation to a little bit of fortunate timing and a lot of ongoing effort from a dedicated group of researchers. Its surprising that all these projects came together at the same time, he says, but it shows that we have a hard-working group with a strong culture of mentoring to help each person reach their full potential. Our small size requires excellence across the whole team, and Im proud that were able to compete successfully against much larger groups, not only in CS but also in medical schools and research institutes. Layla Oesper and Gryte Satas are happy denizens of what they consider to be a technological leading edge. Understandinganalyzing sequencing data from cancer genomes is a difficult task, they explain. There are many factors that make identifying the landscape of mutations in a heterogeneous tumor sample hard. Our algorithms are aimed at quantifying this type of information, an important first step in determining what mutations drive cancer. This wasnt possible even five years ago, and it lets us make use of the vast amount of data that has been accumulating. Were also looking forward to the inaugural Raphael Reunion they laugh, explaining that the conference will allow all of Bens current and former students to reunite in Boston. What do all these colleagues have in common Momentum, collaboration, and energy, says Layla. Theyre qualities that are evidently shared by their mentor. Ben is as passionate about our work as he is about his own, Gryte says. How does he find the time to sleep Ben shrugs. What makes me happy is that all these projects include multiple authors who are great team players. Because our group is part of a CS department, we can recruit people with strong skills in algorithm development and program design, which really gives us an edge. Max Leisersons collaborators, in addition to Raphael, include two researchers from Tel Aviv University. His highlight talk focuses on a paper they published a year ago, about an algorithm developed by Brown CS called Multi-Dendrix . Without prior information, it searches for genes with approximately exclusive mutations and high coverage in a cohort of tumors, which enables the identification of driver genetic pathways that cause cancer when mutated. Asked for his goals for the conference, Max says, Im looking forward to all the talks, the chance to learn from others. My biggest hope is that people will get excited about our results and even more cancer researchers will use our software. He explains that external researchers will have an even easier time using Brown CS tools in the future currently, some of the applications necessary to run Multi-Dendrix are proprietary and need to be purchased, but an upcoming transition to entirely open-source software will allow maximal ease of use. While working under Raphael, Iman Hajirasouliha, Anna Ritz, and Hsin-Ta Wus collaborators have included colleagues from the bioscience industry as well as academia Brown University and elsewhere. Hsin-Ta will present a paper on detecting copy number aberrations in cancer co-authored with Iman, and Iman will present a paper on intra-tumor heterogeneity co-authored with Brown CSs Ahmad Mahmoody. Both were among 29 papers directly accepted in the first round of peer reviews, out of 204 submissions. Only recently, Iman comments, have scientists realized that mutations that we formerly thought of collectively, such as breast cancer or lung cancer, actually vary considerably from person to person. Our task now is to characterize heterogeneous mutations across a tumor. Its a major step forward. Im really eager to introduce people at the conference to our new research about finding driver recurrent copy number aberrations, adds Hsin-Ta. Our new method has advantages in not only accurately identifying candidate copy number aberrations which could drive cancer but providing an algorithm which is simple and fast, and readily adaptable for high-throughput sequencing data. For us as computer scientists, in the future it will be exciting to apply this method to larger cancer datasets as more and more cancer patients are sequenced. Ritz and Hajirasoulihas shared research into structural variants across a single genome, not specific to a particular disease, was partially aimed at the challenges caused by software limitations. Second-generation sequencing platforms, Anna explains, are slow but quite accurate, with an error rate of one or two percent. Third-generation technology gives a more in-depth analysis, but has a fifteen percent error rate. Our algorithm is probabilistic, and it shows that combining the two platforms allows you to reduce the impact of errors while maximizing the third-generation benefits. Anna sees real parallels between Brown CSs progress in computational biology and the fields increasing opportunities Bens first year at Brown was my first year as a graduate student. His great ability to locate the next big problem is helping us make major contributions to the field. Just as one example, our results are helping overcome the hesitation about third-generation sequencing paradigms. If we can prove their worth, theyll get used, and medical progress will be made. Ben agrees. Its so exciting, he says, addressing prospective ISMB 2014 attendees and celebrating the members of the research group that hes put together. Were thrilled to be building on our long-term record of strength in this field, to share our results and demonstrate what a great environment we have for students of all levels. I hope my team gets to see the appreciation for their research. I think it will help them understand how much all their effort, day in and day out, has achieved.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS And CCMB To Enjoy Record Participation At ISMB 2014"], "word_count": 1084, "token_count_estimate": 1300}}, "https://blog.cs.brown.edu/2014/11/10/yurtatbrown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles YurtAtBrown Posted by Jesse Polhemus on Nov. 10, 2014 For more CS News and CS Blog articles about the Yurt, please click here . The YurtAtBrown hashtag documents a milestone, says Professor David Laidlaw of Brown Universitys Computer Science Department Brown CS. 2015 will be a landmark year for visualization at Brown and an evolutionary, transformative leap for the field. This leads to an obvious question other than a dwelling of the Central Asian steppes, what is the Yurt The Yurt YURT Ultimate Reality Theatre is the vastly-enhanced successor to Browns renowned virtual reality display, the Cave CAVE Automatic Virtual Environment, celebrated for its research, computing, and educational advancements in fields as diverse as archaeology, sculpture, and neuroscience. With the Yurt, David explains, our design goals were to match or exceed human perceptual abilities in every aspect of virtual reality by eliminating gaps, brightening colors, and increasing resolution. Remember how you felt when your phones display jumped to retinal quality Imagine standing in an entire room at that resolution, with pixels that are too small to see individually. Its world-class virtual reality. If you improved on any of our specifications, the human eye would almost never be able to detect it. As 2014 winds down, the Yurt is ramping up. The main wall is lit, and the software is blending images well, creating a 24x8 56-million-pixel 3D display. As both hardware doors being hung and protective floor surfaces laid and software image alignment, distributed execution, 3D projection, our VRG3D library, and ultimately applications like CavePainting, Cave Writing, and Adviser come online, Brown CS will chronicle the journey with behind-the-scenes photos, announcements, tweets, and videos that share the exciting progress step by step. You can take part by visiting the Brown CS homepage , Facebook , and Twitter follow browncsdept and look for the YurtAtBrown hashtag. We hope people of all backgrounds worldwide will journey with us as we head into, through, and beyond 2015, says David. This will be our year of experimentation, about pushing the limits. We dont want you to miss any of it, because every step we take is going to offer new ideas and opportunities that previously didnt exist. We want thought leaders running their software here, finding the best and highest uses for the Yurt so we can share them with the world. Any field can gain from the Yurts capabilities, and theres nobody who benefits from the arts, sciences, education or other disciplines who wont someday be impacted. Come join us", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "#YurtAtBrown"], "word_count": 432, "token_count_estimate": 558}}, "https://blog.cs.brown.edu/2015/01/14/gryte-satas-creates-new-opportunities-girls-code/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Gryte Satas Creates Opportunities For Girls To Code Posted by Jesse Polhemus on Jan. 14, 2015 in Diversity Described as a role model by her new colleagues atProvidence, Rhode Islands Rochambeau Library, Gryte Satas ,a PhD candidate at BrownUniversity s Department of ComputerScience , has just made a unique contribution to her community. Shesleading a new Girls Who Code Club, designed to provide young women withcomputer science and programming skills, as well as opportunities to learn abouteverything from cryptography to artificial intelligence to developing mobileapplications. The clubs mission is inspiration and education, equippinggirls with the skills to pursue 21st-century opportunities. Believed to be theonly public club of its kind in the state, its open to any girl from gradessix to twelve.The entire story isavailable at ProvidenceBusiness News .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Gryte Satas Creates Opportunities For Girls To Code"], "word_count": 143, "token_count_estimate": 193}}, "https://blog.cs.brown.edu/2014/12/17/brown-cs-brings-hour-code-130-kids/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS Brings An Hour Of Code To 130 Kids Posted by Elizabeth Hilliard on Dec. 17, 2014 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . For the second year in a row, Brown Computer Science brought an Hour of Code to Providence students at Nathan Bishop Middle School. Hour of Code is a global initiative run by Code.org to bring programming to everyone, especially young students and those that are underrepresented in computing. President Obama kicked off the weeklong event by learning to write some Javascript. This year Professor Amy Greenwald, graduate students David Abel, Amy Becker, Betsy Hilliard, Michael Majzoub seen in the photo above, and Jeff Rasley, and undergraduate Luke Camery, visited all ten Gateway to Tech classes more than 130 6th, 7th, and 8th graders at Nathan Bishop, and introduced them to the Scratch programming language. A handful of the students had some experience, having worked with us last year, but most were new to programming. After about ten minutes of formal instruction, the students were free to work on their own ideas, with us wandering around the classroom giving them input and answering their questions. Mike noted, The student projects were incredible -- ranging from cartoons to video games. I was amazed with how much they were able to do in just one class period. They were also great at helping one another out as they gained a greater understanding of the programming interface. Even more important than what they made or learned about Scratch, however, was what they realized about themselves. Amy Becker remarked, There seemed to be a mentality among the students that there was one right procedure...My favorite part of the experience was witnessing the transition as they went from asking me what the right way was, to exploring what they could make the program do on their own. They experienced the loss of inhibitions and fear of being wrong. It was awesome to watch a student who had been initially hesitant show me what they had figured out and take pride and ownership of their creation. For me, watching kids hit run on their first program is always a special moment. Its exciting to see the pure joy --joy in the creativity and joy in the empowerment-- when students realize they just programmed a computer. It reminds me why I got into Computer Science in the first place.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS Brings An Hour Of Code To 130+ Kids"], "word_count": 436, "token_count_estimate": 510}}, "https://blog.cs.brown.edu/2014/11/19/aaron-gokaslan-18-wins-hackprinceton-best-ios-app-award/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Aaron Gokaslan 18 Wins HackPrinceton Best iOS App Award Posted by Jesse Polhemus on Nov. 19, 2014 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . Brown University computer science concentrator Aaron Gokaslan 18 and a team of his peers have just won a Best iOS App award from Apple at the recent HackPrinceton hackathon, earning an iPad Mini and the envy of several hundred of the countrys best young computer scientists. The event, which has been held semiannually for a number of years, challenged students of all levels to join together and create unique software applications. I was confident, Aaron explains, but the competition was intense. I truly enjoyed it, regardless of the outcome, but I only slept a few hours that weekend. I was actually pretty surprised that we won For this particular award, participants were required to design the best all-around iOS application that relied solely on software as opposed to hardware. The criteria included functionality, design, and ease of use. Aaron and his teammates won for their application, Rabal , which functions as a universal translator. The name is an acronym of our teams first names Ryan Dunn, Aaron Gokaslan, Bryan Ngadimin, Alan Liu, and Leo Shimonaka, Aaron explains. Except over Facebook, I didnt know any of my team members before I arrived, and I met two of them over Chinese food the first night Rabal uses text-to-speech APIs powered by Nuance to transcribe and then translate audio powered by Google Translate. A server then posts translations on web pages that are accessible from any Internet-enabled device, including wearables. The application currently features eight languages, and Aaron notes that it could easily be extended to at least twenty-three. I had a great time meeting new people and seeing old friends, Aaron says of the event. It was exciting throughout we didnt even have a working model until a half-hour before the submission deadline and had to re-purpose one of my teammates websites to get the setup working. There were some really innovative hacks, and Im proud that we competed so well among them.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Aaron Gokaslan \u201918 Wins HackPrinceton Best iOS App Award"], "word_count": 374, "token_count_estimate": 462}}, "https://blog.cs.brown.edu/2015/01/28/outstanding-student-work-2014-flick-gabriel-fernandez/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Outstanding Student Work, 2014 Flick, By Gabriel Fernandez Posted by Jesse Polhemus on Jan. 28, 2015 As a department, how do we evaluate our success Continued innovation from our students means that weve aimed courses at the fields best opportunities, then taught them with real devotion to our craft. Together, that enables students to produce work that advances the state of the art. In this series, well showcase some of the outstanding student work of 2014 Flick designed by Gabriel Fernandez for CS 1300 Designing, Developing and Evaluating User Interfaces taught by Jeff Huang for Brown CS Gabriel describes his project by saying An application that runs on top of every other app on your Mac desktop, Flick answers the question of what a mouse without physical buttons would look like. It follows your mouse around, listening to all movement events. Once it has determined that some specific gesture has been made, it fires a click event that other applications, or even the OS, will capture. For a better understanding of how this works, look at the projects repo here httpsgithub.comcircuitlegoflick . Gabriel also notes that Flick currently supports the most used mouse operations Click, Double Click, Right Click, and Drag. You can watch a video of Flick being used here httpswww.youtube.comwatchv0LWpx5TRWjg .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Outstanding Student Work, 2014: Flick, By Gabriel Fernandez"], "word_count": 228, "token_count_estimate": 298}}, "https://blog.cs.brown.edu/2015/02/09/providence-journal-reports-hackbrown-2015/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles The Providence Journal Reports On Serious Innovation At HackBrown 2015 Posted by Jesse Polhemus on Feb. 9, 2015 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . Its just about building and doing something you love with people who are supportive and want you to succeed, says HackBrown contributor Ricky Medina. He and others were interviewed by the Providence Journal , which covered last weekends second annual Brown hackathon in this mornings edition. Their account of the serious innovation that occurred includes details of the proceedings, comments from attendees from across the country, and a video. Its available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "The Providence Journal Reports On \"Serious Innovation\" At Hack@Brown 2015"], "word_count": 125, "token_count_estimate": 151}}, "https://blog.cs.brown.edu/2015/02/02/cs015-reflection/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles CS015 A Reflection Posted by Jesse Polhemus on Feb. 2, 2015 by Emma Catlin Theres a lot of talk about how introductory classes discourage minorities, and making classes more friendly to those with little prior experience in coding is trending at universities. In one of Browns introductory computer science classes, CS015, I think a successful effort has been made to encourage women to continue coding. The class provides many women role models in the TAs, of whom about half are women. I also appreciated the fact that in the lecture on the history of computer science, just as many important women figures were included as male. Talking to students in CS017, another introductory computer science class, I heard similar experiences. While women were outnumberd by men, one student told me that she didnt feel like she was at a disadvantage because there were enough other women in the class. Also, she shared that the professor and the TAs made everyone feel included. Perhaps its necessary in these classes to reach a critical mass, along with other encouraging factors, to make sure minorities are not dissuaded. It seems like the critical mass has been achieved for women in these classes, but not necessarily for other minorities. What is it like to be a minority in an introductory computer science class When I reflect on my experience in CS015 last semester as someone who identifies as female, a minority among coders, I feel the class was welcoming. There was such a large number of students in the class that there was a diversity in backgrounds such as class year and coding experience more than 50 had never coded before. But while the amount of women in introductory classes such as CS015 may have reached critical mass, the numbers of other minority groups are still not there yet. Introductory classes still have a way to go to make everyone feel included, but I didnt feel discouraged from coding because I was a woman in CS015.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "CS015: A Reflection"], "word_count": 347, "token_count_estimate": 403}}, "https://blog.cs.brown.edu/2015/04/23/aaron-gokaslan-18-and-laura-shea-18-take-second-place-award-software-hackprinceton/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan 18 And Laura Shea 18 Posted by Jesse Polhemus on April 23, 2015 by Aaron Gokaslan 18 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . On April 12, 2015, Brown University students Laura Shea 18 a computer science and math concentrator and I also 18, a computer science concentrator came in second place in software at HackPrinceton. Our team, with fellow students Ergeta Muca and Anthony Lobko, designed a website to convert files into videos, which are then uploaded to YouTube. We pitched that this turns YouTube into free, unlimited cloud storage. The website, which were calling Osiris, uses python, ffmpeg, x264, Django, and Amazon web services. Osiris--the Egyptian mythological figure--suffered the fate of having his body cut into several pieces, scattered throughout Egypt, and then put back together. As our website supports video hosting sites in addition to YouTube, users can symbolically scatter and retrieve data in a similar manner. The website is currently offline while we work on moving some of the heavy computation. Laura and I met our teammates Ergeta and Anthony at the hackathon, and it was rewarding and enjoyable to work with new people. Coincidentally, I won an award in the fall with a different random team, and several of that teams members ended up in the same computer lab as we did To add to the parallelism, they won second place in hardware. All in all, the experience was unforgettable and adds to a successful Hackathon season for both Brown and myself.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan '18 And Laura Shea '18"], "word_count": 285, "token_count_estimate": 374}}, "https://blog.cs.brown.edu/2015/02/15/brown-cs-supports-browns-first-feminist-conference-ri-high-school-students/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS Supports Browns First Feminist Conference For RI High School Students Posted by Jesse Polhemus on Feb. 15, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Brown CS is proud to lend financial support to the FLAME Conference, Browns first feminist conference for Rhode Island high school students. FLAME will take place on Sunday, March 8, 2015 International Womens Day and feature a variety of workshops run by Brown student groups and faculty. Some workshop topics include gender inequality in the workplace, intersectionality, healthy relationships, and sexuality. The purpose of the conference is to provide an opportunity for feminist education to participants as well as to unite feminist-minded student groups at Brown. To learn more, click here to visit the FLAME Conference web site.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS Supports Brown's First Feminist Conference For RI High School Students"], "word_count": 165, "token_count_estimate": 198}}, "https://blog.cs.brown.edu/2015/03/18/cybersecurity-brown-undergraduates-win-it-all/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Cybersecurity Brown Undergraduates Win It All Posted by Jesse Polhemus on March 18, 2015 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . A team of Brown undergraduates from computer science, political science, and international relations has won the Cyber 912 Student Challenge, a national cybersecurity policy competition, says Science News Officer Physical Sciences Kevin Stacey, writing for News from Brown. No all-undergraduate team had ever won. You can read the full story of their historic win here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "Cybersecurity: Brown Undergraduates Win It All"], "word_count": 106, "token_count_estimate": 135}}, "https://blog.cs.brown.edu/2015/04/30/its-never-too-late-try-cs-enthusiastic-undergrads-tell-brown-classmates/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Its Never Too Late To Try CS, Enthusiastic Undergrads Tell Brown Classmates Posted by Jesse Polhemus on April 30, 2015 in Diversity This year alone, 771 Brown students took introductory CS classes. The rest are probably asking themselves What kinds of things can I do with a CS degree Can I do CS without concentrating in it Do I have to take a ton of math to do CS WHAT IS COMPUTER SCIENCE, ANYWAY To answer these questions, some of our undergraduates who took non-traditional paths in computer science created Its Never Too Late, a panel party designed to share their experiences and answer the questions of prospective CS students. It was held on April 10 at 4 PM, and if you missed it, a video of the entire event is available here . If you have any questions about taking a CS course, please contact Tom Doeppner , Director of Undergraduate Studies.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:08+00:00", "headings": ["Information for:", "Brown CS Blog", "It's Never Too Late To Try CS, Enthusiastic Undergrads Tell Brown Classmates"], "word_count": 168, "token_count_estimate": 207}}, "https://blog.cs.brown.edu/2015/03/16/brown-cs-sponsors-intracity-geeks-teach-programming-middle-school-children/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS Sponsors Afterschool Program To Teach Programming To Middle-School Children Posted by Jesse Polhemus on March 16, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . NBC 10 News has just recognized Brown CS and the Providence After School Alliance for their support of IntraCity Geeks, an after-school program that teaches programming skills to local public school children at Nathan Bishop Middle School. The full story is available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS Sponsors Afterschool Program To Teach Programming To Middle-School Children"], "word_count": 110, "token_count_estimate": 134}}, "https://blog.cs.brown.edu/2015/03/10/providence-ranked-americas-eighth-best-college-town-people-who-arent-college/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Providence Ranked Americas Eighth Best College Town For People Who Arent In College Posted by Jesse Polhemus on March 10, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Cond Nast Traveler has just ranked Providence as Americas eighth Best College Town for People Who Arent in College. The full story is available here . photo by Will Hart, used under Creative Commons", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Providence Ranked America's Eighth Best College Town For People Who Aren't In College"], "word_count": 89, "token_count_estimate": 107}}, "https://blog.cs.brown.edu/2015/03/24/hcri-and-ri-students-future-announce-second-ri-robot-block-party-showcase-how-robots-are-used-education-research-work-and-play/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles HCRI And RI Students Of The Future Present RI Robot Block Party, A Showcase Of Robots In Education, Research, Work, And Play Posted by Jesse Polhemus on March 24, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . The Robot Block Party is a celebration of National Robotics Week held on April 11, 2015 at the Pizzitola Center at Brown Uni versity. Organized by Rhode Island Students of the Future, a non-profit organization that engages kids in science, technology, engineering and math through robotics, and the Humanity Centered Robotics Initiative at Brown University, the Robot Block Party showcases how robots are used in education, research, work and play. Exhibitors include University Exhibits and Demonstrations RISD students will demonstrate the rover they built for the 2015 NASA Human Exploration Rover Challenge. The Brown Robotics Lab will demonstrate cloud robotics technologies and quadrotor and telepresence robots. Brown University Planetary Geosciences and NASA Solar System Exploration Virtual Institute SSERVI. The SSERVI Evolution and Environment of Exploration Destinations SEEED team is hosted by Brown University and MIT. NASA and international space probes are exploring all the planets of the solar system and will reach Pluto this summer. Come see pictures of Mars from the sophisticated Curiosity rover, and share close-up images of the surface of a comet. Meet scientists from Brown University who are exploring the planets and satellites of the Solar System and learn of their discoveries and future plans for human and robotic exploration Human 2 Robot Lab will demonstrate the pick and place capabilities of the Baxter industrial robot, created by Rethink Robotics. The Laboratory for Engineering ManMachine Systems Computer Vision LEMS will display their Blindfind project. The Brown IEEE Robotics Olympiad Micromouse competition will hold their annual competition at the Robot Block Party. University of Rhode Island Graduate School of Oceanography will display the autonomous kayak and Lagrangian floats used to explore shallow coastal waters. The URI RoboBoat team and the Robotics Laboratory for Complex Underwater Environments R-CUE will team up to display the URI Autonomous Surface Vehicle a pair of flying robots at least two underwater robots and a variety of soft robotics prototypes use for underwater grasping and manipulation. Roger Williams University School of Engineering, Computing and Construction Management will demonstrate a student built, human scale mobile robot allowing for virtual telepresence. Salve Regina University School of Business Studies and Technology will display student technology projects. New England Institute of Technology will have a demonstration of robotics, quad-copters, and support products. Manufacturing and Community Organizations Hasbro will demonstrate their animatronic toy line, FurReal Friends. igus, inc will display their movement machine and iglide and echain products. The Rhode Island Computer Museum will present Robots on the Run an activity that explains basic circuits and programmable electronics in hobby robots. FabNewport will demonstrate ArtBots that create original works of art. IEEE Providence Section will demonstrate their role in the robotics industry and professional development of engineers. The Providence Childrens Museum will provide the Rigamajig play area which encourages hands on exploration of mechanical design concepts. BLT Robotics will display a Robotic Vertical Hydroponic Farm. Members of Makes book publishing team will be joining the Robot Block Party to show off projects from some of our recent and soon-to-be-published books. Theyll have hands-on interactive projects you can play with from our upcoming Getting Started with littleBits book, some 3d-printed-in-place objects, and some Raspberry Pi demos. AS220 Labs is showing a new line of electronics kits and some drawing machines from the Lab. Robotix Learning Solutions will demonstrate their affordable robot that helps teach kids 4-18 years how to code in an easy and interactive way. Student Exhibits Coventry Alan Shawn Feinstein Middle School students built a robotic claw that can pick up a ball and a Chain Reaction Machine. East Greenwich Our Lady Of Mercy School has over 30 students building autonomous parade floats and interactive robotics projects. The students range from age 6-12. East Providence Martin Middle School has middle school students building autonomous parade floats and interactive projects. Riverside Riverside Middle School students are building autonomous parade floats, and interactive projects. Gordon School students are working on interactive robotics projects and a Chain Reaction Machine. MiddletownNewport Newport Community School is bringing students who built autonomous parade floats. All Saints STEAM Academy students are displaying their Arduino robots and several other interactive projects. Their Jr. FIRST LEGO League team will demonstrate their Think Tank project. The Aquidneck Island 4-H club runs robotics programs for kids aged 9-18. AIR Strike 78, their FIRST Robotics team will demonstrate their award-winning robot. Providence Providence Career and Tech Academy will demonstrate engineering and robotics projects completed by their engineering students. Wheeler School will exhibit projects built by lower and middle school students. FRC 2780 Robotics Team, based at Wheeler School, will demonstrate their FIRST Robotics Robot. Lincoln School will demonstrate Tetrix robots built by the Robotics I II classes, plus a demonstration of our FIRST Tech Challenge bot with field elements from the 2015 FTC game, Cascade Effect. Mount Pleasant High School will demonstrate their student robotics projects. Nathan Bishop Middle School will demonstrate their student robotics projects. The College Crusade is a community-based robotics teams, composed of Cranston Providence youth. They will demonstrate a rover. Narragansett The Pier School will exhibit classroom robotics projects. Warren Kickemuit Middle School is building a chain reaction machine. West Warwick 21st Century Community Learning Center, YMCA at John Deering Middle School will feature students demonstrating autonomous parade floats. Many thanks to our sponsors and supporters National Grid Humanity Centered Robotics Initiative at Brown University Brown-MIT SSERVI-SEEED SAIC igus, inc. Textron Charitable Trust Polaris MEP MAKE 3d Printing Providence", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "HCRI And RI Students Of The Future Present RI Robot Block Party, A Showcase Of Robots In Education, Research, Work, And Play"], "word_count": 981, "token_count_estimate": 1223}}, "https://blog.cs.brown.edu/2015/05/15/learn-about-yurt-optical-tracking-innovation-80-second-video/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Learn About Yurt Optical Tracking Innovation In An 80-Second Video Posted by Jesse Polhemus on May 15, 2015 For more CS News and CS Blog articles about the Yurt, please click here . As we get ready for next weeks Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT symposium click here for details, were taking a moment to tell some of the most interesting stories from the Yurts creation. In this 80-second video , PhD student Johannes Novotny explains a challenge that the team faced with the Yurts optical tracking system and their profoundly creative solution.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Learn About Yurt Optical Tracking Innovation In An 80-Second Video"], "word_count": 115, "token_count_estimate": 149}}, "https://blog.cs.brown.edu/2015/05/18/artemis-alumna-keeps-looking-opportunities-code/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Artemis Alum Keeps Looking For Opportunities To Code Posted by Jesse Polhemus on May 18, 2015 in Diversity Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . BREAKING NEWS Brown CS is proud to report that Louisa has just been declared a Kode with Karlie Scholarship winner. Congratulations, Louisa Profiles of the 2015 scholars are available here . -- Most people, says 14-year-old Louisa Bay, think coding is boring and for boys. I know theyre wrong. By winning the Kode with Karlie Scholarship, I will have the tools I need to change the world. Few things are more satisfying for the Brown CS family than seeing graduates of the Artemis Project our free, five-week summer day camp for rising 9th-grade girls in the Providence area who are interested in learning about science and technology continue what we hope will become a lifelong pursuit of computer science. After an awesome experience with Artemis, Louisa was inspired to start a Coding Club in her high school, but resources have been scarce. To help turn that around, shes competing for the Kode with Karlie Scholarship, which gives 20 girls across the country free tuition to Flatiron Pre-College Academys Introduction to Software Engineering course. You can watch her 90-second video application here . Brown CS wishes her all the best. Good luck, Louisa", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Artemis Alum Keeps Looking For Opportunities To Code"], "word_count": 255, "token_count_estimate": 319}}, "https://blog.cs.brown.edu/2015/05/26/digital-den-cites-brown-cs-well-recognized-vr-leader/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Digital Den Cites Brown CS As A Well Recognized VR Leader Posted by Jesse Polhemus on May 26, 2015 For more stories on why Brown CS is so great, check out our Praise for Brown CS page here . For more CS News and CS Blog articles about the Yurt, please click here . Digital Den recently toured the Yurt as part of last weeks Visualization and Creativity in Immersive 3D Environments From Cave to YURT symposium, describing it as a wonderful event...fascinating. You can read the whole article here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Digital Den Cites Brown CS As A \"Well Recognized\" VR Leader"], "word_count": 106, "token_count_estimate": 136}}, "https://blog.cs.brown.edu/2015/05/19/cave-and-yurt-featured-ri-nsf-epscor-magazine/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Browns Cave And Yurt Featured In RI NSF EPSCoR Magazine Posted by Jesse Polhemus on May 19, 2015 For more CS News and CS Blog articles about the Yurt, please click here . As the countdown to the Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT symposium continues and excitement about the Yurt grows, the online magazine of Rhode Island National Science Foundation NSFs Experimental Program to Stimulate Competitive Research EPSCoR has taken notice. Take a look at page 22 of The Current to learn more.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown's Cave And Yurt Featured In RI NSF EPSCoR Magazine"], "word_count": 105, "token_count_estimate": 138}}, "https://blog.cs.brown.edu/2015/08/18/brown-cs-continues-earn-high-ratings/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Alums Continue To Innovate And Pioneer Posted by Jesse Polhemus on Aug. 18, 2015 Brown CS alums continue to earn praise as successful innovators and industry pioneers. Click these links to learn more Brown University Master Of Science In Cybersecurity Alum Bill Marino Is A Fulbright Finalist Brown CS Student Artem Agvanian And Alum Hannah Gross Earn First And Second Place SOSP Student Research Honors A Guided Tour Of The Brown CS Digital Archive Michael Littmans New Book Recommends That We Code To Joy In A New Age Of Programming Michael Littman Receives The AAAIEAAI Patrick Henry Winston Outstanding Educator Award 13 Of 88 Papers In Volume 2 Of SIGGRAPHs Seminal Graphics Papers Are By Brown CS Faculty, Students, And Alums Brown CS Alum John Stasko Receives An IEEE VGTC Lifetime Achievement Award Philip Klein And Brown CS Alums Receive The 2023 STOC Test Of Time Award Brown CS Alum Atul Butte Has Been Named An AAAS Fellow Look Where Our 2023 Graduates Are Headed Brown CS Alum Ani Kristo And Collaborators Are 2022 Sort Benchmark Winners Brown CS Alum Nick Leiserson Has Been Named The White Houses Assistant National Cyber Director For Cyber Policy And Programs Seny Kamara And Charalampos Papamanthou Win The 2022 CCS Test-Of-Time Award Laidlaw, van Dam, And Two Brown CS Alums Win An IEEE CGA Test Of Time Paper Award Diverse Career Paths How Brown CS Alum Edwina Rissland Has Melded Math, CS, And Law Honored With Endowed Professorships In His Name, Brown CS Alum Ed Lazowska Reflects On His Time At Brown Brown CS Alum Danfeng Yao Has Been Named An IEEE Fellow Brown CS Alums Steven Shi And Alyssa Cantu Receive NSF CSGrad4US Fellowships Diverse Career Paths Brown CS Alum Tatyana Dyshlova Talks Starting Companies, Building Games Brown CS Adopts Software Created By Alum Gaurav Manek To Improve PhD Visit Logistics Brown CS Graduates Build An Online Learning Community For URM Students Kamara, Moataz, And MongoDBs Queryable Encryption Lets Data Stay Protected During Search Five Brown CS Students And Alums Receive NSF Graduate Resesarch Fellowships Three Brown CS Alums Join FASPEs 2022 Design And Technology Program Brown CS Adopts Software Created By Alum Gaurav Manek To Improve PhD Visit Logistics Brown CS Alum David Abel Is A Joint AAAIACM SIGAI Doctoral Dissertation Award Runner-Up Brown CS Alum Guillaume Marceau And Professors Fisler And Krishnamurthi Win The Onward 2011 Most Notable Paper Award Brown CS Alum Jina Yoon Receives An NSF CSGrad4US Fellowship Diverse Career Paths Brown CS Alum Eleanor Tursmans Fellowship Integrates Tech Into Policy Brown CS Alum Irv Lustig Has Been Named An INFORMS Fellow A Brown CS Team Takes Third Place At The Thirteenth AIMMS-MOPTA Optimization Modeling Competition Brown CS Alum Scott A. Smolka Wins The 2021 Edsger W. Dijkstra Prize In Distributed Computing Learnable.ai, Founded By Brown CS Alum Guan Wang, Is Named A World Economic Forum Technology Pioneer Alum Dr. Barbara Gershon Ryder Brown 1969 Wins NCWITs Harrold And Notkin Research And Graduate Mentoring Award Diverse Career Paths Brown CS Alum Sky Adams Aims To Increase Diversity In K-12 CS Diverse Career Paths Brown CS Alum Sharon Lo Ponders How Products Can Harm Society Alum Entrepreneurs Genevive Patterson Brings AI-Powered Video Editing To Millions Diverse Career Paths Brown CS Alum Karen Smith Catlin Helps Build Better Allies Diverse Career Paths Brown CS Alum Morgan McGuire Makes An Impact In Academia And Industry Brown CS Alum Mneera Abdullah Saud Is A 2021 Rhodes Scholar Brown CS Alums Charity Gives K-12 Teachers A Second Monitor To Help During COVID Brown CS Alums And Adjunct Faculty Win The Longuet-Higgins Prize And The PAMI Young Researcher Award Brown CS Students, Faculty, And Alums Publish Seven Papers At SIGMOD 2020 Brown CS Alum Jacob Beck Creates Aggregated Memory For Reinforcement Learning Brown CS Faculty And Alums Win Facebook Privacy Research Awards Brown CS Alum Thomas Dickerson Helps Replicate Brown In Minecraft For Virtual Visitors Brown CS Alum Feng-Hao Liu Wins An NSF CAREER Award New Research May Help Bring About Significant Blockchain Speedups Krishnamurthi And Multiple Alums Win An OOPSLA Most Influential Paper Award For Flapjax Brown CS Alum Evan Wallace Has Been Named An INC 2019 Rising Star Brown CS Alum Victoria Chvez 18 Makes An Impact On The Rhode Island Community Brown CS Alum danah boyd Wins An Electronic Frontier Foundation Pioneer Award Alum Aimee Lucido Publishes A Young Adult Novel About Her Two Loves Coding And Writing Robert Sedgewick, Brown Alum And Former Faculty Member, Wins ACMs Outstanding Educator Award Alum Adventures Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects Brown CS Masters Alum Prabhat Breaks The Exaflop Barrier And Wins ACMs Gordon Bell Prize Servan-Schreiber, Riondato, And Zgraggen Have Been Named Runners-Up For ICDMs Best Student Paper Award danah boyd Has Been Named Among Forbes Top 50 Women In Tech Mentor Alum Deb Mills-Scofield Inspires And Empowers Brown Students PhD Alum Jonathan Mace Earns Honorable Mention For The Dennis M. Ritchie Doctoral Dissertation Award Shriram Krishnamurthi And Collaborators Have Won The SIGPLAN Software Award For Work On Racket Alum Adventures Harry Li Helps The Chan Zuckerberg Initiative Improve K-12 Education Alum Adventures Andrew Ayer Keeps Certificate Authorities Honest With Certificate Transparency Brown CS Alum James Hendler Has Been Honored By The Association Of Moving Image Archivists Brown CS Alum Aimee Lucido Speaks Out About Industry Sexism Pedro Felzenszwalb And Alum David Blei Talk About AI With The ACM Alum Sarah Sachs Tackles Impostor Syndrome With A Little Help From Michelle Obama Brown CS Alum Hoon Ik Chang Has Been Named A 2017 Schwarzman Scholar Brown CS PhD Alums Continue To Impress Us With Their Various Accomplishments Brown CS Alum Sridhar Ramaswamy, SVP Of Advertising And Commerce At Google, Receives The Horace Mann Medal The Atlantic Features Brown CS Alum Lyla Fujiwaras Use Of CS In The Peace Corps Brown Alumni Magazine Features CS Alum Scott Anderson TechCrunch Features Former Student Dylan Fields Design Collaboration Tool, Figma Brown CS Alum Jack Stankovic Receives University Of Virginias Distinguished Scientist Award Brown CS Alum Michael Horn 97 Wins An NSF Grant To Bring Programming To Museums And Homes I Learned A Different Definition Of Success Peter Norvig 78 Remembers Studying CS At Brown Brown Ranks 8 For Graduating Female Founders Of VC-Funded Companies LinkedIn Rates Brown CS 1 For Launching Graduates Into Successful Software Development Careers Brown Rated 3 In USA For Software Developers At Startups Alum Adventures Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects danah boyd Has Been Named Among Forbes Top 50 Women In Tech Brown CS Alums Jacob Beck And Zoe Papakipos Have Been Published In New Scientist For Work On Autonomous Driving Brown CS Alum Victoria Chvez 18 Makes An Impact On The Rhode Island Community", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Alums Continue To Innovate And Pioneer"], "word_count": 1163, "token_count_estimate": 1631}}, "https://blog.cs.brown.edu/2015/05/28/michael-littman-quoted-libertarian-republic-risks-ai/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Michael Littman Quoted By The Libertarian Republic On The Risks Of AI Posted by Jesse Polhemus on May 28, 2015 Heres a provocative question What do actual AI researchers think of the risks of AI Ramez Naam of The Libertarian Republic notes that Elon Musk, Stephen Hawking, and Bill Gates have all expressed recent concern about killer AI scenarios despite having a lack of AI expertise. Instead, he turns to Michael Littman of Brown CS and three of his peers in the field. Dread predictions of computers suddenly waking up and turning on us, Littman comments, are simply not realistic. The entire article is available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "Michael Littman Quoted By The Libertarian Republic On The Risks Of AI"], "word_count": 122, "token_count_estimate": 153}}, "https://blog.cs.brown.edu/2015/06/10/gq-raves-about-providence-worlds-tiniest-state-pops-out-coolest-city/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles GQ Raves About Providence The Coolest City Posted by Jesse Polhemus on June 10, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Continuing a multi-year trend, rave reviews of Providence continue to roll in. This time, GQ cites Brown as one of three contributors to an intimidatingly smart city, waxing lyrical on the subjects of food, caffeine, and Lovecraft. The full article is available here . Photo by Jef Nickerson, used under Creative Commons License By 2.0", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:09+00:00", "headings": ["Information for:", "Brown CS Blog", "GQ Raves About Providence: \"The Coolest City\""], "word_count": 104, "token_count_estimate": 138}}, "https://blog.cs.brown.edu/2015/06/23/vrfocus-praises-yurts-boundless-potential/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles VRFocus Praises The Yurts Boundless Potential Posted by Jesse Polhemus on June 23, 2015 For more CS News and CS Blog articles about the Yurt, please click here . Biology, math, computer science, archaeology, astronomy, art, poetry, and video gaming are just some of the areas that Peter Graham of VRFocus sees the Yurt Brown Universitys new fully immersive 3D virtual reality environment benefiting with its boundless uses. He notes the Yurts improvements upon its predecessor, explaining how its ability to surround the viewer with imagery from all directions offers opportunities to numerous disciplines fully maximise its potential . VRFocus hopes to devote more of its coverage to the Yurt soon. The entire article is available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "VRFocus Praises The Yurt's \"Boundless\" Potential"], "word_count": 133, "token_count_estimate": 172}}, "https://blog.cs.brown.edu/2015/06/12/john-hughes-delivers-invited-lecture-college-de-france/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles John Hughes Delivers An Invited Lecture At The Collge De France Posted by Jesse Polhemus on June 12, 2015 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . There are plants that bloom once a century, and sometimes the right city --this time the one called La Ville Lumire for both its intellectual contributions and early adoption of street lighting-- and the right person can here and now, from blank canvas, evoke the spirit of a science and an art in transition. This time its John Hughes, who strode the Quartier Latin with the words of Cyrille Aime and maybe the crumbs of a financier aux pistaches on his tongue to deliver an invited lecture The Media Transition in Expressive Rendering and Modeling at one of the worlds great bastions of pure learning, the Collge de France. This history of expressive rendering and modeling, he explains, is largely one of imitation we make paintings in the style of Monet, cartoons like Dr. Seuss, watercolors, mosaic tile images, and so on. In each case, problems in representing or simulating the medium require that we be ingenious or devious or both line drawings have aliasing problems watercolors require stable but fast fluid simulation, etc. A few recent papers suggest a new and very promising divergence from this path a search for media that are intrinsically suited to the kinds of representations and interactions that are natural both for a human and a computer rather than those that are naturally occurring in the physical world. I will discuss this evolution, some of the potentials of such new media in both rendering and modeling, and some of their potential pitfalls as well. Photo by LPLT Wikimedia Commons", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "John Hughes Delivers An Invited Lecture At The Coll\u00e8ge De France"], "word_count": 325, "token_count_estimate": 384}}, "https://blog.cs.brown.edu/2015/08/18/brown-ranks-8-graduating-female-founders-vc-funded-companies/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown Ranks 8 For Graduating Female Founders Of VC-Funded Companies Posted by Jesse Polhemus on Aug. 18, 2015 in Diversity For more stories on why Brown CS is so great, check out our Praise for Brown CS page here . Brown CS alumni continue to rank highly as industry pioneers. Click here for a list of related stories. CrunchBase has just concluded its first report on female founders of VC-funded companies. Among other findings, it reveals that their representation nearly doubled between 2009 and 2014. After adjustment based on overall enrollment, Brown ranks eighth in schools graduating female founders, eclipsing competitors such as Cornell University and New York University. The entire story is available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown Ranks #8 For Graduating Female Founders Of VC-Funded Companies"], "word_count": 131, "token_count_estimate": 165}}, "https://blog.cs.brown.edu/2015/08/21/christian-mathiesen-and-teammates-take-first-place-linkedins-intern-hackday/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Christian Mathiesen And Teammates Take First Place At LinkedIns Intern Hackday Posted by Jesse Polhemus on Aug. 21, 2015 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . At LinkedIns 5th Annual Intern Hackday this summer, Brown CS graduate student Christian Mathiesen and his teammates competed against 75 other teams to take first place and bring home the 10,000 grand prize scholarship. Their winning design, Handoff, is a Google Chrome extension that allows multiple users to share online accounts without compromising each individuals login information. Services currently supported by Handoff include Netflix, the New York Times , and HBO, among others. For Christian, the LinkedIn Hackday was a valuable extension of the community fostered by Brown CS. Our team consisted of students I had only known for a few weeks, but somehow we still managed to coordinate, plan, and build our product in less than 24 hours, he says. The consequent strong bond between team members is one of the reasons why the Brown CS community also encourages hacking, suggests Christian. Its not about winning of the product itself. What matters most are the relationships you build. For Team Handoff, the relationship built during those 24 hours continues beyond the LinkedIn headquarters in Mountain View, California. The group is continuing development on the extension, rechristened Asterisks in honor of password fields, which will be released as a beta later this month. You can read more about the full extension on their website andor download the extension directly from the Chrome Web Store . All five group members remain on board Eric Brownrout Northwestern, Clement Fung Waterloo, George Lok Harvard, Fernando Trujano MIT, and Christian. Read more from the team members themselves over at Medium to hear how it all started with a GroupMe message. The official LinkedIn blog release can be found here . From left to right in the photo above Akshay Kothari VP of Product, LinkedIn Christian Mathiesen Brown, Fernando Trujano MIT, Eric Brownrout Northwestern, Matt Huang Partner at Sequoia Capital, George Lok Harvard, Clement Fung Waterloo, James Beshara CEO, Tilt", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Christian Mathiesen And Teammates Take First Place At LinkedIn\u2019s Intern Hackday"], "word_count": 368, "token_count_estimate": 468}}, "https://blog.cs.brown.edu/2015/09/11/read-more-brown-around-world/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Around The World Posted by Madeline DiGiovanni on Sept. 11, 2015 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. To read more, click on these links Franco Preparata Will Be The Keynote Speaker At An Upcoming Collge De France Symposium The Humans To Robots Lab Contributes To A New Exhibit At Londons Science Museum Shriram Krishnamurthi Will Receive An Honorary Doctorate From Universit Della Svizzera Italiana Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers John Savage Delivers Remarks On Cyberspace As A Medium At The Third World Internet Conference John Savage Meets With Vietnams President And Thought Leaders To Improve The Countrys Cybersecurity Esha Ghosh And Tarik Moataz Have Been Chosen For The 2017 IEEE Security And Privacy Student Program Committee Tim Edgar Talks With TIME About The Recent Widespread Internet Infrastructure Attacks John Savage Joins Boston Global Forums Board Of Thinkers And Works To Combat Cyberattacks In Vietnam Seny Kamara Has Been Chosen As A Boston Global Forum Dukakis Fellow Tim Edgar Speaks Out On Behalf Of A Presidential Pardon For Edward Snowden Tim Edgar Travels To Germany To Testify In The Snowden Inquiry Congressional Quarterly Roll Call Documents John Savages Contribution To A Historic International Cybersecurity Agreement Students Senior Thesis Becomes Gates Foundation-Funded Project TAG Touch Art Gallery Student And Community Education With A Worldwide Impact John Savages Recommendations For Securing Cyberspace Have Been Presented To The Japanese Government For The Upcoming G7 Summit New Opportunities In CS An SMS-Based Commodity Exchange In Ghana The Atlantic Features Brown CS Alum Lyla Fujiwaras Use Of CS In The Peace Corps Encryption Cant Make 225, Says Anna Lysyanskaya In Le Nouvel Observateur Timothy Edgar Proposes A Review Of Europes Counterterrorism Policies John Savage Is Awarded A New Patent And Travels To The Munich Security Conference John Savages Participation At The World Internet Conferences Wuzhen Summit Airs On Chinese Television John Hughes Delivers An Invited Lecture At The Collge De France Brown CS Finds A Unique Way To Celebrate Impressive Heidelberg Laureate Forum Representation Brown CS And CCMB To Enjoy Record Participation At ISMB 2014 Anna Lysyanskaya Offers Ukraine Commentary On WPRI Pascal Van Hentenryck Receives Docteur Honoris Causa from lUniversite de Nantes Brown University and National University of Singapore Launch Second Concurrent Degree Program Photo by LPLT Wikimedia Commons", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Around The World"], "word_count": 416, "token_count_estimate": 554}}, "https://blog.cs.brown.edu/2015/09/11/read-more-community-outreach-connects-brown-cs-students-providence-area/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Community Outreach Connects Brown CS Students To The Providence Area Posted by Madeline DiGiovanni on Sept. 11, 2015 in Diversity Every year for decades, Brown CS has taught and inspired students in the greater Providence community through outreach to schools and summer programs. To learn more, click on these links Brown CS Alums Charity Gives K-12 Teachers A Second Monitor To Help During COVID Tellexs Outreach Inspires A High School Student To Study CS, Then Teach Brown CS Supports Browns First Feminist Conference For RI High School Students Brown CS Brings An Hour Of Code To 130 Kids Brown University Hosts Northeast Robotics Colloquium NERC, Delights Scientists, Industry, And Children Students Bootstrap Algebra From Video Games Gryte Satas Creates Opportunities For Girls To Code Middle Schoolers get tour of Robotics Lab for Brown 250 Celebrations Artemis Alum Keeps Looking For Opportunities To Code HCRI And RI Students Of The Future Present RI Robot Block Party, A Showcase Of Robots In Education, Research, Work, And Play Brown CS Sponsors Afterschool Program To Teach Programming To Middle-School Children Artemis 2013 Middle-schoolers are ready, ready, ready for programming adventure Photo courtesy of Brown CS", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Community Outreach Connects Brown CS Students To The Providence Area"], "word_count": 208, "token_count_estimate": 269}}, "https://blog.cs.brown.edu/2015/09/11/read-more-funding-successes-brown-cs-community-members/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Community Members Continue To Win Noteworthy Grants And Awards Posted by Madeline DiGiovanni on Sept. 11, 2015 Brown CS community members continue to win noteworthy grants and awards. To read more, click on these links Tim Kraska Is The Winner Of The University-Wide Early Career Research Achievement Award Maurice Herlihy Is The Winner Of The University-Wide Research Innovation Award Philip Klein Wins NSF Grant For Optimization In Planar Graphs And Beyond Sorin Istrail Receives NSF Grant For Haplotype Reconstruction Algorithms Ben Raphael and Eli Upfal Receive NSF Grant to Develop Techniques for Analysis of DNA Sequence Variants Stan Zdonik and Ugur Cetintemel Receive NSF Grant to Develop Data Management System for Massive Scale Scientific Data Sharp Labs Provides Grant to Andy van Dam and his Research Team Eli Upfal Receives Faculty Research Grant from Yahoo Research Ben Raphael Awarded NIH Grant to Develop Computational Techniques to Study Structural Variation Ben Raphael Awarded NSF CAREER Grant Brown awarded 1.5M for new Big Data tools Jeff Huang Wins NSF CRII Grant And Salomon Award Philip Klein, Claire Mathieu and Ph.D. Alum Glencora Borradaile Receive NSF Grant to Develop New Algorithms for Solving Optimization Problems on Planar Networks BU, Brown and UC Irvine receive 3 million NSF grant Photo courtesy of Brown CS", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Community Members Continue To Win Noteworthy Grants And Awards"], "word_count": 229, "token_count_estimate": 295}}, "https://blog.cs.brown.edu/2015/09/11/read-more-students-continue-excel-hackathons/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Students Continue To Excel In Hackathons And Competitions Posted by Madeline DiGiovanni on Sept. 11, 2015 Brown CS students excel in hackathons and other competitions around the nation and have earned numerous accolades. To learn more, click the links below. If youre looking for news about our students winning awards and fellowships, click here . Brown CS Undergraduates Advance To The International Collegiate Programming Contest Nationals Brown CS Undergrads Take Third At ACMs International Collegiate Programming Contest Regionals And Advance To The Nationals David Armanious And Jared Siskin Are Among CyberStarts Top 10 Scorers Nationwide Brown CS TAs Of CS 15 Win Second Place At HealthHacks RI Hackathon Brown CS Students Make Another Strong Showing At The Third Annual Cyber 912 Student Competition Two Teams Will Represent Brown In Microsofts Build The Shield Competition Two Brown CS Teams Win CyberSEED Prizes Brown CS Students Win Three Awards At HackMIT Christian Mathiesen And Teammates Take First Place At LinkedIns Intern Hackday Cybersecurity Brown Undergraduates Win It All Aaron Gokaslan 18 Wins HackPrinceton Best iOS App Award The Providence Journal Reports On Serious Innovation At HackBrown 2015 Chad Jenkins And His Team Help Develop NASA Software HackBrown 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan 18 And Laura Shea 18 Brown CS Takes First And Ninth Place At CyberSEED Cybersecurity Competition BrownCS Students Win Best Teamwork Award Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyuandai Visionary Challenge", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Students Continue To Excel In Hackathons And Competitions"], "word_count": 261, "token_count_estimate": 355}}, "https://blog.cs.brown.edu/2015/09/12/read-more-yurtbrown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More The Yurt At Brown Posted by Madeline DiGiovanni on Sept. 12, 2015 The Yurt, Brown University s newest 3D virtual reality environment, launched in 2015 and has earned worldwide praise. To read more, click on these links From Medicine To Mars Virtual Reality And The Future Of Data Visualization Seeing The World In A New Way Channing Gray Explores The Yurt Brown Medicine Reports The Yurt To Be Part Of The Next Frontier In Training Surgeons, Planning Medical Treatment, And More A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology Tom Sgouros Brings The Yurt To Life For GPU Technology Conference Attendees National Science Foundation Director Visits Brown The NYT Steps Into Virtual Reality And Finds The Yurt Inspiring A Virtual World Ready To Be Utilized, Motif Magazine Raves About The Yurt Brown Daily Herald Takes Readers Into Another World Inside The Yurt Brown News Investigates The Yurts Advantages For Scientific And Artistic Exploration The Future Of Virtual Reality Has Arrived, Providences East Side Monthly Raves About The Yurt Dazzling The Boston Globe Attends The Yurts Launch And Inaugural Symposium VRFocus Praises The Yurts Boundless Potential Digital Den Cites Brown CS As A Well Recognized VR Leader Browns Cave And Yurt Featured In RI NSF EPSCoR Magazine Learn About Yurt Optical Tracking Innovation In An 80-Second Video Visualization And Creativity In Immersive 3D Environments -- From Cave To YURT May 20-21, 2015 YurtAtBrown Photo courtesy of Brown CS", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: The Yurt At Brown"], "word_count": 259, "token_count_estimate": 358}}, "https://blog.cs.brown.edu/2015/10/15/i-learned-different-definition-success-peter-norvig-78-remembers-studying-cs-brown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles I Learned A Different Definition Of Success Peter Norvig 78 Remembers Studying CS At Brown Posted by Jesse Polhemus on Oct. 15, 2015 Brown CS alumni continue to rank highly as industry pioneers. Click here for a list of related stories. Back then, Peter Norvig 78, now Director of Research at Google, says of his days at Brown, nobody owned their own computer, so people would congregate where the computers were and hang out late at night. There was a real sense of camaraderie. The best things were my fellow students and the faculty members. Some of them, like Professor of Computer Science Andy van Dam and Professor Emeritus of Applied Mathematics Ulf Grenander, are still around. I worked as a teaching assistant, and I learned more from that than from the classes themselves. Clarissa Clemm has just interviewed Peter for the Brown Daily Herald. In the wide-ranging piece, he looks back on the days in which nobody owned their own computer, talks about his current work at Google, and even comments on the value of the UTA program. The full article is available here . The photo above is by Derrick Coetzee and used with permission under Creative Commons license.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "\"I Learned A Different Definition Of Success\": Peter Norvig '78 Remembers Studying CS At Brown"], "word_count": 216, "token_count_estimate": 266}}, "https://blog.cs.brown.edu/2015/11/11/erik-sudderth-and-collaborators-contribute-geoscience-algorithm-helps-predict-landslides/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Erik Sudderth And Collaborators Contribute To Geoscience With An Algorithm That Helps Predict Landslides Posted by Jesse Polhemus on Nov. 11, 2015 Following shortly after his recent contributions to seismic monitoring and nuclear non-prolifereation , Professor Erik Sudderth of Brown University s Department of Computer Science and his collaborators have developed graph algorithms that use remote sensing data to predict where landslides are most likely to occur. Their work was published in the Journal of Geophysical Research Earth Surface and was later chosen as a highlight article on EOS . Landslide prevention presents a massive computational task hillsides are typically modeled as grids, often composed of millions of cells or blocks, each of which has properties such as soil depth, slope, and elevation. The endless possible permutations make determining how unstable cells are arranged enormously demanding, so Sudderth and his collaborators developed an algorithm that analyzes the properties of hillsides and identifies clusters of unstable blocks, which in turn allows analysis of a larger area. They tested their work on a virtual hillside and on data from an Oregon landslide, and in both cases, scientists were able to accurately predict the area and approximate side of the landslides. The paper is available here and the full highlight article is available here . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "Erik Sudderth And Collaborators Contribute To Geoscience With An Algorithm That Helps Predict Landslides"], "word_count": 246, "token_count_estimate": 299}}, "https://blog.cs.brown.edu/2015/11/12/bdh-reports-rising-cs-enrollment-unique-apps-created-cs-students/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Posted by Jesse Polhemus on Nov. 12, 2015 To read more stories about the Brown CS departments increasing enrollment click here . Want to find food, collaborate on a song, or send secure, anonymous messages Theres a Brown CS -developed app for that. Todays issue of the Brown Daily Herald notes soaring Brown CS enrollment over the last five years, our number of degrees awarded has risen by over 200 percent and highlights four students who have created apps for iOS, Android, and even the new Apple Watch. You can read the full article here . For more information, please click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus . The image above is by Cristiano Betta and used under a Creative Commons license.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:10+00:00", "headings": ["Information for:", "Brown CS Blog", "BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students"], "word_count": 157, "token_count_estimate": 189}}, "https://blog.cs.brown.edu/2015/11/10/we-need-value-each-other-msn-quotes-michael-littman-about-fears-robot-apocalypse/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles We Need To Value Each Other MSN Asks Michael Littman About Job Automation And Fears Of A Robot Apocalypse Posted by Jesse Polhemus on Nov. 10, 2015 My biggest concern at the moment, Brown CS Professor Michael Littman says, is that we as a society find a way of valuing people not just for the work they do. He was recently featured alongside other colleagues in an MSN article on job automation, and his response steps outside the usual questions of processor speed, machine learning, and the definition of sentience. The full article is available here . For more information, please click the link that follows to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "\"We Need To Value Each Other\": MSN Asks Michael Littman About Job Automation And Fears Of A Robot Apocalypse"], "word_count": 132, "token_count_estimate": 165}}, "https://blog.cs.brown.edu/2015/11/09/buzzfeed-puts-brown-top-25-most-beautiful-college-campuses-worldwide/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Buzzfeed Puts Brown In The Top 25 Most Beautiful College Campuses Worldwide Posted by Jesse Polhemus on Nov. 9, 2015 We are immensely proud to be part of Brown. For more articles on our parent university check out our Praise for Brown page here . From Australia to Africa to North America, only 25 colleges made Buzzfeeds list of the most beautiful campuses in the world, and Brown University was one of them. Sorry, MIT The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Buzzfeed Puts Brown In The Top 25 Most Beautiful College Campuses Worldwide"], "word_count": 116, "token_count_estimate": 144}}, "https://blog.cs.brown.edu/2015/11/12/two-brown-cs-teams-win-cyberseed-prizes/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Two Brown CS Teams Win CyberSEED Prizes Posted by Jesse Polhemus on Nov. 12, 2015 in Awards Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . Recently, two teams from Brown University s Department of Computer Science extended Browns reputation for cybersecurity excellence in a competition at the University of Connecticut, winning prizes for the second consecutive year. CyberSEED features competitive cybersecurity challenges for students and brings together top information security professionals and business leaders to discuss emerging cybersecurity trends and formulate best strategies for tackling current and future threats. This year, a team composed of Dan Haugh, Joshua Liebow-Feeser, Natalie Roe, and Frederick Rice competed in the Capture The Flag CTF competition, and a team composed of Kevin Cole, Aaron Gokaslan, and Abdullah Yousufi competed in the Social Engineering competition. Both teams ended the competition in fourth place and received a 3000 prize. They also received an award for being in third place at the end of the first day. The students did a great job, said Assistant Professor of the Practice Bernardo Palazzi, who coached both teams. I also want to recognize Josh and Freddie, who put in a lot of work organizing the teams. For more information, please click the link that follows to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Two Brown CS Teams Win CyberSEED Prizes"], "word_count": 242, "token_count_estimate": 302}}, "https://blog.cs.brown.edu/2015/10/26/michael-littman-interviewed-business-insider-about-robot-myths/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Michael Littman Interviewed By Business Insider About Robot Myths Posted by Jesse Polhemus on Oct. 26, 2015 When robots develop feelings, theyre probably going to be hurt when they read this article. According to leading artificial intelligence experts, their field is widely misperceived by the general public, perhaps due to movie treatments where vengeful robots decide to turn on their human masters and conquer the planet. In an attempt to set the record straight, Guia Marie Del Prado of Business Insider interviewed Professor Michael Littman of Brown University s Department of Computer Science and eighteen of his colleagues on the biggest myths about robots. You can read the entire article here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Michael Littman Interviewed By Business Insider About Robot Myths"], "word_count": 127, "token_count_estimate": 158}}, "https://blog.cs.brown.edu/2015/12/28/providence-declared-best-city-raise-kids-america/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Providence Declared Best City To Raise Kids In America Posted by Monica Zuraw on Dec. 28, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Destination Tips lists Providence, RI as the number one city to raise children in America. Its safe neighborhoods, historic attractions, and fun zoo are just a few aspects that make the city a great place for families. The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Providence Declared Best City To Raise Kids In America"], "word_count": 114, "token_count_estimate": 137}}, "https://blog.cs.brown.edu/2015/12/27/datafox-lists-providence-one-2015s-best-cities-found-startup-outside-silicon-valley-and-new-york/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles DataFox Lists Providence As One Of 2015s Best Cities To Found A Startup Outside Of Silicon Valley And New York Posted by Monica Zuraw on Dec. 27, 2015 For more stories on why we love calling Providence home, check out our Praise for Providence page here . Our hometown, Providence, RI has just been listed as one of the best cities to found a startup. According to DataFox, t he key to Providences success is specializing around existing strengths such as art, music, and social entrepreneurship. The low cost of living along with loan forgiveness further establishes Providence as a great city for entrepreneurs who want to start businesses in tech and design. The entire article is available here . For more information, please click the following link to e-mail Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "DataFox Lists Providence As One Of 2015\u2019s Best Cities To Found A Startup Outside Of Silicon Valley And New York"], "word_count": 154, "token_count_estimate": 185}}, "https://blog.cs.brown.edu/2016/01/27/new-course-build-next-generation-cs-entrepreneurs/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles A New Brown CS Course Aims To Build The Next Generation Of CS Entrepreneurs Posted by Monica Zuraw on Jan. 27, 2016 in Diversity The number of new startups launched in the US each year is quickly increasing and many successful ones have been founded by recent CS graduates. Current and future students may be wondering how they too can succeed with a startup of their own. Brown CS has this in mind with csciStartup , a new course offered this Spring 2016. The course, taught by Adjunct Assistant Professor John Jannotti , aims to help students overcome the mechanical hurdles of creating a startup and teach them the keys to designing products people want. John says he is very humbled to be teaching the course. There are a ton of different aspects that go into running a business that I dont know everything about, he says. Thats why he intends to break the course up into two different meetings per week one where he can help teams directly with their products, and another where experts in different areas give guest lectures. csciStartup is different from any other course at Brown because it is very product focused as opposed to just how to build a business, says John. The goal is for each team to have a product ready to hit the ground running by halfway through the semester. Brown alum Evan Stites-Clayton thinks csciStartup will be really beneficial to students interested in starting a company of their own. Evan is the founder of the successful startup, Teespring, which makes designing and selling apparel easy. He says he would have enjoyed having the option to take a class like csciStartup while at Brown. It would have been nice to have a community of other people working on startups and to have the ability to share resources and get advice from experts. For more information about this course go to httpcs.brown.edujjstartup.html .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "A New Brown CS Course Aims To Build The Next Generation Of CS Entrepreneurs"], "word_count": 336, "token_count_estimate": 398}}, "https://blog.cs.brown.edu/2016/01/12/television-commercial-starring-michael-littman-reaches-millions-viewers-nationwide/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Michael Littman Stars In A Television Commercial That Will Reach Millions Of Viewers Nationwide Posted by Jesse Polhemus on Jan. 12, 2016 Ordinary people are being empowered, says Professor Michael Littman of Brown University s Department of Computer Science , in a way that makes the experts unnecessary. Coming from a thought leader whose research is helping create household gadgets that can be programmed in a user-friendly and natural way, its not an unusual statement. Except in this case hes talking about his appearance in a recent television commercial . This week, Michael has taken to the air alongside luminaries such as theoretical physicist Michio Kaku and Nobel laureate George Smoot to demonstrate the simplicity of a popular piece of income tax refund software. A member of the creative team for the commercial is a family friend, he explains, and asked for my help in finding notable geeks. I sent a list and slipped in my own name They watched my popular series of YouTube videos using music to reinforce CS concepts and video of a winning performance on Dancing With The Profs with Quynh Tran and decided it was worth giving me a shot at it. What was the whole experience like Micahel says, Its just such a wonderful opportunity to get a glimpse of another industry. The day of the filming felt like being part of a circus -- there were dozens of trucks and people and machines that all had to work together flawlessly on a very tight schedule. So much of it was planned out, but there were also parts that were incredibly spontaneous and creative. I was very impressed. The portrayal of academics as vast, benign, but slightly awkward intellects is interesting the Michael Littman of the commercial puts his hand to his forehead to peer in a window and doesnt seem quite sure when to end the conversation with the person hes helping, but Michael finds it a balanced one. I think theyre leveraging the perspective of academics as being very bright and talented, he explains. They use that idea to argue that this particular task, doing your taxes via a software program, doesnt require a high level of talent...Part of the humor comes from the idea that the ordinary people are being empowered in a way that makes the experts unnecessary. You can watch the commercial here . For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Michael Littman Stars In A Television Commercial That Will Reach Millions Of Viewers Nationwide"], "word_count": 429, "token_count_estimate": 493}}, "https://blog.cs.brown.edu/2016/04/01/read-more-increased-enrollment/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More More CS Majors And Increased Enrollment Posted by Monica Zuraw on April 1, 2016 To learn about how more and more Brown University students are majoring in CS and enrolling in our classes, click any of the links below Brown CS Graduates A Record Number Of Undergrads 39 Are Women Brown CS Addresses Growth and Student Support Constraints and Challenges In A BDH Op-Ed BDH Cites Faculty Accessibility And Collaboration Even As Brown CS Grows To Become Browns 1 Concentration More Brown Students Are Majoring In CS Than Any Other Subject Brown CS Is Graduating 38 More Undergraduates Than Last Year, With 232 Predicted to Graduate in 2017 BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Brown CS Introductory Course Enrollment Sets Records Enrollment Soars 1 In 5 Students Is Taking A Brown CS Course", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: More CS Majors And Increased Enrollment"], "word_count": 156, "token_count_estimate": 197}}, "https://blog.cs.brown.edu/2016/04/14/bootstrap-expands-across-new-york-state-new-partnerships-aimed-enhancing-stem-education/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Bootstrap Announces A New STEM Education Model That Combines Computing, Modeling, And Physics Posted by Jesse Polhemus on April 14, 2016 Bootstrap , one of the nations leading computer science literacy programs, co-directed by Brown CS faculty members Shriram Krishnamurthi and Kathi Fisler adjunct, continues to extend its reach. Bootstrap has just announced a partnership to use its approach to building systems to teach modeling in physics, an important component of the Next Generation Science Standards NGSS. This project is a collaboration with STEMTeachersNYC, the American Association of Physics Teachers, and the American Modeling Teachers Association. This new effort is part of the White House-inspired 100Kin10 initiative, which will create 100,000 new STEM teachers in ten years. A grant of 200,000 from 100Kin10 will fund this new collaboration. The project Modeling Physics, Computational Thinking, and Bootstrap will help students learn computational thinking while learning basic physics concepts by writing programs to build models of the physical world. The two-year project will involve 20-24 teachers and reach about 1,000 students each year. It will equip teachers with a hands-on, inquiry-based pedagogy supported by a set of tested, engaging curriculum modules for classroom use. After the project period, all four project partners plan to promulgate the approach through professional development workshops for teachers throughout the country.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:11+00:00", "headings": ["Information for:", "Brown CS Blog", "Bootstrap Announces A New STEM Education Model That Combines Computing, Modeling, And Physics"], "word_count": 229, "token_count_estimate": 303}}, "https://blog.cs.brown.edu/2016/05/05/interdisciplinary-team-brown-wins-award-mit-grand-hack-2016/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles An Interdisciplinary Team Including Multiple Brown CS Students Wins An Award At MIT Grand Hack 2016 Posted by Jesse Polhemus on May 5, 2016 in Awards A team that included multiple students from Brown University s Department of Computer Science Brown CS has just won the Best Aging in Place Hack award at MITs Grand Hack 2016. Inspired by a mentor whose mother suffers from Alzheimers disease, Sven Eberhardt Brown University postdoc, Youssef Barhomi Brown University research engineer, Pankaj Gupta Brown University research assistant, Nediyana Daskalova Brown CS PhD candidate, Adrienne Tran Brown University alum and founder of Neurocurious, and Alejandro Scaffa Brown University PhD candidate formed team alzEYEmers to create a unique solution based on computer vision, AI, and neuroscience. Their project leverages software that can recognize common household objects as well as hazards, then supplies an Alzheimers patient with a camera worn around the neck. During any unattended hours, the camera serves as a watchdog if it spies a hazard for example, a fire, it can redirect the patient with recorded prompts, alert a family member, or even call 911. This was a very different hackathon from others Ive been to, says Nediyana, The idea was to talk to many people from diverse backgrounds in order to think about the problem from various points of view before solving it. We spoke to six different people about their experiences with Alzheimers before we even began hacking. We really found it interesting to spend so much time thinking about a problem before jumping to a technological solution. For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "An Interdisciplinary Team Including Multiple Brown CS Students Wins An Award At MIT Grand Hack 2016"], "word_count": 292, "token_count_estimate": 375}}, "https://blog.cs.brown.edu/2016/05/04/rediscovered-video-documents-browns-revolutionary-1976-use-hypertext-education/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles A Rediscovered Video Documents Brown Universitys Revolutionary 1976 Use Of Hypertext In Education Posted by Jesse Polhemus on May 4, 2016 Already being described as astounding and visionary as it makes its way across the Internet, a short film from forty years ago Hypertext an Educational Experiment in English and Computer Science at Brown University has just surfaced after being lost for decades. It documents an extraordinary early use of computing to enhance the learning experience of students taking a poetry course in 1976. Speaking to us from an era more familiar to the parents of todays digital natives, Professor Andy van Dam of the Department of Computer Science and his collaborators demonstrate the use of responsive software, computer-enabled social learning, and hyperlinks that supplement primary texts with additional material. Seeing the affordances of modern computing made available to the college students of 40 years ago is striking whats perhaps even more remarkable is the thoughtful analysis and keen insight with which van Dam and his colleagues and students ponder the potential of this creative graffiti and its impact on education and discourse. Poetry indeed The film is available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "A Rediscovered Video Documents Brown University's Revolutionary 1976 Use Of Hypertext In Education"], "word_count": 226, "token_count_estimate": 261}}, "https://blog.cs.brown.edu/2016/04/11/national-science-foundation-director-visits-brown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles National Science Foundation Director Visits Brown Posted by Jesse Polhemus on April 11, 2016 by Kevin Stacey Science News Officer, Physical Sciences For more CS News and CS Blog articles about the Yurt, please click here . PROVIDENCE, R.I. Brown University National Science Foundation Director France Crdova and U.S. Sen. Jack Reed of Rhode Island joined students, faculty and administrators at Brown on April 8 for a firsthand look at some of the NSF-supported research happening at the University. The visit kicked off with a tour of Institute for Computational and Experimental Research in Mathematics ICERM, Browns NSF-funded mathematics center headquartered on South Main Street. Then it was off to College Hill for tours of the Institute at Brown for Environment and Society IBES, the School of Engineering and the YURT, the Universitys immersive virtual reality theater. This has been a terrific visit, Crdova said following the tour. We got to see a lot of different kinds of science and engineering thats going on and meet a lot of students and some of the award-winning faculty. Brown is just such a highly distinguished university doing quality research, so NSF is proud to support it. At an ICERM reception, Crdova addressed a gathering of some 100 researchers and scholars, some of whom were visiting the institute for one of its weeklong workshops. Crdova congratulated ICERMs leaders on the recent renewal of its NSF funding, a 17.5 million grant that will support activities for the next five years. The institute was founded in 2010 with 15.5 million from NSF. Its one thing to get something off the ground Crdova said. But its quite another thing to show that you have impact And thats what ICERM has done. Jill Pipher, ICERMs director, discussed some of that impact in a meeting prior to the reception with Crdova, Reed, Brown President Christina Paxson, Provost Richard Locke and members of the ICERMs board and directorate. The institute brings together some of the worlds best mathematical minds to explore topics in pure and applied math, computer science and related disciplines. Recent programs have explored cybersecurity, climate modeling, data analytics and other emerging topics. Pipher discussed a workshop held this summer at ICERM focusing on predictive policing, the use of data and mathematical analysis to understand and predict patterns of criminal activity. The workshop was spawned by a public lecture on the mathematics of crime, hosted in late 2014. Several members of the Providence Police Department attended, and the department will supply some of the data that will be used at the upcoming workshop. The workshop is an example, Pipher said, of how ICERMs outreach and research go hand-in-hand. At IBES, Crdova and Reed met with deputy directors Leah VanWey and Dov Sax, as well as researcher Meredith Hastings. Hastings described her work investigating the origin and extent of nitrogen pollution around the world, which has been funded in part by a CAREER award, NSFs premier honor for early-career faculty. Hastings landed her CAREER grant in 2014, and Brown has had a bumper crop of six new CAREER awardees so far in 2016. Crdova said support for early-career researcher is an important part of what NSF does. NSF prides itself on being the first funder for many young people, she said. In addition to learning about NSF-funded research, Crdova heard about IBESs approach to interdisciplinary study and engaged scholarship, which combines learning and research opportunities. Brown undergraduates Kari Malkki and Lovinia Reynolds discussed a project they have been working on that investigates strategies for reforesting a key ecological region in Brazil. At the School of Engineering, Crdova and Reed met with Sorensen Family Dean Larry Larson and toured the Brown Design Workshop. The space provides students with access to 3-D printers, laser cutters and other tools for independent or class-related design and engineering projects. Also in engineering, Crdova met with Daniel Mittleman and his students, whose NSF-supported research focuses on terahertz radiation. T-waves, as they are called, make up a relatively unexplored swath of the electromagnetic spectrum, but they may one day support wireless networks with many times the data capacity of current networks. Mittleman is developing the basic terahertz components that will be critical to constructing these next-generation networks. The tour wrapped up with a virtual reality demonstration in the YURT, an immersive facility built with the help of a 2 million NSF grant. Computer science professor David Laidlaw and his students showed Reed and Crdova several examples of what the YURT can do. The demonstration included work from a collaboration between Laidlaws students and Stephen Gatesy, an anatomist and evolutionary biologist at Brown. Gatesy studies fossilized footprints made by ancient dinosaurs, and hes worked with Laidlaws students in developing 3-D animations of how those tracks may have been made. Laidlaw also discussed how Brown geoscientists use the YURT to study the surfaces of the Moon and Mars, helping to scout locations for potential spacecraft missions. Its a wonderful tool for training, especially in environments that are very difficult and expensive to get to, Crdova said. Virtual reality brings those environments in where you can explore them. At the conclusion of the visit, Reed stressed the importance of research and development investments to the Rhode Island economy. Its something we have to do to maintain our technological edge and ultimately create the jobs of the next century, Reed said. Without the NSF, we wouldnt be able to do that.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "National Science Foundation Director Visits Brown"], "word_count": 917, "token_count_estimate": 1164}}, "https://blog.cs.brown.edu/2016/05/16/providences-risd-museum-tops-architectural-digests-list-americas-best-university-art-museums/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Providences RISD Museum Tops Architectural Digests List Of Americas Best University Art Museums Posted by Jesse Polhemus on May 16, 2016 For more stories on why we love calling Providence home, check out our Praise for Providence page here . The interdisciplinary academic possiblities to having the Rhode Island School of Design RISD as a next-door neighbor are beyond price, but you know what else is pretty niftt Waving your Brown University ID and walking into a museum that Architectural Digest just called the best university art museum in America. Their permanent collection, ranging across every medium imaginable, contains more than 100,000 objects. The full list is available here . For more information, please contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Providence's RISD Museum Tops Architectural Digest's List Of America's Best University Art Museums"], "word_count": 139, "token_count_estimate": 179}}, "https://blog.cs.brown.edu/2016/05/12/john-savages-recommendations-securing-cyberspace-have-been-presented-japanese-government-upcoming-g7-summit/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles John Savages Recommendations For Securing Cyberspace Have Been Presented To The Japanese Government For The Upcoming G7 Summit Posted by Jesse Polhemus on May 12, 2016 As the G7 Summit, one of the most important and wide-reaching global conferences for trade, climate change, health, and other issues approaches, Professor John Savage of Brown University s Department of Computer Science Brown CS has once again found his cybersecurity expertise in demand. Boston Global Forum BGF, chaired by former governor Michael Dukakis, was founded to bring together thought leaders and experts from around the globe to participate in open public forums to discuss and illuminate the most critical issues affecting the world at large. In February, their CEO, Tuan Nguyen, asked John to address BGF and prepare an agenda for the G7 Summit, which will be hosted by the government of Japan in Ise-Shima National Park on May 26 and 27. He did so, later working with other individuals affiliated with BGF to develop his presentation into a formal proposal. At the Harvard Club on Monday, BGF met via teleconference with representatives of the Japanese government to discuss the BGF proposals for the G7 Summit Initiative. A video is available here Johns presentation begins twelve minutes in, and the proposal is available in PDF form here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "John Savage's Recommendations For Securing Cyberspace Have Been Presented To The Japanese Government For The Upcoming G7 Summit"], "word_count": 250, "token_count_estimate": 307}}, "https://blog.cs.brown.edu/2016/05/09/undergraduates-share-unique-projects-their-second-research-symposium/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Undergraduates Share Unique Projects At Their Second Research Symposium Posted by Monica Zuraw on May 9, 2016 Brown CS undergraduates recently showcased their hard work at the second annual research symposium. A panel of judges viewed their research projects, and the top three were awarded prizes. This symposium is extraordinary, said one of the judges, Professor Sorin Istrail. We are surrounded by a very unique group of students here. They have shown an amazing amount of growth and passion. The research projects spanned a wide variety of interesting topics. Sam Kortchmar is a singer, but has trouble reading music. He created a solution to this problem by finding a way to learn music through visualization where you can essentially fly through the song in virtual reality. Researching as an undergraduate is a great way to build relationships with professors, says Sam. They can become great role models. Another one of the undergrads, Advik Iyer Guha, says, It is one of the best ways to truly find out if you are passionate enough about a problem or if you want to do a PhD. His research project focused on finding ways to improve human-robot collaboration with object placement. The three winning projects included Julia Romanskis process for improving large-scale evacuations during natural disasters, Daniel Seidmans method for time efficient determination of identical by descent tracts between unphased genotypes, and Emily Wus social feedback for robotic collaboration. This was definitely the most fun and challenging thing I have done at Brown, said Emily. It gave me a great taste of self-directed study. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Undergraduates Share Unique Projects At Their Second Research Symposium"], "word_count": 294, "token_count_estimate": 364}}, "https://blog.cs.brown.edu/2016/05/16/travel-and-leisure-calls-providence-americas-third-favorite-city/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Travel And Leisure Calls Providence Americas Third Favorite City And Second Best For Food Posted by Jesse Polhemus on May 16, 2016 For more stories on why we love calling Providence home, check out our Praise for Providence page here . The grilled pizza The coffee milk The food trucks The fact that we arguably invented the food truck in 1872 It was a horse-drawn lunch cart. Its enough for Travel and Leisure to declare Providence their third favorite city in America and the second best for foodies, leaving behind Chicago, New Orleans, Portland, and dozens of others. The full lists are available here and here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Travel And Leisure Calls Providence America's Third Favorite City And Second Best For Food"], "word_count": 141, "token_count_estimate": 168}}, "https://blog.cs.brown.edu/2016/05/19/brown-undergrad-uses-yurt-more-intuitively-visualize-developmental-biology/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology Posted by Jesse Polhemus on May 19, 2016 For more CS News and CS Blog articles about the Yurt, please click here . Accelerating into its second year of operation, the YURT Brown University s latest 3D virtual reality environment is adding another entry to the list of fields that have benefited from its capabilities embryonic developmental biology. Rhode Island NSF EPSCoR, a local branch of the National Science Foundations experimental program to stimulate competitive research, reports on the work of Brown University student Beatrice Steinert, who set out to document and study the embryonic developmental stages of the slipper snail. Beginning her research with no preconceptions of what she might find, Beatrice guided by Professor Kristi Wharton, who had used the YURTs predecessor, the CAVE sought out the Yurts mind-blowing tools, using it to manipulate a virtual embryo in 3D flying over it, rotating it, and even stepping inside. Visualizing embryos in the YURT allows you to more intuitively understand what is going on, she says, how cells in the embryo are arranged, and to see things you might not be able to otherwise. And, you can compare models to see how cells have moved or what an experimental manipulation has changed...With a microscope, there is a barrier between you and the embryo. In the YURT, you can just pick it up and turn it around and look. Beatrice mentions that shes also interested in the Yurts possibilities in teaching developmental biology due to the highly visual and spatial nature of the field and the processes through which embryos develop. The full article is available here . For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology"], "word_count": 316, "token_count_estimate": 399}}, "https://blog.cs.brown.edu/2016/06/01/professor-eli-upfals-research-group-publishes-three-successful-papers/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Professor Eli Upfals Research Group Publishes Three Papers Posted by Monica Zuraw on June 1, 2016 Three papers from Professor Eli Upfals research group were recently accepted to Knowledge Discovery and Data Science KDD16, a top-tier conference in the Big Data research community. A total of 784 papers were submitted to the conference, of which 70 were accepted as full papers and 72 were accepted as poster papers. Elis group had two full papers and one poster paper accepted, which is a major achievement. TRIEST Counting Local and Global Triangles in Fully-dynamic Streams with Fixed Memory Size was a joint publication between Lead Researcher and Brown University PhD Candidate Lorenzo De Stefani, Alessandro Epasto , Matteo Riondato, and Eli. The paper tackles the problem of triangle counting in large massive graph. Their work proposes a new algorithm based on adaptive sampling, which provides high quality approximations of the number of triangles in large networks with probabilistic guarantees. ABRA Approximating Betweenness Centrality in Static and Dynamic Graphs with Rademacher Averages was co-written by Lead Researcher and Visiting Assistant Professor Matteo Riondato and Eli. The algorithm, ABRA, uses progressive random sampling, which allows it to automatically determine when the obtained approximation has the required quality. In their experimental evaluation, ABRA proved to be much faster than existing state-of-the-art methods. On September 9, Two Sigma published an online article on ABRA here . The last paper, Scalable Betweenness Centrality Maximization via Sampling, was written by Lead Researcher and Brown CS PhD Candidate Ahmad Mahmoody , Charalampos Tsourakakis, and Eli. In their work, they considered an extension of the classic betweenness centrality problem, where the goal was to find the most central group of nodes of a given size. Their method improved the state of the art algorithm by using a more efficient sampling algorithm, and provided a better theoretical guarantee. I think good team work is a great tool to both increase the quality of the work and maintain high motivation which is then bound to lead to good results, says Lorenzo when asked why Elis research group was so successful in getting their work published. A well-functioning research group offers the possibility of having other qualified people to bounce off ideas and challenge your understanding of topics. Further, it is a chance of learning new skills working alongside other talented and motivated people. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Professor Eli Upfal\u2019s Research Group Publishes Three Papers"], "word_count": 425, "token_count_estimate": 536}}, "https://blog.cs.brown.edu/2016/06/22/bootstrap-sells-out-its-june-27-cs4ri-workshop/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Bootstrap Sells Out Its June 27-29 CS4RI Workshop Posted by Jesse Polhemus on June 22, 2016 Bootstrap is a computer science literacy curriculum used worldwide by 10,000 students whose founders include two Brown CS faculty members, Kathi Fisler adjunct and Shriram Krishnamurthi . Recently cited by the White House for its efforts to improve the inclusiveness, accessibility, and reach of computer science education , it continues to expand globally, nationally, and within its home state, most recently as part of Governor Gina Raimondos CS4RI program. Developed in response to President Obamas landmark Computer Science For All initiative, which calls for CS educational funding for all students nationwide, CS4RI is designed to bring computer science to every school in Rhode Island by 2018. Bootstrap is one of the two most popular programs that CS4RI offers to teachers. Next week, as part of CS4RI, Bootstrap is looking forward to a fully-attended workshop on June 27-29. Teachers from every public middle school and high school were eligible to participate, and more than forty enrolled, causing the event to sell out.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Bootstrap Sells Out Its June 27-29 CS4RI Workshop"], "word_count": 192, "token_count_estimate": 257}}, "https://blog.cs.brown.edu/2016/06/14/amy-greenwald-helps-coordinate-inaugural-artificial-intelligence-social-good-conference/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Amy Greenwald Helps Coordinate The Inaugural Artificial Intelligence For Social Good Conference Posted by Jesse Polhemus on June 14, 2016 in Diversity Professor Amy Greenwald of Brown University s Department of Computer Science Brown CS, along with colleagues from Harvard University, the Computing Community Consortium, the White House Office of Science and Technology Policy, and other organizations, have just returned from the successful Artificial Intelligence for Social Good conference, which they co-organized. Held in Washington, DC, the event discussed the successful deployments and the potential use of AI in various topics that are essential for social good, including but not limited to urban computing, health, environmental sustainability, and public welfare. Amy and the other organizers are presently engaged in preparing a report summarizing the workshop for use by the OSTP as they shape future technology policy. For more information, please click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:12+00:00", "headings": ["Information for:", "Brown CS Blog", "Amy Greenwald Helps Coordinate The Inaugural Artificial Intelligence For Social Good Conference"], "word_count": 171, "token_count_estimate": 208}}, "https://blog.cs.brown.edu/2016/10/27/brown-cs-tas-cs-15-win-second-place-healthhacks-hackathon/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS TAs Of CS 15 Win Second Place At HealthHacks RI Hackathon Posted by Jesse Polhemus on Oct. 27, 2016 Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . At many hackathons, teams assemble according to shared interests among people who have just met. Its part of the appeal. But sometimes, you just want to hack with people that you already love working with. Two weeks ago, the TAs of CS 15 Katie Chu, Grant Fong, Sarah Kim, Hannah Tipperman, Adrian Turcu, and Zach Kirschenbaum, all sophomores formed a team called The Balcony and took second place at HealthHacks RI, a 48-hour hackathon focused on issues in health, wellness, dietnutrition, and aging. Working alongside fellow students, engineers, researchers, physicians, entrepreneurs, mentors, and others, the Brown CS teams challenge was to create a solution for the health and wellness industry. Their answer was an iOS app called CareConnect that helps streamline communication between caregivers and family. In addition to bragging rights, their second place finish earned them a 1000 prize.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS TAs Of CS 15 Win Second Place At HealthHacks RI Hackathon"], "word_count": 195, "token_count_estimate": 268}}, "https://blog.cs.brown.edu/2016/07/06/brown-cs-student-accomplishments/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Recent Accomplishments By Brown CS Students Posted by Jesse Polhemus on July 6, 2016 For more stories on why Brown CS is a great place to study, check out our Praise For Brown CS page . On any given week, Brown CS students are designing apps to improve parking or combat cancer, earning fellowships from Google and Y Combinator, launching their own hackathons and research symposia, and reaching out into their communities to increase the diversity of our field. These are their stories from recent years click any link below to read the full article. 2024 Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Yong Zheng-Xin, Cristina Menghini, And Stephen Bach Earn A Socially Responsible Language Modelling Research SoLaR Best Paper Award Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Brown CS Student Artem Agvanian And Alum Hannah Gross Earn First And Second Place SOSP Student Research Honors 2023 Brown CS Researchers Use Virtual Reality To Control A Robot Proxy With Natural Movements Brown CS Student Joshua Yang Earns First-Place At The ACM CHI 23 Student Research Competition Brown CS Student Angel Arrazola Builds A Positive Learning Environment For Providence Middle School Students Brown CS Joint Concentrator Lucas Brito Earns A Goldwater Scholarship WIRED Asks A New Brown CS Research Group About Multilingual Large Language Models Twenty-Seven Students Win 2023 Brown CS Senior Prizes Brown CS Undergraduates Advance To The International Collegiate Programming Contest Nationals Anh Truong And Qiuhong Anna Wei Win The Randy F. Pausch Computer Science Undergraduate Summer Research Award Brown CS Student Rachel Ma Receives A CRA Outstanding Undergraduate Researcher Honorable Mention 2022 Tassallah Amina Abdullahi Wins An ACM SIGHPC Computational and Data Science Fellowship Five Brown CS Students And Alums Receive NSF Graduate Research Fellowships Brown CS PhD Student Denizalp Goktas Becomes A 2022 J.P. Morgan PhD Fellow Kaiyu Zheng, George Konidaris, And Stefanie Tellex Of Brown CS Win The IROS RoboCup Best Paper Award 2021 Brown CS PhD Student Fumeng Yang Wins The Computing Innovation Fellowship 2021 A Brown CS Team Takes Third Place At The Thirteenth AIMMS-MOPTA Optimization Modeling Competition Wrenn, Nelson, And Krishnamurthi Win The Programming Editors Choice Award Brown CS Student Aric Zhuang Wins 15,000 At This Years Brown Venture Prize Leonhard Spiegelberg Wins A Facebook Fellowship Twenty-Two Students Win Brown CS Senior Prizes Cousins, Lim, Martinez, Wrenn, And Zamanian Win University And ACM Distinctions Ross Briden And Zachary Espiritu Win The Randy F. Pausch Computer Science Undergraduate Summer Research Award Kamara, Moataz, Park, And Qin Explore Possibilities For An Ultra-Secure Gun Registry 2020 Brown CS Students Create A Futuristic Art Exhibition Brown CS Holds Our 5th Annual Research Open House Recording Available Full Stack At Browns First Hackathon, Datathon, And CTF HackHome Brown CS PhD Student Brandon J. Woodard Wins The NASA RI Space Grant Fellowship Brown CS Students, Faculty, And Alums Publish Seven Papers At SIGMOD 2020 Brown And RISD Undergrads Win A 40K Challenge By MassRobotics Seventeen Students Win Brown CS Senior Prizes PhD Student Jinq Qian And Adobe Add AR Annotations To Physical Documents PhD Student Lucy Qin Receives An NSF Graduate Research Fellowship Brown CS Undergraduate Nishanth Kumar Has Been Named A 2020 Barry M. Goldwater Scholar Deep Learning Day Showcases Student Research Into Adversarial Networks, Sentiment Analysis, And More Brown CS Undergraduate Nishanth Kumars Student Abstract Has Been Accepted At AAAI-20 Areyan And Greenwald Take Second Place In The International Automated Negotiation Agents Competition Brown CS Undergraduates Dai And Bermudez-Silverman Present Their Work At The Inaugural AAAI Undergraduate Consortium Kai Wang Wins An Adobe Research Fellowship Bayazit, Galgana, Kumar, And Safranchik Win CRA Outstanding Undergraduate Researcher Honorable Mentions 2019 Undergrad Nishanth Kumar Wins Best Plenary Presentation At ILURS Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing David Abel Wins A Presidential Award For Excellence In Teaching Evgenios Kornaropoulos Wins The Joukowsky Family Foundation Outstanding Dissertation Award Twenty-Seven Students Win Brown CS Senior Prizes Jiwon Choe Wins The Memsys Best Student Presentation Award Brown CS Student Liyaan Maskati Wins The Association For Women In Mathematics Student Essay Contest For Writing About Ellie Pavlick Fong, Ren, And Weir Win CRA Outstanding Undergraduate Researcher Honorable Mentions 2018 Pombrio, Krishnamurthi Win The PLDI Distinguished Artifact Award For Inferring Rule Types For Syntactic Sugar Brown CS Students Advance To The Second Round Of The Cyber 912 Competition Lauren Ho And Nina Polshakova Earn KPCB Fellowships Building News4Good A First Take At Software Engineering For Four Undergrads Karamcheti, Porncharoenwase, And Rosen Win CRA Outstanding Undergraduate Researcher Honorable Mentions igniteCS Brown Kamara, Moataz, And Zhu Use Structured Encryption To Create Pixek, Offering Searchable Privacy For Digital Photos Seeing Theory Teaching Statistics Through Interactive Web-Based Visualizations Toymaker A New Seven-Minute Animated Short From Brown CS Novotny And Collaborators Win The VIS Best Poster Award For Visualizing Dinosaur Tracks Natalie Reed Becomes Browns Tenth Google Women Techmakers Scholar Martha Edwards And Kalvin Lam Win hackNY Fellowships 2017 David Armanious And Jared Siskin Are Among CyberStarts Top Scorers Nationwide New Software From Rosen And Whitney Allows Virtual Reality Control Of Robots Meta-TA Zach Kirschenbaum Helps Represent Brown CS At The Out For Undergraduate Tech Conference Brown Students Win Best Data Visualization Prize At HackMIT Alum Tushar Bhargava Wins A 2017 Undergraduate Award For Work With Tim Edgar The NYT Asks Brawner And Krishnamurthi About CSCI 0030 And Teaching Computational Thinking Arumugam, Karamcheti, Gopalan, Wong, Tellex Help Robots Follow Spoken Commands Esha Ghosh Wins An Inaugural Microsoft Research Dissertation Grant Tiffany Chen Has Been Named A Women Techmakers Scholar Look Where Our 2017 Graduates Are Headed Brown CS Returns To The Cyber 912 Student Challenge Geopipe, Co-Founded By Thomas Dickerson, Wins 100K At The NYU 300K Entrepreneurs Challenge Twelve Brown CS Students Will Be Recognized For Their Achievements With The Senior Prize In Computer Science Markell, Picard, And Tipperman Earn KPCB Fellowships, Setting A Brown CS Record Sorawee Porncharoenwase Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award Connor Gramazio Will Give An Invited Talk At OpenVis Conf Alexandra Papoutsaki Lands A Dream Job At Pomona College Tellex, Rosen, And Whitney Use Social Feedback To Help Robots Fetch Objects Intelligently Krishnamurthi And Quay-de la Vallee Look At App Store Insecurity In Fast Company 2016 Sarah Sachs Wins A Distinguished Senior Thesis Prize The Thinking Behind StartupBrown Pombrio And Krishnamurthis Work Has Been Selected As One Of ACM SIGPLAN ICFPs Best Papers Professor Eli Upfals Research Group Publishes Three Papers Students Senior Thesis Becomes Gates Foundation-Funded Project Papoutsaki, Laskey, Huang Advance Eye Tracking Through Webcam, Browser-Based Democratization Andrew Crotty Wins A Google PhD Fellowship TAG Touch Art Gallery Student And Community Education With A Worldwide Impact Brown CS Student Youn Kim Is Awarded A Presidential Fellowship At MIT A Brown University Undergraduate Uses The Yurt To More Intuitively Visualize Developmental Biology GeekWire Reviews James MacGlashan And Michael Littmans Work With Training Virtual Agents Like Dogs New Opportunities In CS An SMS-Based Commodity Exchange In Ghana Undergraduates Share Unique Projects At Their Second Research Symposium Krishna Chaitanya Aluru Wins A Y Combinator Fellowship An Interdisciplinary Team Including Multiple Brown CS Students Wins An Award At MIT Grand Hack 2016 csciStartup Students Develop A Solution To The Horrors Of Parking In Providence With Their New App Spotter David Abel Has Been Selected For Browns Highly Competitive Open Graduate Education Program Brown CS Students Make Another Strong Showing At The Third Annual Cyber 912 Student Competition Two Teams Will Represent Brown In Microsofts Build The Shield Competition MIT Technology Review Includes Research From The Humans To Robots Laboratory In Its 2016 Ten Breakthrough Technologies Inclusiveness And Learning, Rather Than Competition And Prestige Three Years In, HackBrown Is Bigger And More Diverse Than Ever Jonathan Mace Receives A Facebook Graduate Fellowship 2015 Stefanie Tellex And John Oberlins Award-Winning Video Earns Brown CS A New Baxter Robot Touch Art Gallery TAG Expands Worldwide With A Nobel MuseumNobel Media Collaboration Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Crotty, Galakatos, Zgraggen, Binnig, And Kraska Win Best Demo At VLDB 2015 Four Brown CS Students Recognized As 2015 Google Scholars Brown CS Uses Minecraft To Unboggle The Robot Mind Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Research By Undergraduate Sarah Sachs Gets Attention From Wired, The Today Show, And Others Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 MIT Tech Review Reports On Oberlin And Tellexs Work In Robot Object Manipulation Touch Art Gallerys Digital Museum Experiences Featured In Campus Technology BDH Reports On Rising CS Enrollment, Unique Apps Created By CS Students Two Brown CS Teams Win CyberSEED Prizes Slashdot And MIT Technology Review Cover A BrownCornell Collaboration That Allows Robots To Teach Robots PhD Student Ashley Conard Interviewed About GHC By SiliconANGLE Brown CS Continues Strong Levels Of VIS Participation Oberlin, Meier, Kraska, And Tellexs Acquiring Object Experiences At Scale Featured On CCCs Great Innovative Ideas Brown CS HackMIT Winners Featured In Times Square Students Hone Business Ideas At Startup Conference Brown CS Students Win Three Awards At HackMIT StartupBrown 926-27 Brings Together Innovative Startups And Talented Students MongoDB Intern Spotlight Features Benjamin Murphy 18 Christian Mathiesen And Teammates Take First Place At LinkedIns Intern Hackday Leiserson, Raphael, And Brown CS Colleagues Create A Web App To Help Researchers Explore Cancer Genetics I Had To Hire Henry The New Yorker Documents A Brown CS Students Hacking The Humanities MIT Technology Review, Smithsonian, And Others Cover The Tellex Labs Minecraft AI Project Jonathan Mace And Rodrigo Fonseca Develop Retro To Improve Server Resource Management For Big Data 2nd Place Award For Software At HackPrinceton Goes To Aaron Gokaslan 18 And Laura Shea 18 Brown CS Launches Inaugural Undergraduate Computer Science Research Symposium Cybersecurity Brown Undergraduates Win It All Michael Chang Wins KPCB Fellowship Victor Naroditskiy PhD 09 Demonstrates Crowdsourcings Vulnerability To Malicious Behavior East Side Monthly Recognizes Gryte Satass Efforts In Closing The Gender Gap The Providence Journal Reports On Serious Innovation At HackBrown 2015 Gryte Satas Creates Opportunities For Girls To Code Dana Metaxa-Kakavouli Selected As Runner-Up For CRA Award Algorithm Identifies Networks Of Genetic Changes Across Cancers", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Recent Accomplishments By Brown CS Students", "2024", "2023", "2022", "2021", "2020", "2019", "2018", "2017", "2016", "2015"], "word_count": 1717, "token_count_estimate": 2440}}, "https://blog.cs.brown.edu/2017/05/18/erway-kupcu-papamanthou-tamassia-earn-4-rank-2009-security-papers/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Erway, Kp, Papamanthou, Tamassia Earn The 4 Rank For 2009 Security Papers Posted by Jesse Polhemus on May 18, 2017 Click the links that follow for more Brown CS content about C. Christopher Erway , Alptekin Kp , Charalampos Papamanthou , and Roberto Tamassia . Professor Konrad Rieck of Technische Universitt Braunschweig has released a list of Influential Security Papers, and research Dynamic Provable Data Possession from Brown CS PhD alums C. Christopher Erway now Chief Architect of the SolarWinds Monitoring Cloud, Alptekin Kp now Assistant Professor at Ko University, and Charalampos Papamanthou now Assistant Professor at University of Maryland, College Park and Plastech Professor of Computer Science Roberto Tamassia has earned the 4 spot for papers published in 2009. Its also the 50th most cited paper since 1981. The list ranks papers published at the four top-tier security conferences, and their work, originally presented at the ACM Conference on Computer and Communications Security CCS has received 907 cites at Google Scholar, putting it 476 above that years average. The research was completed while Christopher, Alptekin, and Charalampos were PhD students at Brown CS, and it resulted in an issued patent. The full list is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Erway, K\u00fcp\u00e7\u00fc, Papamanthou, Tamassia Earn The #4 Rank For 2009 Security Papers"], "word_count": 232, "token_count_estimate": 330}}, "https://blog.cs.brown.edu/2016/08/22/fodors-new-england-cites-humanity-centered-robotics-initiative/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Fodors New England Cites The Humanity-Centered Robotics Initiative Posted by Jesse Polhemus on Aug. 22, 2016 We are immensely proud to be part of Brown. For more articles on our parent university check out our Praise for Brown page here . The size of a travel guide is necessarily limited by the tourists ability to carry yet another object while exploring or cram it into an overflowing backpack. In the latest edition of Fodors New England , Brown University gets a mere thirteen lines that mention the universitys 40 academic departments, its Gothic and Beaux-Arts structures, the List Art Center, the Haffenreffer Museum of Anthropology. But among the perhaps more expected entries is a noteworthy endorsement for HCRI The Humanity-Centered Robotics Initiatives Robot Block Party, held in April, celebrates robots and how they are being used to solve the worlds problems. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Fodor's New England Cites The Humanity-Centered Robotics Initiative"], "word_count": 175, "token_count_estimate": 220}}, "http://burlap.cs.brown.edu": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc About The Brown-UMBC Reinforcement Learning and Planning BURLAP java code library is for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. BURLAP uses a highly flexible system for defining states and and actions of nearly any kind of form, supporting discrete continuous, and relational domains. Planning and learning algorithms range from classic forward search planning to value function-based stochastic planning and learning algorithms. Also included is a set of analysis tools such as a common framework for the visualization of domains and agent performance in various domains. BURLAP is licensed under the permissive Apache 2.0 license. For more background information on the project and the people involved, see the Information page. Where to git it BURALP uses Maven and is available on Maven Central That means that if youd like to create a project that uses BURLAP, all you need to do is add the following dependency to the dependencies section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project If you do not have Maven installed, you can get it from here . You can also get the full BURLAP source to manually compilemodify from Github at httpsgithub.comjmacglashanburlap Alternatively, you can directly download precompiled jars from Maven Central from here . Use the jar-with-dependencies if you want all dependencies included. Prior versions of BURLAP are also available on Maven Central, and branches on github. Tutorials and Example Code Short video tutorials, longer text tutorials, and example code are available for BURLAP.All code can be found in our examples repository, which also provides the kind of POM file and file sturcture you should consider using for a BURLAP project. The example repository can be found at httpsgithub.comjmacglashanburlapexamples Video Tutorials Written Tutorials Hello Grid World - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain Documentation Java documentation is provided for all of the source code in BURLAP. You can find an online copy of the javadoc at the below location. httpburlap.cs.brown.edudocindex.html Features Current A highly felixible state representation in which you define states with regular Java code and only need to implement a short interface. This enables support for discrete, continuous, relational, or any other kind of state representation that you can code BURLAP also has optional interfaces to provide first class support for the rich OO-MDP state representation 1. Supported problem formalisms Markov Decision Processes single agent Stochastic Games multi-agent Partially Observable Markov Decision Processes single agent Tools for visualizing and defining visualizations of states, episodes, value functions, and policies. Tools for setting up experiments with multiple learning algorithms and plotting the performance using multiple performance metrics. An extendable shell framework for controlling experiments at runtime. Tools for creating multi-agent tournaments. Classic goal-directed deterministic forward-search planning. Breadth-first Search Depth-first Search A IDA Statically Weighted A 2 Dynamically Weighted A 3 Stochastic Planning. Value Iteration 4 Policy Iteration Prioritized Sweeping 20 Real-time Dynamic Programming 5 UCT 6 Sparse Sampling 17 Bounded Real-time Dynamic Programming 21 Learning. Q-learning 7 SARSA 8 Actor Critic 9 Potential Shaped RMax 12 ARTDP 5 Value Function Approximation Gradient Descent SARSA 8 Least-Squares Policy Iteration 18 Fitted Value Iteration 24 Framework for implementing linear and non-linear VFA CMACsTile Coding 10 Radial Basis Functions Fourier Basis Functions 19 The Options framework 11 supported in most single agent planning and learning algorithms. Reward Shaping Inverse Reinforcement Learning Maximum Margin Apprenticeship Learning 16 Multiple Intentions Maximum-likelihood Inverse Reinforcement Learning 22 Receding Horizon Inverse Reinforcement Learning 23 Multi-agent Q-learning and Value Iteration, supporting Q-learning with an n-step action history memory Friend-Q 13 Foe-Q 13 Correlated-Q 14 Coco-Q 15 Single-agent partially observable planning algorithms Finite horizon optimal tree search QMDP 25 Belief MDP conversion for use with standard MDP algorithms Pre-made domains and domain generators. Grid Worlds Domains represented as graphs Blocks World Lunar Lander Mountain Car Cart Pole Frostbite Blockdude Grid Games a multi-agent stochastic games domain Multiple classic Bimatrix games. RLGlue agent and environment interfacing Extensions for controlling ROS -powered robots Extensions for controlling Minecraft Features in development Learning from human feedback algorithms POMDP algorithms like POMCP and PBVI General growth of all other algorithm classes already included References Diuk, C., Cohen, A., and Littman, M.L.. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning 2008. 240-270. Pohl, Ira. First results on the effect of error in heuristic search. Machine Intelligence 5 1970 219-236. Pohl, Ira. The avoidance of relative catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving August, 1973 Puterman, Martin L., and Moon Chirl Shin. Modified policy iteration algorithms for discounted Markov decision problems. Management Science 24.11 1978 1127-1137. Barto, Andrew G., Steven J. Bradtke, and Satinder P. Singh. Learning to act using real-time dynamic programming. Artificial Intelligence 72.1 1995 81-138. Kocsis, Levente, and Csaba Szepesvari. Bandit based monte-carlo planning. ECML 2006. 282-293. Watkins, Christopher JCH, and Peter Dayan. Q-learning. Machine learning 8.3-4 1992 279-292. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. Barto, Andrew G., Richard S. Sutton, and Charles W. Anderson. Neuronlike adaptive elements that can solve difficult learning control problems. Systems, Man and Cybernetics, IEEE Transactions on 5 1983 834-846. Albus, James S. A theory of cerebellar function. Mathematical Biosciences 10.1 1971 25-61. Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1 1999 181-211. Asmuth, John, Michael L. Littman, and Robert Zinkov. Potential-based Shaping in Model-based Reinforcement Learning. AAAI. 2008. Littman, Michael L. Markov games as a framework for multi-agent reinforcement learning. ICML. Vol. 94. 1994. Greenwald, Amy, Keith Hall, and Roberto Serrano. Correlated Q-learning. ICML. Vol. 3. 2003. Sodomka, Eric, Hilliard, E., Littman, M., Greenwald, A. Coco-Q Learning in Stochastic Games with Side Payments. Proceedings of the 30th International Conference on Machine Learning ICML-13. 2013. Abbeel, Pieter, and Andrew Y. Ng. Apprenticeship learning via inverse reinforcement learning. Proceedings of the twenty-first international conference on Machine learning. ACM, 2004. Kearns, Michael, Yishay Mansour, and Andrew Y. Ng. A sparse sampling algorithm for near-optimal planning in large Markov decision processes. Machine Learning 49.2-3 2002 193-208. Lagoudakis, Michail G., and Ronald Parr. Least-squares policy iteration. The Journal of Machine Learning Research 4 2003 1107-1149 G.D. Konidaris, S. Osentoski and P.S. Thomas. Value Function Approximation in Reinforcement Learning using the Fourier Basis. In Proceedings of the Twenty-Fifth Conference on Artificial Intelligence, pages 380-385, August 2011. Li, Lihong, Michael L. Littman, and L. Littman. Prioritized sweeping converges to the optimal value function. Tech. Rep. DCS-TR-631, 2008. McMahan, H. Brendan, Maxim Likhachev, and Geoffrey J. Gordon. Bounded real-time dynamic programming RTDP with monotone upper bounds and performance guarantees. Proceedings of the 22nd international conference on Machine learning. ACM, 2005. Babes, Monica, et al. Apprenticeship learning about multiple intentions. Proceedings of the 28th International Conference on Machine Learning ICML-11. 2011. MacGlashan, James and Littman, Micahel, Between imitation and intention learning, in Proceedings of the International Joint Conference on Artificial Intelligence, 2015. Gordon, Geoffrey J. Stable function approximation in dynamic programming. Proceedings of the twelfth international conference on machine learning. 1995. Littman, M.L., Cassandra, A.R., Kaelbling, L.P., Learning Policies for Partially Observable Environments Scaling Up, in Proceedings of the 12th Internaltion Conference on Machine Learning. 1995.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["About", "Where to", "it", "Tutorials and Example Code", "Video Tutorials", "Written Tutorials", "Documentation", "Features", "Current", "Features in development", "References"], "word_count": 1249, "token_count_estimate": 1999}}, "https://blog.cs.brown.edu/2017/03/08/brown-cs-graduating-38-more-undergraduates-last-year-232-predicted-graduate-2017/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS Is Graduating 38 More Undergraduates Than Last Year, With 232 Predicted To Graduate In 2017 Posted by Monica Zuraw on March 8, 2017 Overall enrollment is currently up and introductory course enrollment is up as well. To read more stories about the Brown CS departments increasing enrollment click here . Browns Department of Computer Science continues to grow as more students choose concentrations in computer science. This year, the department is predicted to graduate 232 undergraduates, which is a 38 increase from 2016. This growth trend can be seen the year before as well, with 168 students graduating in 2016 a 28 increase from the previous record year. Brown University offers a wide range of concentrations in computer science, emphasizing the importance of interdisciplinary study. Brown CS is predicted to graduate 232 undergraduates in Spring 2017 Computer Science Bachelor of Arts 65 Computer Science Bachelor of Science 98 Computer Science- Economics Bachelor of Arts 5 Computer Science- Economics Bachelor of Science 30 Math- Computer Science 8 Applied Math- Computer Science 26 Brown CS graduated 168 undergraduates in Spring 2016 Computer Science Bachelor of Arts 46 Computer Science Bachelor of Science 75 Computer Science- Economics Bachelor of Arts 5 Computer Science- Economics Bachelor of Science 4 Math- Computer Science 11 Applied Math- Computer Science 13 Computational Biology 9 Combined Bachelor of Arts and Bachelor of Science 2 Combined Masters 3 Brown CS graduated 131 undergraduates in Spring 2015 Computer Science Bachelor of Arts 42 Computer Science Bachelor of Science 52 Computer Science- Economics Bachelor of Arts 3 Computer Science- Economics Bachelor of Science 6 Math- Computer Science 5 Applied Math- Computer Science 12 Computational Biology 6 Combined Bachelor of Arts and Bachelor of Science 2 Math- Computer Science Bachelor of Arts and Bachelor of Science 1 Combined Masters 2 For more information, please click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS Is Graduating 38% More Undergraduates Than Last Year, With 232 Predicted To Graduate In 2017"], "word_count": 335, "token_count_estimate": 425}}, "https://blog.cs.brown.edu/2017/06/01/read-more-brown-cs-students-continue-win-awards-and-fellowships/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Students Continue To Win Awards And Fellowships Posted by Jesse Polhemus on June 1, 2017 Brown CS is extremely proud of our undergraduate and graduate students, who continue to win significant awards and fellowships at a national and international level. To learn more, click any of the links below. If youre looking for stories about the awards theyve won at hackathons and other competitions, click here . Bayazit, Galgana, Kumar, And Safranchik Win CRA Outstanding Undergraduate Researcher Honorable Mentions Fong, Ren, And Weir Win CRA Outstanding Undergraduate Researcher Honorable Mentions Novotny And Collaborators Win The VIS Best Poster Award For Visualizing Dinosaur Tracks Natalie Reed Becomes Browns Tenth Google Women Techmakers Scholar Martha Edwards And Kalvin Lam Win hackNY Fellowships Esha Ghosh Wins An Inaugural Microsoft Research Dissertation Grant Geopipe, Co-Founded By Thomas Dickerson, Wins 100K At The NYU 300K Entrepreneurs Challenge Foreign Policy Magazine Names Tellex And Oberlin 2016 Global Thinkers De Stefani, Epasto, Riondato, And Upfal Win A Best Student Paper Award At KDD 2016 Andrew Crotty Wins A Google PhD Fellowship Krishna Chaitanya Aluru Wins A Y Combinator Fellowship Multiple Brown CS Collaborators Win Two Best Paper Award Runner Up Honors At HCOMP 2015 Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Four Brown CS Students Recognized As 2015 Google Scholars Esha Ghosh, Olya Ohrimenko, And Roberto Tamassia Win The ACNS 2015 Best Student Paper Award Dana Metaxa-Kakavouli Selected As Runner-Up For CRA Award Molly Long And Layla Oesper Win Google Anita Borg Memorial Scholarship Layla Oesper Wins ISMB Workshop Best Presentation Award", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Students Continue To Win Awards And Fellowships"], "word_count": 279, "token_count_estimate": 417}}, "https://blog.cs.brown.edu/2018/02/05/ignitecs-brown/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles igniteCS Brown Posted by Jesse Polhemus on Feb. 5, 2018 in Diversity by Natalie Reed and Eric Rosen As President Obama has said, Computers are going to be a big part of our futureand that future is yours to shape. Technology is one of the fastest-growing fields today, solving problems in every industry while impacting our everyday lives. Despite this, computer science is not yet adequately taught in most K-12 schools, particularly not in underserved school districts such as Providence and Central Falls in Rhode Island. Led by Professor Amy Greenwald, a group of undergraduate and graduate students who have a passion for computer science, both as an intellectual pursuit and as a path to a stable financial future, have come together to bridge the education gap by creating Browns Google igniteCS Initiative. Serving elementary, middle, and high school students, Browns igniteCS chapter focuses on empowering students through skill acquisition, including programming tools and basic algorithmic thinking. Initiatives vary from in-school programs to after-school clubs to district-wide weekend club meetings. The purpose of these initiatives is to provide as many students as possible with knowledgeable mentors who can help them start or continue on their path to learning CS. Brown CSs igniteCS club ran more than 30 Hour of Code sessions at five local Providence and Central Falls schools Spaziano Elementary School, Kennedy Elementary School, Ella Risk Elementary School, Veterans Memorial Elementary School, and Jorge Alvarez High School during CSEd Week, December 4 to 8, 2017. This is the fifth year Brown igniteCS has participated in Hour of Code outreach. Collectively, nearly 40 Brown students undergraduate and graduate taught nearly 1,000 K-12 students. Their first objective was to increase student exposure to the computer science discipline, and their second, to demonstrate how computer science has the potential to help make the world a better place. With funding from Google, Browns igniteCS club expects to continue to have a dedicated and expanded role in future Hour of Code and other outreach initiatives for many years to come. Eric Rosen, one of the student organizers for igniteCS, looks back on the program In the spring of 2017, I volunteered with a fellow mentor at Central Falls Middle School to teach 5th-7th graders about computer science in an after-school club. On our first day, we spent most of our time learning about the students favorite subjects, their hobbies, what they enjoyed and disliked, and what their general thoughts were about computers. Mostly we spent the day in an open discussion, which was a lot of fun to joke around with the kids and learn their personalities. We learned pretty quickly that this particular group of students really enjoyed video games, and in particular a lot of them played Minecraft. So my partner and I spent the next week creating a Minecraft-themed curriculum that integrated core CS ideas into it. For example, when we came back the next week, we started the class by breaking down how crafting an item, like a pickaxe, in Minecraft can be thought of as a process of steps AKA an algorithm. We were able to actually break out a game of Minecraft and play together as a class, connecting each step of the process to a step in our algorithm. Not only did the students have a ton of fun getting to play with us, they also quickly grasped the idea of an algorithm and started to try applying the concept to other things in the game, such as detailing an algorithm to build a house. As quickly as we were able to write out the steps of our algorithm, students were asking and trying to make their own personal algorithms for things they like to do in Minecraft. It was amazing to teach the students core CS thinking concepts, but I also got to have a lot of fun seeing how to apply algorithmic thinking to problems in Minecraft that I hadnt considered but the students wanted to know. The kids had a lot of fun playing Minecraft, but they also walked away seeing how ideas from CS and Minecraft were related, which is extremely important for setting the foundation of a passion for STEM getting to connect your hobbies with a subject is a really fun way to learn. I like to think that as much information as we teach the students, we as mentors get to learn so much from them since theres so much freedom to personalize what our clubs teach, and how its taught. Natalie Reed, one of igniteCSs student teachers, shares her experience This past semester, I helped run Coding Girls with four fellow student mentors. The club met every Sunday for two hours. Though on the surface the club simply taught basic programming concepts like functions and conditionals, the mentors and I really aimed to inspire our students to develop a passion for computer science. Not only were we looking to bridge the computer science education gap, but also the gender gap in computer science by targeted middle-school girls. In order to target a diverse group of students, we partnered with many of the local middle schools and libraries directly to reach our students. We also used the theme of storytelling to try to demystify the foreign and complex field of computer science. Because our goal for the camp was for the students to enjoy computer science, we tried to partner every coding concept with a fun storytelling game or exercise. We started each class with these unplugged storytelling games no computers involved. Then, the computer science concept was introduced and the students were able to use the stories they had come up with in the exercise to create an animation using the computer science concept of the day. I was amazed at how creative the students were At the end of the club, the students were able to complete a final project to show off their storytelling and programming skills alike. Each project was amazingly unique to the student. We had projects about mystical dance battles, discovering new worlds, and the cast of Hamilton fighting for supreme control of Mars. This past year was a great launch of Browns Google igniteCS chapter and were looking forward to continue to make an impact in the following academic year. Many of our initiatives this past year will become annual events, like our Classical High School After School Club, Calcutt Middle School After School Club, and Coding Girls Camp. Were also looking to expand our initiatives to reach more students and further inspire our past students. This summer, we launched our website, brownignitecs.wordpress.com , in order to maintain our connection to our students and give them a way to continue to learn after the class. Were looking forward to continuing our initiative to inspire students to learn computer science this coming fall and cant wait to get the season started. Were always looking for more student mentors to organize or teach events, so if youre interested, please apply by going to httpsignitecs.withgoogle.comregister and using V7L4QWD6 as the Brown CS group code.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "igniteCS @ Brown"], "word_count": 1193, "token_count_estimate": 1383}}, "https://blog.cs.brown.edu/2018/03/14/providence-has-been-named-americas-fourth-quirkiest-city/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Providence Has Been Named Americas Fourth Quirkiest City Posted by Jesse Polhemus on March 14, 2018 Click the link that follows for more news items about why we love calling Providence home . Theres a reason why you see Keep Providence Eldritch t-shirts around here. Citing our unorthodox founder, inventive puppetry, marching bands, and inimitable foodstuffs, Travel and Leisure has just named Providence the fourth quirkiest city in America. You can read the full article here . The image above is 2018 by Craig Fildes and used with permission under a Creative Commons license. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Providence Has Been Named America's Fourth Quirkiest City"], "word_count": 128, "token_count_estimate": 169}}, "http://burlap.cs.brown.edu/faq.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc F.A.Q. Question Index What is BURLAP What is BURLAPs software license Who do I contact if I have a question or comment Why Java and not language x What is an object-oriented Markov decision process OO-MDP What is the difference between a PropositionalFunction and a GroundedProp What is a HashableStateFactory How are terminal states defined in BURLAP Domains dont seem to provide access to the entire state space. Why not and how can I get it Can actions have preconditions My planning or learning algorithm is running out of memory, is there anything that I can do Can I have BURLAP control a robot I heard that you can use BURLAP for AI in Minecraft, how can I do that How do I cite BURLAP Is the FAQ and Java doc for version 2 of BURLAP still available Answers What is BURLAP BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAPs software license Prior to BURLAP 3, BURLAP was licensed under LGPL 3 . With the release of BURALP 3, the license was changed to the more permissive Apache 2.0 license . Who do I contact if I have a question or comment You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process OO-MDP This topic is more fully described in the Building an OO-MDP Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. Prior to BURLAP 3, all domains were represented as OO-MDPs. However, with BURLAP 3, domains use arbitrary representations that you define, with OO-MDPs having optional interfaces and tools that you can use if you wish to use that representation. What is the difference between a PropositionalFunction and a GroundedProp First, be sure read the Java documentation for these classes which provides a good deal of information. In brief, a PropositionalFunction defines the function and function signature for a propositional function a function that operates on state objects in an OO-MDP. However, when you evaluate a propositional function, you must specify on which object argument to evaluate it. A GroundedProp is a reference to a PropositionalFunction and a set of parametersarguments on which to evaluate it. What is a HashableStateFactory Tabular learning and planning algorithms need a way to quickly look up values or stored actions or otherwise for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for states and perform equality evaluations between them. We might imagine letting the State object simply implement the standard equals and hashCode methods to handle that. However, it is often the case that different experiments call for different ways of hashing or checking equality e.g., when providing state abstraction or variable discretization. Therefore, hashing and equality is provided through a HashableStateFactory that can be customized by the client. When you arent doing anything fancy, you can probably just use the SimpleHashableStateFactory , or if you do want to use a States equals and hashCode method, you can use ReflectiveHashableStateFactory How are terminal states defined in BURLAP Terminal states are defined either by an Environment implementation, or for your own simulated domains, the SampleModel. However, often times models in BURLAP are implemented with a FactoredModel that separates the state transition model, reward function, and terminal states, with the latter being defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a flag from the model or Environment, this property of the transition dynamics does not need to be specifically coded into the state transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero and is in the existing BURLAP planning and learning algorithms. If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains dont seem to provide access to the entire state space. Why not and how can I get it In many MDPs or classes of domains, the state space is infinite, in which case it cannot be defined. Other times, the state space is only finite when considering the states that are reachable from some seed initial state. And even if the state space is always finite and well defined, its often an undue burden to require the the designer to specify the entire thing manually. However, if youd like to gather all the possible states from a domain instance that youve created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible however, if you want a representation of the space, you may want to consider the FlatStateGridder class, which will sample states in the space along a regular grid that you can define. And if youre using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Can actions have preconditions Yes This is precisely the role of an ActionType , which lets you define which set of actions are applicable in a given state. My planning or learning algorithm is running out of memory, is there anything that I can do Possibly. The first thing to do is to make sure that Javas JVM is being given a large enough heap. If its not, its possible that its artificially using less memory than you have. To set the amount of memory Javas JVM can use, you want to add a -Xmx argument when you call java e.g., java -Xmx2048M class path here. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB 2GB. If youre running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments thats where you would put that flag. If youre still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many data members youve defined, or can they be compressed into a smaller set Also, you may also want to consider making your states perform shallow copies so that the pool of states reuses the same data. More information about shallow copying can be found in the Building a Domain tutorial. Can I have BURLAP control a robot Sure There are two ways you can do this. You can 1 implementyour own Environment class to manage the connection, control, and state perception of your robot or 2 use our BURLAP library extension burlaprosbridge that has a standard Environment implementation for communicating with robots controlled with ROS over Rosbridge . When using burlaprosbridge it is expected that you will implement the method to turn the ROS message into a State object.Burlaprosbridge also allows you to handle the execution of action in a variety of ways, including sending direct messages to the ROS controller e.g., Twist messages or by sending string messages to a ROS action controller. See burlaprosbridges githubpage for more information and examples of how to use it. Burlaprosbridge is also on Maven Central, so to link to it, simply add the following dependency alongside the BURLAP dependency in your projects pom.xml file edu.brown.cs.burlap burlaprosbridge 3.0.0 You can also manually compile from the source on the github page . I heard that you can use BURLAP for AI in Minecraft, how can I do that Yes, we have been building a mod for Minecraft that allows you to use BURLAPs planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP For the moment, youll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once its available. Is the FAQ and Java doc for version 2 of BURLAP still available Yes, you can access the older FAQ here , and the older Java doc here .", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["F.A.Q.", "Question Index"], "word_count": 1688, "token_count_estimate": 2074}}, "http://burlap.cs.brown.edu/faqv1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc F.A.Q. This is FAQ for version 1 of BURLAP. To go back to the version 2 FAQ, go here . Question Index What is BURLAP What is BURLAPs software license Who do I contact if I have a question or comment Why Java and not language x What is an object-oriented Markov decision process OO-MDP What is the difference between an Action and a GroundedAction What about a PropositionalFunction and a GroundedProp What is an AbstractGroundedAction class It seems that Action parameters correspond to typed OO-MDP state objects can I define an action with non-object parameters What is a StateHashFactory What is object identifier invariance If object identifier invariance leads to smaller state spaces, why wouldnt I want to use it How are terminal states defined in BURLAP Domains dont seem to provide access to the entire state space. Why not and how can I get it Where are transition dynamics defined Can actions have preconditions What is a SingleAction class What is a parameter order group Is there a way to set up an Environment that maintains the current state with which the agent interacts My planning or learning algorithm is running out of memory, is there anything that I can do Can I have BURLAP control a robot I heard that you can use BURLAP for AI in Minecraft, how can I do that How do I cite BURLAP Answers What is BURLAP BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAPs software license BURLAP is licensed under LGPL. In brief, that means you can use it for free and even link to it in sold software. Who do I contact if I have a question or comment You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process OO-MDP This topic is more fully described on page 2 of the Building a Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. What is the difference between an Action and a GroundedAction What about a PropositionalFunction and a GroundedProp An Action object defines an actions name, set of parameters, and the code that defines the physics of an action. Because actions can be parameterized, there needs to be a way to refer to each specific application of an action. A GroundedAction serves this purpose by being a reference to an Action object along with a set of parameters with which the action is to be applied. To give an example, in a blocks world, the pickup Action object defines an action that is parameterized to a block object and how the state changes when it is applied to any given block. In a world with three blocks, there would be three different GroundedAction objects that reference the pickup Action object one for each block. If an Action does not define any parameters, then a corresponding GroundedAction for it will have an empty set of specified parameter values. The difference between a PropositionalFunction object and a GroundedProp object is similar. A PropositionalFunction defines how a propositional function evaluates and to which object classes it is parameterized. A GroundedProp is a reference to a propositional function and the parameters with which it should be evaluated. What is an AbstractGroundedAction class AbstractGroundedAction is an abstract super class for the GroundedAction class and others. The reason it exists is because BURLAP supports a variety of planning and learning problem types, including multi-agent stochastic games domains, which require a bit different under-the-hood management. However, because BURLAP seeks to reuse code as much as possible, difference pieces can be connected as long as they inherit from the same super class. For example, the GroundedSingleAction and JointAction objects are also subclasses of AbstractGroundedAction, which means tools like Policy objects can be reused for both single agent domains and multi-agent domains. It seems that Action parameters correspond to typed OO-MDP state objects can I define an action with non-object parameters Yes Although the default behavior for action parameters are to correspond to OO-MDP objects in a state, you can have any kind of parameterization that you want. To have your action use a different kind of parameterization you need to do two things. First, for the Action in question, override the method getAllApplicableGroundedActionsState to return the list of GroundedAction objects with all parameterizations of your Action possible in the given state. Because the parameters in a GroundedAction are specified with String objects, you can represent any number of parameter data types in their string form. Second, override the method parametersAreObjects and have it return false this lets planning and learning algorithms know that because the parameters are not objects, it does not need to account for object identifier invariance in the actions. With those changes, the parameters passed to the standard Action object methods e.g., performActionState, String, will always be one of the possible parameterizations that youve defined. The parameters always come in String data types, which means you can provide any kind of information that you can represent in a String. What is a StateHashFactory Tabular learning and planning algorithms need a way to quickly look up values or stored actions or otherwise for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for OO-MDP State objects and perform equality evaluations between them. Depending the kind of problem youre solving there may be different ways that you need to compute the hash code and perform equality evaluations. For example, perhaps you want to plan in an abstract space that ignores certain objects or attribute values. Or maybe you need to discretize real-valued attributes before comparing the states. Or maybe you dont want to use object identifier invariance. Since different problems may require different ways of hashing and comparing states, different StateHashFactory implementations will produce different StateHashTuple objects that compute hash codes and perform state equality evaluations differently. There are a number of different variants already in BURLAP, but if you need to perform State equality evaluations in an entirely unique way, the power of BURLAP is that you can implement your own and hand it off to the planning and learning algorithm What is object identifier invariance For a larger discussion of this topic, see page 2 of the Building a Domain tutorial . In short, if a domain and StateHashFactory is object identifier invariant, then it means that the equality of two states is independent of the order of the objects or their name in the states. Instead, two states will be considered equal as long as there is a bijection between their objects such that each matched object is equal to one another. Using object identifier invariance results in a compression of the state space size since you dont have to treat every ordering of the same objects as different states If object identifier invariance leads to smaller state spaces, why wouldnt I want to use it When you dont - For example, if you want to define a goal in which the condition for a specific object is satisfied, you need to differentiate between objects with different identifiers. Additionally, if you are creating a relational domain, then you must have object identifier dependence, because being invariant to object identifiers in a relational domain would require solving graph isomorphism which is thought to be NP-hard. So while detecting graph isomorphism is doable, BURLAP does not support by default object identifier invariance in relational domains since its not tractable. How are terminal states defined in BURLAP Terminal states are defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a TerminalFunction class, this property of the transition dynamics does not need to be specifically coded into the action transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero and is in the existing BURLAP planning and learning algorithms. If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains dont seem to provide access to the entire state space. Why not and how can I get it In an OO-MDP, the state space is infinite because you can always just imagine another world with an additional object. Although in practice your state space may always be well defined, the domain generators in BURLAP can support much more than any single instance, which may make enumerating the state space for any domain instance non-trivial. For example, even in grid worlds you can imagine any number of different grid worlds. In other cases, it can just be hard to manually enumerate all possible state, which would make requiring it for domains a burden on the designer. However, if youd like to gather all the possible states from a domain instance that youve created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible however, if you want a representation of the space, you may want to consider the StateGridder class, which will sample states in the space along a regular grid that you can define. And if youre using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Where are transition dynamics defined Transition dynamics for a single-agent domain are defined in the Action classes that you or an existing domain implement. Specifically, there are two Action class methods related to the transition dynamics performActionHelperState, String and getTransitionsState String. The performActionHelper method, as the name implies performs the action on the given state and the given parameters, if any, in the String array and returns the outcome state the input state can be directly modified and returned safely since the perfomAction method copies the state before passing it to performActionHelper. If the domain is stochastic, then the method should randomly sample an outcome state according to the distribution. Note that this method does not require the probability of the sampled outcome state to be returned, which in some domains may be non-trivial to compute. This method must be overridden to implement an Action. The getTransitions method returns a list of all the possible outcome states with non-zero probability as well as their probability of occurring. Although this method does not need to be implemented, some algorithms, such as dynamic programming variants, require it to be implemented. If you or the existing domain do not override the method, then when it is called by an algorithm that requires it, an UnsupportedOperation exception will be thrown. If your action is deterministic, the getTransitions method can be trivially implemented by returning the result of the deterministicTranstionState, String method, which will get the outcome state by calling the performAction method, wrap it in a TransitionProbability object with assigned probability 1.0 and insert it in a list with just that element. For multi-agent domains, similar methods that need to be overridden exist in the JointActionModel abstract class actionHelperState, JointAction and transitionProbsForState, JointAction, respectively. Can actions have preconditions Yes By default, actions are assumed to always be applicable in all states, but you can add preconditions by implementing the Action method applicableInStateState, String. For multi-agent domains, you should similarly implement the isApplicableInStateState, String method in the SingleAction class. This method should return true when the Action being implemented can be applied in the given state with the given parameters and false when it cannot be applied. What is a SingleAction class A SingleAction defines an action that can be taken by single agent in a multi-agent stochastic games domain. For a world with a given set of agents acting the world, each single action selected by each agent makes up the total JointAction that is taken a in single time step of the world. Unlike the Action class in single agent domains, SingleAction objects do not implement transition dynamics, because the change in world state is dependent on the joint action taken by all agents. Instead the multi-agent domain transition dynamics are defined in the JointActionModel abstract class. What is a parameter order group You will see this term used in the definition of parameters for actions and propositional functions in particular as possible arguments in some of the possible constructors. Parameters that belong to the same parameter order group POG can have their values swapped without changing the effect of the action or evaluation of the propositional function. For example, consider the propositional function prototype touchingX, Y, which returns true when the object assigned to X is touching the object assigned to Y. This evaluation should be be transitive. That is, if touchinga, b is true, then touchingb, a is true and inversely when one evaluates to false, flipping the parameters should still result in a false evaluation. To encode that the parameters are transitive, we assign them to the same POG which can be named anything as long as its the same name for both. If they are not transitive, then we would assign different POGs to them. If you use an Action constructor or PropositionalFunction constructor without the POG values argument, it will automatically assign each parameter to a different POG that is, non-transitivity is the default assumption. Specifying the parameter transitivity with POGs is useful because when you request a list of all grounded versions of an action with the getAllApplicableGroundedActionsState method or propositional function with the getAllGroundedPropsForStateState method, it will not produce a grounding that is transitively identical to another already in the list. In our touchingX, Y example, for instance, it will return a list with only the grounding for touchinga, b, or touchingb, a, but not both. Is there a way to set up an Environment that maintains the current state with which the agent interacts Yes. In general, the learning algorithms in BURLAP do not require environments to be set up you can just tell them run a learning episode from a given initial state and they will do so. However, sometimes an environment is useful, especially when the state of the environment can change from external forces e.g., robotics in which the real world changes on its own, or humans manipulating the state of your environment. For such purposes, you can subclass the Environment class. To have an agent learn in the environment, you can then set up a DomainEnvironmentWrapper , which creates a domain that funnels all perfomAction methods through the Environment. To use a standard BURLAP LearningAgent instance with an Environment, upon construction of the LearningAgent, set its domain to be the DomainEnvironmentWrapper that you created for your environment, and then tell it to learn from whatever the current state of the Environment is which you can retrieve using the getCurState method. In general, however, if you do not have outside forces affecting the state of your learning problem, you probably dont need to set up an Environment class. My planning or learning algorithm is running out of memory, is there anything that I can do Possibly. The first thing to do is to make sure that Javas JVM is being given a large enough heap. If its not, its possible that its artificially using less memory than you have. To set the amount of memory Javas JVM can use, you want to add a -Xmx argument when you call java e.g., java -Xmx2048M class path here. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB 2GB. If youre running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments thats where you would put that flag. If youre still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many OO-MDP objects youve defined, or can they be compressed into a smaller set Second, you might want to override the Action class performActionState String method. Note, this is not the same as the performActionHelperState String that youre typically required to override. The role of the performAction method is to first copy the input state and then pass it to the performActionHelper method, which ensures that the performActionHelper method can modify the input state without affecting the state of the world in which the action is applied. To save some memory, a trick you can do is instead of calling the State copy method, call the semiDeepCopy method. The semiDeepCopy method takes as arguments a list of object instances that need to be deep copied. In the returned state, only the specified objects will have been deep copied and the rest will have been shallow copied. As long as you deep copy the objects that the Action will modify, this semiDeepCopy operation will be safe. The exception is if some other code goes back and edits the value of some previous states object values that were not deep copied, then all of the shallow copies of it in each state will change. Can I have BURLAP control a robot Sure There are three ways you can do this. You can 1 define your domain to directly control the robot and update the world state through your Action classes specifically via your implementations of performActionHelper 2 implementan Environment class to manage the connection, control, and state perception of your robot or 3 use our BURLAP library extension burlaprosbridge for communicating with robots controlled with ROS . burlaprosbridge provides a standard Environment class implementation that maintains the state of the real world and controlsthe physical robot by communicating to ROS over Rosbridge . On the ROS side, it is expected that you create a ROS topic that is publishing BURLAP state messages formatted according our defined burlapmsgs type and that there is a topic BURLAP can push to that accepts action commands as a string type. See burlaprosbridges githubpage for more information on how to use it. I heard that you can use BURLAP for AI in Minecraft, how can I do that Yes, we have been building a mod for Minecraft that allows you to use BURLAPs planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP For the moment, youll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once its available.", "metadata": {"last_modified": "2016-03-04T22:05:06+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["F.A.Q.", "Question Index"], "word_count": 3433, "token_count_estimate": 4159}}, "http://burlap.cs.brown.edu/faqv2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc F.A.Q. Question Index What is BURLAP What is BURLAPs software license Who do I contact if I have a question or comment Why Java and not language x What is an object-oriented Markov decision process OO-MDP What is the difference between an Action and a GroundedAction What about a PropositionalFunction and a GroundedProp What is an AbstractGroundedAction class What is a HashableStateFactory What is object independence invariance If object identifier independence leads to smaller state spaces, why wouldnt I want to use it How are terminal states defined in BURLAP Domains dont seem to provide access to the entire state space. Why not and how can I get it Where are transition dynamics defined Can actions have preconditions What is an SGAgentAction class What is a parameter order group My planning or learning algorithm is running out of memory, is there anything that I can do Can I have BURLAP control a robot I heard that you can use BURLAP for AI in Minecraft, how can I do that How do I cite BURLAP Is the FAQ and Java doc for version 1 of BURLAP still available Answers What is BURLAP BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. What is BURLAPs software license BURLAP is licensed under LGPL. In brief, that means you can use it for free and even link to it in sold software. Who do I contact if I have a question or comment You can either field the question to the community in our Google group or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu. Why Java and not language x Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them. What is an object-oriented Markov decision process OO-MDP This topic is more fully described on page 2 of the Building a Domain tutorial . In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined. What is the difference between an Action and a GroundedAction What about a PropositionalFunction and a GroundedProp First, be sure read the Java documentation for these classes which provides a good deal of information. In brief, an Action is subclassed and instantiated to define your MDP actions that means the action name, its preconditions, parameterizations, and transition dynamics. Because actions can be defined to be parameterized, decisions that an agent makes are not only over the space of actions definitions, but the space of possible parameterizations for each action definition. As a consequence, there needs to be a way for agents to refer to which action-parameterization theyre considering. The GroundedAction serves this purpose by containing a reference to an Action, as well as parameter assignments with which the action will be applied. When you subclass Action, the kinds of parameterizations your action supports are defined by the getAssociatedGroundedAction and getAllApplicableGroundedActionsburlap.oomdp.core.states.State methods, which should return a subclass of GroundedAction that contains the possible parameterizations. Because you can create your own subclasses of GroundedAction, you can define any kind of action parameterization that youd like From continuous valued parameters, to STRIPs-like object references. If your action is not parameterized and has no preconditions, you should consider subclassing SimpleAction , which implements many of the Action methods and returns the parameter-free SimpleGroundedAction . The difference between PropositionalFunction and GroundedProp is similar PropositionalFunction defines the propositional function and GroundedProp is a reference to the PropositionalFunction along with the parameters with which to evaluate it. In this case, however, the parameters to propositional functions are always OO-MDP objects in the state. What is an AbstractGroundedAction class AbstractGroundedAction is the common interface for the GroundedAction class and other and acton groundings used in other problem types for example, GroundedSGAgentAction in stochastic games. This common interface allows tools in BURLAP be re-used across different problem types. For example, the Policy class can be used in both single agent problems and stochastic games problems, because it returns AbstractGroundedAction implementations, rather than a single problem types grounded action. What is a HashableStateFactory Tabular learning and planning algorithms need a way to quickly look up values or stored actions or otherwise for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for OO-MDP State objects and perform equality evaluations between them. Depending the kind of problem youre solving there may be different ways that you need to compute the hash code and perform equality evaluations. For example, perhaps you want to plan in an abstract space that ignores certain objects or attribute values. Or maybe you need to discretize real-valued attributes before comparing the states. Or maybe you dont want to use object identifier invariance. Since different problems may require different ways of hashing and comparing states, different HashableStateFactory implementations will produce different HashableState objects that compute hash codes and perform state equality evaluations differently. However, unless you want to do something special, like state abstraction use SimpleHashableStateFactory . You can also always implement your own if you need special functionality not already supported in BURLAP What is object identifier independence For a larger discussion of this topic, see page 2 of the Building a Domain tutorial . In short, if a domain is object identifier independent, then it means that the equality of two states is independent of the order of the objects or their name in the states. Instead, two states will be considered equal as long as there is a bijection between their objects such that each matched object is equal to one another. Using object identifier independence results in a compression of the state space size since you dont have to treat every ordering of the same objects as different states. If object identifier independence leads to smaller state spaces, why wouldnt I want to use it When you dont - For example, if you want to define a goal in which the condition for a specific object is satisfied, you need to differentiate between objects with different identifiers. Additionally, if you are creating a relational domain, then you must have object identifier dependence, because being invariant to object identifiers in a relational domain would require solving graph isomorphism which is thought to be NP-hard. So while detecting graph isomorphism is doable, BURLAP does not implement object identifier independence in relational domains since its not tractable. How are terminal states defined in BURLAP Terminal states are defined with an object that implements the TerminalFunction interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a TerminalFunction class, this property of the transition dynamics does not need to be specifically coded into the action transition dynamics, which makes it easy to define various ad hoc tasks for the same domain. Given this interpretation, the value of terminal states should be fixed at zero and is in the existing BURLAP planning and learning algorithms. If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world treats the terminal state has having a non-zero value. Domains dont seem to provide access to the entire state space. Why not and how can I get it In an OO-MDP, the state space is infinite because you can always just imagine another world with an additional object. Although in practice your state space may always be well defined, the domain generators in BURLAP can support much more than any single instance, which may make enumerating the state space for any domain instance non-trivial. For example, even in grid worlds you can imagine any number of different grid worlds. In other cases, it can just be hard to manually enumerate all possible state, which would make requiring it for domains a burden on the designer. However, if youd like to gather all the possible states from a domain instance that youve created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the StateReachability class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the StateEnumerator class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each. If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible however, if you want a representation of the space, you may want to consider the StateGridder class, which will sample states in the space along a regular grid that you can define. And if youre using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it. Where are transition dynamics defined Transition dynamics for a single-agent domain are defined in the Action classes that you or an existing domain implement. Specifically, there are two methods used for defining transition dynamics. The performActionHelperState, GroundedAction and, if your Action class implements FullActionModel , getTransitionsState GroundedAction. The performActionHelper method, as the name implies performs the action on the given state and the given parameters, if any, in the GroundedAction argument and returns the outcome state. If the domain is stochastic, then the method should randomly sample an outcome state according to the distribution. Note that this method does not require the probability of the sampled outcome state to be returned, which in some domains may be non-trivial to compute. This method must be implemented to implement an Action. The getTransitions method returns a list of all the possible outcome states with non-zero probability as well as their probability of occurring.This method only needs to be implemented if your action implements the optional interface FullActionModel, because for some domains it is impossible to enumerate all possible outcomes. However, some algorithms, such as DynamicProgramming algorithms, require being able to access the fully enumerated transition dynamics. So if you plan on using these algorithms with your domain, your Action will need to implement the interface and method. For stochastic games problems, similar methods that need to be overridden exist in the JointActionModel abstract class actionHelperState, JointAction and transitionProbsForState, JointAction, respectively. Can actions have preconditions Yes When you subclass Action , one of the methods you must implement is applicableInStateState, GroundedAction, which should return true in states where you preconditions are satisfied and false in states where they are not. For stochastic games, the SGAgentAction has a method with the same name for the same purpose. What is a SGActionACtion class A SGAgentAction class is used to define stochastic games problems. Stochastic games are formalism for a multi-agent problem. In the definition, each agent in the world has a set of individual actions that they apply and at each time step, they each choose from their set of actions and execute them at the same time. Similar, to the single-agent problem Action class, the SGAgentAction class is used to define the name, preconditions, and parameterizations of an action that an agent in a stochastic games problem can take. Since states in a stochastic game change as a function of joint actions taken by all agents in the world, SGAgentAction does not have transition dynamics defined in it. Instead, transition dynamics for stochastic games are defined in the JointActionModel abstract class. What is a parameter order group You will see this term used in the definition of STRIPs-like ObjectParameterizedAction implementations and the PropositionalFunction class. A parameter order group is used with OO-MDP object parameters to specify whether there is symmetry between parameters. That is, parameters that belong to the same parameter order group POG can have their values swapped without changing the effect of the action or evaluation of the propositional function. For example, consider the propositional function prototype touchingX, Y, which returns true when the object assigned to X is touching the object assigned to Y. This evaluation should be be transitive. That is, if touchinga, b is true, then touchingb, a is true and inversely when one evaluates to false, flipping the parameters should still result in a false evaluation. To encode that the parameters are transitive, we assign them to the same POG which can be named anything as long as its the same name for both. If they are not transitive, then we would assign different POGs to them. If you use an ObjectParameterizedAction constructor or PropositionalFunction constructor without the POG values argument, it will automatically assign each parameter to a different POG that is, non-transitivity is the default assumption. Specifying the parameter transitivity with POGs is useful because when you request a list of all grounded versions of an ObjectParameterizedAction with the getAllApplicableGroundedActionsState method or propositional function with the getAllGroundedPropsForStateState method, it will not produce a grounding that is transitively identical to another already in the list. In our touchingX, Y example, for instance, it will return a list with only the grounding for touchinga, b, or touchingb, a, but not both. My planning or learning algorithm is running out of memory, is there anything that I can do Possibly. The first thing to do is to make sure that Javas JVM is being given a large enough heap. If its not, its possible that its artificially using less memory than you have. To set the amount of memory Javas JVM can use, you want to add a -Xmx argument when you call java e.g., java -Xmx2048M class path here. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB 2GB. If youre running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments thats where you would put that flag. If youre still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many OO-MDP objects youve defined, or can they be compressed into a smaller set Finally, if youre still running out memory, you should considering writing your own implementation of the State interface that allows for the most efficient management of your state data. Its possible the standard MutableState implementation that is mostly used in BURLAP domains is too general and is being wasteful for your specific domain. Can I have BURLAP control a robot Sure There are two ways you can do this. You can 1 implementyour own Environment class to manage the connection, control, and state perception of your robot or 2 use our BURLAP library extension burlaprosbridge that has a standard Environment implementation for communicating with robots controlled with ROS over Rosbridge . When using burlaprosbridge it is expected that you create a ROS topic that is publishing BURLAP state messages. By default,these messaged are assumed to adhere our ROS burlapmsgs type. However, you can also subclass the RosEnvironment to implement custom parsing of differently formatted topics. Burlaprosbridge allows you to handle the execution of action in a variety of ways, including sending direct messages to the ROS controller e.g., Twist messages or by sending string messages to a ROS action controller. See burlaprosbridges githubpage for more information and examples of how to use it. Burlaprosbridge is also on Maven Central, so to link to it, simply add the following dependency alongside the BURLAP dependency in your projects pom.xml file edu.brown.cs.burlap burlaprosbridge 2.1.0 You can also manually compile from the source on the github page . I heard that you can use BURLAP for AI in Minecraft, how can I do that Yes, we have been building a mod for Minecraft that allows you to use BURLAPs planning and learning algorithms to control the player. For more information on that project, see its github page and its accompanying wiki page . How do I cite BURLAP For the moment, youll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once its available. Is the FAQ and Java doc for version 1 of BURLAP still available Yes, you can access the older FAQ here , and the older Java doc here .", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["F.A.Q.", "Question Index"], "word_count": 2897, "token_count_estimate": 3603}}, "http://burlap.cs.brown.edu/index.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc About The Brown-UMBC Reinforcement Learning and Planning BURLAP java code library is for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them. BURLAP uses a highly flexible system for defining states and and actions of nearly any kind of form, supporting discrete continuous, and relational domains. Planning and learning algorithms range from classic forward search planning to value function-based stochastic planning and learning algorithms. Also included is a set of analysis tools such as a common framework for the visualization of domains and agent performance in various domains. BURLAP is licensed under the permissive Apache 2.0 license. For more background information on the project and the people involved, see the Information page. Where to git it BURALP uses Maven and is available on Maven Central That means that if youd like to create a project that uses BURLAP, all you need to do is add the following dependency to the dependencies section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project If you do not have Maven installed, you can get it from here . You can also get the full BURLAP source to manually compilemodify from Github at httpsgithub.comjmacglashanburlap Alternatively, you can directly download precompiled jars from Maven Central from here . Use the jar-with-dependencies if you want all dependencies included. Prior versions of BURLAP are also available on Maven Central, and branches on github. Tutorials and Example Code Short video tutorials, longer text tutorials, and example code are available for BURLAP.All code can be found in our examples repository, which also provides the kind of POM file and file sturcture you should consider using for a BURLAP project. The example repository can be found at httpsgithub.comjmacglashanburlapexamples Video Tutorials Written Tutorials Hello Grid World - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain Documentation Java documentation is provided for all of the source code in BURLAP. You can find an online copy of the javadoc at the below location. httpburlap.cs.brown.edudocindex.html Features Current A highly felixible state representation in which you define states with regular Java code and only need to implement a short interface. This enables support for discrete, continuous, relational, or any other kind of state representation that you can code BURLAP also has optional interfaces to provide first class support for the rich OO-MDP state representation 1. Supported problem formalisms Markov Decision Processes single agent Stochastic Games multi-agent Partially Observable Markov Decision Processes single agent Tools for visualizing and defining visualizations of states, episodes, value functions, and policies. Tools for setting up experiments with multiple learning algorithms and plotting the performance using multiple performance metrics. An extendable shell framework for controlling experiments at runtime. Tools for creating multi-agent tournaments. Classic goal-directed deterministic forward-search planning. Breadth-first Search Depth-first Search A IDA Statically Weighted A 2 Dynamically Weighted A 3 Stochastic Planning. Value Iteration 4 Policy Iteration Prioritized Sweeping 20 Real-time Dynamic Programming 5 UCT 6 Sparse Sampling 17 Bounded Real-time Dynamic Programming 21 Learning. Q-learning 7 SARSA 8 Actor Critic 9 Potential Shaped RMax 12 ARTDP 5 Value Function Approximation Gradient Descent SARSA 8 Least-Squares Policy Iteration 18 Fitted Value Iteration 24 Framework for implementing linear and non-linear VFA CMACsTile Coding 10 Radial Basis Functions Fourier Basis Functions 19 The Options framework 11 supported in most single agent planning and learning algorithms. Reward Shaping Inverse Reinforcement Learning Maximum Margin Apprenticeship Learning 16 Multiple Intentions Maximum-likelihood Inverse Reinforcement Learning 22 Receding Horizon Inverse Reinforcement Learning 23 Multi-agent Q-learning and Value Iteration, supporting Q-learning with an n-step action history memory Friend-Q 13 Foe-Q 13 Correlated-Q 14 Coco-Q 15 Single-agent partially observable planning algorithms Finite horizon optimal tree search QMDP 25 Belief MDP conversion for use with standard MDP algorithms Pre-made domains and domain generators. Grid Worlds Domains represented as graphs Blocks World Lunar Lander Mountain Car Cart Pole Frostbite Blockdude Grid Games a multi-agent stochastic games domain Multiple classic Bimatrix games. RLGlue agent and environment interfacing Extensions for controlling ROS -powered robots Extensions for controlling Minecraft Features in development Learning from human feedback algorithms POMDP algorithms like POMCP and PBVI General growth of all other algorithm classes already included References Diuk, C., Cohen, A., and Littman, M.L.. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning 2008. 240-270. Pohl, Ira. First results on the effect of error in heuristic search. Machine Intelligence 5 1970 219-236. Pohl, Ira. The avoidance of relative catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving August, 1973 Puterman, Martin L., and Moon Chirl Shin. Modified policy iteration algorithms for discounted Markov decision problems. Management Science 24.11 1978 1127-1137. Barto, Andrew G., Steven J. Bradtke, and Satinder P. Singh. Learning to act using real-time dynamic programming. Artificial Intelligence 72.1 1995 81-138. Kocsis, Levente, and Csaba Szepesvari. Bandit based monte-carlo planning. ECML 2006. 282-293. Watkins, Christopher JCH, and Peter Dayan. Q-learning. Machine learning 8.3-4 1992 279-292. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. Barto, Andrew G., Richard S. Sutton, and Charles W. Anderson. Neuronlike adaptive elements that can solve difficult learning control problems. Systems, Man and Cybernetics, IEEE Transactions on 5 1983 834-846. Albus, James S. A theory of cerebellar function. Mathematical Biosciences 10.1 1971 25-61. Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1 1999 181-211. Asmuth, John, Michael L. Littman, and Robert Zinkov. Potential-based Shaping in Model-based Reinforcement Learning. AAAI. 2008. Littman, Michael L. Markov games as a framework for multi-agent reinforcement learning. ICML. Vol. 94. 1994. Greenwald, Amy, Keith Hall, and Roberto Serrano. Correlated Q-learning. ICML. Vol. 3. 2003. Sodomka, Eric, Hilliard, E., Littman, M., Greenwald, A. Coco-Q Learning in Stochastic Games with Side Payments. Proceedings of the 30th International Conference on Machine Learning ICML-13. 2013. Abbeel, Pieter, and Andrew Y. Ng. Apprenticeship learning via inverse reinforcement learning. Proceedings of the twenty-first international conference on Machine learning. ACM, 2004. Kearns, Michael, Yishay Mansour, and Andrew Y. Ng. A sparse sampling algorithm for near-optimal planning in large Markov decision processes. Machine Learning 49.2-3 2002 193-208. Lagoudakis, Michail G., and Ronald Parr. Least-squares policy iteration. The Journal of Machine Learning Research 4 2003 1107-1149 G.D. Konidaris, S. Osentoski and P.S. Thomas. Value Function Approximation in Reinforcement Learning using the Fourier Basis. In Proceedings of the Twenty-Fifth Conference on Artificial Intelligence, pages 380-385, August 2011. Li, Lihong, Michael L. Littman, and L. Littman. Prioritized sweeping converges to the optimal value function. Tech. Rep. DCS-TR-631, 2008. McMahan, H. Brendan, Maxim Likhachev, and Geoffrey J. Gordon. Bounded real-time dynamic programming RTDP with monotone upper bounds and performance guarantees. Proceedings of the 22nd international conference on Machine learning. ACM, 2005. Babes, Monica, et al. Apprenticeship learning about multiple intentions. Proceedings of the 28th International Conference on Machine Learning ICML-11. 2011. MacGlashan, James and Littman, Micahel, Between imitation and intention learning, in Proceedings of the International Joint Conference on Artificial Intelligence, 2015. Gordon, Geoffrey J. Stable function approximation in dynamic programming. Proceedings of the twelfth international conference on machine learning. 1995. Littman, M.L., Cassandra, A.R., Kaelbling, L.P., Learning Policies for Partially Observable Environments Scaling Up, in Proceedings of the 12th Internaltion Conference on Machine Learning. 1995.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["About", "Where to", "it", "Tutorials and Example Code", "Video Tutorials", "Written Tutorials", "Documentation", "Features", "Current", "Features in development", "References"], "word_count": 1249, "token_count_estimate": 1999}}, "http://burlap.cs.brown.edu/information.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Contact If you would like to contact the creator, send an email to James MacGlashan at jmacglashan at cs dot brown dot edu. Alternatively, it may be worthwhile to direct your question to the BURLAP Google group at httpsgroups.google.comforumforumburlap-discussion Obtaining BURLAP BURALP now fully supports Maven and is available on Maven Central That means that if youd like to create a project that uses BURLAP, all you need to do is add the following dependency to the dependencies section of your projects pom.xml edu.brown.cs.burlap burlap 3.0.0 and the library will automatically be downloaded and linked to your project If you do not have Maven installed, you can get it from here You can also get thefull BURLAP source to manually compilemodify from Github at httpsgithub.comjmacglashanburlap Alternatively, you can directly download precompiled jars from Maven Central from here , including older versions of Java. Use the jar-with-dependencies if you want all dependencies included. If you are looking for the older version 1 of BURLAP that predated Maven, you can get the pre-compiled jars for it below, or use the v1 branch on git. version 1 pre-compiled jar with dependencies included, or version 1 pre-compiled jar with out dependencies. The Java doc for version 2 can be found here and version 1 Java doc can be here . History and Future The Brown-UMBC Reinforcement Learning and Planning BURLAP Java library is primarily developed and maintained by James MacGlashan, a postdoc at Brown University , with a number of contributions from various students. BURLAP originated from James MacGlashans dissertation work at the University of Maryland, Baltimore County UMBC in transfer learning for reinforcement learning Multi-source Option-based Policy Transfer. This work motivated the need for a reinforcement learning code framework that was built on top of a highly expressive domain representation that could support flexible task definitions. The answer to this demand was the object-oriented Markov Decision process OO-MDP formalism, which represents states as a set of objects in the worldeach defined by their own attributesand provides a set of high-level propositional functions that operate on the objects in states. At the time, there were no existing libraries that supported OO-MDPs in fact, OO-MDPs were a fairly new idea in general instead, most libraries were restricted to RLs more classic fixed feature vector representation. As a consequence, code to rapidly deploy OO-MDP domains was developed. After James graduated and moved to Brown, the initial OO-MDP code proved to be valuable in being able to quickly generate a variety of different classes of problems to which already implemented algorithms could be trivially applied. The ability to support lots of different problems enabled the code to be easily used for a number of different projects that more typically would have required reimplementation of standard algorithms for a different representation. In response, a decision was made to polish, expand, and document the code base, and make it all available to the public. The result is BURLAP as it is now. If everything goes well, BURLAP will never be finished because it will continue to have more algorithms found in reinforcement learning and planning literature added to it and grow with the field. Ideally, it will also continue grow to support even more classes of problems. As of writing this, BURLAP supports finite, infinite, continuous, and relational state spaces in single-agent or multi-agent stochastic game problem spaces with a finite number of parameterizable actions. Object-oriented Partially observable MDPs POMDPs is currently in development with a number of POMDP algorithms being implemented. BURLAP could also be trivially extended to support continuous action and time domains, but has not yet since there are currently no implemented algorithms in BURLAP to take advantage of it. In the future, we hope to expand into this space as well. If there is a reinforcement learning or planning problem class that BURLAP cannot support that you would like to see, we would love to hear from you so that we can consider adding in support. The ultimate goal of BURLAP is to be able to pick and choose different algorithms for any number of different problems you might want to solve and stop us from reinventing the wheel every time. BURLAP Extensions Currently there are three BURLAP library extension projects used to connect BURLAP up with other systems. BURLAP Rosbridge This extension allows you to control ROS-powered robots with BURLAP planning and learning algorithms by providing a standard BURLAP Environment class that communicates to ROS over Rosbridge . BURLAP Rosbridge is also on Maven Central, so you can simply add the following dependency along with your BURLAP dependency edu.brown.cs.burlap burlaprosbridge 3.0.0 BurlapCraft This extension allows you to use BURLAP planning and learning algorithms to control a player in the video game Minecraft . BURLAP Weka This extensions provides some tools for hooking up BURLAP with Weka , the machine learning library. Weka, however, is licensed under GPL, so if you use this extension, the whole license is GPL. People Organizers Brown University James MacGlashan - Creator and primary maintainer. Contact jmacglashan at cs dot brown dot edu Michael Littman Stefanie Tellex University of Maryland, Baltimore County Marie desJardins Code Contributers David Abel Izaak Baker Gabriel Barth-Maron Stephen Brawner Spandan Dutta Daniel Fernandez Nakul Gopalan Esha Gosh Ellis Herskowitz Mark Ho Anubhav Malhotra John Meehan Michalis Michaelidis Philippe Morere Takehiro Oyakawa Chan Trau Lei Yang", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Contact", "Obtaining BURLAP", "History and Future", "BURLAP Extensions", "People", "Organizers"], "word_count": 898, "token_count_estimate": 1206}}, "http://burlap.cs.brown.edu/tutorials/bd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 2 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Next Part Java Interfaces for MDP Definitions To define your own MDP in BURLAP that can then be used with BURLAPs planning or learning algorithms, you will want to familiarize yourself with the following Java interfaces and data structures. Here we will give a brief review of what each these are, and in the subsequent sections we will be implenting the interfaces to define our grid world. A UML diagram of these elements is shown in the below figure. Figure UML Digram of the Java interfacesclasses for an MDP definition. SADomain - A data structure that stands for single agent domain. This data structure stores information about an MDP that you will define and is typically passed to different planning or learning algorithms. State - Implement this interface to define the state variables of your MDP state space. An instace of this object will specify a single state from the state space. Action - Implement this interface to define a possible action that the agent can select. If your MDP action set is discrete and unparameterized, you may consider using the provided concrete implementation SimpleAction , which defines an aciton entirely by a single String name ActionType - Implement this interface to define a kind of Java factory for generating your Actions. In particular, this interface allows you define preconditions for actions. Actions with preconditions are actions that the agent can only selectexecute in some states, and not others. It also allows you to specify which kinds of parameterizations of your actions are allowable in a state, if your actions are parameterized. Often, MDPs have unparameterized actions that can be executed in any state no precondtions. In such cases, you should consider the provided concrete implementation UniversalActionType . SampleModel - Implement this interface to define the model of your MDP. This inferface only requires you to implement methods that can sample a transition spit back out a possible next state and reward given a prior state and action taken. Some planning algorithms, however, require more information they may require being able to enumerate the set of possible transitions and their probability of occurring. If you wish to support these kinds of algorithms, then you will instead want to implement the FullModel interface that extends the SampleModel interface with a method for enumerating the transition probability distribution. Note that if you are defining a learning problem in which an agent interacts with an external environment from BURLAP, it may not be possible to define even a SampleModel. For example, if youre going to use BURLAP to control robots via reinforcement learning, it might not be possible for you to specify a model of reality in a meanginful way or it might simply be unncessary. In these cases, the model can be omitted from the MDP description and instead youll want to implement a custom Environment instance, described next. Environment - An MDP defines the nature of an environment, but ultimately, an agent will want to interact with an actual environment, either through learning or to execute a policy it computed from planning for the MDP. An environment has a specific state of the world that the agent can only modify by using the MDP actions. Implement this interface to provide an environment with which BURLAP agents can interact. If you defined the MDP yourself, then youll probably dont want to implement Environment yourself and instead use the provided concreate SimulatedEnvironment class, which takes an SADomain with a SampleModel, and simulates an environment for it. EnvironmentOutcome - A tuple that contains a prior stateobservation, an action taken in that state, a reward recieved, and a next stateobservation to which the environment transitioned. This object is typically returned by an Environment instance when an action is taken, or from a SampleModel when you sample a transition. TransitionProb - A tuple containing a double and an EnvironmentOutcome object, which specifies the probability of the transition specified by EnvironmentOutcome occurring. Typically, a list of these objects is returned by a FullModel instance when querying it for the transition probability distribution. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 2"], "word_count": 727, "token_count_estimate": 878}}, "http://burlap.cs.brown.edu/tutorials/bd/p1.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 1 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Next Part You are viewing the tutorial for BURLAP 3 if youd like the BURLAP 2 tutorial, go here . Introduction This tutorial will cover three topics. First, we will review a little of the theory behind Markov Decision Processes MDPs, which is the typical decision-making problem formulation that most planning and learning algorithms in BURLAP use. Next, we will discuss how you can implement an MDP definition in BURLAP. Finally, we will show you some basics with how to interact with your MDP and visualize it. Other Problem Types Beyond MDPs, BURLAP also supportsstochastic games and partially observable MDPs. The BURLAP example code repository has some examples with these problems, but a core understanding of the MDP representation will cover a lot of the basics that are shared in those problem types. BURLAP also has first class support for the object-oriented MDP OO-MDP state representation. OO-MDPs have a lot of nice properties, but its easier to first describe how to define general MDP states, and OO-MDPs are not necessary forevery problem. Therefore, we will leave the discussion about OO-MDPs for a subsequent tutorial. If you are alreadyfamiliar with MDPs, or just want to get down to coding, feel free to skip the firstsection that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Note that all of the code in this tutorial is listed at the end and is also available in the burlapexamples github repository. Markov Decision Process To implement agents that learn how to behave or plan out behaviors for an environment, a formal description of the environment and the decision-making problem must first be defined. One of the most common formalisms used by learning and planning algorithms is the Markov Decisions Process MDP, which considers the agent making decisions at discrete time steps to maximize a reward signal. In this tutorial, we will formalize a grid world as an MDP. A grid world is a 2D environment in which an agent can move north, south, east or west by one unit each time step, provided there are no walls in the way. The below image shows a simple grid world with the agents position represented by a gray circle and walls of the environment painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. Figure An example grid world. All MDPs are defined by four components that we will need to specify for our grid world a set of possible states of the environment S a set of actions that the agent can take A a definition of how actions change the state of the environment, known as the transition dynamics T and the rewards the agent receives for each of its actions R, known as the reward function, which will determine what the best behavior is that is, the agent will want to act in a way that maximizes the reward it receives. The transition dynamics are formulated as a probabilistic function Ts s, a, which defines the probability of the environment changing to state s in the next discrete timestep when the agent takes action a in the current state s. The fact that the environment can change stochastically is one of the unique properties of an MDP compared to more classic AI deterministic planningdecision making problems. The reward function is a function of the last state, the action taken in that last state, and the next state to which the environment transitioned as a result of that action Rs, a, s. Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action Requiring this temporal independence from everything earlier than the last event makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will define the transition dynamics to be stochastic so that with high probability 0.8 the agent will move in the intended direction, and with some low probability 0.2 move in a different direction. You can imagine this stochasticity being a model for a robot with slightly unreliable driving capabilities which, as it turns out, is often the norm. The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we will define a reward function that returns a high reward when the agent reaches the top right corner of the environment and zero everywhere else, to motivate movement to that corner. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks i.e., action stops once the agent achieves a goal, failure conditions, or any number of other reasons. In our grid world, well want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function more on that later. The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, wed say that the goal is to find a policy pi, that is a mapping from states in the MDP to actions that the agent takes pi S rightarrow A. Sometimes, the policy can also be defined as a probability distribution over action selection in each state and BURLAP supports this represenation, but for the moment we will consider the case when it is a direct mapping from states to actions. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, its often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 because they all would eventually reach the goal however, what wed probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didnt set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult A commonalternative that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sumlarge sumt0infty gammat rt,where rt is the reward received at time t and gamma is the discount factor that dictates how much preference an agent has for more immediate rewards in other words, the agents patience. With gamma 1, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step therefore, gamma 1 results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With gamma 0 all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless its one step away. However, a gamma value somewhere in between 0 and 1 often results in what we want. That is, for all values of 0 lt gamma lt 1, the expected future discounted reward in an MDP when following any given policy is finite, while still considering events that happen in the distant future, and with a preference for more immediate satisfaction. If we set gamma to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual 1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward, with the geometric discount factor gamma left as a parameter that the user can specify. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 1", "Other Problem Types"], "word_count": 1634, "token_count_estimate": 1918}}, "http://burlap.cs.brown.edu/tutorials/bd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 3 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Next Part Defining a Grid World State The first primary task we will complete in defining our Grid World MDP is to define what states look like. Before doing that though, lets first make a class that will use to generate our ultimate SADomain, and hold constants for various important values. We will then use some of these constants in the definition of our State. Start by creating the below class, which implements DomainGenerator. DomainGenerator is an optional interface commonly used in BURLAP that constains a method for generating a Domain object. Below is the class with the constants we will use throughout this tutorial, as well as the imports it will ultimately be using. import burlap.mdp.auxiliary.DomainGeneratorimport burlap.mdp.core.StateTransitionProbimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.action.Actionimport burlap.mdp.core.action.UniversalActionTypeimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.model.statemodel.FullStateModelimport burlap.shell.visual.VisualExplorerimport burlap.visualizer.StatePainterimport burlap.visualizer.StateRenderLayerimport burlap.visualizer.Visualizerimport java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Listpublic static final String VARX xpublic static final String VARY ypublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westpublic class ExampleGridWorld implements DomainGenerator public SADomain generateDomain return null well come back to this later With this class and its constants defined, lets now create a class for describing Grid World states well place this in a separate file. To do that, we will want our class to implement the State interface. We will actually go one step further, and have it implement MutableState, an extension to the State interface that also provides a method for setting state variables. Start with the below code, which has stubs for each of the required methods and all the imports for what well eventually be using. import burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport burlap.mdp.core.state.UnknownKeyExceptionimport burlap.mdp.core.state.annotations.DeepCopyStateimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VARXimport static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VARYpublic class EXGridState implements MutableStateOverridepublic MutableState setObject variableKey, Object value return thisOverridepublic ListObject variableKeys return nullOverridepublic Object getObject variableKey return nullOverridepublic EXGridState copy return null Our grid world state will be defined entirely by the agents x and y location in the world. Lets add data members for that to our class. Well also add relevant constructors. Serialization To support trivial serialization of states with something like Yaml the default approach BURLAP uses, you should make sure your State objects are Java Beans , which meanshaving a default constructor and get and set methods for all non-public data fields that follow standard Java getter and setter method name paradigms. public int xpublic int ypublic EXGridState public EXGridStateint x, int y this.x xthis.y y Although weve now defined our state variables, unless some client code knows exactly what kind of State object it is, it wont be able to access or modify in the case of MutableState objects these state variables. Most of the methods of the State and MutableState interface provide a general mechanism for client code to work with a States variables. The variableKeys method returns a list of Object elements that specify variable keys that can be used to get or state variables the get method takes a variable key, and returns the variable value for that key and the setMethod takes a variable key and a value and sets the variable to that value and is expected to return itself to support method chaining of variable sets. Note that the variable keys, being of type Object, can be of any data type that is most relevant to indexingspecifying a variable. Common choices include String or Integer keys, but it can really be any type. Variable values are also typed to Object, which similarly means that your States variables can be made up any conceivable data type that you want, allowing you to easily represent any kind of state To implement these three methods, lets first define a class constant list for the variable keys we dont need a separate copy for each State instance, since the variable keys are always the same, and using a class constant will save on the memory overhead. private final static ListltObject keys Arrays.ObjectasListVARX, VARY Note that for keys, we are using Strings for variable names, and the constants for these names were defined in our ExampleGridWorld domain generator. Now lets implement the variableKeys, set, and get methods, which is done mostly as you would expect. Overridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARXthis.x StateUtilities.stringOrNumbervalue.intValueelse ifvariableKey.equalsVARYthis.y StateUtilities.stringOrNumbervalue.intValueelsethrow new UnknownKeyExceptionvariableKeyreturn thisOverridepublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARXreturn xelse ifvariableKey.equalsVARYreturn ythrow new UnknownKeyExceptionvariableKey There are two things to note. First, if client code passes a variable key that is not the x or y key, then we throw a standard BURLAP UnknownKeyException. Second, you will notice that in the set method, we process the variable value through the StateUtilities stringOrNumber method. This method takes as input an Object. If that object is a String, then it returns a Java Number instance of the number that String represents. If it is a Number already, then it simply returns it back, cast as a Number. This method is useful because it allows client code to specify values with string representations of numbers or an actual number. BURLAP Shell And MutableState One piece of client code that benefits from setting state variables with string representations of the value is the BURLAP shell, which is a runtime shell that lets you interact with BURLAP environments with different commands and you can make your own commands to add to the shell too. If the environment is a simulated BURLAP environment, then one of the shell commands lets you modify the state of the environment from the command line, provided your States set method supports String representations of keys and values. Later in this tutorial, we will launch a visual BURLAP shell with the domain we create and you can try it out Next we will want to implement the copy method. The copy method returns, as the name suggests, a State object that is a copy of this state. The copy method is most commonly use when defining the MDPs transition dynamicsmodel. That is, when the outcome of executing an action in a specific input state is request, we will usually first make a copy of the input state, modify the values that need to be modified, and return the modified copied. We will see how to define transition dynamics that use this approach shortly. We can implement the copy method by simply creating a new EXGridState instance and passing its constructor this objects current x and y values. Overridepublic EXGridState copy return new EXGridStatex, y Because our States data fields are simple Java primitives, the copy we return is a deep copy. Consequently, modifying any data member of a copied state will not affect the values of the state from which it was copied. However, for State implementations with more complex data members, we might instead define our copy operation to do a shallow copy, which simply passes the references of the data members. To help indicate to clients what kind of copy operation a State performs, there are two optional class annotations you can add to your class DeepCopyState and ShallowCopyState. Since our State is a DeepCopyState, lets add the optional annotation to our class. DeepCopyStatepublic class EXGridState implements MutableState... Why would you ever shallow copy Recall that the State copy method is typically used when generating the transition dynamics of an MDP as you will see shortly. Using a shallow copy is often more memory efficient, because it means common data between states that are generated through transitions are shared, rather than replicated for each state. However, it does mean that the transition code needs to make sure that it manually makes a copy of the specific data members that it modifies of the copy, since the copy method itself wont do it. It is also usually a good idea to have the set method of shallow copied states perform a copy on write that is, it automatically makes a copy of the value its modifying first. If you are in doubt, then making your copy method always perform a deep copy will be safe, but if youre looking to improve memory overhead, you may want to consider shallow copies. Many of the included BURLAP domains use shallow copies, with the set method performing a copy on write. Were just about done defining our Grid World State, but lets also add a toString method, so that we can have meaningful string representations of our State. To implement that method, we can simply use the corresponding StateUtilities method, which will iterate through the variable keys or you can implement it manually yourself, if you wish. Overridepublic String toString return StateUtilities.stateToStringthis And with that, were finished defining our GridWorld State Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 3", "Serialization", "BURLAP Shell And MutableState", "Why would you ever shallow copy?"], "word_count": 1484, "token_count_estimate": 2065}}, "http://burlap.cs.brown.edu/tutorials/bd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 4 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Next Part Defining a Grid World Model Next, we will define the model of our Grid World how transitions and rewards are generated from actions. Lets start by defining a map of our grid world, that matches the Grid World image we used earlier in the tutorial an 11x11 world split into 4 rooms. We will define this map using a 2D int array, with the first dimension representing x, and the second dimension representing y. Add the following to your ExampleGridWorld domain generator class ordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0, To define our Grid World Model, were going to use a FactoredModel implemention that is provided with BURLAP. A FactoredModel is a model that divides its duties into three components a SampleStateModel, which defines the state transitions a RewardFunction, which defines the rewards for given state transitions and a TerminalFunction, which defines which states are terminal states of the MDP. Most domains in BURLAP use a FactoredModel, because it is often the case that clients will want to change the task of a domain defined by the reward function and terminal state, but not the physics of the domain how state transitions occur. Lets start with the most complex part the state model. Just as there is a SampleModel and a FullModel for the complete model, where the SampleModel merely samples transitions and a FullModel can also enumerate the probability distribution, a state model also has a SampleStateModel and a FullStateModel. We will implement the FullStateModel. Below, weve defined an inner class to ExampleGridWorld for our FullStateModel, with the required methods left as unimplemented, which we will walk through. protected class GridWorldStateModel implements FullStateModelOverridepublic ListStateTransitionProb stateTransitionsState s, Action a return nullOverridepublic State sampleState s, Action a return null Were going to define our domain so that our four north, south, east, west actions are stochastic with 0.8 probability they will go in the intended direction, and with 0.2 probability, it will randomly go in one of the other directions. To encode this stochasticity, lets define a matrix of direction transition probabilities for each action, so that the first dimension indexes by the selected action, and the next dimension indexes by the actual direction the agent will move, with the values specifying the movement in that direction, given the action selected. We will also implement a constructor that fills out this matrix, which will have 0.8 along the diagonal, and 0.83 on the off-diagonal elements. Note that each row will sum to 1, making it a proper probability distribution. protected double transitionProbspublic GridWorldStateModel this.transitionProbs new double44forint i 0 i 4 iforint j 0 j 4 jdouble p i j 0.23 0.8transitionProbsij p Our actions in this domain will be represented with String names we could alternatively make Actions that are defined by int values, but for simplicity and descriptive reasons, we will use String names. Therefore, we will first want to define a method that converts an action name into an int index for the direction transition matrix we defined protected int actionDirAction aint adir -1ifa.actionName.equalsACTIONNORTHadir 0else ifa.actionName.equalsACTIONSOUTHadir 1else ifa.actionName.equalsACTIONEASTadir 2else ifa.actionName.equalsACTIONWESTadir 3return adir When we either sample a state transition, or enumerate all possible outcomes, we will want to query the outcome of the agent moving in some direction. Lets add a method for doing that now. protected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,ny This method will return a 2 element int array, where the first component is the new x position of the agent and the second component is the new y position. Primarily, the method just incrementsdecrements the x and y values depending on what the action direction was. However, it also checks the map of our world, and if the agent would have moved into a wall, then the agents position will not change. Now lets implement the sample method. Overridepublic State sampleState s, Action a s s.copyEXGridState gs EXGridStatesint curX gs.xint curY gs.yint adir actionDirasample direction with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i 4 isumProb this.transitionProbsadiriifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positiongs.x newPos0gs.y newPos1return the state we just modifiedreturn gs The first thing we do is make a copy of the input state, which will be modified and returned. Then we get the agents x and y position, by type casting the State to our EXGridState class. We also get the index of our action, and then sample a resulting direction from the direction transition matrix. We then get the resulting new position from our moveResult method, and update the copied state to be at that new position. Next we will implement the transitions method. Overridepublic ListStateTransitionProb stateTransitionsState s, Action a get agent current positionEXGridState gs EXGridStatesint curX gs.xint curY gs.yint adir actionDiraListStateTransitionProb tps new ArrayListStateTransitionProb4StateTransitionProb noChange nullforint i 0 i 4 iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeEXGridState ns gs.copyns.x newPos0ns.y newPos1create transition probability object and add to our list of outcomestps.addnew StateTransitionProbns, this.transitionProbsadirielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChange nullnoChange.p this.transitionProbsadirielseotherwise create this new state and transitionnoChange new StateTransitionProbs.copy, this.transitionProbsadiritps.addnoChangereturn tps In many ways, this method is a lot like our sample method, except instead of randomly sampling a direction, we iterate over each possible outcome direction and consider movement in that direction. For each of those possible directions, we make a copy of the input state, change its position based on our moveResult method, and then put it in a StateTransitionProb tuple, which is a pair consisting of the probability of the outcome determined from the entry in our transition matrix and the outcome state we created, and we add each StateTransitionProb to a list to be returned by our method. There is one extra bit of book keeping we perform in this method. If the agent tries to move into a wall, its position does not change. And if a wall exists on multiple sides of the agent, then there are multiple possible directions that would result in the agent not moving. However, we dont want a separate StateTransitionProb element for multiple occurrences of the agent not changing position. So instead, if the agents position doesnt change, we simply add the probability mass of the agent attempting to move in that direction to any existing StateTransitionProb element we have created that results in the agent not changing position. Weve now completed the state transition model. Next, lets implement a RewardFunction and TerminalFunction. Well start with the TerminalFunction, which well let specify a single location in our grid world to be a terminal goal state and well let that location be a parameter. public static class ExampleTF implements TerminalFunction int goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateint ax Integers.getVARXint ay Integers.getVARYare they at goal locationifax this.goalX ay this.goalYreturn truereturn false Our reward function will work similarly, but return a reward of -1 for all transitions, except the transition to a goal location, which will return 100. public static class ExampleRF implements RewardFunction int goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, Action a, State sprime int ax Integers.getVARXint ay Integers.getVARYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1 Note that the reward function operates on the sprime method argument, not the s argument. The sprime argument specifies the state to which the agent transitioned, whereas the argument s specifies the state the agent left, and we want the goal reward to occur on transitions to the goal location, so we evaluate sprime. Were just about ready to finish up our domain. Before we do, lets add two data members and ExampleGridWorld methods to allow a client to set the goal location. Add the data members protected int goalx 10protected int goaly 10 And add the method public void setGoalLocationint goalx, int goalythis.goalx goalxthis.goaly goaly Now lets finish by implementing our generateDomain method Overridepublic SADomain generateDomain SADomain domain new SADomaindomain.addActionTypesnew UniversalActionTypeACTIONNORTH,new UniversalActionTypeACTIONSOUTH,new UniversalActionTypeACTIONEAST,new UniversalActionTypeACTIONWESTGridWorldStateModel smodel new GridWorldStateModelRewardFunction rf new ExampleRFthis.goalx, this.goalyTerminalFunction tf new ExampleTFthis.goalx, this.goalydomain.setModelnew FactoredModelsmodel, rf, tfreturn domain The generateDomain method starts by making a new SADomain instance. Then we add an ActionType for each of our actions. Our grid world north, south, east, west actions are unparameterized actions that can be applied anywhere in the world, so we can use BURLAPs provided UnviersalActionType implementation, which simply requires a name for each of the actions. We then create an instance of our state model, and a reward function and terminal function using our implemented methods with a goal location set to the ExampleGridWorld instances goalx and goaly values. The elements are used to define a FactoredModel, which is added to our domain. Then, we return the created domain Weve now created all the elements we need for our grid world MDP and its now ready to be used with BURLAP algorithms. However, it is often very useful to be able to visualize a domain. In the next section, we will show you have to create a visualizer for our grid world domain. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 4"], "word_count": 1630, "token_count_estimate": 2649}}, "http://burlap.cs.brown.edu/tutorials/bd/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 5 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Defining a GridWorld Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Creating a State Visualizer It is often the case that you will want to visualize states of your domain in various contexts. For example, maybe you want to interact with the environment, acting as the agent yourself, or maybe you want to review episodes generated from a learning agent or a policy. BURLAP provides standard interfaces and tools for doing these kinds of things. Specifically, BURLAP provides a MultiLayerRenderer object that is a JPanel. It maintains a list of RenderLayer objects that paint to the graphics context of the MultiLayerRenderer or rather, an offscreen buffer of it in the order of the RenderLayers i.e., painters algorithm. One of the more common RenderLayer instances is the StateRenderLayer, used to render a state. StateRenderLayer holds a current State to paint, which can be updated externally, and a list of StatePainter instances that, similar to a RenderLayer, are interfaces that are provided a State and Graphics2D context to which an aspect of the state is painted. Also useful is the Visualizer class, an extension of MultiLayerRenderer that is assumed to contain a StateRenderLayer and provides quick access methods for updating the State of the StateRenderLayer to render. A UML diagram of these classes is shown below. Figure UML Digram of the Java interfacesclasses for visualization. Therefore, the standard way to provide state visualization in BURLAP, is to implement one or more StatePainters, which can then be added to a StateRenderLayer used by a Visualizer. For our grid world, we will create two StatePainter implementations, one for drawing the walls of our grid world, and another for drawing the location of the agent. Well make these inner classes of our ExampleGridWorld class. public class WallPainter implements StatePainter public void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cellon our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on ourcavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements StatePainter Overridepublic void paintGraphics2D g2, State s,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integers.getVARXint ay Integers.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, height There is nothing fancy going on in this code. In the case of the AgentPainter, we get the x and y variable values of the agent, get their position in screen space, and draw a circle. We do something similar for the wall painter, but iterate over our map drawing black rectangles wherever a wall is present. Finally, lets add some methods to our ExampleGridWorld class for packaging instances of these painters into a StateRenderLayer and a Visualizer. public StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStatePainternew ExampleGridWorld.WallPainterrl.addStatePainternew ExampleGridWorld.AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayer Testing it Out Now that weve made all the pieces of our domain, lets test it out A good way to test out a domain is to create a VisualExplorer that lets you act as the agent and see the state of the world through a Visualizer. Add the following main method to our ExampleGridWorldClass. public static void mainString argsExampleGridWorld gen new ExampleGridWorldgen.setGoalLocation10, 10SADomain domain gen.generateDomainState initialState new EXGridState0, 0SimulatedEnvironment env new SimulatedEnvironmentdomain, initialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTH, exp.addKeyActions, ACTIONSOUTH, exp.addKeyActiond, ACTIONEAST, exp.addKeyActiona, ACTIONWEST, exp.initGUI The first block of code instantiates our domain with the goal state set to 10, 10 the top right corner creates an initial state with the agent in location 0, 0 and creates a Simulated Environment around our domain. The environment could be used for any number of purposes, including using it with learning algorithms. Here, we use it as the domain well explore with a VisualExplorer that visualizes states with the Visualizer components we defined earlier. The addKeyAction methods let us set up key bindings to execute actions in the environment. The arguments of this method correspond to the key you want to send the action, the name of the ActionType, and a String representation of the parameters of the action, which we leave empty since our actions are unparameterized. Another variant of this method will let you specify the direct Action object you want it to use, rather than generating the Action from an ActionType identified by its name. Finally, the initGUI method will start the VisualExplorer. When you run the ExampleGridWorld class, the visual explorer should pop up, which will look like the below image. Figure Screenshot of the VisualExplorer that will launch. If you use the w-a-s-d keys, you can control the agents movements in the environment. Note that because we made our grid world stochastic, sometimes the agent will go in a different direction than the action you selected This is precisely the kind of mechanics that a learning agent would experience, given the definition of the MDP we made. One other element of the VisualExplorer you might want to experiment with is the shell, which you can open with the Show Shell button, which will bring up a text box and field you can use to send special commands for working with an environment. If you want a list of commands that are available in the shell, enter cmds. Most commands also include help information, which you can get by entering the command with the -h option. To see an example of something you can do with the shell, try changing the agents position in the environment to 3,2 by entering the command setVar x 3 y 2 and you should see that the agent in the visualizer appears in the specified location You can also add your own commands to a BURLAP shell, by implementing the ShellCommand interface, and adding it to the shell. You can get the shell of a VisualExplorer with the method getShell and you can add ShellCommands to it with the method addCommandShellCommand. The shell is a powerful tool for controlling runtime experimentation. Conclusion Thats it Weve now walked you through how you can implement your own MDP in BURLAP that can be used with the various learning and planning algorithms. We also showed you how to create a visualizer for them and how to interact with them. There is another tutorial specifically about creating MDPs that use the object-oriented MDP state representation, but this is an advanced optional rich state representation and you should be able to get by fine with standard MDP definitions. Final Code ExampleGridWorld.java import burlap.mdp.auxiliary.DomainGeneratorimport burlap.mdp.core.StateTransitionProbimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.action.Actionimport burlap.mdp.core.action.UniversalActionTypeimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.model.statemodel.FullStateModelimport burlap.shell.visual.VisualExplorerimport burlap.visualizer.StatePainterimport burlap.visualizer.StateRenderLayerimport burlap.visualizer.Visualizerimport java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Listpublic class ExampleGridWorld implements DomainGenerator public static final String VARX xpublic static final String VARY ypublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westprotected int goalx 10protected int goaly 10ordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,public void setGoalLocationint goalx, int goalythis.goalx goalxthis.goaly goalyOverridepublic SADomain generateDomain SADomain domain new SADomaindomain.addActionTypesnew UniversalActionTypeACTIONNORTH,new UniversalActionTypeACTIONSOUTH,new UniversalActionTypeACTIONEAST,new UniversalActionTypeACTIONWESTGridWorldStateModel smodel new GridWorldStateModelRewardFunction rf new ExampleRFthis.goalx, this.goalyTerminalFunction tf new ExampleTFthis.goalx, this.goalydomain.setModelnew FactoredModelsmodel, rf, tfreturn domainpublic StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStatePainternew ExampleGridWorld.WallPainterrl.addStatePainternew ExampleGridWorld.AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayerprotected class GridWorldStateModel implements FullStateModelprotected double transitionProbspublic GridWorldStateModel this.transitionProbs new double44forint i 0 i 4 iforint j 0 j 4 jdouble p i j 0.23 0.8transitionProbsij pOverridepublic ListStateTransitionProb stateTransitionsState s, Action a get agent current positionEXGridState gs EXGridStatesint curX gs.xint curY gs.yint adir actionDiraListStateTransitionProb tps new ArrayListStateTransitionProb4StateTransitionProb noChange nullforint i 0 i 4 iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeEXGridState ns gs.copyns.x newPos0ns.y newPos1create transition probability object and add to our list of outcomestps.addnew StateTransitionProbns, this.transitionProbsadirielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChange nullnoChange.p this.transitionProbsadirielseotherwise create this new state and transitionnoChange new StateTransitionProbs.copy, this.transitionProbsadiritps.addnoChangereturn tpsOverridepublic State sampleState s, Action a s s.copyEXGridState gs EXGridStatesint curX gs.xint curY gs.yint adir actionDirasample direction with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i 4 isumProb this.transitionProbsadiriifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positiongs.x newPos0gs.y newPos1return the state we just modifiedreturn gsprotected int actionDirAction aint adir -1ifa.actionName.equalsACTIONNORTHadir 0else ifa.actionName.equalsACTIONSOUTHadir 1else ifa.actionName.equalsACTIONEASTadir 2else ifa.actionName.equalsACTIONWESTadir 3return adirprotected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,nypublic class WallPainter implements StatePainter public void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cellon our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on ourcavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements StatePainter Overridepublic void paintGraphics2D g2, State s,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integers.getVARXint ay Integers.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, heightpublic static class ExampleRF implements RewardFunction int goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, Action a, State sprime int ax Integers.getVARXint ay Integers.getVARYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1public static class ExampleTF implements TerminalFunction int goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateint ax Integers.getVARXint ay Integers.getVARYare they at goal locationifax this.goalX ay this.goalYreturn truereturn falsepublic static void mainString argsExampleGridWorld gen new ExampleGridWorldgen.setGoalLocation10, 10SADomain domain gen.generateDomainState initialState new EXGridState0, 0SimulatedEnvironment env new SimulatedEnvironmentdomain, initialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTH, exp.addKeyActions, ACTIONSOUTH, exp.addKeyActiond, ACTIONEAST, exp.addKeyActiona, ACTIONWEST, exp.initGUI ExGridState.java import burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport burlap.mdp.core.state.UnknownKeyExceptionimport burlap.mdp.core.state.annotations.DeepCopyStateimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VARXimport static edu.brown.cs.burlap.tutorials.domain.simple.ExampleGridWorld.VARYDeepCopyStatepublic class EXGridState implements MutableStatepublic int xpublic int yprivate final static ListObject keys Arrays.ObjectasListVARX, VARYpublic EXGridState public EXGridStateint x, int y this.x xthis.y yOverridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARXthis.x StateUtilities.stringOrNumbervalue.intValueelse ifvariableKey.equalsVARYthis.y StateUtilities.stringOrNumbervalue.intValueelsethrow new UnknownKeyExceptionvariableKeyreturn thispublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARXreturn xelse ifvariableKey.equalsVARYreturn ythrow new UnknownKeyExceptionvariableKeyOverridepublic EXGridState copy return new EXGridStatex, yOverridepublic String toString return StateUtilities.stateToStringthis End.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 5"], "word_count": 2028, "token_count_estimate": 3965}}, "https://blog.cs.brown.edu/2018/04/04/providence-will-be-shiru-cafes-first-us-location/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Providence Will Be Shiru Cafes First US Location Posted by Jesse Polhemus on April 4, 2018 Click the link that follows for more news items about why we love calling Providence home . Providence is Shiru Cafes first US location. As noted on their website, the international chain has opened on the Brown University campus ahead of Amherst College, Harvard University, Princeton University, and Yale University, which will follow. Shiru is known for its unconventional business model, which provides free drinks, Wi-FI, electrical outlets, and study spaces to students faculty and staff are required to pay 1 for most items that are paid for by sponsor companies whose promotions appear on cups, smart devices of customers, and the cafes digital signage. The new location is on 165 Angell Street, near Browns CareerLAB. The image above is 2018 by Craig Fildes and used with permission under a Creative Commons license. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Information for:", "Brown CS Blog", "Providence Will Be Shiru Cafe's First US Location"], "word_count": 183, "token_count_estimate": 231}}, "http://burlap.cs.brown.edu/tutorials/bpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Initializing the data members Now that we have the structure of our class, well need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing well do in the constructor is create our domain. public BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRoomstf new GridWorldTerminalFunction10, 10gwdg.setTftfgoalCondition new TFGoalConditiontfdomain gwdg.generateDomainmore to come... The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layoutthe four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh 1999and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array with 1s specifying the cells with walls and 0sspecifying open cells, or you could simply specify the size of the domain like we did and then use the GridWorldDomainobjects horiztonalWall and verticalWall methods to place walls on it. The GridWorldDomain also supports1 dimensional walls between cells that you can set, if youd prefer that kind of domain. For simplicity, well stick with thefour rooms layout. By default, our grid world will set the reward function a reward function that always returns -1 but we will need to set where the terminal state is, that when paired with the -1 rewards will motivate the agent to get to it as soon as possible and complete the task. For that, weve told the grid world to use a GridWorldTerminalFunction that marks state 10, 10 as a terminal state. Rewards and terminal states are fine for MDP-based algorithms, but some of the algorithms in BURLAP are search-based planning algorithms algorithms that search for a path in a detemrinistic domain that reaches some goal condition. For that, we create a StateConditionTest that will be passed to these algorithms and set it to be one that marks all terminal states as goal states. StateConditionTest objects are not actually part of a domain definition, but since we will use it conjunction with the terminal states, well create it here anyway. At this point weve fully specified the domain and generate it. The next step will be to define the initial state of this task. For GridWorlds, we use the GridWorldState instance. Add the following code initialState new GridWorldStatenew GridAgent0, 0, new GridLocation10, 10, loc0 The GridWorldState uses an OO-MDP representation, which means the state itself consists of multiple objects see the Building an OO-MDP Domain tutorial for more information. Here weve made it consist of an agent, located at position 0,0, and a location object located at 10,10. Were not actually going to do anything meaningful with the location object and could have ommitted it, but it will give us a nice visual representation of the goal we placed at 10,10 when we visualizer our results. Next we will instantiate the HashableStateFactory that we wish to use. Since we are not doing anything fancy like state abstraction, we will use SimpleHashableStateFactory. hashingFactory new SimpleHashableStateFactory Finally, we will instantiate an Environment with which the agent will interact in our learning algorithm demonstrations. Since we will be using BURLAPs simulation of the environment, we will use a SimulatedEnvironment, which along with the domain, needs to be told which initial state to use for the environment. env new SimulatedEnvironmentdomain, initialState At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRoomstf new GridWorldTerminalFunction10, 10gwdg.setTftfgoalCondition new TFGoalConditiontfdomain gwdg.generateDomaininitialState new GridWorldStatenew GridAgent0, 0, new GridLocation10, 10, loc0hashingFactory new SimpleHashableStateFactoryenv new SimulatedEnvironmentdomain, initialState Setting up a result visualizer Before we get to actually running planning and learning algorithms, were going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after its finished. Offline visualization has the advantage of not bogging down the runtime of planninglearning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state Visualizer and pass it to an EpisodeSequenceVisualizer . A Visualizer is a Java JPanel that can render State objects. An EpisodeSequenceVisualizer lets you view and explore episodes state-action-reward sequences and can either load the episodes from files or be provided them programmatically. In this example, we will save results to file and load them back up. To handle this kind of result visualization, create the below method. public void visualizeString outputPathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapnew EpisodeSequenceVisualizerv, domain, outputPath Note that the outputPath parameter specifies the directory where our planninglearning results were storedwell get to this when we actually apply a planninglearning algorithm. The state Visualizer we will use is the one designed for rendering grid world states. It takes as input the map of the world a 2D int array, which we retrieve from our GridWorldDomain instance. Note that other domains included in BURLAP have their own Visualizers that you can use for them. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main method. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultswe will call planning and learning algorithms hererun the visualizerexample.visualizeoutputPath Note that you can set the output path to whatever you want. If it doesnt already exist, the codethat saves the results will automatically created it more on that next. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 2"], "word_count": 1001, "token_count_estimate": 1396}}, "http://burlap.cs.brown.edu/tutorials/bpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 3 if youd like the BURLAP 2 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a grid world domain bundled with BURLAP, and having the task solved with Q-learning, Sarsa learning, BFS, DFS, A, and ValueIteration. This tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algorithms largely amounts to changing the algorithm Java object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. The complete set of code written in this tutorial is availabe at the end, and in the burlapexamples github repository. Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class BasicBehavior but feel free to name it to whatever you like.Since we will also be running the examples from this class, well include a main method. For convenience, we have also included at the start all of the class the imports that you will need for this tutorial. If you have a good IDE, like IntelliJ or Eclipse, those can auto import the classes as you go so that you never have to write an import line yourself. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyphimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolationimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2Dimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2Dimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.behavior.singleagent.learning.tdmethods.SarsaLamimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.singleagent.planning.deterministic.DeterministicPlannerimport burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIterationimport burlap.behavior.valuefunction.QProviderimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridLocationimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.auxiliary.stateconditiontest.StateConditionTestimport burlap.mdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.state.Stateimport burlap.mdp.core.state.vardomain.VariableDomainimport burlap.mdp.singleagent.common.GoalBasedRFimport burlap.mdp.singleagent.common.VisualActionObserverimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.awt.import java.util.Listpublic class BasicBehavior GridWorldDomain gwdgOOSADomain domainRewardFunction rfTerminalFunction tfStateConditionTest goalConditionState initialStateHashableStateFactory hashingFactorySimulatedEnvironment envpublic static void mainString args well fill this in later If youre already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what each data member is and why were going to need it. GridWorldDomaingwdg A GridWorldDomain is a DomainGenerator implementation for creating grid worlds. Domain domain An OOSADomain object is a fundamental class for defining problem domains that have OO-MDP state representations although we will not focus on the OO-MDP aspects here. In short, any Domain object contain all of the elements of an MDP, except the entire state space, which is not included since for many domains it may be infinite. TerminalFunction tf By default, our grid world will use a UniformCostRF , a reward function that returns -1 everywhere. But if we want to specify a goal state, we need to tell our GridWorld generator which states are terminal states, which we do with a TerminalFunction. TerminalFunction is an interface with a boolean method that defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences that will cause the agent to reach specific goal states. A StateConditionTest is an interface with a boolean method that takes a state as an argument similar to aTerminalFunction, only we use it as a means to specify arbitrary state conditions, rather than just terminal states. We will use StateConditionTest to specify the goal states of search-based planning algorithms. State initialState Since domains are not required to enumerate entire state spaces, we will need to define at least the initial state of our problem, which we hold in this data member. HashableStateFactory hasingFactory In this tutorial we will cover tabular algorithms algorithms that learn or plan with tabular identifiers for states in the later Solving Continuous Domains tutorial , we will cover how to use BURLAP to solve continuous domains. Typically, for fast access, tabular algorithms will associate values for states in a HashMap, which means tabular methods need some way to compute hash codes and test equality of states. The obvious solution is for State implementations to implement the Java equals and hashCode methods. However, it is not uncommon that differnet scenarios will require different ways of computing hash codes or state equality that the creator of the State did not anticipate, such as state abstraction or variable discretization. Therefore, BURLAP makes use of HashableStateFactory objects that allows a client to specify how to hash and check state equality for states. There are a number of default implementations also provided in BURLAP. Environment env Learning algorithms address a problem in which the agent observes its environment, makes a decision, and then observes how the environment changes. This is a challenging problem because initially, an agent will not know how the environment works or what a good decision is, but must live with the consequences of their decision. To facilitate the construction of learning problems, all single-agent learning algorithms in BURLAP algorithms that implement the LearningAgent interface, interact with an implementation of the Environment interface. One of the included concrete implementations is SimulatedEnvironment , which you can use when youre constructing an Environment for a BURLAP domain that has an included model. Other concrete Environment implementations in BURLAP or library extensions to BURLAP include RL Glue hooks using a BURLAP agent with an RL Glue Environment. burlaprosbridge for using BURLAP with robots embodied in the real world. BurlapCraft , for using BURLAP to control a Minecraft player. Since Environment is an interface, you can also easily implement your own version if you need a BURLAP agent to interact with external code or systems that are not already provided in BURLAP. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 1"], "word_count": 1027, "token_count_estimate": 1888}}, "http://burlap.cs.brown.edu/tutorials/bpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Lets start by defining the BFS method. public void BFSExampleString outputPathDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath bfs The first part of the method creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the HashableStateFactory. Because BFS implements the Planner interface, planning can be initiated by callingthe planFromState method and passing it the initial state form which it should plan. The planFromState method automatically returns a Policy object. Using the PolicyUtils class, we rollout the policy from an initial state. This method requires the model of the envionrment or alternatively, you can have it rolled out within an actual environment. The result of the rollout method is an Episode object, which is a record of the state, action, and reward sequence from rolling out the policy. Episode objects can be written to disk, using the write method, which we call here. Using non-default policies Each Planner implementation will return a different kind of Policy from planFromState that is relevant for the results the Planner stores. However, often times, after calling the planFromState method, you can wrap a different policy than the one that is returned around your planner instance to get slightly different behavior. For example, BFSs planFromState will return an SDPlannerPolicy instance, which will return the action the planner selected for any states on its solution path if the policy is queried for a state not on the solution path, it will throw a runtime exception. However, you might choose to wrap a DDPlannerPolicy around BFS instead of using the returned SDPlannerPolicy. DDPlannerPolicy will act the same as SDPlannerPolicy except rather than throw a runtime exception if an action selection is queried for a state not on the current solution path, it will transparently recall planFromState on the new state to get an action to return that is, it will perform replanning. And thats all you need to code to plan with BFS on a defined domain and task Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultsrun exampleexample.BFSExampleoutputPathrun the visualizerexample.visualizeoutputPath Note that our output path ended with a . Whatever path you use, you should include the trailing since the code we wrote to write the file will automatically append to that path name. With the planning method hooked up, run the code Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state, if the State is an OOState and the domain includes PropositionalFunction definitions. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search DFS. Define the below method to providea means to solve the task with DFS. public void DFSExampleString outputPathDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath dfs You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of a BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you Planning with A One of the most well known optimal search-based planning algorithms is A. A is an informed planner because it takesas input an admissible heuristic that estimates the cost to the goal from any given state. We can also use A to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use or you can use a NullHeuristic which will make A uninformed. The below code defines a methodfor using A with a Manhattan distance to goal heuristic. public void AStarExampleString outputPathHeuristic mdistHeuristic new Heuristic public double hState s GridAgent a GridWorldStates.agentdouble mdist Math.absa.x-10 Math.absa.y-10return -mdistDeterministicPlanner planner new AStardomain, goalCondition, hashingFactory, mdistHeuristicPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath astar To implement our heursitic, we made an annonmous class that implements Heuristic, which requires implementing the h method. We typecast the state to a GridWorldState, pull out the agent, and compute the Manhatten distance to 10, 10, our goal location. The h method then returns the negative value of the distance. We return the negative value, because BURLAP is based on rewards rather than costs . However, negative rewards are equivalent to costs, so the heursitic we give must be a non-positive value 0. Note that A also only operates on costs negative rewards, so whenever using A, you should make sure that the reward function for your domain returns negative values. By default, GridWorldDomain uses a UniformCostRF, which causes all rewards to be -1. Beyond defining a heuristic for A, instantiating it and using it works mostly the same Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 3", "Using non-default policies"], "word_count": 1197, "token_count_estimate": 1576}}, "http://burlap.cs.brown.edu/tutorials/bpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with Value Iteration A common stochastic domain planner is Value Iteration VI. An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath vi Instantiating value iteration works a lot like our deterministic search planning algorithms. However, because Value Iteration is based on solving MDPs, it requires us to specify a discount factor to use weve chosen 0.99. It also needs stopping criteria specified, because Value Iteration, as the name implies, is an interative algorithm and we need to define when enough iterations for a good solutions have been performed. Weve chossen for VI to terminate when either the changes in the value function are no longer than 0.001, or 100 iterations over the state space have been performed. VI computes the optimal value function for the problem, which specifies the expected future discounted reward for taking each action in each state the Q-function. Therefore, it returns a GreedyQPolicy . This policy looks at the Q-values the planner computes and returns the action with the maximium Q-value and breaks ties randomly. This policy can be used with any planning or learning algorithm that returns Q-values by implementing the QProvider interface. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you will run multipleepisodes of learning in which the agent interacts with an Environment instance to solve it or one very long episode if it is a continuing task rather than an episodictask. The method you should define to utilize Q-learning is shown below. public void QLearningExampleString outputPathLearningAgent agent new QLearningdomain, 0.99, hashingFactory, 0., 1.run learning for 50 episodesforint i 0 i 50 iEpisode e agent.runLearningEpisodeenve.writeoutputPath ql iSystem.out.printlni e.maxTimeStepreset environment for next learning episodeenv.resetEnvironment Lets first look at the constructor. Rather than a planning instance, were creating a LearningAgent instance which provides some methods for learning with an environment. QLearning is an instance of the LearningAgent interfaceand takes parameters for the domain, a discount factor, a HashableStateFactory, an initial value for the Q-values, and a learning rate which for a deterministic domain, 1.0 is a good choice. Note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a setter that allows you to set itif youd like to use a different policy. Other parameters for Q-learning could also be set, but we will not detail them here. With the QLearning instance created, next we will run 50 learning episodes, so we set up a for loop.To run a learning episode, we call the method runLearningEpisode on the LearningAgent instanceand pass it the Environment in which learning will be performed. The method returns an Episode object similar to policies so that a record of the interactions can be examined. As before, we can then write the returned episode to disk for viewing later. Finally, at the end of the loop, we call the resetEnvironment method on the Environment. This method is the typical way to signal that an Environment needs to reset to an initial state from its current state, which may be a terminal state. When the method returns, it is expected that the environment in a non-terminal state from which an agent can act again. After that, you can call this method from your main method and run the agents behavior for each of the 50 episodes of learning You should find that as learning progessed, the agent got better. By the end, the agents behavior will still be slightly random since its following an epislon greedy policy that always takes some random actions. However, since QLearning implements the QFunction interface, you could always wrap a GreedyQPolicy around it, like with VI, to remove random action selection. Learning with Sarsa A similar learning algorithm to Q-learning is Sarsa. The first difference between the twoalgorithms is that Sarsa updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state see Wikipedia for more information. The second, and larger, difference is that at every time step, Sarsa will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa. public void SarsaLearningExampleString outputPathLearningAgent agent new SarsaLamdomain, 0.99, hashingFactory, 0., 0.5, 0.3run learning for 50 episodesforint i 0 i 50 iEpisode e agent.runLearningEpisodeenve.writeoutputPath sarsa iSystem.out.printlni e.maxTimeStepreset environment for next learning episodeenv.resetEnvironment You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 typicallyyou should use lower learning rates when you have a higher value of . The last parameter ofthe constructor is the value which we set to 0.3. A value of 1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. It is not always a good idea to use a large value. Otherwise, the rest is the same you can call this method from the main method and give it shot Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 4"], "word_count": 1025, "token_count_estimate": 1384}}, "http://burlap.cs.brown.edu/tutorials/bpl/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms interacting with an environment. To present a live visualization we make use of the EnvironmentObserver interface. Objects that implement EnvironmentObserver interface can be told about agent interactions with an Environment. In this example, we will instantiate a VisualActionObserver and which implements both interfaces and visualizes state changes. To add a VisualActionObserver, we can modify our constructor by adding the following lines to the end of it VisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapobserver.initGUIenv.addObserversobserver The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizerwe use the same kind of state visualizer that we used for our EpisodeSequenceVisualizer. The second line initializes the Java GUI for its visualization. The third line is how we set up the VisualActionObserver to receive events from an Environment. You can add EnviornmentObservers to any Environment that implements the EnvironmentServerInterface interface, with the SimulatedEnvironment does. If your environment does not implement that interface, you can always instantiate an EnvironmentServer, which is an Environment delegator that will intercept environment interactions and send them to observers before or after calling the underlying Environment. Performance with VisualActionObservers By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelaylong delay method, which takes as an argument the number of milliseconds that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning or planning occurs since it stalls everything for that frame delay. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. For these reasons, you may prefer the offline visualization. Alternatively, you can also visualize interactions in the environment with a VisualExplorer without stalling performance. In previous tutorials, we used VisualExplorer to manually interact with our environment as the agent. Alternatively, you can launch the visual explorer around the environment with which your learning agent is interacting, and then call the stateLiveStatePolling method, with a specified inteval which will cause the visualizer to draw the currnet state of the environment on the interval you specified. This approach allows the agent to take more steps than can be rendered in the rendering interval. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show you how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. The value function assigns a value to each state that represents the expected future discounted reward when following the optimal policy from that state. In particular,we will show you how to visualize the value function for the ValueIteration results, but you could do the same with Q-Learning, or anyplanninglearning algorithm that implements the ValueFuncton interface which the QFunction interface extends. We will show you how to construct a value function visualizer in two ways. In the first way, we will make use of a GridWorldDomain method that will put all the pieces together for you and is very simple. However, since not all domains have automated code for that, we will also show you how to put all the pieces together manually. Lets start with the simple way, which requires adding the following method to your code. public void simpleValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, domain, hashingFactoryValueFunctionVisualizerGUI gui GridWorldDomain.getGridWorldValueFunctionVisualizationallStates, 11, 11, valueFunction, pgui.initGUI Note that this method takes as input a ValueFunction instance and a Policy object since along with the value function, we will also render the policy. Before we do anything with it, we are going to have to tell the renderer for which states wed like to visualize the value function. Although Domain objects are not required to enumerate the entire state space since for many domains that might be impossible, we can use the BURLAP tool StateReachability to find all states that are reachable from some input state. Algorithms like ValueIteraiton also have a method to return all states that they enumerated that we could have used. Next we call the GridWorldDomain method getGridWorldValueFunctionVisualization , which takes the set of states for which the value function will be rendered, the ValueFunction instance, and the Policy to render, and returns a ValueFunctionVisualizationGUI instance that will do it for us. Finally, we launch the return GUI with the initGUI method. The last step is to direct our value iteration method to this method once planning is complete. Your new value iteration method should look like the following. public void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath visimpleValueFunctionVisValueFunctionplanner, p If you now point your main method to run the valueIterationExample, you should find that after planning completes, it launches a GUI like the below note that you can toggle the policy visualization with the check box in the bottom left. Now that weve shown you how to easily create a value function and policy visualization for grid worlds, lets walk through the process of manually creating one so that you know how to do so for other domains. Add the following method to your code. public void manualValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, domain, hashingFactorydefine color functionLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEdefine a 2D painter of state values, specifying which variables correspond to the x and y coordinates of the canvasStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYKeysagentx, agenty, new VariableDomain0, 11, new VariableDomain0, 11, 1, 1create our ValueFunctionVisualizer that paints for all statesusing the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, valueFunctiondefine a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYKeysagentx, agenty, new VariableDomain0, 11, new VariableDomain0, 11, 1, 1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALEDadd our policy renderer to itgui.setSppsppgui.setPolicypset the background color for places where states are not rendered to greygui.setBgColorColor.GRAYstart itgui.initGUI The method signature looks the same as before and also as before we will use StateReachability to get all the states for which the value function will be rendered. Since we will be rendering the value of a cell of the grid world with a color that blends from red to blue, we will create an instance of the ColorBlend interface. In particular, we will use the LandmarkColorBlendInterpolation . This class lets you input a real value that spits out a color that is interpolated between various specified colors. So in this case, we defined the interpolation to blend from red to blue we could have added additional points of color in between feel free to experiment. The numeric values to which we assign these colors are normalized, so 0 is the minimum value and 1 is the maximum. Next we want to define a StateValuePainter instance, which is an interface that has a method that takes as input a graphics context, a State and a value for that state and renders it to the graphics context. In particular, we will use the StateValuePainter2D implementation, which will rendered colored cells for each state where the color to render is based on a ColorBlend instance which we defined above. For this class to determine where in a graphics context to render a states cell, it needs to be told what the x and y state variables are. It also needs to know the variable domain, and how wide in the variable domain each rendered call will span. At this point, we create our ValueFunctionVisualizerGUI instance, which takesthe states for which to render the value, the StateValuePainter to use, and the sourceValueFunction that specifies the value for the states. However, before we finish, we also added a Policy renderer that can overlay the value function visualization. For this rendering, we will need a StatePolicyPainter implementation and in the code we use a PolicyGlyphPainter2D that renders a policy at some position in a 2D graphics context by drawing glyphs for the selected action or actions if there are a set of actions that the policy selects. Like the StateValuePainter2D, this class needs to be told about the state variables to use for the x and y position. It also needs to be told which ActionGlyphPainter to use to paint a glyph for each action by action name. Here we used the existing ArrowActionGlyph for each action, where the parameter in its constructor for 0 to 3 indicates a north, south east, and west arrow respectively. The PolicyGlyphPainter2D also have various ways to render the glyphs. Here we use DISTSCALED which means each action glyph is rendered at a size proportional to the probability that the agent will select that action. Finally, we set the ValueFunctionVisualizerGUI to use the StatePolicyPainter we created, and set the Policy it should render. Then we set the background color to gray, and launch the GUI. If you now point the value iteration method to this value function visualization method instead of the simple one, you should find that your get the same visualization. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 5", "Performance with VisualActionObservers"], "word_count": 1621, "token_count_estimate": 2271}}, "http://burlap.cs.brown.edu/tutorials/bpl/p6.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an EnvironmentObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another EnvironmentObserver called PerformancePlotter to record a learning algorithms performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe construction process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If youd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will change our domains reward function. To do so, we will exploit the fact that the model for our grid world is a FactoredModel a model that has individual components for the reward function, terminal states, and state transition model. This is also the kind of model the vast majority of domains in BURLAP use. Since it is a FactoredModel, we can retreive it from our domain, and change its reward function. Well use a GoalBasedRF that returns a value 5 for transitions to our goal state and -0.1 everywhere else. public void experimenterAndPlotterdifferent reward function for more structured performance plotsFactoredModeldomain.getModel.setRfnew GoalBasedRFthis.goalCondition, 5.0, -0.1 For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To easily get a clean version of each agent, the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA algorithm. Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory public String getAgentName return Q-Learningpublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory public String getAgentName return SARSApublic LearningAgent generateAgent return new SarsaLamdomain, 0.99, hashingFactory, 0.0, 0.1, 1. Note that the factory also requires a getAgentName method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithms performance. We are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv, 10, 100,qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpData Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plots width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window again, filling columns first. The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method weve created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, youll note that a translucent filled area around each of the curves is present. This filledarea shows the 95 confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, youll find a number of other options that you can set, includingchanging the labels. Another important feature youll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it createdexpDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data even for the metrics that we did not plot. Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code youve created The complete set of code that we wrote in this tutorial is shownbelow for your convenience. The full code is also in the BURLAP code libary under the examples package. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyphimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolationimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2Dimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2Dimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.behavior.singleagent.learning.tdmethods.SarsaLamimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.singleagent.planning.deterministic.DeterministicPlannerimport burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIterationimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridLocationimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.auxiliary.stateconditiontest.StateConditionTestimport burlap.mdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.state.Stateimport burlap.mdp.core.state.vardomain.VariableDomainimport burlap.mdp.singleagent.common.GoalBasedRFimport burlap.mdp.singleagent.common.VisualActionObserverimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.awt.import java.util.Listpublic class BasicBehavior GridWorldDomain gwdgOOSADomain domainTerminalFunction tfStateConditionTest goalConditionState initialStateHashableStateFactory hashingFactorySimulatedEnvironment envpublic BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRoomstf new GridWorldTerminalFunction10, 10gwdg.setTftfgoalCondition new TFGoalConditiontfdomain gwdg.generateDomaininitialState new GridWorldStatenew GridAgent0, 0, new GridLocation10, 10, loc0hashingFactory new SimpleHashableStateFactoryenv new SimulatedEnvironmentdomain, initialStateVisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapobserver.initGUIenv.addObserversobserverpublic void visualizeString outputpathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapnew EpisodeSequenceVisualizerv, domain, outputpathpublic void BFSExampleString outputPathDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath bfspublic void DFSExampleString outputPathDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath dfspublic void AStarExampleString outputPathHeuristic mdistHeuristic new Heuristic public double hState s GridAgent a GridWorldStates.agentdouble mdist Math.absa.x-10 Math.absa.y-10return -mdistDeterministicPlanner planner new AStardomain, goalCondition, hashingFactory, mdistHeuristicPolicy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath astarpublic void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatePolicyUtils.rolloutp, initialState, domain.getModel.writeoutputPath visimpleValueFunctionVisValueFunctionplanner, pmanualValueFunctionVisValueFunctionplanner, ppublic void qLearningExampleString outputPathLearningAgent agent new QLearningdomain, 0.99, hashingFactory, 0., 1.run learning for 50 episodesforint i 0 i 50 iEpisode e agent.runLearningEpisodeenve.writeoutputPath ql iSystem.out.printlni e.maxTimeStepreset environment for next learning episodeenv.resetEnvironmentpublic void sarsaLearningExampleString outputPathLearningAgent agent new SarsaLamdomain, 0.99, hashingFactory, 0., 0.5, 0.3run learning for 50 episodesforint i 0 i 50 iEpisode e agent.runLearningEpisodeenve.writeoutputPath sarsa iSystem.out.printlni e.maxTimeStepreset environment for next learning episodeenv.resetEnvironmentpublic void simpleValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, domain, hashingFactoryValueFunctionVisualizerGUI gui GridWorldDomain.getGridWorldValueFunctionVisualizationallStates, 11, 11, valueFunction, pgui.initGUIpublic void manualValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, domain, hashingFactorydefine color functionLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEdefine a 2D painter of state values, specifying which attributes correspond to the x and y coordinates of the canvasStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYKeysagentx, agenty, new VariableDomain0, 11, new VariableDomain0, 11, 1, 1create our ValueFunctionVisualizer that paints for all statesusing the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, valueFunctiondefine a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYKeysagentx, agenty, new VariableDomain0, 11, new VariableDomain0, 11, 1, 1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALEDadd our policy renderer to itgui.setSppsppgui.setPolicypset the background color for places where states are not rendered to greygui.setBgColorColor.GRAYstart itgui.initGUIpublic void experimentAndPlotterdifferent reward function for more structured performance plotsFactoredModeldomain.getModel.setRfnew GoalBasedRFthis.goalCondition, 5.0, -0.1 Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory public String getAgentName return Q-Learningpublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory public String getAgentName return SARSApublic LearningAgent generateAgent return new SarsaLamdomain, 0.99, hashingFactory, 0.0, 0.1, 1.LearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv, 10, 100, qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpDatapublic static void mainString args BasicBehavior example new BasicBehaviorString outputPath outputexample.BFSExampleoutputPathexample.DFSExampleoutputPathexample.AStarExampleoutputPathexample.valueIterationExampleoutputPathexample.qLearningExampleoutputPathexample.sarsaLearningExampleoutputPathexample.experimentAndPlotterexample.visualizeoutputPath End.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 6"], "word_count": 1680, "token_count_estimate": 3724}}, "http://burlap.cs.brown.edu/tutorials/cpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 3 if youd like the BURLAP 2 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and be easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here. Value Iteration Overview Value Iteration VI is an algorithm that finds the optimal value function the expected discounted future reward of being in a state and behaving optimally from it, and consequently, the optimal policy, for an MDPs entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return the action with the maximum Q-value where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In mathlarge Vs maxa Qs,alarge Qs,a sums Ts s,a left Rs, a, s gamma Vs right, where Ts s, a is the probability of transitioning to state s when taking action a in state s, Rs, a, s is the reward received for transitioning to state s after taking action a in state s, and gamma is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, its unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming DP planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function Vs arbitrarily for all states s. Repeat until convergence... For each state s Vs maxa sums Ts s, a leftRs,a,s Vsright Since there are a number of different DP algorithms that can be implemented, BURLAP includes a class called DynamicProgramming that includes a number of helpful methods for automatically performing Bellman Updates on states and which is extended by many of the DP algorithms included in BURLAP. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch without using the DynamicProgramming class. However, we will extend the MDPSolver class since it provides a number of useful data members and setter and getter methods that you will commonly want to have for algorithms that solve MDPs. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 1"], "word_count": 716, "token_count_estimate": 862}}, "http://burlap.cs.brown.edu/tutorials/cpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part VI Code Lets start by creating our class for VI, which well call VITutorial. Our class will extend MDPSolver , to gain many of the useful datastructures used in solving an MDP, and it will implement the Planner and QProvider interfaces. The former because we will implement the planFromState method and the latter because Value Iteration computes the value function from which Q-values can be computed the QProvider interface extends the QFunction interface, which in turns extends the ValueFunction interface. QFunction adds a method to ValueFunction get the Q-value for a state-action pair, and QProvider provides a method to return all Q-values for an input state. We will also add all the imports we will need in developing this class. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.valuefunction.ConstantValueFunctionimport burlap.behavior.valuefunction.QProviderimport burlap.behavior.valuefunction.QValueimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.core.action.Actionimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.model.FullModelimport burlap.mdp.singleagent.model.TransitionProbimport burlap.statehashing.HashableStateimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.public class VITutorial extends MDPSolver implements Planner, QProviderOverridepublic double valueState s return 0.Overridepublic ListQValue qValuesState s TODO Auto-generated method stubreturn nullOverridepublic double qValueState s, Action a TODO Auto-generated method stubreturn 0.Overridepublic Policy planFromStateState initialState TODO Auto-generated method stubOverridepublic void resetSolver TODO Auto-generated method stub Because we are sub classing MDPSolver, this object will auto create data members that define our domain and task the Domain, discount factor, andHashableStateFactory that is used to hash and check the equality of states. However, the other critical data that VI needs to store are its estimates of the value function A value function is ultimately a mapping from states to a real value. Therefore, for fast access we can use a HashMap and use a HashableStateFactory to provide HashableState instances from states. One way to make VI run faster is to inititialize its value funciton to something close to the optimal value function. Therefore, we can also accept another ValueFunction to use as the initial value function. Well also have a parameter that specifies how long value iteration should run before it terminates there are others to test for convergence that we will not cover here. Lets create datamembers for these elements and create a constructor. protected MapHashableState, Double valueFunctionprotected ValueFunction vinitprotected int numIterationspublic VITutorialSADomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunction vinit, int numIterationsthis.solverInitdomain, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapHashableState, Double Note that since our MDPSolver superclass will hold our data members for the domain, discount factor, and HashableStateFactory, we can initialize them with its solverInit method. There is one other critical component VI needs that isnt part of the data weve given it in the constructor the full state space One reason we might not want to demand this upfront is because in an MDP, it is possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but its much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. Lets define a method to get all reachable states from an input state and initialize the value for them with our ValueFunctionInitialization object. Add the below method. public void performReachabilityFromState seedStateSetHashableState hashedStates StateReachability.getReachableHashedStatesseedState, this.domain, this.hashingFactoryinitialize the value function for all statesforHashableState hs hashedStatesifthis.valueFunction.containsKeyhsthis.valueFunction.puths, this.vinit.valuehs.s In the first line, we make use of BURLAPs StateReachability tool to do the heavy lifting of finding all reachable states. Then we simply iterate through the list, and for every HashableState for which we do not already have an entry, we initialize it with the value returned from the ValueFunction we use for initialization. You may notice that the value function is passed hs.s. Since our set of states are actually a set of HashableState instances, we retrieve the underlying State object stored in the HashableState by its s method. The other method well need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states a requirement of implementing the QProvider interface, we will implement those methods and a Bellman Equation method next. Overridepublic ListQValue qValuesState s ListAction applicableActions this.applicableActionssListQValue qs new ArrayListQValueapplicableActions.sizeforAction a applicableActionsqs.addnew QValues, a, this.qValues, areturn qsOverridepublic double qValueState s, Action a ifthis.model.terminalsreturn 0.what are the possible outcomesListTransitionProb tps FullModelthis.model.transitionss, aaggregate over each possible outcomedouble q 0.forTransitionProb tp tpswhat is reward for this transitiondouble r tp.eo.rwhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.eo.opadd contribution weighted by transition probability anddiscounting the next stateq tp.p r this.gamma vpreturn q Youll note that the qValues method returns a list of QValue objects, which are just triples consisting of a State object, an Action object, and a double for the Q-value associated with them. In the qValues method, we simply find all possible grounded actions using a method inherited from MDPSolver which we extended. Alternatively, we could use an ActionUtils method that takes is list of Action objects and State and returns all applicable groundings, ask our qValue method what the Q-value is, and then return the list of all those Q-values. In the qValue method, we first ask our model whether the input state is terminal. If it is, then the Q-value must be 0, because that is the definition of a terminal state. Otherwise, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. You might wonder where the model data member comes from. Because we are extending the MDPSolver class, when we called the solverInit method, it automatically unpacked the model included with the domain into a model data member that we can use. This is convenient, because we also allow a client to change the model the solver uses to something other than when comes out of the domain object with the setModel method. Note that the model cast to the super interface SampleModel. To perform dynamic programming, we require a FullModel, and we assume the model is of that type, so we type cast to that and call the FullModel transitions method. We now have all the tools we need to do planning, so its time to implement the planFromState method. This method is called whenever a client wants to run planning from a given initial or seed state. What well do then is first check if weve already performed planning that includes that state. If so, well do nothing, having assumed to already have computed the value for it. However, if we havent seen it before, then well first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. The Bellman equation is just the maximum Q-value, and we can call the QProvider helper method to get the maximum Q-value from objects that implement QProvider, which our class does Finally, all planFromState methodsrequire return a suitable Policy object to use the planning results. For value iteration, assuming it converged, the optimal policy is to select the action with the highest Q-value therefore, well return a GreedyQPolicy object. GreedyQPolicy objects need to be told what their QFunction source is, which in this case, is the instance of our class. Overridepublic GreedyQPolicy planFromStateState initialState HashableState hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn new GreedyQPolicythis already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforHashableState sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, QProvider.Helper.maxQthis, sh.sreturn new GreedyQPolicythis Were now just about finished The only thing left is that each MDPSolver instance is asked to implement the method resetSolver, which when called should have the effect of resetting all data so that its as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. Overridepublic void resetSolver this.valueFunction.clear Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial. Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy and visualizes the results. public static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setTfnew GridWorldTerminalFunction10, 10gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8SADomain domain gwd.generateDomainget initial state with agent in 0,0State s new GridWorldStatenew GridAgent0, 0setup vi with 0.99 discount factor, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, 0.99, new SimpleHashableStateFactory,new ConstantValueFunction0.0, 30run planning from our initial statePolicy p vi.planFromStatesevaluate the policy with one roll out visualize the trajectoryEpisode ea PolicyUtils.rolloutp, s, domain.getModelVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, Arrays.asListea If youre looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, its now time to move on to our Q-learning example If youd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 2"], "word_count": 1688, "token_count_estimate": 2653}}, "http://burlap.cs.brown.edu/tutorials/cpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part Q-Learning Overview For our learning algorithm example, well be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning 1 to learn a model of the world from experience and then use planning with that learned model to dictate behavior model-based and 2 to learn a policy or value function directly from experience model-free. Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values Qs,a arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action a in the current world state s based on current Q-value estimates Qs,cdot. Take the action a and observe the the outcome state s and reward r. Update Qs,a Qs,a alpha left r gamma maxa Qs, a - Qs,a right The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates step 3, but one of the most common is to use an epsilon-greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction 1-epsilon of the time where epsilon is a fraction between 0 and 1, and randomly selected among all actions a fraction epsilon of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. The update rulelarge Qs,a Qs,a alpha left r gamma maxa Qs, a - Qs,a rightupdates the Q-value of the last state-action pair s,a with respect to the observed outcome state s and reward r, where alpha in 0, 1 is a learning rate parameter. To unpack this update, recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the discounted max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, were not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, well see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, its often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, well use a fixed value for the learning rate rather that one that changes with time though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface. Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend MDPSolver and implement the LearningAgent and QProvider interfaces. The LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class. import burlap.behavior.policy.EpsilonGreedyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.valuefunction.ConstantValueFunctionimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QProviderimport burlap.behavior.valuefunction.QValueimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.core.action.Actionimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.environment.Environmentimport burlap.mdp.singleagent.environment.EnvironmentOutcomeimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.statehashing.HashableStateimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.ArrayListimport java.util.HashMapimport java.util.Listimport java.util.Mappublic class QLTutorial extends MDPSolver implements LearningAgent, QProvider Overridepublic Episode runLearningEpisodeEnvironment env return nullOverridepublic Episode runLearningEpisodeEnvironment env, int maxSteps return nullOverridepublic void resetSolver Overridepublic ListQValue qValuesState s return nullOverridepublic double qValueState s, Action a return 0.Overridepublic double valueState s return 0. Similar to VI, the primary data we will want to store is a set of estimated Q-values for each state and action pair. Well also again let the user specify the Q-value function initialization with a QFunction object. Well also need a learning rate parameter to be set. Finally, well need a learning policy to follow that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, well assume an epsilon-greedy policy and let the client specify the value for epsilon. Lets add data members for those elements now. MapHashableState, ListQValue qValuesQFunction qinitdouble learningRatePolicy learningPolicy Lets also add a constructor to initialize our data members and some of those that we inherit from MDPSolver. public QLTutorialSADomain domain, double gamma, HashableStateFactory hashingFactory, QFunction qinit, double learningRate, double epsilonthis.solverInitdomain, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMapHashableState, ListQValuethis.learningPolicy new EpsilonGreedythis, epsilon Note that the EpsilonGreedy policy object we create takes as input a QProvider, which this class implements, and the value for epsilon to use. Getting and storing Q-values is the primary tool well need for our algorithm, so lets implement the value function methods now. Overridepublic ListQValue qValuesState s first get hashed stateHashableState sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListAction actions this.applicableActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforAction a actionsadd q with initialized valueqs.addnew QValues, a, this.qinit.qValues, astore this for laterthis.qValues.putsh, qsreturn qsOverridepublic double qValueState s, Action a return storedQs, a.qprotected QValue storedQState s, Action afirst get all Q-valuesList qs this.qValuessiterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value.Overridepublic double valueState s return QProvider.Helper.maxQthis, s Note that the qValues method checks if weve already stored Q-values for the given state. If not, we create them with the initial Q-value defined by our QFunction initialization object. For the qValue method, we go through a helper method that returnes the stored QValue object for a given action this storedQ method will be useful for updating our Q-values for the actual learning algorithm. The value method, like for our value iteration example, can simply return the result of the QProvider Helper class method maxQ. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode in some Environment one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We will have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an Episode object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, well record the results to an Episode object. Below is the learning algorithm code for Q-learning. Overridepublic Episode runLearningEpisodeEnvironment env return this.runLearningEpisodeenv, -1Overridepublic Episode runLearningEpisodeEnvironment env, int maxSteps initialize our episode object with the initial state of the environmentEpisode e new Episodeenv.currentObservationbehave until a terminal state or max steps is reachedState curState env.currentObservationint steps 0whileenv.isInTerminalState steps maxSteps maxSteps -1select an actionAction a this.learningPolicy.actioncurStatetake the action and observe outcomeEnvironmentOutcome eo env.executeActionarecord resulte.transitioneoget the max Q value of the resulting state if its not terminal, 0 otherwisedouble maxQ eo.terminated 0. this.valueeo.opupdate the old Q-valueQValue oldQ this.storedQcurState, aoldQ.q oldQ.q this.learningRate eo.r this.gamma maxQ - oldQ.qupdate state pointer to next environment state observedcurState eo.opstepsreturn e The beginning of the code is fairly straightforward we construct a new Episode object rooted in the current state of the environment, which we get back from the Environment method getCurrentObservation. We then begin an execution loop that lasts either until the Environment reaches a terminal state or until the number of steps weve taken exceeds the number requested. Inside the execution loop, we first select an action using our learning policy. Then we execute the action in the environment using the GroundedAction method executeInEnvironment,which returns to us an EnvironmentOutcome object. Environment Observations You may have noticed that the Environment uses observation terminology instead of state terminology. This choice is because Environment objects are not under obligation to return to the agent a full state, only an observation. Typically, for MDPdomains you can expect it to be a full State, and regardless of whether it is a partial observation or not, the observation itself will always be represnted by a BURLAP State object. Note that the use of this terminology is especially useful if you begin using BURLAPs POMDP framework. Using the new observations from the environment, we record the transition in our Episode and update the previous Q-Value. To update the previous Q-value, we need to get the maximum Q-value for the next state we encounted. However, if that state is a terminal state, then the value should always be zero, because the agent cannot act further from that state. Otherwise, we can get the maximum value by using value method that we previously defined. Finally, we can implement the resetSover method, which only needs to clear our Q-values. Overridepublic void resetSolver this.qValues.clear Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates a similar Grid World domain and task as the test code we wrote for our VI implementation, except applies the Q-Learning algorithm to it in a simulated environment. The results of each leaning episode will be presented for you after learning completes. Note that because the domain is stochastic and follows a nosiy exploration policy, it can take much longer to learn and the resulting policy will not be a straight shot to the goal. public static void mainString args GridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsgwd.setProbSucceedTransitionDynamics0.8gwd.setTfnew GridWorldTerminalFunction10, 10SADomain domain gwd.generateDomainget initial state with agent in 0,0State s new GridWorldStatenew GridAgent0, 0create environmentSimulatedEnvironment env new SimulatedEnvironmentdomain, screate Q-learningQLTutorial agent new QLTutorialdomain, 0.99, new SimpleHashableStateFactory,new ConstantValueFunction, 0.1, 0.1run Q-learning and store results in a listListEpisode episodes new ArrayListEpisode1000forint i 0 i 1000 iepisodes.addagent.runLearningEpisodeenvenv.resetEnvironmentVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, episodes Next Part", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 3", "Environment Observations"], "word_count": 1876, "token_count_estimate": 2901}}, "http://burlap.cs.brown.edu/tutorials/cpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAPs existing implementations of Value Iteration and Q-Learning since they support a number of other features Options, learning rate decay schedules, etc.. If you would like to see all of the code that was written in this tutorial, we have provided it below first the Value Iteration code , then the Q-learning Code . The code is also available in the burlapexamples repository. Full VI Code import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.valuefunction.ConstantValueFunctionimport burlap.behavior.valuefunction.QProviderimport burlap.behavior.valuefunction.QValueimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.core.action.Actionimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.model.FullModelimport burlap.mdp.singleagent.model.TransitionProbimport burlap.statehashing.HashableStateimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.public class VITutorial extends MDPSolver implements Planner, QProvider protected MapHashableState, Double valueFunctionprotected ValueFunction vinitprotected int numIterationspublic VITutorialSADomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunction vinit, int numIterationsthis.solverInitdomain, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapHashableState, DoubleOverridepublic double valueState s Double d this.valueFunction.gethashingFactory.hashStatesifd nullreturn vinit.valuesreturn dOverridepublic ListQValue qValuesState s ListAction applicableActions this.applicableActionssListQValue qs new ArrayListQValueapplicableActions.sizeforAction a applicableActionsqs.addnew QValues, a, this.qValues, areturn qsOverridepublic double qValueState s, Action a ifthis.model.terminalsreturn 0.what are the possible outcomesListTransitionProb tps FullModelthis.model.transitionss, aaggregate over each possible outcomedouble q 0.forTransitionProb tp tpswhat is reward for this transitiondouble r tp.eo.rwhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.eo.opadd contribution weighted by transition probability anddiscounting the next stateq tp.p r this.gamma vpreturn qOverridepublic GreedyQPolicy planFromStateState initialState HashableState hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn new GreedyQPolicythis already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforHashableState sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, QProvider.Helper.maxQthis, sh.sreturn new GreedyQPolicythisOverridepublic void resetSolver this.valueFunction.clearpublic void performReachabilityFromState seedStateSetHashableState hashedStates StateReachability.getReachableHashedStatesseedState, this.domain, this.hashingFactoryinitialize the value function for all statesforHashableState hs hashedStatesifthis.valueFunction.containsKeyhsthis.valueFunction.puths, this.vinit.valuehs.spublic static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setTfnew GridWorldTerminalFunction10, 10gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8SADomain domain gwd.generateDomainget initial state with agent in 0,0State s new GridWorldStatenew GridAgent0, 0setup vi with 0.99 discount factor, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, 0.99, new SimpleHashableStateFactory,new ConstantValueFunction0.0, 30run planning from our initial statePolicy p vi.planFromStatesevaluate the policy with one roll out visualize the trajectoryEpisode ea PolicyUtils.rolloutp, s, domain.getModelVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, Arrays.asListea Full Q-Learning Code import burlap.behavior.policy.EpsilonGreedyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.valuefunction.ConstantValueFunctionimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QProviderimport burlap.behavior.valuefunction.QValueimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.core.action.Actionimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.environment.Environmentimport burlap.mdp.singleagent.environment.EnvironmentOutcomeimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.statehashing.HashableStateimport burlap.statehashing.HashableStateFactoryimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.ArrayListimport java.util.HashMapimport java.util.Listimport java.util.Mappublic class QLTutorial extends MDPSolver implements LearningAgent, QProvider MapHashableState, ListQValue qValuesQFunction qinitdouble learningRatePolicy learningPolicypublic QLTutorialSADomain domain, double gamma, HashableStateFactory hashingFactory, QFunction qinit, double learningRate, double epsilonthis.solverInitdomain, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMapHashableState, ListQValuethis.learningPolicy new EpsilonGreedythis, epsilonOverridepublic Episode runLearningEpisodeEnvironment env return this.runLearningEpisodeenv, -1Overridepublic Episode runLearningEpisodeEnvironment env, int maxSteps initialize our episode object with the initial state of the environmentEpisode e new Episodeenv.currentObservationbehave until a terminal state or max steps is reachedState curState env.currentObservationint steps 0whileenv.isInTerminalState steps maxSteps maxSteps -1select an actionAction a this.learningPolicy.actioncurStatetake the action and observe outcomeEnvironmentOutcome eo env.executeActionarecord resulte.transitioneoget the max Q value of the resulting state if its not terminal, 0 otherwisedouble maxQ eo.terminated 0. this.valueeo.opupdate the old Q-valueQValue oldQ this.storedQcurState, aoldQ.q oldQ.q this.learningRate eo.r this.gamma maxQ - oldQ.qupdate state pointer to next environment state observedcurState eo.opstepsreturn eOverridepublic void resetSolver this.qValues.clearOverridepublic ListQValue qValuesState s first get hashed stateHashableState sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListAction actions this.applicableActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforAction a actionsadd q with initialized valueqs.addnew QValues, a, this.qinit.qValues, astore this for laterthis.qValues.putsh, qsreturn qsOverridepublic double qValueState s, Action a return storedQs, a.qprotected QValue storedQState s, Action afirst get all Q-valuesListQValue qs this.qValuessiterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value.Overridepublic double valueState s return QProvider.Helper.maxQthis, spublic static void mainString args GridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsgwd.setProbSucceedTransitionDynamics0.8gwd.setTfnew GridWorldTerminalFunction10, 10SADomain domain gwd.generateDomainget initial state with agent in 0,0State s new GridWorldStatenew GridAgent0, 0create environmentSimulatedEnvironment env new SimulatedEnvironmentdomain, screate Q-learningQLTutorial agent new QLTutorialdomain, 0.99, new SimpleHashableStateFactory,new ConstantValueFunction, 0.1, 0.1run Q-learning and store results in a listListEpisode episodes new ArrayListEpisode1000forint i 0 i 1000 iepisodes.addagent.runLearningEpisodeenvenv.resetEnvironmentVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, episodes End.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 4"], "word_count": 793, "token_count_estimate": 2241}}, "http://burlap.cs.brown.edu/tutorials/hgw/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Hello Grid World Tutorials Hello Grid World Part 1 Tutorial Contents Introduction Compiling from Source Hello Grid World Project Conclusion You are viewing the tutorial for BURLAP 3 with Maven. If youd like the BURLAP 2 tutorial, go here . Introduction In this tutorial we will walk you through getting started with BURLAP. We will assume that you have Maven installed for this process, since it will make management of dependencies very straightforward. If you do not already have Maven installed, you can probably get it from your favorite package manager. For example, on Debian systems, sudo apt-get install maven Or on Mac OS with homebrew brew install maven Alternatively, you can manually install it from httpsmaven.apache.orgdownload.cgi . Be sure to follow their installtion instructions. To verify that you have maven installed try the following from the command line mvn -v We also highly recommend that you use an IDE for your work, which will make working with the library substantially easier. If you do not have an IDE we recommend either IntelliJ or Eclipse . Both will have tools for working with Maven projects. That said, for this tutorial we will give instructions using just the command line and your favorite text editor. You can probably follow along in an IDE if you prefer. In this tutorial you will have two options. You can either build and install BURLAP from its source, or you can simply use the released version of BURLAP from Maven Central. The latter will require the least work, but if youd like to be able to modify BURLAP at all or want to make sure you always have the most update to date version, it may be worth it to checkout out the code and manually compile it. If you prefer to simply use the Maven Central copy, skip the next section. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are on windows, you can use either use the command prompt something like Cygwin . Compiling from Source To compile the code from source, you will probably want to have git installed, or you can manually download the source from github. If you have git installed, navigate from your command line to a directory where you would like to place the code. Then type the following git clone httpsgithub.comjmacglashanburlap.git If you do not have git installed on your computer, then you can manually download the files by navigating to the website httpsgithub.comjmacglashanburlap and clicking on download zip to save it and unarchive it at a desired location. Whether you used git to clone the source, or manually downloaded it, navigate into the directory with your command line. The directory should look something like the following LICENSEREADME.mdburlap-repopom.xmlsrc Now we can compile using Maven, which you should have installed on the previous step. You can use the standard Maven methods for compilation. That is, to simply compile the code, use mvn compile To create a jar file and Java doc in the target directory as well as jar file that includes all dependencies use mvn package And to install BURLAP to your local Maven repository, use mvn install And if you want to skip the tests which may take a while, use the command mvn install -DskipTests Thats it Hello Grid World Project Whether you compiled and installed BURLAP from source in the prior step or not, this next section is the same because BURLAP is available on Maven Central, which means Maven will automatically download it and install it if you did not compile it from source. To begin our example project, create a directory somewhere on your file system where you will store the project code and navigate into it on your command line. If youve used Maven before, you may want to create your project by generating an archetype. Feel free to do so if you, like. However, we will manually set up the project from the command line and text editors here. First create a file named pom.xml. With your favorite text editor, insert the following 4.0.0 com.mycompany.app myProj 1 edu.brown.cs.burlap burlap 3.0.0 org.codehaus.mojo exec-maven-plugin 1.2.1 java You should set the group id at the top to anything that seems relevant for you, and you can also rename the artifact id to something else if you prefer. Note the dependencies section with the BURLAP dependency, which tells Maven that your project depends on BURALP. As of writing this tutorial, the latest version of BURLAP is 3.1.0. However, you may want to change this value to whatever the latest is, or to a version you prefer especially if youve installed your own custom version with its own version number. You can see the list of all release versions of BURLAP from here . The plugin we added will also allow us to use Maven to easily run code that we write. Now create the following directory tree srcmainjavamyProj. Inside the nested myProj folder, we will create two text files, HelloGridWorld.java and PlotTest.java. HelloGridWorld.java should have the following contents. package myProjimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridLocationimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.SADomainimport burlap.shell.visual.VisualExplorerimport burlap.visualizer.Visualizerpublic class HelloGridWorld public static void mainString args GridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success rateSADomain domain gw.generateDomain generate the grid world domainsetup initial stateState s new GridWorldStatenew GridAgent0, 0, new GridLocation10, 10, loc0create visualizer and explorerVisualizer v GridWorldVisualizer.getVisualizergw.getMapVisualExplorer exp new VisualExplorerdomain, v, sset control keys to use w-s-a-dexp.addKeyActionw, GridWorldDomain.ACTIONNORTH, exp.addKeyActions, GridWorldDomain.ACTIONSOUTH, exp.addKeyActiona, GridWorldDomain.ACTIONWEST, exp.addKeyActiond, GridWorldDomain.ACTIONEAST, exp.initGUI And PlotTest.java should have the contents package myProjimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.state.GridAgentimport burlap.domain.singleagent.gridworld.state.GridLocationimport burlap.domain.singleagent.gridworld.state.GridWorldStateimport burlap.mdp.auxiliary.common.ConstantStateGeneratorimport burlap.mdp.auxiliary.common.SinglePFTFimport burlap.mdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.oo.propositional.PropositionalFunctionimport burlap.mdp.singleagent.common.GoalBasedRFimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.statehashing.simple.SimpleHashableStateFactorypublic class PlotTest public static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success rateends when the agent reaches a locationfinal TerminalFunction tf new SinglePFTFPropositionalFunction.findPFgw.generatePfs, GridWorldDomain.PFATLOCATIONreward function definitionfinal RewardFunction rf new GoalBasedRFnew TFGoalConditiontf, 5., -0.1gw.setTftfgw.setRfrffinal OOSADomain domain gw.generateDomain generate the grid world domainsetup initial stateGridWorldState s new GridWorldStatenew GridAgent0, 0, new GridLocation10, 10, loc0initial state generatorfinal ConstantStateGenerator sg new ConstantStateGeneratorsset up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory new SimpleHashableStateFactory Create factory for Q-learning agent LearningAgentFactory qLearningFactory new LearningAgentFactory public String getAgentName return Q-learningpublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1define learning environmentSimulatedEnvironment env new SimulatedEnvironmentdomain, sgdefine experimentLearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv,10, 100, qLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDstart experimentexp.startExperiment Your directory structure should now look like the following. pom.xmlsrcmainjavamyProjHelloGridWorld.javaPlotTest.java Were now ready to compile and run In the command line, make sure youre in the same directory as your pom.xml file. Then, to compile, run mvn compile Maven should download BURLAP if you did not manually compile and install it and other information, and then compile your two sources. To run the HelloGridWorld code, use the following command mvn execjava -Dexec.mainClassmyProj.HelloGridWorld Running this code should launch a GUI with a grid world, similar to the image below. If you click on the image and then use the w-a-s-d keys, youll be able to control the agents movements. Note, however, that we made this a stochastic grid world in the code, which means some of the time you may find the agent going in a different direction than the one you intended We can similarly run our PlotTest code with mvn execjava -Dexec.mainClassmyProj.PlotTest Which will run Q-learning on the same grid world 10 times, plotting the most recent trial and average performance. It should look something like the below image. Conclusion In this tutorial we walked you through compiling BURLAP and setting up your own Maven project that uses BURLAP. We used the command line to set everything up, but we strongly encourage you to use a full IDE for most projects, such as IntelliJ or Eclipse . You can initialize your projects the way we did here and then import the code into the IDE, or you can have these IDEs create a new Maven project themselves. Now that youve completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding End.", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Hello", "World!", ">", "> Part 1"], "word_count": 1367, "token_count_estimate": 2379}}, "http://burlap.cs.brown.edu/tutorials/index.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorials You are viewing the tutorials for BURLAP 2 if youd like the BURLAP version 1 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. You can find code for all of the tutorials and more in our examples repository httpsgithub.comjmacglashanburlapexamples Video Tutorials Text Tutorials Hello Grid World - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains Building an OO-MDP Domain", "metadata": {"last_modified": "2016-06-20T16:16:01+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorials", "Video Tutorials"], "word_count": 105, "token_count_estimate": 144}}, "http://burlap.cs.brown.edu/tutorials/oomdp/p1.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building an OO-MDP Domain Tutorials Building an OO-MDP Domain Part 1 Tutorial Contents Introduction Java Interfaces for OO-MDPs Object Identifier Independence Grid World OO-MDP States Grid World OO-MDP Model OO-MDP Visualization Testing it Out Conclusion Final Code Next Part Introduction In the Building a Domain tutorial, we showed you how to construct an MDP. In this tutorial, we will show you how to construct an Object-oriented MDP OO-MDP. OO-MDPs are MDPs that have a specific kind of rich state representation and BURLAP provides first class support for defining MDPs as OO-MDPs many of the existing domains in BURLAP are in fact implemented as OO-MDPs themselves. Although you can probably do fine defining your domains without using the OO-MDP interfaces provided in BURLAP, you may find that the extra richness is useful, or you may be able to write learning algorithms that can exploit this kind of structured state. OO-MDPs represent states as an unordered collection of objects. Each object has its own set of state variables that are defined by an OO-MDP object class from which the object is instantiated. Additionally, OO-MDPs can also include a set of propositional functions functions that take as input state objects that belong to certain typed state classes, and evaluate properties of, or relationships between, the object arguments. Since Java is an object-oriented programming language, we can make the definition of OO-MDP state objects as simple as defining a Java class for them that implements an interface In this tutorial we will review the Java interfaces involved in defining OO-MDPs and review an important invariance of states that we can exploit through the OO-MDP definitions object identifier independence. We will then walk through how to define the Grid World we made in the previous Building a Domain tutorial as an OO-MDP with additional OO-MDP objects for marking important goal locations and a propositional function that will evaluate whether an agent is at one of those locations. As usual, all example code is provided at the end of this tutorial, and is available in the burlapexamples , github repository. Java Interfaces for OO-MDPs A UML diagram of the Java interfaces and classes related to creating OO-MDPs is shown in the below figure. Figure UML Digram of OO-MDP interfacesclasses. OO-MDP States As indicated by the UML diagram, implementing an OO-MDP state involves implementing the OOState interface. An OOState is ultimately defined by a collection of objects that implement the ObjectInstance interface. ObjectInstance is itself an extension to the State interface, which means objects of an OO-MDP are also just states and can be treated entirely as such, allowing for composition of various tools. Defining the Java class for an ObjectInstance simultaneously serves as defining the OO-MDP object class. To implement an ObjectInstance, in addition to the standard State methods, you must also implement a method for returning the name of the OO-MDP object class, a name that uniquely identifies the object from other objects that will appear alongside it in the same OOState, and a method that can produce a copy of the object with a different identifying name. In addition to implementing an OOState that it is made up of ObjectInstances, you will also need to implement methods for querying the number of ObjectInstances, retrieving an ObjectInstance by name, retrieving a list of all the objects, and retrieving a list of Objects belonging to a specified OO-MDP class. When implementing the State get and variableKeys methods for an OOState, it is recommended that you use keys that are OOVariableKey objects, which is a pair specifying a name of an object and its variable key, which is the information a client would need to query about each variable in the entire OOState. If an ObjectInstance accepts string representations of variable keys, an OOVariableKey can also be constructed from a String representation following the format obNamevariableKey. If you would like a mutable state that is also an OOState, then you may also want to consider implementing the MutableOOState interface, which provides methods for adding objects to the state, removing objects, and renaming an objects identifier. For maximum performance and minimum memory overhead, you should consider implementing your own OOState classes however, BURLAP also provides a general purpose concrete OOState implementation GenericOOState. GenericOOState implements MutableOOState and uses ShallowCopying of the ObjectInstances to minimize some of the memory overhead, with the set method using copy-on-write to prevent contamination of ancestor states from which it was copied. GenericOOState also provides some additional methods for causing an object belonging to the state to be replaced with a copy, so that you can directly modify copied ObjectInstances without going through the set method. DeepOOState is a concrete extension of GenericOOState that always performs deep copies so you can directly modify ObjectInstances without having to manually manage the copying of ObjectInstances. In this tutorial, we will make use of GenericOOState and show you how to work with it. Propositional Functions In addition to OO-MDP states being made up of collections of objects, OO-MDPs can also have an associated set of propositional functions that provide high-level state information in the form of boolean properties and relationships between objects in the State. In BURLAP, you can create these propositional functions by extending the abstract class PropositionalFunction . Extending a PropositionalFunction requires giving it a name, a function signature, and implementing the isTrue method. The function signature is the OO-MDP object class types to which the object parameters of the function must belong. The isTrue method defines the function. Since the PropositionalFunction class defines the function, it is useful to have an object that specifies a certain set of parameters on which you can evaluate the function. The GroundedProp class provides that it is a pair that references a PropositionalFunction and the parameters names of objects in an OO-MDP state on which to evaluate the function. It also has a shortcut method, isTrue, that will return the result of the PropositionalFunction isTrue method given the GroundedProp parameters. The PropositionalFunction class also includes the method allGroundings that given a state, will determine all possible parameter assignments on which the PropositionalFunction can be evaluated given its function signature and returns the possible assignments as a list of GroundedProp objects. Similarly, there is a static method, allGorundingsFromList, which will take a list of PropositionalFunction objects and return the concatenated list of GroundedProp objects that results from applying the allGroundings method on each of them. Finally, Propositional functions can also have special signature information, called parameter order groups, specified. This is advanced functionality that allows you to specify whether the order of certain parameters matters. For example, if we defined a proposition function for testing whether two objects were touching, then it follows that touchingob1, ob2 touchingob2, ob1 and you wouldnt need to evaluate both orders of the parameter assignments. By setting both parameters to the same order group, this symmetry is defined and the allGroundings method will only return one grounding for each set of equivalent parameter assignments. By default, the parameter order groups are all set to be different for each parameter that is, by default, it is assumed that different orderings of parameters can affect the result of the function. OO-MDP Domains Finally, OODomain is a special domain interface for OO-MDP domains, with OOSADomain being a concrete implementation of it for single agent domains and it accordingly also extends SADomain. OODomain implementations should contain the set of PropositionalFunctons for the domain and also provide a method for getting the Java class that is used to define a specific OO-MDP object class that is, a map from the String name of an OO-MDP object class to the ObjectInstance Java class used to define it. Object Identifier Independence One useful aspect of using OO-MDPs is the ability to use a state invariance that we call object identifier independence . To understand object identifier independence, consider the following scenario where we have a domain made up of block objects. Each block resides in some location on a 2D grid. Suppose the environment state consists of two blocks identified as block0 and block1 that are otherwise identical, but in different positions. Now suppose an action was taken that swapped the locations of the blocks, as shown in the below figure. Figure Swapping the location of two blocks The question is, is the state before the swap and after the swap the same The only thing that is different is the identifier we use to refer to the blocks at each location. If we used a more standard representation where states were defined by different state variables for each block, these states would be treated differently. But in practice, the difference in these states might not matter. In fact, if the transition dynamics and reward function are independent of the identifier of the blocks, then in fact we dont want to treat these states as different. By exploiting the structure of the OO-MDP representation, we can provide this desired invariance where these two states are treated as the same, thereby decreasing the size of the state space that must be examined by a planning or learning algorithm. In BURLAP, tabular planning and learning methods rely on a method to hash states and test equality that is provided by a HashableStateFactory implementation. The concrete provided SimpleHashableStateFactory , and its derivatives, will automatically perform the necessary work to provide this kind of identifier independent state invariance for states that implement the OOState interface. However, if it turns out that your reward function or transition dynamics do depend on object identifiers, then you can optionally set the SimpleHashableStateFactory and its derivatives to not perform the invariance. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:13+00:00", "headings": ["Tutorial: Building an OO-MDP Domain", ">", "> Part 1"], "word_count": 1615, "token_count_estimate": 2015}}, "http://burlap.cs.brown.edu/tutorials/oomdp/p2.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building an OO-MDP Domain Tutorials Building an OO-MDP Domain Part 2 Tutorial Contents Introduction Java Interfaces for OO-MDPs Object Identifier Independence Grid World OO-MDP States Grid World OO-MDP Model OO-MDP Visualization Testing it Out Conclusion Final Code Previous Part Next Part Grid World OO-MDP States In the remaining sections, we will be reimplementing our previous Grid World from the Building a Domain tutorial as an OO-MDP. Much of the code will remain the same, so in this tutorial, we will assume you are familiar with the work in the previous tutorial, and just describe the aspects that weve changed. Lets start by creating an OO-MDP Grid World DomainGenerator that will hold constants and generate our domain. Lets call this class ExampleOOGridWorld. import burlap.mdp.auxiliary.DomainGeneratorimport burlap.mdp.auxiliary.common.SinglePFTFimport burlap.mdp.core.StateTransitionProbimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.action.Actionimport burlap.mdp.core.action.UniversalActionTypeimport burlap.mdp.core.oo.OODomainimport burlap.mdp.core.oo.propositional.PropositionalFunctionimport burlap.mdp.core.oo.state.OOStateimport burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.oo.state.generic.GenericOOStateimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.common.SingleGoalPFRFimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.model.statemodel.FullStateModelimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.shell.visual.VisualExplorerimport burlap.visualizer.import java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ExampleOOGridWorld implements DomainGeneratorpublic static final String VARX xpublic static final String VARY ypublic static final String VARTYPE typepublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION locationpublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westpublic static final String PFAT atordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,Overridepublic OOSADomain generateDomain well fill this in later Lets now implement our Grid World State as an OO-MDP. Previously, we had a single ExGridState that we implemented. In our OO-MDP, we will define the OO-MDP to consist of an agent object, and any number of location objects that well use to mark places of interest. Our agent object will look much like our previous ExGridState class that tracks an x and y location. Create the below file for our agent object, named ExGridAgent. import burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport burlap.mdp.core.state.UnknownKeyExceptionimport burlap.mdp.core.state.annotations.DeepCopyStateimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.CLASSAGENTimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VARXimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VARYDeepCopyStatepublic class ExGridAgent implements ObjectInstance, MutableState public int xpublic int ypublic String name agentprivate final static ListObject keys Arrays.ObjectasListVARX, VARYpublic ExGridAgent public ExGridAgentint x, int y this.x xthis.y ypublic ExGridAgentint x, int y, String name this.x xthis.y ythis.name nameOverridepublic String className return CLASSAGENTOverridepublic String name return nameOverridepublic ObjectInstance copyWithNameString objectName return new ExGridAgentx, y, objectNameOverridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARXthis.x StateUtilities.stringOrNumbervalue.intValueelse ifvariableKey.equalsVARYthis.y StateUtilities.stringOrNumbervalue.intValueelsethrow new UnknownKeyExceptionvariableKeyreturn thisOverridepublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARXreturn xelse ifvariableKey.equalsVARYreturn ythrow new UnknownKeyExceptionvariableKeyOverridepublic ExGridAgent copy return new ExGridAgentx, y, nameOverridepublic String toString return StateUtilities.stateToStringthis The first change to notice from our ExGridState is that in addition to implementing MutableState, we also implement ObjectInstance to declare this an OO-MDP object that makes up an OO-MDP state. We also added a data member, name, to track this objects name, which we default to the value agent. The className method simply returns the class name constant we defined in our domain generator the name method returns the name data member for this object and the copyWithName method returns a new instance of the object with the same x and y values, and the new name. Otherwise the rest is the same as our previous ExGridState Now lets define a ObjectInstance for locations. Our location object will also be marked by an x and y position, as well as a type, so that we could have locations of different types. To implement this class, we will simply extend our ExGridAgent, add a type data type, and modify the methods to return a different class, handle the new type key, and return copies of the ExGridLocation instance instead of ExGridAgent in the copy methods. import burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.public class EXGridLocation extends ExGridAgentpublic int typeprivate final static ListObject keys Arrays.ObjectasListVARX, VARY, VARTYPEpublic EXGridLocation public EXGridLocationint x, int y, String name superx, y, namepublic EXGridLocationint x, int y, int type, String name superx, y, namethis.type typeOverridepublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARTYPEreturn this.typereturn super.getvariableKeyOverridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARTYPEthis.type StateUtilities.stringOrNumbervalue.intValueelsesuper.setvariableKey, valuereturn thisOverridepublic String className return CLASSLOCATIONOverridepublic ObjectInstance copyWithNameString objectName return new EXGridLocationx, y, type, objectNameOverridepublic EXGridLocation copy return new EXGridLocationx, y, type, name So far weve defined the ObjectInstances for our State, but we havent define the OOState that will be made up of these ObjectInstances. However, for this tutorial we will be making use of BURLAPs provided GenericOOState implementation, so at this point were done with the explicit state definition code. However, we will now add a propositional function to our domain that evaluates whether the agent object is at a location, indicated by their x and y location being the same. Add the following code to the ExampleOOGridWorld class. protected class AtLocation extends PropositionalFunction public AtLocationsuperPFAT, new String CLASSAGENT, CLASSLOCATIONOverridepublic boolean isTrueOOState s, String... params ObjectInstance agent s.objectparams0ObjectInstance location s.objectparams1int ax Integeragent.getVARXint ay Integeragent.getVARYint lx Integerlocation.getVARXint ly Integerlocation.getVARYreturn ax lx ay ly The constructor we added calls the super constructor that will define the PropositionalFunctions signature that is, its name the PFAT constant, and OO-MDP classes to which its parameters must belong. In this case, our at propositional function will operate on an agent object and a location object, so we provided parameters with those types. The isTrue method takes as input a OOState to evaluate, and the names of the objects on which to evaluate the function in the variable length String argument params. The first step is to get the agent and location ObjectInstances from the state for the parameters provided to function. Because we defined the function to operate on two parameters, an agent and then a location, we know the params argument passed to the isTrue method has two elements. Then we get the agent and location ObjectInstance by by using the OOState method object on the first and second elements of the params argument. Next, we get the x and y values for each of the objects using the standard State get method, and then check if the agent and location positions are equal to determine whether the agent is at the location. Lets also add a method to our ExampleOOGridWorld class to generate a list of all our propositional functions. In this case we only have one, but this is often a useful method to include. public ListPropositionalFunction generatePfsreturn Arrays.PropositionalFunctionasListnew AtLocation We are now finished defining the OO-MDP state information and next will implement the grid world model. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building an OO-MDP Domain", ">", "> Part 2"], "word_count": 1053, "token_count_estimate": 2219}}, "https://blog.cs.brown.edu/2019/04/05/tech-social-good-spotlight-ben-spector-17/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Tech For Social Good Spotlight Ben Spector 17 Posted by Jesse Polhemus on April 5, 2019 in Socially Responsible Computing by Adi Melamed Click the link that follows for other stories in the Tech for Social Good Spotlight series and more news items about our Socially Responsible Computing program and our innovative and pioneering alums. The Tech For Social Good Spotlight is a series focused on recent Brown Computer Science graduates working at the intersection of computer science and social good. The goal of these interviews is to explore what it means to work in the technology for social good space, what technology for social good might even mean in the first place, and most importantly, share advice for Brown students considering this path. The spotlight is organized by Impact Labs , a student-run organization creating awareness and access to opportunities in the tech for social good space. Ben Spector Class of 17 has a BA in Computer Science and Music. He works as a Lead High School Instructor for Operation Spark , a nonprofit coding bootcamp focused on providing training opportunities for low-opportunity individuals to ease the process of getting software jobs. The following conversation has been edited for length and clarity. What were your past experiences in the CS for Social Good space My sophomore summer I did an internship at a popular travel website doing software engineering, which was my first experience doing actual software engineering. I really liked the company, and really liked the people I was working with, but I didnt love the job I was doing. That also came after the year where I was taking CS 32 and CS 33, as well as CS 22... Yeah, so it was just a really intense, full year, followed by the internship and I just felt really burnt out. The next summer I got an internship at one of the big tech companies doing software engineering. I was hoping I would feel a little different about software engineering in general, but pretty much from the moment I got there I realized I didnt want to be doing software engineering.I didnt like the people, I didnt like working for the company, I didnt like what I was doing. So during my senior year I was really trying to figure out what exactly I was trying to do. I started taking some more education courses, and I started volunteering with BEAM Brown Elementary Afterschool Program...I had worked with kids before, and I always thought that teaching is something that Id be interested in. ...Then, I dont remember how I found Venture for America , but it is a fellowship program aimed at getting recent college grads jobs at startups in cities with smaller startup ecosystems. After graduation, I knew I wanted to work at a startup after working at two big companies and I also wanted to work at a company that had some social impact to it. So I got into Venture for America, and then the job hunt phase started There are over 400 startups you can join, and I was connected to Operation Stark through them Operation Spark is really the reason I joined Venture for America it checked all the boxes, it was CS and education, and allowed me to teach in a non-traditional teaching environment. What do you enjoy most about working in a social good tech startup I see education as a way to take my skills and apply them for good. The thing that really turned me off about my internships at the travel site and larger tech company was the fact that I wondered, well definitely at the former, why am I building this website for people to find vacations I think its great, and its a great website, and the company itself is amazing, but I felt totally disconnected from what I was doing. At the large tech company it was even worse. I was building this ad search engine, it just felt very disconnected from what I am interested in Education is definitely something I want to continue being a part of. Working with kids is really fulfilling. Schools here in New Orleans dont have computer science programs. Its really cool to provide opportunities for these kids, and seeing them get excited about it is really cool. Being able to build relationships with them is really rewarding. What is your advice for students at Brown interested in pursuing a career in the tech for social good space My advice would be to take time to look for whats out there because there are tons of opportunities for people. Part of what everyone knows from going into computer science is that it is a highly sought after, highly marketable skill. Yes, you can make a huge amount of money going to one of these enormous companies, but there are also tons of companies out there that are trying to to use software to make a social impact. You just have to find them. You probably wont end up making six figures in your initial job, but 99 of people arent going to be doing that anyway. I think theres a little bit of adjusting your expectations that needs to happen... I think if you are really driven to make social change there are a lot of opportunities, and yes you have to look for them, and you may have to make certain sacrifices, but its not really a sacrifice if you dont view it as a sacrifice. You just have to change your perspective on what is expected, particularly at Brown, which is a very elite place. People here have high expectations, people are driven by prestige and I think it kind of corrupts what you view as normal. Brown is a place where normal is working at a top 5 bank, consulting firm or tech company, and I think thats great, but I also think you need to understand that that is not normal. The views and opinions expressed above are those of an individual, and do not necessarily state or reflect those of Brown University or Brown Universitys Department of Computer Science, nor does their publication here constitute an endorsement of them. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "Tech For Social Good Spotlight: Ben Spector '17"], "word_count": 1069, "token_count_estimate": 1198}}, "http://burlap.cs.brown.edu/tutorials/oomdp/p4.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building an OO-MDP Domain Tutorials Building an OO-MDP Domain Part 4 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Grid World OO-MDP Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Conclusion Weve now walked you through what an OO-MDP is and how to make your OO-MDP domains using our previous MDP Grid World example from our Building a Domain tutorial as a starting point. We also showed you how to make use of the OO-MDP visualization tools. All of the code from this tutorial is included below and as always can also be found in the burlapexamples repository. Final Code ExGridAgent.java import burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport burlap.mdp.core.state.UnknownKeyExceptionimport burlap.mdp.core.state.annotations.DeepCopyStateimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.CLASSAGENTimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VARXimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.VARYDeepCopyStatepublic class ExGridAgent implements ObjectInstance, MutableState public int xpublic int ypublic String name agentprivate final static ListObject keys Arrays.ObjectasListVARX, VARYpublic ExGridAgent public ExGridAgentint x, int y this.x xthis.y ypublic ExGridAgentint x, int y, String name this.x xthis.y ythis.name nameOverridepublic String className return CLASSAGENTOverridepublic String name return nameOverridepublic ObjectInstance copyWithNameString objectName return new ExGridAgentx, y, objectNameOverridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARXthis.x StateUtilities.stringOrNumbervalue.intValueelse ifvariableKey.equalsVARYthis.y StateUtilities.stringOrNumbervalue.intValueelsethrow new UnknownKeyExceptionvariableKeyreturn thisOverridepublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARXreturn xelse ifvariableKey.equalsVARYreturn ythrow new UnknownKeyExceptionvariableKeyOverridepublic ExGridAgent copy return new ExGridAgentx, y, nameOverridepublic String toString return StateUtilities.stateToStringthis ExGridLocation.java import burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.state.MutableStateimport burlap.mdp.core.state.StateUtilitiesimport java.util.Arraysimport java.util.Listimport static edu.brown.cs.burlap.tutorials.domain.oo.ExampleOOGridWorld.public class EXGridLocation extends ExGridAgentpublic int typeprivate final static ListObject keys Arrays.ObjectasListVARX, VARY, VARTYPEpublic EXGridLocation public EXGridLocationint x, int y, String name superx, y, namepublic EXGridLocationint x, int y, int type, String name superx, y, namethis.type typeOverridepublic ListObject variableKeys return keysOverridepublic Object getObject variableKey ifvariableKey.equalsVARTYPEreturn this.typereturn super.getvariableKeyOverridepublic MutableState setObject variableKey, Object value ifvariableKey.equalsVARTYPEthis.type StateUtilities.stringOrNumbervalue.intValueelsesuper.setvariableKey, valuereturn thisOverridepublic String className return CLASSLOCATIONOverridepublic ObjectInstance copyWithNameString objectName return new EXGridLocationx, y, type, objectNameOverridepublic EXGridLocation copy return new EXGridLocationx, y, type, name ExampleOOGridWorld.java import burlap.mdp.auxiliary.DomainGeneratorimport burlap.mdp.auxiliary.common.SinglePFTFimport burlap.mdp.core.StateTransitionProbimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.action.Actionimport burlap.mdp.core.action.UniversalActionTypeimport burlap.mdp.core.oo.OODomainimport burlap.mdp.core.oo.propositional.PropositionalFunctionimport burlap.mdp.core.oo.state.OOStateimport burlap.mdp.core.oo.state.ObjectInstanceimport burlap.mdp.core.oo.state.generic.GenericOOStateimport burlap.mdp.core.state.Stateimport burlap.mdp.singleagent.common.SingleGoalPFRFimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.FactoredModelimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.model.statemodel.FullStateModelimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.shell.visual.VisualExplorerimport burlap.visualizer.import java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ExampleOOGridWorld implements DomainGeneratorpublic static final String VARX xpublic static final String VARY ypublic static final String VARTYPE typepublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION locationpublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westpublic static final String PFAT atordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,public ListPropositionalFunction generatePfsreturn Arrays.PropositionalFunctionasListnew AtLocationOverridepublic OOSADomain generateDomain OOSADomain domain new OOSADomaindomain.addStateClassCLASSAGENT, ExGridAgent.class.addStateClassCLASSLOCATION, EXGridLocation.classdomain.addActionTypesnew UniversalActionTypeACTIONNORTH,new UniversalActionTypeACTIONSOUTH,new UniversalActionTypeACTIONEAST,new UniversalActionTypeACTIONWESTOODomain.Helper.addPfsToDomaindomain, this.generatePfsOOGridWorldStateModel smodel new OOGridWorldStateModelRewardFunction rf new SingleGoalPFRFdomain.propFunctionPFAT, 100, -1TerminalFunction tf new SinglePFTFdomain.propFunctionPFATdomain.setModelnew FactoredModelsmodel, rf, tfreturn domainprotected class OOGridWorldStateModel implements FullStateModel protected double transitionProbspublic OOGridWorldStateModel this.transitionProbs new double44forint i 0 i 4 iforint j 0 j 4 jdouble p i j 0.23 0.8transitionProbsij ppublic ListStateTransitionProb stateTransitionsState s, Action a get agent current positionGenericOOState gs GenericOOStatesExGridAgent agent ExGridAgentgs.objectCLASSAGENTint curX agent.xint curY agent.yint adir actionDiraListStateTransitionProb tps new ArrayListStateTransitionProb4StateTransitionProb noChange nullforint i 0 i 4 iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeGenericOOState ns gs.copyExGridAgent nagent ExGridAgentns.touchCLASSAGENTnagent.x newPos0nagent.y newPos1create transition probability object and add to our list of outcomestps.addnew StateTransitionProbns, this.transitionProbsadirielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChange nullnoChange.p this.transitionProbsadirielseotherwise create this new state and transitionnoChange new StateTransitionProbs.copy, this.transitionProbsadiritps.addnoChangereturn tpspublic State sampleState s, Action a s s.copyGenericOOState gs GenericOOStatesExGridAgent agent ExGridAgentgs.touchCLASSAGENTint curX agent.xint curY agent.yint adir actionDirasample direction with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i 4 isumProb this.transitionProbsadiriifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.x newPos0agent.y newPos1return the state we just modifiedreturn gsprotected int actionDirAction aint adir -1ifa.actionName.equalsACTIONNORTHadir 0else ifa.actionName.equalsACTIONSOUTHadir 1else ifa.actionName.equalsACTIONEASTadir 2else ifa.actionName.equalsACTIONWESTadir 3return adirprotected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleOOGridWorld.this.map.lengthint height ExampleOOGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleOOGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,nypublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayerpublic StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStatePainternew ExampleOOGridWorld.WallPainterOOStatePainter ooStatePainter new OOStatePainterooStatePainter.addObjectClassPainterCLASSLOCATION, new LocationPainterooStatePainter.addObjectClassPainterCLASSAGENT, new AgentPainterrl.addStatePainterooStatePainterreturn rlprotected class AtLocation extends PropositionalFunction public AtLocationsuperPFAT, new String CLASSAGENT, CLASSLOCATIONOverridepublic boolean isTrueOOState s, String... params ObjectInstance agent s.objectparams0ObjectInstance location s.objectparams1int ax Integeragent.getVARXint ay Integeragent.getVARYint lx Integerlocation.getVARXint ly Integerlocation.getVARYreturn ax lx ay lypublic class WallPainter implements StatePainter public void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cellon our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on ourcavas of dimension widthxheightforint i 0 i ExampleOOGridWorld.this.map.length iforint j 0 j ExampleOOGridWorld.this.map0.length jis there a wall hereifExampleOOGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements ObjectPainter Overridepublic void paintObjectGraphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integerob.getVARXint ay Integerob.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, heightpublic class LocationPainter implements ObjectPainter Overridepublic void paintObjectGraphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integerob.getVARXint ay Integerob.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic static void mainString argsExampleOOGridWorld gen new ExampleOOGridWorldOOSADomain domain gen.generateDomainState initialState new GenericOOStatenew ExGridAgent0, 0, new EXGridLocation10, 10, loc0SimulatedEnvironment env new SimulatedEnvironmentdomain, initialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTH, exp.addKeyActions, ACTIONSOUTH, exp.addKeyActiond, ACTIONEAST, exp.addKeyActiona, ACTIONWEST, exp.initGUI End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building an OO-MDP Domain", ">", "> Part 4"], "word_count": 1113, "token_count_estimate": 3074}}, "http://burlap.cs.brown.edu/tutorials/oomdp/p3.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building an OO-MDP Domain Tutorials Building an OO-MDP Domain Part 3 Tutorial Contents Introduction Markov Decision Process Java Interfaces for MDP Definitions Defining a Grid World State Grid World OO-MDP Model Creating a State Visualizer Testing it Out Conclusion Final Code Previous Part Next Part Grid World OO-MDP Model Lets now implement our OO-MDP grid world model. Once again, we will basically have the same FactoredModel implementation for state transitions that we implemented in the Building a Domain tutorial, except with slight modifications to work with state that is a GenericOOState . Add the following code to your ExampleOOGridWorld class. protected class OOGridWorldStateModel implements FullStateModel protected double transitionProbspublic OOGridWorldStateModel this.transitionProbs new double44forint i 0 i 4 iforint j 0 j 4 jdouble p i j 0.23 0.8transitionProbsij ppublic ListStateTransitionProb stateTransitionsState s, Action a get agent current positionGenericOOState gs GenericOOStatesExGridAgent agent ExGridAgentgs.objectCLASSAGENTint curX agent.xint curY agent.yint adir actionDiraListStateTransitionProb tps new ArrayListStateTransitionProb4StateTransitionProb noChange nullforint i 0 i 4 iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeGenericOOState ns gs.copyExGridAgent nagent ExGridAgentns.touchCLASSAGENTnagent.x newPos0nagent.y newPos1create transition probability object and add to our list of outcomestps.addnew StateTransitionProbns, this.transitionProbsadirielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChange nullnoChange.p this.transitionProbsadirielseotherwise create this new state and transitionnoChange new StateTransitionProbs.copy, this.transitionProbsadiritps.addnoChangereturn tpspublic State sampleState s, Action a s s.copyGenericOOState gs GenericOOStatesExGridAgent agent ExGridAgentgs.touchCLASSAGENTint curX agent.xint curY agent.yint adir actionDirasample direction with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i 4 isumProb this.transitionProbsadiriifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.x newPos0agent.y newPos1return the state we just modifiedreturn gsprotected int actionDirAction aint adir -1ifa.actionName.equalsACTIONNORTHadir 0else ifa.actionName.equalsACTIONSOUTHadir 1else ifa.actionName.equalsACTIONEASTadir 2else ifa.actionName.equalsACTIONWESTadir 3return adirprotected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleOOGridWorld.this.map.lengthint height ExampleOOGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleOOGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,ny The first main difference form our Building a Domain tutorial implementation to note is that we cast our state to a GenericOOState . Then, to get the agent x and y, we pull out the ExGridAgent object. We assume that our agent objects always have the same name as the agent class defined by the CLASSAGENT constant. When we make a copy of states and modify the x and y value of the agent, note that we get the agent object through the touch method, which is a special method defined for GenericOOState. Recall that GenericOOState uses shallow copying whenever a copy is made, the new state contains the same references to the ObjectInstances Java objects as the ancestor state that is, the ObjectInstances are not copied themselves thereby saving on memory overhead. The touch method returns the object with the given name, but first causes the state to changes its reference to a copy of that ObjectInstance. As a result, any changes to an ObjectInsance returned by the touch method will not contaminate the values of the object in the previous state from which the new state was copied. Lets now implement our generateDomain method. Overridepublic OOSADomain generateDomain OOSADomain domain new OOSADomaindomain.addStateClassCLASSAGENT, ExGridAgent.class.addStateClassCLASSLOCATION, EXGridLocation.classdomain.addActionTypesnew UniversalActionTypeACTIONNORTH,new UniversalActionTypeACTIONSOUTH,new UniversalActionTypeACTIONEAST,new UniversalActionTypeACTIONWESTOODomain.Helper.addPfsToDomaindomain, this.generatePfsOOGridWorldStateModel smodel new OOGridWorldStateModelRewardFunction rf this.rfTerminalFunction tf this.tfifrf nullrf new SingleGoalPFRFdomain.propFunctionPFAT, 100, -1iftf nulltf new SinglePFTFdomain.propFunctionPFATdomain.setModelnew FactoredModelsmodel, rf, tfreturn domain First note that unlike the Building a Domain tutorial, we have our domain be an instance of OOSADomain. One of the pieces of information an OOSADomain tracks is a mapping from the name of an OO-MDP class to the Java class that defines it, so in this case we set the map from the CLASSAGENT string constant to our ExGridAgent class, and the CLASSLOCATION constant to the EXGridLocation class. We also add to our OOSADomain the propositional function that we created. We also construct the reward function and terminal function, differently than we did in the Building a Domain tutorial. Rather than have a custom reward function and terminal function, we make use of our propositional function. The SingleGoalPFRF reward function provided with BURLAP takes as input a propositional function, a goal reward, and default reward. It returns the goal reward whenever any parameter assignment satisfies the propositional function in the state to which the agent transitions and otherwise returns the default reward. The SinglePFTF function takes a propositional function and similarly classifies terminal states as any state for which there exists a parameter assignment that causes the propositional function to be true. Since weve provided these objects our at propositional function, it means a goal terminal state is any state in which an agent is at a location. OO-MDP Visualization To visualize states of an OO-MDP, we could implement state StatePainter instances, just like we did for a regular MDP. However, BURLAP also provides some additional tools for rendering OO-MDP states. Specifically, BURLAP provides an OOStatePainter that takes as input a set of ObjectPainters that are tasked with painting objects from the OO-MDP state, allowing you to define a different painter for different object classes. To demonstrate, lets implement visualization of our domain by creating a wall painter, just like the one in the previous domain, and then an ObjectPainter for the agent class and an ObjectPainter for the location class. public class WallPainter implements StatePainter public void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cellon our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on ourcavas of dimension widthxheightforint i 0 i ExampleOOGridWorld.this.map.length iforint j 0 j ExampleOOGridWorld.this.map0.length jis there a wall hereifExampleOOGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements ObjectPainter Overridepublic void paintObjectGraphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integerob.getVARXint ay Integerob.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, heightpublic class LocationPainter implements ObjectPainter Overridepublic void paintObjectGraphics2D g2, OOState s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleOOGridWorld.this.map.lengthfloat fHeight ExampleOOGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax Integerob.getVARXint ay Integerob.getVARYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, height Note that the ObjectPainter paintObject method not only receives the OOState for which painting should be performed, but the specific ObjectInstance from that state it is being asked to paint. For the AgentPainter, we will draw a gray circle, just like we did in the Building a Domain tutorial for the ExGridState. For the location painter, well do something similar, but instead paint a blue rectangle wherever the input location object is positioned. Lets now add methods to package up a Visualizer for our domain. public Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayerpublic StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStatePainternew ExampleOOGridWorld.WallPainterOOStatePainter ooStatePainter new OOStatePainterooStatePainter.addObjectClassPainterCLASSLOCATION, new LocationPainterooStatePainter.addObjectClassPainterCLASSAGENT, new AgentPainterrl.addStatePainterooStatePainterreturn rl Note that this time we created a OOStatePainter and assigned it a LocationPainter instance for painting objects of class CLASSLOCATION, and an AgentPainter for objects of class CLASSAGENT. We provided it the location painter first, because the OOStatePainter will paint objects in the order that the ObjectPainters are provided to it. By having locations painted before the agent, it will cause the agent to be painted on top of the blue rectangle when the agent enters the same cell as the location. Testing it Out Lets now write some code to test our OO-MDP grid world out by adding a main method. public static void mainString argsExampleOOGridWorld gen new ExampleOOGridWorldOOSADomain domain gen.generateDomainState initialState new GenericOOStatenew ExGridAgent0, 0, new EXGridLocation10, 10, loc0SimulatedEnvironment env new SimulatedEnvironmentdomain, initialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTH, exp.addKeyActions, ACTIONSOUTH, exp.addKeyActiond, ACTIONEAST, exp.addKeyActiona, ACTIONWEST, exp.initGUI This main method looks pretty similar to the one in the Building a Domain tutorial, but this time our state is a GenericOOState and we construct it with an ExGridAgent object, started in position 0,0, and a single ExGridLocation object named loc0 and positioned at 10,10. If you now run the main method, you should get a visual explorer that shows the agent and the location of our location object, just like in the image below. Figure A VisualExplorer for our OO-MDP Grid World. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building an OO-MDP Domain", ">", "> Part 3"], "word_count": 1582, "token_count_estimate": 2710}}, "http://burlap.cs.brown.edu/tutorials/scd/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 3 if youd like the BURLAP 2 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planninglearning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means youre unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being able to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen near by states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end, or you can get it from the burlapexamples respoistory. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in a valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration LSPI. LSPI requires a collection of state-action-reward-state SARS transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data and therefore how it is collected is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values this change in policy is known as policy improvement . This process repeats until the approximate Q-value function and consequently the policy stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. Well begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static methods that demonstrates solving each domain and algorithm in this tutorial, so well start with our method for solving Mountain Car with LSPI using Fourier basis functions MCLSPIFB. As usual, weve preemptively included all imports that youll use in the rest of this tutorial. import burlap.behavior.functionapproximation.DifferentiableStateActionValueimport burlap.behavior.functionapproximation.dense.ConcatenatedObjectFeaturesimport burlap.behavior.functionapproximation.dense.DenseCrossProductFeaturesimport burlap.behavior.functionapproximation.dense.NormalizedVariableFeaturesimport burlap.behavior.functionapproximation.dense.NumericVariableFeaturesimport burlap.behavior.functionapproximation.dense.fourier.FourierBasisimport burlap.behavior.functionapproximation.dense.rbf.DistanceMetricimport burlap.behavior.functionapproximation.dense.rbf.RBFFeaturesimport burlap.behavior.functionapproximation.dense.rbf.functions.GaussianRBFimport burlap.behavior.functionapproximation.dense.rbf.metrics.EuclideanDistanceimport burlap.behavior.functionapproximation.sparse.tilecoding.TileCodingFeaturesimport burlap.behavior.functionapproximation.sparse.tilecoding.TilingArrangementimport burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.gridset.FlatStateGridderimport burlap.behavior.singleagent.learning.lspi.LSPIimport burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLamimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.domain.singleagent.cartpole.CartPoleVisualizerimport burlap.domain.singleagent.cartpole.InvertedPendulumimport burlap.domain.singleagent.cartpole.states.InvertedPendulumStateimport burlap.domain.singleagent.lunarlander.LLVisualizerimport burlap.domain.singleagent.lunarlander.LunarLanderDomainimport burlap.domain.singleagent.lunarlander.state.LLAgentimport burlap.domain.singleagent.lunarlander.state.LLBlockimport burlap.domain.singleagent.lunarlander.state.LLStateimport burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.domain.singleagent.mountaincar.MCStateimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.mdp.auxiliary.StateGeneratorimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.state.Stateimport burlap.mdp.core.state.vardomain.VariableDomainimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.common.VisualActionObserverimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ContinuousDomainTutorial public static void mainString argsMCLSPIFBpublic static void MCLSPIFBwell fill this in in a moment... Next well create an instance of the Mountain car domain and Well use the standard reward function, physics, and termination conditions, so we dont need to adjust any parameters. These return a reward of 100 when reaching the top of the mountain on the right side and zero everywhere else. MountainCar mcGen new MountainCarSADomain domain mcGen.generateDomain Other Mountain Car Parameters We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code for that now. StateGenerator rStateGen new MCRandomStateGeneratormcGen.physParamsSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, domain.getModel, 5000, 20, null The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, weve told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This process of generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results and return it rather than adding to an existing SARSData instance. LSPI as a LearningAgent In this case were opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm it does implement the LearningAgent interface in which it starts with no data, acts in the world from whatever the worlds current state is and reruns LSPI as it experiences more transitions thereby improving the policy that it follows. However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider subclassing and overriding LSPIs runLearningEpisode method to use an approach that is a better fit for your domain. To learn more about how LSPIs default runLearningEpisode method is used, see the classs documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a state variable vector, where each element is a normalized scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the DenseStateFeatures interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions which grow exponentially with the dimension of input state feature vector and the more fine grained the representation becomes, allowing for a more precise linear value function approximation. Fourier basis features will ultimately give us a dense vectorized representation of states, but to construct them we will first need to turn our state objects into a normalized numeric vector of state variables. We can construct that using some standard BURLAP tools NormalizedVariableFeatures inputFeatures new NormalizedVariableFeatures.variableDomainx, new VariableDomainmcGen.physParams.xmin, mcGen.physParams.xmax.variableDomainv, new VariableDomainmcGen.physParams.vmin, mcGen.physParams.vmax NormalizedVariableFeatures is an implementation of DenseStateFeatures, which provides a method to take an input State object and turn it into a double array. To construct it, it needs to be told which variable keys to use and what the numeric variable domain of that variable is. The double array output for states is then a array equal to the number of variables we specified with the normalized value according to the variable domain we gave it. Here, were telling it to use the x and v variable keys from mountain car specifying the x position and velocity of the car and we gave it the variable domain by the values in our mountain car physics parameters. With a method of producing a normalized state variable vector, we can now construct our Fourier basis features, using the FourierBasis class, an implementation of DenseStateFeatures itself. FourierBasis fb new FourierBasisinputFeatures, 4 In particular, we opted to use 4th order Fourier basis features, which is what the second parameter specifies. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions tell it to use a 0.99 discount factor set its SARS dataset to the datasetwe collected and run LSPI until the weight values of its fitted linear function change no more than 10-6 between iterations or until 30 iterationshave passed. LSPI lspi new LSPIdomain, 0.99, new DenseCrossProductFeaturesfb, 3, datasetPolicy p lspi.runPolicyIteration30, 1e-6 One thing to note is that we gave LSPI DenseCrossProductFeatures on our constructed FourierBassis object. Note that FourierBasis features are just a mapping from states to features. But to actual learn a control mechanism, LSPI needs state-action features that is, separate features for each action so that the value of actions can be modeled, from which a policy can be constructed. It is not uncommon in RL to first define a state feature representation, and then construct state-action features by taking the cross product of those features with each action. That is precisely what the DenseCrossProductFeatures will do it takes as input the state features and creates a cross product of them with the actions actions. The 3 argument we provided it tells it how many actions there are. After LSPI has run until convergence, we will want to analyze the policy is produced. To analyze the resulting policy, we could roll it out and load an EpisodeSequenceVisualizer, as we have in prior tutorials. But for fun, lets watch it in real time. To visualize the animated results, we can simply grab the existing visualizer from the domain MountainCarVisualizer , create a SimulatedEnvironment in which to evaluate the policy, and add a VisualActionObserver to the to the environment. Note that we can add an EnvironmentObserver to a SimulatedEnvironment, because it implements the EnvironmentServerInterface otherwise we could use an EnvironmentServer wrapper for Environment instances that do not implement the observer interface. Specifically, well let it run for five policy rollouts. Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObservervvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, new MCStatemcGen.physParams.valleyPos, 0.env.addObserversvobforint i 0 i 5 iPolicyUtils.rolloutp, envenv.resetEnvironmentSystem.out.printlnFinished We also set the initial state of the environment to start in the bottom of the valley. We can get the x position value for the bottom of the valley, but calling the valleyPos method on mountain car physics parameters object we also set the initial velocity to zero. If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and youll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible even if unlikely that the car wont make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code resulting in a a new random data collection, you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features specifically, lets consider using radial basis functions. A radial basis function is defined with a center state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the functions center state. As the query state gets further away, the basis functions returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter as the bandwidth value increases, the less sensitive the function is to distance that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away. A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, well define radial basis functions. For the moment, the code below will create an instance of a radial basis features RBFFeatures , but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. public static void MCLSPIRBFMountainCar mcGen new MountainCarSADomain domain mcGen.generateDomainMCState s new MCStatemcGen.physParams.valleyPos, 0.NormalizedVariableFeatures inputFeatures new NormalizedVariableFeatures.variableDomainx, new VariableDomainmcGen.physParams.xmin, mcGen.physParams.xmax.variableDomainv, new VariableDomainmcGen.physParams.vmin, mcGen.physParams.vmaxStateGenerator rStateGen new MCRandomStateGeneratormcGen.physParamsSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, domain.getModel, 5000, 20, nullRBFFeatures rbf new RBFFeaturesinputFeatures, truewe will add rbfs nextLSPI lspi new LSPIdomain, 0.99, new DenseCrossProductFeaturesrbf, 3, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObservervvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, senv.addObserversvobforint i 0 i 5 iPolicyUtils.rolloutp, envenv.resetEnvironmentSystem.out.printlnFinished Youll notice that we passed true to our RBFeatures constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This provides a Q-value y intercept value to the linear function that will be estimated. This is often not necessary, but it doesnt hurt. Since RBF features compute distances between states, it too will operate on a numeric vector of state variables. Here weve opted to use our NormalizedVariableFeatures class to provide that since we dont want different domain sizes of the variables to affect the state distance calculation. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the FlatStateGridder class in BURLAP. FlatStateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. FlatStateGridder can even do things like include constant values for some variables. There is also an OOStateGridder for gridding OO-MDP states. For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To use StateGridder, it does require that the State objects implement MutableState, which our mountain car states do as do the states for just about all standard BURLAP domains. To get the set of states that span a 5x5 grid over the car position and velocity attributes for a total of 25 states, add the below code right below the instantiation of the RBFFeatures. If you want to know how to set up a more specific grid e.g., an asymmetric grid like a 3x7, see the classs documentation FlatStateGridder gridder new FlatStateGridder.gridDimensionx, mcGen.physParams.xmin, mcGen.physParams.xmax, 5.gridDimensionv, mcGen.physParams.vmin, mcGen.physParams.vmax, 5ListState griddedStates gridder.gridStates Notice that the gridInputState method requires an example State object An example state is required because it tells the gridder 1 what the input State Java class is and 2 only will grid over the values you specified with calls to gridDimension, leaving any other variables in the input state left unchanged in the gridded states. Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Specifically, well use Gaussian RBFs with a 0.2 bandwidth parameter and a Euclidean distance metric BURLAP has implementation for both these. However, to define the center point of these states, well need to convert the state into its numeric state vector representation, which we provided by passing each of our Gridded states through the NormalizedVariableFeatures object we constructed. DistanceMetric metric new EuclideanDistanceforState g griddedStatesrbf.addRBFnew GaussianRBFinputFeatures.featuresg, metric, 0.2 Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBFMountainCar mcGen new MountainCarSADomain domain mcGen.generateDomainMCState s new MCStatemcGen.physParams.valleyPos, 0.NormalizedVariableFeatures inputFeatures new NormalizedVariableFeatures.variableDomainx, new VariableDomainmcGen.physParams.xmin, mcGen.physParams.xmax.variableDomainv, new VariableDomainmcGen.physParams.vmin, mcGen.physParams.vmaxStateGenerator rStateGen new MCRandomStateGeneratormcGen.physParamsSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, domain.getModel, 5000, 20, nullRBFFeatures rbf new RBFFeaturesinputFeatures, trueFlatStateGridder gridder new FlatStateGridder.gridDimensionx, mcGen.physParams.xmin, mcGen.physParams.xmax, 5.gridDimensionv, mcGen.physParams.vmin, mcGen.physParams.vmax, 5ListState griddedStates gridder.gridStatesDistanceMetric metric new EuclideanDistanceforState g griddedStatesrbf.addRBFnew GaussianRBFinputFeatures.featuresg, metric, 0.2LSPI lspi new LSPIdomain, 0.99, new DenseCrossProductFeaturesrbf, 3, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObservervvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, senv.addObserversvobforint i 0 i 5 iPolicyUtils.rolloutp, envenv.resetEnvironmentSystem.out.printlnFinished If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time weve used radial basis functions Now that weve demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, well move on to a different algorithm Sparse Sampling and a different domain the Inverted Pendulum. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 1", "Other Mountain Car Parameters", "LSPI as a LearningAgent"], "word_count": 3261, "token_count_estimate": 5200}}, "http://burlap.cs.brown.edu/tutorials/scd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem for other variants, see the CartPoleDomain and its parameters, but in this example well be using one of the more simple forms. The problem is as follows a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole the inverted pendulum and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling more on that in a moment. Let us start by making a method IPSS for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. public static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.RewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.ip.setRfrfip.setTftfSADomain domain ip.generateDomainState initialState new InvertedPendulumState Here were using a non-default configuration for demonstration purposes. The line ip.physParams.actionNoise 0. sets our domain to have no noise in the actions. physParams is a data member containing all physics parameters that you can modify. We also set the reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than 8 radians. Specifically, the agent will receive zero reward everywhere except when the poles angle is greater than 8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm were going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every new state encountered in the real world, planning needs to happen all over again unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces. Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. SparseSampling ss new SparseSamplingdomain, 1, new SimpleHashableStateFactory, 10, 1ss.setForgetPreviousPlanResultstruess.toggleDebugPrintingfalsePolicy p new GreedyQPolicyss Note that were using a discount factor of 1 because we are computing the Q-values for a finite horizon rather than computing an infinite horizon and a discount factor of 1 with a finite horizon will always result in finite Q-values. The method call setForgetPreviousPlanResultstrue tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we dont expect to see the same state twice, this is useful to free up memory that we dont expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed. The final thing youll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first unless we had let it remember past planning results and it was the same state as a state for which its planned before. At this point, were basically done. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode with a maximum of 500 steps and then visualize the episode using an EpisodeSequnceVisualizer like weve used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. Episode e PolicyUtils.rolloutp, initialState, domain.getModel, 500System.out.printlnNum steps e.maxTimeStepVisualizer v CartPoleVisualizer.getCartPoleVisualizernew EpisodeSequenceVisualizerv, domain, Arrays.asListe If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. Were now finished with the Sparse Sampling example If youre looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class. In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 2"], "word_count": 1186, "token_count_estimate": 1533}}, "http://burlap.cs.brown.edu/tutorials/scd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving Lunar Lander with SARSA In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and Tile coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example LLSARSA and instantiating a Lunar Lander domain , task, and initial state. public static void LLSARSALunarLanderDomain lld new LunarLanderDomainOOSADomain domain lld.generateDomainLLState s new LLStatenew LLAgent5, 0, 0, new LLBlock.LLPad75, 95, 0, 10, pad Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain but you can change various properties such as the force of gravity, thrust, etc.. The default reward function returns 1000 for landing, -100 for collisions, and -1 for regular transitions you can also change the reward function for the domain in the usual ways. The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The initial state sets the agent at location 5, 0, with facing up, and with zero velocity the 0 velocity is implict with the 3 argument constructor and sets a goal landing pad rectange spanning 75-90 along the x dimension and 0-10 along the y dimension. This will create an initial state that looks like the below as visualized in BURLAP. The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. Were going to solve this problem with gradient descent SARSA , which is a learning algorithm that behaves much like conventional tabular SARSA discussed in previous tutorials, except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA does not need to use a linear approximator however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA. However, this time well use a different basis function Tile coding. Tile coding creates a set of features by generating multiple tilings over the state space. Each tile represents a features and that feature is on if the state falls within that tile. Tile coding in detail Tile coding address learning in continuous domains in an only slightly more complex way than merely discretizing the state space, yet also diminishes the aliasing effects that discretization can incur. To describe how it works, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. Well let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile. The larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. Tile coding diminishes this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 one for each active tile in each tiling. Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on tile coding with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using tile coding is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation. Morever, when computing the value for a given input state, you only need to add the weights for the active tiles and can ignore all other tiles that is, tile coding can be represented sparsely. Lets continue our code implementation by instantiating a TileCodingFeatures object and implementation of SparseStateFeatures and define the tiling of our state space. To implement tile coding basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each variable. In this case, we will use 5 tilings with a width for each variable that produces 10 tiles along each variable range. We will limit this tiling to the Lunar Lander ship variables values and ignore variables for the landing pad. Since the agents ship is defined by 5 variables x position, y position, x velocity, y velocity, and rotation angle from the vertical axis, this will produce 5 tilings that each define at most 105 tiles since tiling coding can be represtently sparsely though, we dont necessarily have to store weights for all tiles if the agent never visits them To do so, add the below code. ConcatenatedObjectFeatures inputFeatures new ConcatenatedObjectFeatures.addObjectVectorizionLunarLanderDomain.CLASSAGENT, new NumericVariableFeaturesint nTilings 5double resolution 10.double xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutiondouble angleWidth 2 lld.getAngmax resolutionTileCodingFeatures tilecoding new TileCodingFeaturesinputFeaturestilecoding.addTilingsForAllDimensionsWithWidthsnew double xWidth, yWidth, velocityWidth, velocityWidth, angleWidth,nTilings,TilingArrangement.RANDOMJITTER To specify our tilings on the state variables, we will first want to convert our states into a variable vector. Lunar lander states are OO-MDP representations, so to vectorize the state, we use the ConcatenatedObjectFeatures class. This class lets us specify a variable vectorization for certain object classes, and then produce a state variable vector by concatenating the vectors for each object of those classes. In this case, we set it to create a state vector consisting of just the agent object class, and the agent object class is vectorized by assuming each of its variables are numeric and filling them out into an array functionality provided by the NumericVariableFeatures class, a DesneStateFeatures implementation. Next we create some local variable for specifying our tiling configuration. We choose to 5 tilings and we set the resolution to be 10 which is how many tiles will span a variable dimension. Then, we set the width of the tiles along each dimension by dividing the range of the variable by our resolution. Our LunarLanderDomain object has methods for getting these variable range values. Finally, we instantiate our TileCodingFeatures, an implementation of SparseStateFeatures, which means it provides a method that will return a list of of any non-zero state features for a given state input. We give it the state vectorization were using for states, and provide it tile widths along each of those dimensions, tell it to create 5 tilings along that space, and that those 5 tilings should be randomly offset from each other. If you wanted, you could also add additional tilings that operated on different sets of state variables--an advanced functionality of tile coding. Now that we have the TileCodingFeatures set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA. double defaultQ 0.5DifferentiableStateActionValue vfa tilecoding.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, 0.99, vfa, 0.02, 0.5 SARSA lambda, like LSPI, requires state-action features, and TileCoding only provides state features. However, by default the generateVFA method of TileCoding will produce a function approximator that will cross product its features with the actions, if it is used for state-action value function approximation it also implements DifferentiableStateValue to provide state value function approximation. Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value 0.5 by the number of tilings 5, because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.55, the linear estimate will predict our desired initial Q-value 0.5. We also set the learning rate for gradient descent SARSA to 0.02 in general, you should decrease the learning rate as the number of features increases, and set to 0.5. With gradient descent SARSA instantiated, we can run learning episodes wtih an Environment just like we do for typical SARSA. Lets create a SimulatedEnvironment, run learning for 5000 episodes, and then visualize the results with an EpisodeSequenceVisualizer. SimulatedEnvironment env new SimulatedEnvironmentdomain, sList episodes new ArrayList forint i 0 i 5000 iEpisode ea agent.runLearningEpisodeenvepisodes.addeaSystem.out.printlni ea.maxTimeStepenv.resetEnvironmentVisualizer v LLVisualizer.getVisualizerlld.getPhysParamsnew EpisodeSequenceVisualizerv, domain, episodes If you now point your main method to LLSARSA and run it, you should initially see a bunch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizerGUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial Closing remarks and the full code we created can be found on the next page. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 3", "Tile coding in detail"], "word_count": 1882, "token_count_estimate": 2515}}, "http://burlap.cs.brown.edu/tutorials/scd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP LSPI, Sparse Sampling, and gradient descent SARSA. We also demonstrated how to use these algorithms on three different continuous state domains Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions which can be used with LSPI and gradient descent SARSA Fourier basis functions, radial basis functions and Tile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below or in the burlapexamples repository. Final Code import burlap.behavior.functionapproximation.DifferentiableStateActionValueimport burlap.behavior.functionapproximation.dense.ConcatenatedObjectFeaturesimport burlap.behavior.functionapproximation.dense.DenseCrossProductFeaturesimport burlap.behavior.functionapproximation.dense.NormalizedVariableFeaturesimport burlap.behavior.functionapproximation.dense.NumericVariableFeaturesimport burlap.behavior.functionapproximation.dense.fourier.FourierBasisimport burlap.behavior.functionapproximation.dense.rbf.DistanceMetricimport burlap.behavior.functionapproximation.dense.rbf.RBFFeaturesimport burlap.behavior.functionapproximation.dense.rbf.functions.GaussianRBFimport burlap.behavior.functionapproximation.dense.rbf.metrics.EuclideanDistanceimport burlap.behavior.functionapproximation.sparse.tilecoding.TileCodingFeaturesimport burlap.behavior.functionapproximation.sparse.tilecoding.TilingArrangementimport burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.policy.PolicyUtilsimport burlap.behavior.singleagent.Episodeimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.gridset.FlatStateGridderimport burlap.behavior.singleagent.learning.lspi.LSPIimport burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLamimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.domain.singleagent.cartpole.CartPoleVisualizerimport burlap.domain.singleagent.cartpole.InvertedPendulumimport burlap.domain.singleagent.cartpole.states.InvertedPendulumStateimport burlap.domain.singleagent.lunarlander.LLVisualizerimport burlap.domain.singleagent.lunarlander.LunarLanderDomainimport burlap.domain.singleagent.lunarlander.state.LLAgentimport burlap.domain.singleagent.lunarlander.state.LLBlockimport burlap.domain.singleagent.lunarlander.state.LLStateimport burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.domain.singleagent.mountaincar.MCStateimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.mdp.auxiliary.StateGeneratorimport burlap.mdp.core.TerminalFunctionimport burlap.mdp.core.state.Stateimport burlap.mdp.core.state.vardomain.VariableDomainimport burlap.mdp.singleagent.SADomainimport burlap.mdp.singleagent.common.VisualActionObserverimport burlap.mdp.singleagent.environment.SimulatedEnvironmentimport burlap.mdp.singleagent.model.RewardFunctionimport burlap.mdp.singleagent.oo.OOSADomainimport burlap.statehashing.simple.SimpleHashableStateFactoryimport burlap.visualizer.Visualizerimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ContinuousDomainTutorial private ContinuousDomainTutorial do nothingpublic static void MCLSPIFBMountainCar mcGen new MountainCarSADomain domain mcGen.generateDomainStateGenerator rStateGen new MCRandomStateGeneratormcGen.physParamsSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, domain.getModel, 5000, 20, nullNormalizedVariableFeatures inputFeatures new NormalizedVariableFeatures.variableDomainx, new VariableDomainmcGen.physParams.xmin, mcGen.physParams.xmax.variableDomainv, new VariableDomainmcGen.physParams.vmin, mcGen.physParams.vmaxFourierBasis fb new FourierBasisinputFeatures, 4LSPI lspi new LSPIdomain, 0.99, new DenseCrossProductFeaturesfb, 3, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObservervvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, new MCStatemcGen.physParams.valleyPos, 0.env.addObserversvobforint i 0 i 5 iPolicyUtils.rolloutp, envenv.resetEnvironmentSystem.out.printlnFinishedpublic static void MCLSPIRBFMountainCar mcGen new MountainCarSADomain domain mcGen.generateDomainMCState s new MCStatemcGen.physParams.valleyPos, 0.NormalizedVariableFeatures inputFeatures new NormalizedVariableFeatures.variableDomainx, new VariableDomainmcGen.physParams.xmin, mcGen.physParams.xmax.variableDomainv, new VariableDomainmcGen.physParams.vmin, mcGen.physParams.vmaxStateGenerator rStateGen new MCRandomStateGeneratormcGen.physParamsSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, domain.getModel, 5000, 20, nullRBFFeatures rbf new RBFFeaturesinputFeatures, trueFlatStateGridder gridder new FlatStateGridder.gridDimensionx, mcGen.physParams.xmin, mcGen.physParams.xmax, 5.gridDimensionv, mcGen.physParams.vmin, mcGen.physParams.vmax, 5ListState griddedStates gridder.gridStatesDistanceMetric metric new EuclideanDistanceforState g griddedStatesrbf.addRBFnew GaussianRBFinputFeatures.featuresg, metric, 0.2LSPI lspi new LSPIdomain, 0.99, new DenseCrossProductFeaturesrbf, 3, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObservervvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, senv.addObserversvobforint i 0 i 5 iPolicyUtils.rolloutp, envenv.resetEnvironmentSystem.out.printlnFinishedpublic static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.RewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.ip.setRfrfip.setTftfSADomain domain ip.generateDomainState initialState new InvertedPendulumStateSparseSampling ss new SparseSamplingdomain, 1, new SimpleHashableStateFactory, 10, 1ss.setForgetPreviousPlanResultstruess.toggleDebugPrintingfalsePolicy p new GreedyQPolicyssEpisode e PolicyUtils.rolloutp, initialState, domain.getModel, 500System.out.printlnNum steps e.maxTimeStepVisualizer v CartPoleVisualizer.getCartPoleVisualizernew EpisodeSequenceVisualizerv, domain, Arrays.asListepublic static void LLSARSALunarLanderDomain lld new LunarLanderDomainOOSADomain domain lld.generateDomainLLState s new LLStatenew LLAgent5, 0, 0, new LLBlock.LLPad75, 95, 0, 10, padConcatenatedObjectFeatures inputFeatures new ConcatenatedObjectFeatures.addObjectVectorizionLunarLanderDomain.CLASSAGENT, new NumericVariableFeaturesint nTilings 5double resolution 10.double xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutiondouble angleWidth 2 lld.getAngmax resolutionTileCodingFeatures tilecoding new TileCodingFeaturesinputFeaturestilecoding.addTilingsForAllDimensionsWithWidthsnew double xWidth, yWidth, velocityWidth, velocityWidth, angleWidth,nTilings,TilingArrangement.RANDOMJITTERdouble defaultQ 0.5DifferentiableStateActionValue vfa tilecoding.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, 0.99, vfa, 0.02, 0.5SimulatedEnvironment env new SimulatedEnvironmentdomain, sListEpisode episodes new ArrayListEpisodeforint i 0 i 5000 iEpisode ea agent.runLearningEpisodeenvepisodes.addeaSystem.out.printlni ea.maxTimeStepenv.resetEnvironmentVisualizer v LLVisualizer.getVisualizerlld.getPhysParamsnew EpisodeSequenceVisualizerv, domain, episodespublic static void mainString args MCLSPIFBMCLSPIRBFIPSSLLSARSA End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 4"], "word_count": 498, "token_count_estimate": 2069}}, "http://burlap.cs.brown.edu/tutorials_v1/bd/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials v1 Building a Domain Part 1 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 1 if youd like the BURLAP 2 tutorial, go here . Introduction This tutorial will cover three topics. First, we will discuss Markov Decision Processes MDPs and more specifically, Object-oriented MDPs OO-MDPs the decision making process that BURLAP uses to express single agent domains and decision making problems then we will discuss how BURLAP implements that OO-MDPs. Finally, we will cover how to create a domain, so that the planning and learning algorithms in BURLAP can be used on it, as well as how to visualize it, which is useful for testing and reviewing results. Note Beyond MDPs, BURLAP also supportsstochastic games, but a discussion of stochastic games will be left for a different tutorial and many of the coreelements of the OO-MDP code that BURLAP uses is reused in the stochastic games package of BURLAP as well. That is, BURLAP implements a form of Object-oriented Stochastic games. If you are alreadyfamiliar with MDPs or OO-MDPs, or just want to get down to coding, feel free to skip the firstsections that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the OO-MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Markov Decision Process To define worlds in which an agent can plan or learn, BURLAP uses the object-oriented Markov Decision Process OO-MDP formalism, which is an extension of the classic Markov Decision Process MDP formalism.A MDP provides a formal definition of a world, how it works, and how the agent who will be making decisions interacts with the world in a series of discretetime steps. In this tutorial we will formalize a grid world as an MDP. A grid world is a 2D world in which an agent can move north, south, east or west by one unit, provided there are no walls in the way. The below image shows a simple grid world with the agents position represented by a gray circle and walls of the world painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. An example grid world. To define any world and task as an MDP, we will need to break down the problem into four components a set of possible states of the world S a set of actions that the agent can apply A a definition of how actions change the state of the world, known as the transition dynamics T and the rewards the agent receives for each of its actions R , known as the reward function, which will determine what the best behavior is that is, the agent will want to act in a way that maximizes the reward it receives. The transition dynamics are formulated as a probabilistic function T s s, a , which defines the probability of the world changing to state s in the next discrete timestep when the agent takes action a in the current state s . The fact that the world can change stochastically is one of the unique properties of an MDP compared to more classic planningdecision making problems. The reward function is defined as R s, a, s , which returns the reward received for the agent taking action a in state s and then transitioning to state s . Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action Requiring this level of temporal independence makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will make the transition dynamics stochastic so that with high probability 0.8 the agent will move in the intended direction, and with some low probability 0.2 move in a different direction. The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we can define a reward function that returns a high reward when the agent reaches the top right corner of the world and zero everywhere else. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks i.e., action stops once the agent achieves a goal, failure conditions, or any number of other reasons. In our grid world, well want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function more on that later. The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, wed say that the goal is to find a policy , which is a mapping from states in the MDP to actions that the agent takes. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, its often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 because they all would eventually reach the goal however, what wed probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didnt set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult A commonalternative temporal objective that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sum where rt is the reward received at time t and is the discount factor that dictates how much preference an agent has for more immediate rewards, or in other words, the agents patience. With 1, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step therefore, 1 results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With 0 all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless its one step away. However, a value somewhere in between 0 and 1 often results in what we want. That is, for all values of 0 1, the expected reward in an MDP when following any given policy is finite and the agent will value future rewards at least somewhat. If we set to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual 1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward with left as a parameter that the user can specify. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 1", "Note"], "word_count": 1487, "token_count_estimate": 1753}}, "http://burlap.cs.brown.edu/tutorials_v1/bd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials v1 Building a Domain Part 2 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part OO-MDPs In the classic MDP formalism, each state is simply described by its identity. The cell in the bottom left corner of the grid world would simply be state 0 and the one above it might simply be state 11. This is known as a flat state representation because there is no other information about the states other than their identity. Although many planninglearning algorithms work just fine with flat representations, using a flat state representation makes defining transition dynamics and reward functions inconvenient. In fact, when we described the gridworld in the previous section, we used words regarding spatial adjacency and direction to explain it. It would similarly be nice to define the states, transitions, etc. using such concepts. For these reasons and others, it is oftenmuch easier to use a factored state representation, which can be exploited when defining the MDP transition dynamics and other properties. A classic way to define a factored state representation is with a set of state variables or attributes . In our grid world, for example, we would define the state by an x-position attribute and a y-position attribute. The bottom left cell of the world would be state 0, 0 the cell directly above it would be 0, 1 and so on. The factored representation that BURAP uses is the object-oriented MDP OO-MDP, which rather than representing states by a set of attributes, states are represented by a set of objects . Each object belongs to an object class, and each object class has an associated set of attributes. Each attribute can be of a different type with its own value domain. An object in a state is simply a value assignment to its class attributes. In our grid world, we can define an agent class that has two integer attributes associated with it with a value domain spanning the width and height of the grid world. In this definition, a state would contain an object instance belonging to the agent class with a value assignment specifying the agents x and y position. Although grid worlds are simple enough to describe without using an OO-MDP representation, there are a number of reasons why the OO-MDP representation is useful. For example, its trivial to define transition dynamics that create new objects in the world or remove them, merely by having the objects added or removed from the list of objects present in a state. If there are multiple objects belonging to the same class, states can also be defined invariantly to the reference or order of the objects in the state. For instance, consider a state s0 with block objects defined by 2D spatial positions. Now imagine a new state s1 that is the result of swapping the positions of the block objects as show in the below image. Even though the object identifiers associated with the blocks is different between s0 and s1, the states are isomorphic that is, if block0 was renamed to block1 and block1 to block0, the states would be the same therefore, from a decision making algorithm perspective it may be useful to treat the states as equal, rather than distinct states that each require independent computation and reasoning. In an OO-MDP paradigm it is possible to treat these states as equal and BURLAP will do that automatically unless otherwise specified Another advantage to the OO-MDP paradigm is that it leverages the object-oriented nature to provide additional high-level state features in the form of propositional functions that operate on objects in the world. In our grid world, we can introduce an additional object class for location objects similarly defined by x,y position attributes and then define a propositional function called at that operates on the agent object and a location object and evaluates to true when they are in the same location. Including propositional functions is useful for bridging the gap between MDPs and more classic AI approaches that are based on logical representations. In this tutorial we will implement the at propositional function in our grid world to demonstrate how to create them. BURLAP OO-MDP Java Class Overview BURLAP implements the OO-MDP paradigm in Java with the following class structure, which can be found in the packages burlap.oomdp.core and burlap.oomdp.singleagent . Attribute - this class defines an attribute name, data type, and value range. Attribute data types can be discrete categorical or integers, real-valued, relational, strings, or int and double arrays for very large data. ObjectClass - this class defines an object class name and is defined with an associated set of Attribute objects. Value - this class provides a value assignment for a specific attribute. There is a different Value subclass for each attribute data type, but management of it is handled behind the scenes. ObjectInstance - this class is used to represent an OO-MDP object, which is defined by an ObjectClass and a set of Value assignments to each of the class Attribute objects. State - this class provides an OO-MDP state definition, which is specified as a list of ObjectInstance objects. PropositionalFunction - this abstract class is subclassed to define propositional functions of an OO-MDP that operate on objects in State objects. Action - this abstract class is subclassed to provide the actions an agent can take in the world. The action subclass defines the transition dynamics for the action, preconditions if any, and parameters the action takes if any. TransitionProbability - this class is a pair that defines the probability of transitioning to another state and is returned by the Action class when querying for its transition dynamics. GroundedAction - this class provides a reference to an action and the specific parameters if any with which it should be applied. GroundedProp - this class provides a reference to a PropositionalFunction and the parameters with which it will be evaluated. SADomain - this class provides the definition of an OO-MDP domain, and includes the references to all of the ObjectClass objects, Attribute objects, PropositionalFunction objects, and Action objects that define the domain. TerminalFunction - this interface is implemented to specify the terminal states of a task in a specific OO-MDP domain. RewardFunction - this interface is implemented to specify the rewards received for any state, action, next state transition. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 2"], "word_count": 1101, "token_count_estimate": 1331}}, "http://burlap.cs.brown.edu/tutorials_v1/bd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials v1 Building a Domain Part 3 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part Defining GridWorld Object Classes To begin implementing our grid world domain in BURLAP, we will create a class that in this tutorial we will call ExampleGridWorld. Furthermore, we will make it implement the DomainGenerator interface, which is a common convention in BURLAP when developing domains and requires implementing the generateDomain method. In that method, we will also create an SADomain object that will keep track of all of our attributes, object classes, etc. that we define. Note that the Domain class that is returned by the method is the abstract superclass of SADomain. It is abstract because for stochastic games we will have a different domain subclass that contains different and shared information. You should have code that looks like the below to make things easier for the future, the below code has all of the library imports that youll need for the rest of the tutorial. import java.awt.Colorimport java.awt.Graphics2Dimport java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Listimport burlap.oomdp.auxiliary.DomainGeneratorimport burlap.oomdp.core.Attributeimport burlap.oomdp.core.Attribute.AttributeTypeimport burlap.oomdp.core.Domainimport burlap.oomdp.core.ObjectClassimport burlap.oomdp.core.ObjectInstanceimport burlap.oomdp.core.PropositionalFunctionimport burlap.oomdp.core.Stateimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.singleagent.Actionimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.explorer.TerminalExplorerimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.ObjectPainterimport burlap.oomdp.visualizer.StateRenderLayerimport burlap.oomdp.visualizer.StaticPainterimport burlap.oomdp.visualizer.Visualizerpublic class ExampleGridWorld implements DomainGenerator Overridepublic Domain generateDomain SADomain domain new SADomainreturn domain The first thing that we will want to decide in the construction of our domain is what the object classes and attributes that define the domain are. For our grid world, we will define two object classes an agent class, to represent the agent in the world and a location class, which we can use to refer to special places in the world. The location class isnt necessary to define grid world problems, but were going to include it to help illustratehow to define propositional functions in BURLAP. Both the agent and location class will be defined by their x and y position in the 2D world. For convenience, it is often useful to define the names of all attributes, object classes, etc. that the domain definesas string constants so that they can be precisely referenced by code that uses the domain, so lets add those to our code now. public static final String ATTX xpublic static final String ATTY ypublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION location Next we will create the actual Attribute objects and the classes associated with them. Since grid worlds have discrete states, but our attributes represent numeric positions, we willset our attributes to be of type int. We will also construct a world that is 11x11 in size, so we will set the attribute limits to be from 0 to 10 inclusively. Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattreturn domain Notice how we never directly told the domain about the attributes or object classes that we created Thats because the constructor of the attributes and object classes will tell the domain about themselves automatically to streamline construction. With that code written, were already finished defining the state representation of the domain The next step will be to define actions. Defining GridWorld Actions Defining actions in BURLAP means specifying the actions the agent can take, their preconditions if any, their parameters if any, and their transition dynamics. We will construct four actions north, south, east, and west. None of these actions will have preconditions and they will not take any parameters. The transition dynamics we define for them will depend on the location of walls in the world. We could have potentially made the walls objects of the OO-MDP themselves,but for simplifying the state representation we will keep the walls embedded in our transition dynamics without explicit state representation. To facilitate the definition of the transition dynamics, we will create a 2D int matrix specifying the location of walls in each cell. We will also create a world withthe same wall layout shown in the image at the beginning of this tutorial. To do so, add the following code. ordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0, Next we will create our actions. We will define north, south, east, and west actions that have a probability of 0.8 of going in the intended direction and a probability of 0.2 of going in any other direction. To create these actions, we will define a single subclass of the Action class that we will call Movement and instantiate it multiple times for each action. Subclassing Action requires us to implement the method performActionHelper, which is called whenever an action is applied and must return the resulting state from applying the action. We will also want to override the method getTransitions, which specifies the probability of transitioning to each possible next state when applying the action in the provided state and with the provided parameters. Overriding this method is not required if the domain is not going to be used with planning or learning algorithms that require exact and fully enumerated transition dynamics, and for some domains, it may not even be possible to enumerate all possible outcomes. However, if you do not override the method and a planning or learning algorithm tries to use it, an UnsupportedOperation exception will be thrown. Since the number of possible outcomes is trivial to enumerate for our grid world and since wed like to be able to use algorithms like Value Iteration that require the fully enumerated transition dynamics, we will implement the method. If our actions had preconditions and were only applicable in certain states, we would also have to override the applicableInState method. Since our actions can be taken anywhere, however, we will not override it, which has the default behavior of making the actions applicable everywhere. protected class Movement extends ActionOverrideprotected State performActionHelperState s, String params return nullOverridepublic List getTransitionsState s, String paramsreturn null So that we can reuse this Action class for each movement direction, lets define a data member that specifies the probability of going in each direction and let the intended direction which will succeed with probability 0.8 be specified in the constructor, along with a name for the action and the domain to which it belongs. protected class Movement extends Action0 north 1 south 2east 3 westprotected double directionProbs new double4public MovementString actionName, Domain domain, int directionsuperactionName, domain, forint i 0 i 4 iifi directiondirectionProbsi 0.8elsedirectionProbsi 0.23.Overrideprotected State performActionHelperState s, String params return nullOverridepublic ListTransitionProbability getTransitionsState s, String paramsreturn null Notice how we called a super constructor with the action name, domain, and empty quotes Calling the super constructor will automatically connect the action with the domain object and set its name. The empty quotes are used to specify that this action takes no parameters. Now well want to start defining our performActionHelper and getTransitions methods. To do so, lets add a helper method for getting the result of moving in a given direction. As long as the cell is free that is, there is no wall, the agent will move to that position if there is a wall there, the agent will stay in the same place. This method will then return the resulting x and y position of the agent. protected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or out of boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,ny With this helper method defined, all the performActionHelper method needs to do is determine the current position of the agent, sample from the direction distribution, call the moveResult method to get the new position, and set the agent attribute values to the new position. Getting the direction and setting the values can be performed by grabbing agent object instance in the state and using the pertinent value getter and setter methods. Since there is only ever one agent object instance in the state, we can retrieve the agent ObjectInstance using the getFirstObjectOfClass method that returns the first object instance of an object belonging to a specified class in the state. Overrideprotected State performActionHelperState s, String params get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getDiscValForAttributeATTXint curY agent.getDiscValForAttributeATTYsample directon with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i this.directionProbs.length isumProb this.directionProbsiifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.setValueATTX, newPos0agent.setValueATTY, newPos1return the state we just modifiedreturn s Note You might be wondering why we can modify the state directly and then return it, since it seems like that might cause problems if the passed in State object was used elsewhere in a planning or learning algorithm. Notice how the method we are overriding has a Helper qualifier at the end and is marked as protected Thats because there is a public method called performAction that will first copy any input state and then pass the copied state to the performActionHelper method that we are overriding. This copying ensures that youre never modifying a State object that is used for something else. For the getTransition method, well do something similar, except in this case, we create a copy of the input state for each possible outcome, modify the copied state to the possible results, and return a List that couples the probability with each of those possible outcomes. In general, each possible outcome from a movement action is the result of the agent moving in each direction with the probability of the action making the agent move in that direction. However, moving in multiple directions may result in the agent not changing position at all if there are walls in those directions. Therefore, we should merge the result and probability of directions that result in the same outcome before returning our set of outcome states. Overridepublic ListTransitionProbability getTransitionsState s, String paramsget agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getDiscValForAttributeATTXint curY agent.getDiscValForAttributeATTYListTransitionProbability tps new ArrayListTransitionProbability4TransitionProbability noChangeTransition nullforint i 0 i this.directionProbs.length iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeState ns s.copyObjectInstance nagent ns.getFirstObjectOfClassCLASSAGENTnagent.setValueATTX, newPos0nagent.setValueATTY, newPos1create transition probability object and add to our list of outcomestps.addnew TransitionProbabilityns, this.directionProbsielsethis direction didnt lead anywhere newif there are existing possible directions that wouldnt lead anywhere, aggregate with themifnoChangeTransition nullnoChangeTransition.p this.directionProbsielseotherwise create this new state outcomenoChangeTransition new TransitionProbabilitys.copy, this.directionProbsitps.addnoChangeTransitionreturn tps With the Action class defined, well want to hook it up to our domain. First, lets add some string constants for the names of the actions. public static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST west Then we just need to call the constructor in our generateDomain method. As with the object classes and attributes, calling the constructor will automatically tell our domain about it, so we dont need to do anything further. new MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3 Defining Propositional Functions Although we have a functioning domain at this point, were going to add an optional propositional function to it to demonstrate how to use them. The propositional function we will create is atagent, location. Notice that it will take two parameters, one which is an OO-MDP object belonging to OO-MDP class agent and the other an OO-MDP object belonging to OO-MDP class location. The function should evaluate to true when the provided agent objects position is equal to the provided location objects position. To implement this function, we will need to subclass the PropositionalFunction class. Lets first create another string constant for the name of the function. public static final String PFAT at And then lets make the shell of the class implementation with a constructor. protected class AtLocation extends PropositionalFunctionpublic AtLocationDomain domainsuperPFAT, domain, new String CLASSAGENT,CLASSLOCATIONOverridepublic boolean isTrueState s, String params TODO Auto-generated method stubreturn false Inside the constructor we called a super constructor that takes as arguments the name of the propositional function, the domain with which it will be associated, and an array specifying the OO-MDP class types to which its parameters must adhere. Now lets implement the isTrue method, which is as simple as getting the object instances of the provided parameters and checking if the attributes are equal. The parameters that are provided to the method are the names or identifiers of the objects in the world that its referencing, so we can retrieve the objects from the provided state object by simply querying for the object with the given identifier. Overridepublic boolean isTrueState s, String params ObjectInstance agent s.getObjectparams0ObjectInstance location s.getObjectparams1int ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYint lx location.getDiscValForAttributeATTXint ly location.getDiscValForAttributeATTYreturn ax lx ay ly Finally, lets call the constructors from our generateDomain method. As before, the constructor will automatically tell the domain about the propositional function. Our final generateDomain method will look like the below. Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattnew MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3new AtLocationdomainreturn domain Note Although we have defined a propositional function, you might be wondering how you can find all possible parameters in a state with which it can be evaluated. The PropositionalFunction super class provides a method for doing just this called getAllGroundedPropsForStateState , which will return a list of GroundedProp objects that can be evaluated. A GroundedProp is simply a PropositionalFunction object reference and parameters with which to evaluate it. Similarly, if you want all possible GroundedProp objects for a list of different PropositionalFunction objects, you can use the PropositionalFunction static method getAllGroundedPropsForStateState . Testing the Domain We now have a functional domain However, its probably important to test that the domain actually works as expected. By the end of this tutorial we will have created a visualizer for our domain that we can use to interactively visualize and test it, but we can also test it in the command line. To test our domain, lets first add a method to generate a state with the agent in the bottom left corner and a location object in the top right. public static State getExampleStateDomain domainState s new StateObjectInstance agent new ObjectInstancedomain.getObjectClassCLASSAGENT, agent0agent.setValueATTX, 0agent.setValueATTY, 0ObjectInstance location new ObjectInstancedomain.getObjectClassCLASSLOCATION, location0location.setValueATTX, 10location.setValueATTY, 10s.addObjectagents.addObjectlocationreturn s Note that we made this method static and had it take as a parameter the domain object. We made the method static because the domain object is only ever created once the generateDomain method is called and that method can produce different Domain objects each time it is called. Although not especially important for our example, this is useful if you have parameterizable domains. Since ObjectInstance objects have to belong to a specific ObjectClass, we have to have the have the corresponding domain object from which to retrieve the ObjectClass. In addition to taking an ObjectClass, the ObjectInstance constructor also takes as a parameter the name or identifier of the object instance. This name will be used to identify the object from other objects in the state and to further disambiguate it from multiple objects of the same class. This name is also what will be passed to the PropositionalFunction isTrue method parameters and for actions that are parameterized to objects though in our Grid World, our Actions are not parameterized. Lets now add a main method that we will launch into to test our domain. To do the testing, we will make use the TerminalExplorer which lets us act as the agent through the command line. Create the main method as shown below. public static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainTerminalExplorer exp new TerminalExplorerdomainexp.exploreFromStateinitialState When you run main in the command lineterminal you should see a print out describing the example state. If you now type the name of an action such as north and hit enter, it will change state and print out the new state. Remember that our actions are stochastic, so 20 of the time youll find yourself going in a different direction While using the TerminalExplorer works for all domains that you might create, as your domains get more complex it be can be difficult to make sense of them from text alone. Having a visualizer makes understanding whats happening in your domain much easier. Furthermore, you can reuse a visualizer not just for interacting in the world yourself, but for visualizing results of learning and planning algorithms. In the next sections, we will walk through how to create a state visualizer for this domain. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 3", "Note", "Note"], "word_count": 2814, "token_count_estimate": 4423}}, "http://burlap.cs.brown.edu/tutorials_v1/bd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials v1 Building a Domain Part 4 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part The Components of a Visualizer Different visualization components in BURLAP are built around implementing the RenderLayer interface, which requires being passed a graphics context on which the implementing class will paint. Having everything built around RenderLayer objectsmeans you can trivially stack different kinds of information ontop of each other. For example, you might have a render layer to display a state, and another one to display value function information, layered on top. In this tutorial we will focus onrendering the state, for which there is a specific implementation of the RenderLayer interface that we can use called StateRenderLayer , which after constructing we can pass to the Visualizer class, which will create a Java canvas to which are StateRenderLayer can paint. The StateRenderLayer is provided a number of different subpainters that it will call sequentially to paint to the canvas. Each subpainter is either a StaticPainter or an ObjectPainter . The StaticPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP State object, and the width and height of the canvas that then paints to the canvas information about the overall state or the domain to which the state belongs. For example, in the grid world weve been creating, walls are not explicitly represented in our OO-MDP state object, but when rendering a state, wed like to paint where the walls are. The ObjectPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP state, a specific OO-MDP ObjectInstance from that state, and the width and height of the canvas that then paints to the canvas information about that specific object instance. In our GridWorld, we would want to provide a different ObjectPainter forthe agent class objects and location class objects. When our StateRenderLayer object is provided a bunch of StaticPainter and ObjectPainter objects, during its state paint method it will first paint to the graphics context with the StaticPainter objects. Then for each OO-MDP object in the state, it will paint to the canvas using the corresponding ObjectPainterthat we will associate with that class. Implementing the Painters To implement a StaticPainter for painting the walls of our grid world as black rectangles, add the below class inside the ExampleGridWord class code weve been writing. public class WallPainter implements StaticPainterOverridepublic void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on our cavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left corrdinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, height The main idea of this code is to first determine how wide and tall cells in our grid world will be rendered on a canvas of the given size. This is simply with widthheight of the canvas dividedby the number of cells in our grid world along each dimension.Then we iterate through our map and draw a rectangle in the corresponding position when the map has a wall listed as being there. The only extra thing to take care of is that the Javapainting coordinate system is in the top left corner, whereasweve defined our map with a bottom left coordinate system, so we perform a coordinate system switch in the rendering as shown. Now lets create a painter for the OO-MDP agent class, which well represent as a gray circle in the word. This codewill look almost identical to our map painter code except instead of iterating through the map, well get the agent x and y position from the OO-MDP ObjectInstance our painter is provided and instead of painting a black rectangle well paint a gray circle. As before add the below class inside our ExampleGridWorld class. public class AgentPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getDiscValForAttributeATTXint ay ob.getDiscValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, height Well also do the same for a location object, but well use a blue rectangle instead. public class LocationPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getDiscValForAttributeATTXint ay ob.getDiscValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, height Finally, well want to add some methods to our ExampleGridWorld domain generator to create a StateRenderLayer and correspondingVisualizer to hold it. The StateRenderLayer merely needs to be given a WallPainter instance and told to use a AgentPainter instance for objects of OO-MDP class agent and a LocationPainter instance for objects of OO-MDP class location. Once a StateRenderLayer object is created, a Visualizer object merely needs to be pointed to it. To do so, add the following methods to our ExampleGridWorld class. public StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStaticPainternew WallPainterrl.addObjectClassPainterCLASSLOCATION, new LocationPainterrl.addObjectClassPainterCLASSAGENT, new AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayer Note that in the getStateRenderLayer method we added the location object painter before the agent object painter. This implicitly tells the StateRenderLayer the order in which objects should be painted first objects of class location and then objects of class agent. The result is that when an agent is at the same position as a location, the agent will be rendered on top of it. Now that we can construct a visualizer, lets swap out our TermainalExplorer in our main method for a VisualExplorer . The VisualExplorer can be controlled by manually typing in actions into a text field, but its often easier to control the agent with the keyboard. To do so, we can specify a binding between a key press and an action name with the addKeyAction method. In this case, well set w to correspond to north s south d east and a west. Change your main method to now look like the below. public static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainTerminalExplorer exp new TerminalExplorerdomainexp.exploreFromStateinitialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, v, initialStateexp.addKeyActionw, ACTIONNORTHexp.addKeyActions, ACTIONSOUTHexp.addKeyActiond, ACTIONEASTexp.addKeyActiona, ACTIONWESTexp.initGUI Now when you run your code, youll be presented a visualization of the state and you can interact with it with the wasd keys, similar to what you see in the below image. Note that you may need to click on the image for it to begin accepting key presses. Remember, since we made movement stochastic, you may find the agent moving in unintended directions some of the time. Also note that when the agent enters the same position as the location object that in the bottom text box in the window youll see atagent0, location0 appear. This text box always lists all propositional functions that are true in the current state automatically. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 4"], "word_count": 1385, "token_count_estimate": 1975}}, "http://burlap.cs.brown.edu/tutorials_v1/bd/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials v1 Building a Domain Part 5 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Reward Functions and Terminal Functions Now that youve created a world, youll want to definetasks for the world so that you can run planning and learningalgorithms on it. Tasks in BURLAP are typically defined with RewardFunction and TerminalFunction implementations. The former specifies the reward received by the agent for transition tuples previous state, action taken, resulting state the later specifies which states are terminal states that cause all further action to cease. While we wont be using any planning or learning algorithms in this tutorial, we will briefly cover how to create your own reward functions and terminal state functions so that you can run planning and learning algorithms on your domain. Before you make your own RewardFunction and TerminalFunction,it is sometimes worth checking to see if BURLAP already has an implementation that you can use. For example, many different problems use a reward function that returns -1 everywhere.For problems like these, you can use the UniformCostRF object. If your domain is continuing i.e., non-terminating, thenyou can use the NullTermination object. It also not uncommon to have a goal condition that is satisfied whenever any object grounding of a propositional function returns true. In our grid world, for example, if we let location objects indicate goal locations, we might want a terminal function that returns true for any state in which the agent is at a location. In such a case you can use the SinglePFTF TerminalFunction and point it to the atLocation propositional function. If none of the existing RewardFunction or TerminalFunction objects in BURLAP suit your needs, you can always create your own. For example, suppose we wanted a reward function that returned -1 everywhere, except when the agent reached designated x, y position at which point it returned a reward of 100. We can implement such a reward function as shown below. public static class ExampleRF implements RewardFunctionint goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, GroundedAction a, State sprime get location of agent in next stateObjectInstance agent sprime.getFirstObjectOfClassCLASSAGENTint ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1 Notice that when we get the agent position, we get it from the sprime variable Thats because parameter s represents the previous state, a represents the action the agent took in the previous state, and sprime represents the state the agent ended up in as a result. Since we want to return 100 when the agent reaches our goal location, we care about where the agent ended up, which is held in sprime. If we wanted to make a similar TerminalFunction that marked our goal state as a terminal state, we would do so with the similar below code. public static class ExampleTF implements TerminalFunctionint goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn truereturn false And that is all there is to defining reward functions and terminal states Conclusions In this tutorial we showed you how to create a domain, visualize it, interact with it, and how to define tasks for it. With a domain and task in hand youre now ready to use the planning and learning algorithms in BURLAP on it, which you will learn about in the next tutorial . Although we showed you how to create a grid world domain in this tutorial, if you do want to run experiments on a grid world, we highly recommend that you use the GridWorldDomain already in BURLAP. It will support many more features than we covered in this tutorial including 1 dimensional walls, location types, and more flexible transition dynamics. Final Code For reference, you can find all of the code we wrote below. import java.awt.Colorimport java.awt.Graphics2Dimport java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.ArrayListimport java.util.Listimport burlap.oomdp.auxiliary.DomainGeneratorimport burlap.oomdp.core.Attributeimport burlap.oomdp.core.Attribute.AttributeTypeimport burlap.oomdp.core.Domainimport burlap.oomdp.core.ObjectClassimport burlap.oomdp.core.ObjectInstanceimport burlap.oomdp.core.PropositionalFunctionimport burlap.oomdp.core.Stateimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.singleagent.Actionimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.explorer.TerminalExplorerimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.ObjectPainterimport burlap.oomdp.visualizer.StateRenderLayerimport burlap.oomdp.visualizer.StaticPainterimport burlap.oomdp.visualizer.Visualizerpublic class ExampleGridWorld implements DomainGenerator public static final String ATTX xpublic static final String ATTY ypublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION locationpublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westpublic static final String PFAT atordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattnew MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3new AtLocationdomainreturn domainpublic static State getExampleStateDomain domainState s new StateObjectInstance agent new ObjectInstancedomain.getObjectClassCLASSAGENT, agent0agent.setValueATTX, 0agent.setValueATTY, 0ObjectInstance location new ObjectInstancedomain.getObjectClassCLASSLOCATION, location0location.setValueATTX, 10location.setValueATTY, 10s.addObjectagents.addObjectlocationreturn spublic StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStaticPainternew WallPainterrl.addObjectClassPainterCLASSLOCATION, new LocationPainterrl.addObjectClassPainterCLASSAGENT, new AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayerprotected class Movement extends Action0 north 1 south 2east 3 westprotected double directionProbs new double4public MovementString actionName, Domain domain, int directionsuperactionName, domain, forint i 0 i 4 iifi directiondirectionProbsi 0.8elsedirectionProbsi 0.23.Overrideprotected State performActionHelperState s, String params get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getDiscValForAttributeATTXint curY agent.getDiscValForAttributeATTYsample directon with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i this.directionProbs.length isumProb this.directionProbsiifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.setValueATTX, newPos0agent.setValueATTY, newPos1return the state we just modifiedreturn sOverridepublic ListTransitionProbability getTransitionsState s, String paramsget agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getDiscValForAttributeATTXint curY agent.getDiscValForAttributeATTYListTransitionProbability tps new ArrayListTransitionProbability4TransitionProbability noChangeTransition nullforint i 0 i this.directionProbs.length iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeState ns s.copyObjectInstance nagent ns.getFirstObjectOfClassCLASSAGENTnagent.setValueATTX, newPos0nagent.setValueATTY, newPos1create transition probability object and add to our list of outcomestps.addnew TransitionProbabilityns, this.directionProbsielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChangeTransition nullnoChangeTransition.p this.directionProbsielseotherwise create this new state and transitionnoChangeTransition new TransitionProbabilitys.copy, this.directionProbsitps.addnoChangeTransitionreturn tpsprotected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,nyprotected class AtLocation extends PropositionalFunctionpublic AtLocationDomain domainsuperPFAT, domain, new String CLASSAGENT,CLASSLOCATIONOverridepublic boolean isTrueState s, String params ObjectInstance agent s.getObjectparams0ObjectInstance location s.getObjectparams1int ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYint lx location.getDiscValForAttributeATTXint ly location.getDiscValForAttributeATTYreturn ax lx ay lypublic class WallPainter implements StaticPainterOverridepublic void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on our cavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getDiscValForAttributeATTXint ay ob.getDiscValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, heightpublic class LocationPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getDiscValForAttributeATTXint ay ob.getDiscValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic static class ExampleRF implements RewardFunctionint goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, GroundedAction a, State sprime get location of agent in next stateObjectInstance agent sprime.getFirstObjectOfClassCLASSAGENTint ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1public static class ExampleTF implements TerminalFunctionint goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint ax agent.getDiscValForAttributeATTXint ay agent.getDiscValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn truereturn falsepublic static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainTerminalExplorer exp new TerminalExplorerdomainexp.exploreFromStateinitialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, v, initialStateexp.addKeyActionw, ACTIONNORTHexp.addKeyActions, ACTIONSOUTHexp.addKeyActiond, ACTIONEASTexp.addKeyActiona, ACTIONWESTexp.initGUI End.", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 5"], "word_count": 1563, "token_count_estimate": 3389}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 1 if youd like the BURLAP 2 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a GridWorld domain bundled with BURLAP,creating a task for it, having the task solved with Q-learning, Sarsa learning, BFS, DFS, A, and ValueIteration. The tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algoritms largely amounts to just changing the algorithm object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. At the conclusion section of this tutorial, you will find all of the code we created, so if youd prefer to jumpt rightin, only coming back to this tutorial as questions arise, feel free to do so Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class BasicBehavior but feel free to name it to whatever you like.Since we will also be running the examples from this class, well include a main method. import burlap.behavior.singleagent.import burlap.domain.singleagent.gridworld.import burlap.oomdp.core.import burlap.oomdp.singleagent.import burlap.oomdp.singleagent.common.import burlap.behavior.statehashing.DiscreteStateHashFactorypublic class BasicBehavior GridWorldDomaingwdgDomaindomainStateParserspRewardFunctionrfTerminalFunctiontfStateConditionTestgoalConditionStateinitialStateDiscreteStateHashFactoryhashingFactorypublic static void mainString args well fill this in later If youre already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what data member is and why were going to need it. GridWorldDomaingwdg This object is a DomainGenerator provided in the domains package. We will use thisobject to create a basic grid world domain for our demonstration. Domain domain The domain object is an fundamental OO-MDP object. The domain object defines a set ofattributes, object classes, propositional functions, and actions along with the actions transition dynamics. Youcan imagine domain objects as holding information regarding how states in a problem are representedand how the physics of the problem work. StateParser sp A StateParser object is used to convert OO-MDP states to and from string representations. This is usefulif you want to be be able to record planning and learning results to files, which we will be doing in this tutorial. RewardFunction rf A RewardFunction is an object that returns a double valued reward for any given state-action-state sequence. This is a fundamental component of every MDP and its what an agent tries to maximize. That is, the goalof an agent is acquire as much reward from the world as possible. TerminalFunction tf A common form of MDPs are episodic MDPs MDPs that end in some specific state or set of states. A typicalreason to define an episodic MDP is when there is a goal state the agent is trying to reach. In such cases, the goalstate is a terminal state, because once the agent reaches it, there is nothing left to do. Inversely, some states may be fail states that prevent the agent continuing these too would be terminal states. There may also be other reasons to provide termination states, but whatever you reason may be, theTerminalFunction object defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences to reach specific goal states. A StateConditionTest object operates muchlike a TerminalFunction, only it can be used as a means to specify any kind of state check. In this tutorial we willuse it to specify goal states for planning algorithms that search for action sequences to reach goals rather thanplanning algorithms that try to maximize reward. State initialState To perform any planning or learning, we will generally need to specify an initial statefrom which to perform it. An OO-MDP state consists of an arbitrary set of instantiated object classes from a givendomain. An instantiated object of an object class means that there is a value is defined for each attribute ofthe object class. A state may also consist of an arbitrary number of object instances for any given class, but insome domains you may typically only have one instance for each. In the GridWorld domain, for instance, there willbe one instance of the agent object which is defined by an x and y position and one instance of a location objectwhich is also defined by an x and y position,which will be used to specify a goal location where the agent needs to go. Not all planning algorithms directly care about an initial state. For instance, while classic planners are designedaround finding an action sequence from an initial state to a goal state, planners like Value Iteration VI are concernedwith finding a policy, a mapping from states to actions, that tells the agent how act in every conceivablestate in the world. Nevertheless, the BURLAP implementations of VI and other complete policy-computing planning algorithms will still require that an initial state isprovided to it for planning. The reason BURLAPs VI will ask for an initial state is because technically an OO-MDPsstate space is infinite. Because an OO-MDP state consists of a set of objects, you can always imagine another stateby simply adding another instance of one of the objects in the domain. By passing to VI an initial state, however,it asks VI to be performed in world with some given initial number of objects instances with some initial set of values.BURLAPs VI will then find all reachable states from that initial state and use that as the effective state space for a whicha policy will be returned. Note Even when VI is passed an initial state its possible for the state space to be infinite.For instance, perhaps there are actions in the domain that allow an indefinite number of new object instances to be created, or perhaps the valuesof object attributes are continuous with an infinite number of reachable values. The fact is that some problems are inherentlyinfinite in their state space and Value Iteration isnt an algorithm that can handle these kinds of problems. DiscreteStateHashFactory hasingFactory To perform planning and learning, there will need to be some wayto look up previously examined states in data structures and to do so efficiently will require some way to computehash codes for states and to compare them for equality. The DiscreteStateHashFactory provides a general means to do this for any discrete and non-relationalOO-MDP domain. A nice property of the DiscreteStateHashFactory object is that hashing results are invariantto specific object references. For instance, consider a state s0 with block objects defined by spatial positioninformation. Now imagine a new state s1 that is the result of swapping the positions of the blocks objects.Even though the object idenitifers associated with the block positions is different between s0 and s1, these really are the same state. The below illustration helps clarify this property. An advantageof the DiscreteStateHashFactory is that it will treat s0 and s1 identically that is, it recognizesthat s0 s1 and the same hash code will also be computed for each state. In BURLAP, we refer to this kindof state invariance as object identifier invariance . Note There may be some problems in which you do not want to use object identifier invariance. For instance, maybe the taskof a problem is to move a specific block to a specific location and it does matter which block is in that location.For such a task, using object identifier invariance will break the planninglearning algorithms ability to correctly findthe solution. In cases like these, a different state hashing factory should be used, such as NameDependentStateHashFactory . The Power of the StateHashFactory objects is that you can define your ownnew equality and hashing mechanisms for states and simply pass them along to your planning and learning algorithm. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 1", "Note", "Note"], "word_count": 1393, "token_count_estimate": 1807}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Initializing the data members Now that we have the structure of our class, well need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing well do in the constructor is create our domain. public BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRooms domain gwdg.generateDomainmore to come... The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layoutthe four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh 1999and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array with 1s specifying the cells with walls and 0sspecifying open cells, or you could simply specify the size of the domain like we did and then use the GridWorldobjects horiztonalWall and verticalWall methods to place walls on it. The GridWorld domain also supports1 dimensional walls between cells that you can set, if youd prefer that kind of domain. For simplicity, well stick with thefour rooms layout. The third line will produce the Domain object for the GridWorld. Recall from the previouspart of the tutorial that Domain objects hold references to all the attributes, object classes, propositional functions, and actionsalong with the actions transition dynamics. In our GridWorlds case, there are two attributes, an X attribute anda Y attribute. There are also two classes an AGENT class and a LOCATION class, each of which is defined by theX and Y attributes. While there could potentially be any number of AGENT object instantiations in a state, inthis domain we expect only one to ever be defined. The location objects will be used for points of interest.Specifically, we will use a single location object to represent a goal location. The GridWorld domain also definesfive propositional functions agentAtLocationAGENT, LOCATION wallToNorthAGENT wallToSouthAGENTwallToEastAGENT wallToWestAGENT. The first of those returns true when the specified AGENT object is at thesame location as the specified LOCATION object. The latter four propositional functions return true when there is a wall in the immediate cell of the defined direction of the specified AGENT object. Finally, the GridWorld domain defines four actions to move north, south, east, or west of the agents current position.Although we could have told the GridWorldDomain generator to make these movements stochastic that is, specify a probability in which the agent moves in an unintended direction, in our specific examplewe have left them as the default deterministic actions. If an agent moves into a wall, then its position does notchange. Although this domain instantiation has specific settings for grid worlds, differentdomains in BURLAP follow similar conventions. That is, you create an instanceof a domain generator specify the parameters of the domain through mutators,and then finally extract the domain with a call to a generateDomain method.For example, the LunarLander domain generator lets you set properties like themaximum velocity and the force of gravity. Next we will create a state parser sp new GridWorldStateParserdomain This state parser is a custom state parser that is part of the GridWorld package. We could have alsoused the UniversalStateParser , StateYAMLParser , or StateJSONParser , all which can provide state parsingfor any possible OO-MDP domain however, the UniversalStateParser is verbose in its String output, which can beundesirable if you are recording thousands of learning results. In such cases, a custom parser, such as the onewe used here, can be more compact. The next thing we will want to do is define the actual task to be solved for this domain. We will do this by specifyinga reward function, a termination function, and a goal condition, the latter of which we will use exclusively for search-based deterministic planners that this tutorial will cover. In general,you can always define your own reward functions, terminal functions, and goal conditions by implementing the RewardFunction , TerminalFunction , and StateConditionTest interfaces, respectively, yourself. However, BURLAPalso comes packaged with a bunch of standard instances as well as various domain-specific functions that we will use here. If you want to know moreabout defining your own, consult the Building a Domain tutorial. rf new UniformCostRF tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATION goalCondition new TFGoalConditiontf The first line will create a reward function that always returns -1 for every state-action-state transition.This might seem like a problem it may seem like we would need to define a reward function that returns agreater reward when the agent reaches the goal and there are existing reward function classes in the burlap.oomdp.singleagent.common package to do so. However, the next line which defines the termination function makesspecifying a reward function that returns a greater reward at the goal unnecessary. Before explaining why, lets examine thecreation of the TerminalFunction, which is specified as an instance of the SinglePFTF class that stands for single propositional function terminal function. This is a classwhich is provided a single propositional function of the domain. Any state for which any object binding ofthat propositional function is true will be marked as a terminal state. In the constructor parameters, thepropositional function is retrieved by querying the domain for the propositional function with the name GridWorldDomain.PFATLOCATION which is a constant field of the Gridworld domain referencing the nameused for the atLocation propositional function. Note that if there were multiple LOCATION objects in the world,this TerminalFunction would mark any state in which the agent was at any of the locationsas a terminal state. Note We are using a terminal function and set of statesthat include location objects to highlight the OO-MDPway of working with objects and propositional functionsin BURLAP.If youd prefer a more classic method of defininggrid world reward functions and terminal functionsbased on the location of the agent, you can do so usingthe GridWorldRewardFunction and GridWorldTerminalFunction classes that are part of the burlap.domain.singleagent.gridworld package. The final line sets up the goal condition to be synonymous with the termination function. Note that goal stateswill not always be the same as terminal states there may beterminal states that are not goal states, but in this example they are. Let us now return to why our reward function does not need to return a greater reward when reaching the goal condition.Since we defined a terminal function that marks goal states as terminal states, it means that once an agent reachesthis state, it can no longer receive any reward. Since all rewards are negative,the best way to maximize reward will be to run to the goal as fast as possible, after which no more negative reward willbe received. The next step will be to define the initial state of this task. We could either do thisby creating an empty State object and then manually adding object instantiations for each object class,or we could use some methods of the GridWorldDomain class to facilitate the process. We will do the latterfor brevity, but if you want a more complete description of creating astate object by hand, consider looking in the Building a Domain tutorial. initialState GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10 The first line will return a state object with a single instance of the AGENT class and a single instanceof the LOCATION class. The second line of code then sets the agent to be at position 0,0. The third line ofcode sets the location to be at position 10,10. The first zero you see in the parameters indicates whichLOCATION object index position to set. Since there is only one LOCATION object, we are setting the positionof the 0th indexed LOCATION object. The last part of the constructor is to define a method for computing state hash codes that can be used toefficiently look up state objects in various planning and learning algorithm data structures. Since this domain isdiscrete, we will use the common DiscreteStateHashFactory class. hashingFactory new DiscreteStateHashFactoryhashingFactory.setAttributesForClassGridWorldDomain.CLASSAGENT, domain.getObjectClassGridWorldDomain.CLASSAGENT.attributeList Note that the second line is optional. If we did not include that line, state hash codes would be computedwith respect to all attributes of all objects. However, in this task, the location object position will be constant,therefore, there is no reason to use the location object attributes for computing hash codes. Instead the hashing only needs to be computedwith respect to the X and Y attributes of the AGENT object, which will vary between states in the task. The second line of code tells the hashing factorythat we are going to manually define the set of attributes to be used for computing hashing codes and it tells itto use all of the attributes used in the AGENT class for hashing. We could have also told it to use only the Xattribute, or we could have specified attributes for other classes as well by adding additional calls to the setAttributesForClass method. Regardless of a choice of which attributes to usefor computing hash codes, its important to note that when states are compared for equality, all attributeswill be checked for equality. For instance, if two states with different positions for the location objectwere compared with our above definition of the hashing factory, they would produce identical hash codes, butbe evaluated as different states. If you wanted to not only limit which attributes were used for computing hashcodes, but also which ones were used for checking state equality, then instead you should use theDiscreteMaskHashingFactory class. Note that GridWorldDomain.CLASSAGENT is a constant field of theGridWorldDomain class that points to the name of AGENT class. The domain.getObjectClass methodwill return the object class with the specified name and the attributeList field of will return the list ofattributes associated with that object class. At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehaviorcreate the domaingwdg new GridWorldDomain11, 11gwdg.setMapToFourRooms domain gwdg.generateDomaincreate the state parsersp new GridWorldStateParserdomain define the taskrf new UniformCostRF tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATION goalCondition new TFGoalConditiontfset up the initial state of the taskinitialState GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10set up the state hashing systemhashingFactory new DiscreteStateHashFactoryhashingFactory.setAttributesForClassGridWorldDomain.CLASSAGENT, domain.getObjectClassGridWorldDomain.CLASSAGENT.attributeList Setting up a result visualizer Before we get to actually running planning and learning algorithms, were going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after its finished. Offline visualization has the advantage of not bogging down the runtime of planninglearning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state visualizer and pass it to an EpisodeSequenceVisualizer . To do so, first add the following imports. import burlap.oomdp.visualizer.Visualizerimport burlap.behavior.singleagent.EpisodeSequenceVisualizer Then create the below method. public void visualizeString outputPathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapEpisodeSequenceVisualizer evis new EpisodeSequenceVisualizerv, domain, sp, outputPath Note that the outputPath parameter specifies the directory where our planninglearning results were storedwell get to this when we actually apply a planninglearning algorithm. In order to visualize states, the domain will need to have a Visualizer defined for it, because it is impossible to tell how a domain should be visualized byattributes alone In this case, however, a class to generate a GridWorldDomain Visualizer, called GridWorldVisualizer already exists as part of the domains package. This specific Visualizer class willrequire the 2D int array specifying the layout of the map since different grid worldscan use different layouts. This map is retrieved from our GridWorldDomain generator object using the getMap method. The final line will construct and load the EpisodeSequenceVisualizer. Note that in order to visualize episoderesults with this class, you will need to pass it a visualizer, the domain, the state parser which will be usedto extract the states out of stored files, and the path to which all the episodes you wish to visualize are located.Later in this tutorial, we will examine how to use the GUI of the EpisdoeSequenceVisualizer. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main class. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultswe will call planning and learning algorithms hererun the visualizerexample.visualizeoutputPath Note that you can set the output path to whatever you want. If it doesnt already exist, the codethat will follow will automatically create it for you. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 2", "Note"], "word_count": 2113, "token_count_estimate": 2896}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with Value Iteration A common stochastic planner is Value Iteration VI. An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void ValueIterationExampleString outputPathifoutputPath.endsWithoutputPath outputPath OOMDPPlanner planner new ValueIterationdomain, rf, tf, 0.99, hashingFactory, 0.001, 100planner.planFromStateinitialStatecreate a Q-greedy policy from the plannerPolicy p new GreedyQPolicyQComputablePlannerplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sp VI is a planning method defined for the classic MDP formalism, so unlike the previousdeterministic planners, its constructor takes as input the reward function and termination function,rather than a goal condition. VI also takes as a parameter a discount factor which specifies how much future rewards are favored over immediate rewards. In this case,a fairly large value of 0.99 is set which means the agent will prefer later future rewards almost as much asimmediate rewards. The last two parameters to the constructor specify stopping conditions for theplanning. The second to last parameter specifies that when the maximumchange in the value function of any state is less than that specified threshold value 0.001 in this case, planning will stop. The last parameter specifies a maximumnumber of updates for each state that can happen before planning is stopped 100 in this case, regardlessof whether the maximum value function change threshold was crossed. Since VI is a stochastic planning algorithm, rather than a deterministic one like the previous algorithms weused, we cannot capture its planning results in a SDPlannerPolicy Policy class. Instead, a policy can be derivedfrom the value function the planner estimates for each state using the GreedyQPolicy class that canbe defined for any planner that adheres to the QComputablePlanner interface, which the VI algorithm does. Once the solution is captured in a Policy class object, the results can be captured and visualized in the same way. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you run will run multipleepisodes of learning to solve it or one very long episode if it is a continuing task rather than an episodictask. The method you should define to utilize Q-learning is shown below. public void QLearningExampleString outputPathifoutputPath.endsWithoutputPath outputPath creating the learning algorithm object discount 0.99 initialQ0.0 learning rate0.9LearningAgent agent new QLearningdomain, rf, tf, 0.99, hashingFactory, 0., 0.9run learning for 100 episodesforint i 0 i 100 iEpisodeAnalysis ea agent.runLearningEpisodeFrominitialStateea.writeToFileString.formatse03d, outputPath, i, sp System.out.printlni ea.numTimeSteps Lets first look at the constructor. Rather than a planning instance, were creating a LearningAgent instance which provides some methods for learning. QLearning is an instance of the LearningAgent classand like the Value Iteration planner, takes a parameters the reward function, termination function, anddiscount factor rather than a goal condition. The last two parameters of the constructor represent theinitial Q-value to use for previously untaken state-action pairs which we set to 0.0 and the last parameteris the learning rate, which we set fairly high since this is a simple deterministic task. Note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a mutator that allows you to set itif youd like to use a different policy. Alternatively, you could also pass Q-learning an object thatspecifies how the Q-value for each state-action pair should be initialized, rather than initializing them all to the samevalue as we did here. For this tutorial, we will not bother with that, however. With the QLearning instance created, next we will run learning episodes rather than tell it to plan a solution.To make sure a decent solution is learned, we will let learning run for 100 episodes, so we set up a loop to doso. To run a learning episode, we call the method runLearningEpisodeFrom on the LearningAgent instanceand pass it the initial state from which it should begin the learning episode. Since this method will performlearning for an entire episode, the method will return an EpisodeAnalysis object that stores the resultsof the episode. Once we have this episode, we simple save it to a file like we did the planning results in previousexamples with care to give each episode a different name so that we can view them all. We also added a lineto print the number of steps taken in each learning episode to the terminal so that we can follow its overallprogress as it learns. After that, you can call this method from your main method and run the results This time, in theEpisodeSequenceVisualizer launcher you will find there are 100 episode files in the list, one for eachepisode of learning that occurred. You should find that in the earlier episodes behavior was quite bad, butas the agent experiences the world, its performance became better. You may find that even after a large amountof learning that the behavior is slightly random this randomness is a result of learning using the epsilon greedypolicy which always takes a random action with some probability. Alternatively, you could also capture the finallearning results in a GreedyQPolicy like we did with VI and record those results, instead of the resultswith the learning policy. Note While QLearning adheres to the LearningAgent interface, it is also aninstance of the OOMDPPlanner, which means we could have called the planFromState method on it. For the QLearningalgorithm, the planFromState method will run some number of learning episodes automatically for you. By default it will only run one which is unlikely to yield very good results, but you can adjust the number of episodesit would run, similar to how the VI planner decides to stop planning. Specifically, you can set a maximum number of learningepisodes to run with the setMaxEpisodesForPlanning method, or you can specify a Q-value changethreshold with the setMaxQChangeForPlanningTerminaiton method that will terminate planning when the maximum Q-value change within an episode less than the threshold. Learning with Sarsa A similar learning algorithm to Q-learning is Sarsa. The first difference between the twoalgorithms is that Sarsa updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state see Wikipedia for more information. The second, and larger, difference is that at every time step, Sarsa will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa. public void SarsaLearningExampleString outputPathifoutputPath.endsWithoutputPath outputPath discount 0.99 initialQ0.0 learning rate0.5 lambda1.0LearningAgent agent new SarsaLamdomain, rf, tf, 0.99, hashingFactory, 0., 0.5, 1.0run learning for 100 episodesforint i 0 i 100 iEpisodeAnalysis ea agent.runLearningEpisodeFrominitialStateea.writeToFileString.formatse03d, outputPath, i, spSystem.out.printlni ea.numTimeSteps You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 typicallyyou should use lower learning rates when you have a higher value of . The last parameter ofthe constructor is the value which we set to 1.0. A value of 1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. Otherwise, the rest is the same you can call this method from the main method and give it shot You should findthat learning is much faster than Q-learning when the higher value of is used. Like QLearning, theSarsaLam instance also supports the planning method and the conditions for planning termination can be set in the sameway SarsaLam is actually a subclass of QLearning. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 4", "Note"], "word_count": 1381, "token_count_estimate": 1927}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms or planning algorithms that operate by trying actions in theworld more on that in a bit. To present a live visualization we make use of the ActionObserver interface.Objects that adhere to the ActionObserver interface can be passed to Action objects in a domain. Whenever the actionis executed in a state, the action will automatically inform the the observer of the state, action, nextState eventbefore returning the result to the code that executed the action. You can use this interface to do any kind of analysisyou want, but in this tutorial we will show how we can use a built in VisualActionObserver class to watch learningor planning unfold as it is happening. Note The action observer class only works when the performAction method is called on an action.This means that ActionObservers will work for learning algorithms, in which the agent must sequentiallyinteract with the world, and planning algorithms that try executions of actions. However, you cannot usean ActionObserver to intercept what a planning algorithm like VI does, because VI uses the Actiontransition dynamics to perform planning, rather than taking actions in states. It is worth noting further that theforward search deterministic planning algorithms do work with ActionObserver objects,because the planners operate by applying actions to states. This may have some interesting visualizations,since forward search planning algorithms like A will hop around the state space. To use our VisualActionObserver, first add the necessary import. import burlap.oomdp.singleagent.common.VisualActionObserver Then, we can modify our constructor by adding the following lines to then end of it VisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapSADomainthis.domain.setActionObserverForAllActionobserverobserver.initGUI The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizerwe use the same state visualizer that we used for our EpisodeSequenceVisualizer. The second linetells the domain to add this observer for all actions in the domain. We could have alternatively only added theobserver to specific actions that we wanted to observe, but since we want to watch everything that happens,we added to all actions. The last line will cause a GUI showing the viewer to appear. Now that the observer is set up, try running one of the learning algorithms that weset up previously. You should have a visualizerpop up showing what the agent is doing at each step of learning Note By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelaylong delay method, which takes as an argument the number of ms that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning occurs. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. Nevertheless, it is often useful as a way to confirm that your experimentis working as planned. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. In particularlywe will show how to visualize it for ValueIteration, but you could do the same with Q-Learning, or anyplanninglearning algorithm that implements the QComputablePlanner interface. The first step will be to add our necessary imports. import java.awt.Colorimport java.util.Listimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyph Then we will define a new method in our class to perform this visualization. The method will takea QComputablePlanner object and a policy for it that we wish to visualize. public void valueFunctionVisualizeQComputablePlanner planner, Policy pList State allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactoryLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYspp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphRenderStyle.DISTSCALEDValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, plannergui.setSppsppgui.setPolicypgui.setBgColorColor.GRAYgui.initGUI In the first line, we first define a set of states for which we want the value function and policy visualized.In our example, wed like to simply visualize all the states in our domain, which means we want to findall the states in our domain. We can do this by using the StateReachability tool, which takes as inputan initial state, a single agent domain, a hashing factory to identify and perform equality checks between states, and returnsa list of all states that are reachable from the provided initial state. Note that the GridWorld domainis an instance of the single agent domain class SADomain, so we can type cast it in this way the alternativeis a domain for stochastic games, which involve multiple simultaneously acting agents. For our visualization were going to render the value of a state with a color between red for low values andblue for high values. The LandmarkColorBlendInterpolation class can be used to do this, which you can notehas a landmark added first for red and then for blue. If we wanted to render across more colors like a rainbow scalewe could have continued adding more colors. Following our color blend definition, we then create a 2D value function visualizer, which requires a color blendobject which we just created to define the color shown for the value of states. This class also requiresit to be told which attributes for which class should be used to determine the x and y coordinates to rendereach state. In this case, we want to use the agents X and Y attributes to determine the location on a screen thata state is rendered. We could stop here and only visualize the value function, but it may also be useful to visualize the policyderived. In this case, we will render the policy using a PolicyGlyphPainter2D. Similar to the value functionpainter we defined above, this class needs to be told which attributes for which class correspond to where a statespolicy will be rendered on the screen again we use the agent X and Y attributes. This class alsowants to be told which glyph to paint for each action. We will use the prebuilt ArrowActionGlyph class,which takes as input a direction for an arrow with 0,1,2, and 3 corresponding to a north, south, east, and west arrow glyph,respectively. Finally, The PolicyGlyphPainter2D class also needs to be told how to render a policy. That is, some policiesare stochastic, which requires the painter to determine how to render each glyph for each action based on the probability of thataction being taken by the agent. The PolicyGlyphRenderStyle.MAXACTION specification tells the painter to only render the glyph for the action withthe maximum probability of being selected if there are ties for the max, then all actions that tied for max will be rendered.See the class documentation for the other policy render modes. The final lines of this method create our ValueFunctionVisualizerGUI, which takes the states to render, the objectthat defines how the value function is rendered, and the QComputablePlanner which specifies the value function. The policy and policy painter are optional, so they are passed as arguments through the subsequent method calls. We also setthe background color of the canvas to be grey and then launch the GUI. Try calling this method from the VI method we created earlier, passing it the VI object and its policy, and see what happens. visualize the value function and policythis.valueFunctionVisualizeQComputablePlannerplanner, p You may also want to disable in main the method that activates the offline EpisodeSequenceVisualizer, so that youdo not have two different GUIs floating around. You should get a GUI with colors in each cell of the of the world representing the value function in that state as well as the numeric value written in text the text rendering can be disable if desired, or have its font properties and position manipulated . Additionally,if you check the Show Policy check box at the bottom of the window youll see arrows indicating the policy. The below imageshould resemble what you see. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 5", "Note", "Note"], "word_count": 1421, "token_count_estimate": 2064}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Before we begin, lets import a few more packages and classes that we will use for all the planning and learningalgorithms. import burlap.behavior.singleagent.learning.import burlap.behavior.singleagent.learning.tdmethods.import burlap.behavior.singleagent.planning.import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.singleagent.planning.deterministic.import burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration With those classes imported, lets start by defining the BFS method. public void BFSExampleString outputPathifoutputPath.endsWithoutputPath outputPath BFS ignores reward it just searches for a goal condition satisfying stateDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactory planner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sp The first if condition regarding the outputPath is just to make sure the string is well formed and ends with a and is not very important. The next part of the method actually creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the hashing factory. Planning is then performed by simply callingthe planFromState method on the planner and passing it the initial state form which it should plan. After thismethod completes, the plan will be stored inside the BFS object. It might seem a little strange that this methoddoes not simply return a sequence of actions or something of the sort. The reason it does not is becausenot all planning and learning algorithms compute a sequence of actions. In particular, stochastic planners and plannersthat compute solutions for non-terminating tasks compute a policy rather than a sequence of actions. Because theDeterministicPlanner class is also a subclass of the OOMDPPlanner class, which is used as a superclass for allplanning algorithms, the common planFromState method does not return anything. Since the planFromState method does not explicitly return the plan results, we will instead capture it using aPolicy class, which is more general for capturing solutions with any number of planners and allows flexibility indetermining how the solution is captured. For capturing the plan solution of deterministic planners, the SDPlannerPolicy class may be used, whose constructor takes as a parameter a DeterministicPlanner object. Sincemany deterministic planners will compute a sequence of actions to take from the initialstate, the SDPlannerPolicy will only be defined for states along the path to the solution. If you wanted somethingslightly more general that will return an answer for states not on the solution path,you could instead use the DDPlannerPolicy class which will compute the solution using the specifiedplanner if the planner had not yet computed the solution for the state for which the policy was queried. Once you have a Policy object, you can extract an entire episode from it by calling the evaluateBehavior method. There are a few different versions of the evaluateBehavior method which take different parameters to determine theanalysis and stopping criteria. In this case, however, we are passing it the initial state from which the policy shouldstart being followed, the reward function used to assess the performance and the the termination function whichspecifies when the policy should stop. The method will return an EpisodeAnalysis object which will containall of the states visited, actions taken, and rewards received when following that policy. You can investigate these individual elements of the episode if you like,but for this tutorial were just going to save the results of this episode to a file and then use the offlinevisualizer we previously defined to view it. An EpisodeAnalysis objectcan be written to a file by calling the writeToFile method on it and passing it a path to the file andthe state parser to use.Note that the method will automatically append a .episode extension to the file path if you did not specify it yourself. And thats all you need to code to plan with BFS on a defined domain and task Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultsrun exampleexample.BFSExampleoutputPathrun the visualizerexample.visualizeoutputPath And with the planning method hooked up, run the code Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search DFS. Define the below method to providea means to solve the task with DFS. public void DFSExampleString outputPathifoutputPath.endsWithoutputPath outputPath DFS ignores reward it just searches for a goal condition satisfying stateDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryplanner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sp You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you Planning with A One of the most well known optimal search-based planning algorithms is A. A is an informed planner because it takesas input an admissible heuristic which estimates the cost to the goal from any given state. We can also use A to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use. The below code defines a methodfor using A with a Manhattan distance to goal heuristic. public void AStarExampleString outputPathifoutputPath.endsWithoutputPath outputPath Heuristic mdistHeuristic new Heuristic Overridepublic double hState s String an GridWorldDomain.CLASSAGENTString ln GridWorldDomain.CLASSLOCATIONObjectInstance agent s.getObjectsOfTrueClassan.get0 ObjectInstance location s.getObjectsOfTrueClassln.get0 get agent positionint ax agent.getDiscValForAttributeGridWorldDomain.ATTXint ay agent.getDiscValForAttributeGridWorldDomain.ATTYget location positionint lx location.getDiscValForAttributeGridWorldDomain.ATTXint ly location.getDiscValForAttributeGridWorldDomain.ATTYcompute Manhattan distancedouble mdist Math.absax-lx Math.absay-lyreturn -mdistprovide A the heuristic as well as the reward function so that it can keeptrack of the actual costDeterministicPlanner planner new AStardomain, rf, goalCondition, hashingFactory, mdistHeuristicplanner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sp There are two main differences between this method and the methods that we wrote for BFS and DFSplanning. The smaller difference is that the A constructor takes the reward function andheuristic as parameters. The reward function is needed because it is what A uses to keep trackof the actual cost of any path it is exploring. Note A is an algorithm that operates on costs and is not an algorithm that can workwith negative costs. BURLAP in general represents state-action evaluations as rewards ,rather than costs. However, a cost can be represented as a negative reward therefore,the reward function provided to A should return negative values. If the rewardfunction returns any positive values, A will not function properly. Since our examples reward functionreturns only negative values it returns -1 for every state-action pair, our reward function will workfine with A. The bigger difference between the previous planning code and A is in defining theheuristic, which we will explain in more detail. First note that the heuristic follows a standard interface for which we have may an anonymous java class. The h method of the classis passed a state object and the method should return the estimated reward to the goal fromthat state. Since we have opted to use the Manhattan distance as our heuristic, this will involvecomputing the distance between the agent position and the location position for which we will assumethere is only one. To compute this difference, the method will first need to extract the agentobject instance and the location object instance out of the state, which is done in lines 16 and 17.Specifically, the getObjectsOfTrueClass method of a state will return the list of objectsin the state that belong to the class with the specified name. Since the task we are solving willonly have one agent object and one location object, we can then just return the 0th indexedobjects in each of those respective lists. Lines 20-25 then extract the integer values for theX and Y attributes of both objects. Once those attribute values are retrieved, the Manhattan distanceis computed and returned in lines 28-30. Note that the negative distance is returned, because our reward functionreturns -1 for each step. With the rest of the code being the same, you can have the main method call the A method for planningand view the results in the usual way Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 3", "Note"], "word_count": 1751, "token_count_estimate": 2465}}, "http://burlap.cs.brown.edu/tutorials_v1/bpl/p6.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials v1 Basic Planning and Learning Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an ActionObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another ActionObserver calledPerformancePlotter to record a learning algorithms performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If youd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. First, add the following imports import burlap.oomdp.auxiliary.StateGeneratorimport burlap.oomdp.auxiliary.common.ConstantStateGeneratorimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialMode Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will setup the new reward function using aninstance of the GoalBasedRF which takes a StateCondition test object to specify goal conditions which we have already set up previously in the tutorial for our search algorithms like BFS, a goal reward, and a default reward for all non-goal states. public void experimenterAndPlottercustom reward function for more interesting resultsfinal RewardFunction rf new GoalBasedRFthis.goalCondition, 5., -0.1 For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To be able to easily get a clean version of each agent the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA algorithm. Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-learningOverridepublic LearningAgent generateAgent return new QLearningdomain, rf, tf, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory Overridepublic String getAgentName return SARSAOverridepublic LearningAgent generateAgent return new SarsaLamdomain, rf, tf, 0.99, hashingFactory, 0.0, 0.1, 1. Note that the factory also requires a getAgentName method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithms performance. For experimentation, the LearningAlgorithmExperimenter will also need to able to generate a new state for the beginningof each episode. In some tasks we might consider generating a random start state for each episode, but for simplifyingpurposes we will consider a task that always starts in the bottom left hand corner of the world, like we didin our previous planning and learning examples of the this tutorial. We can make a state generator that alwaysreturns the same initial state using the BURLAP provided ConstantStateGenerator. StateGenerator sg new ConstantStateGeneratorthis.initialState With the task and learning algorithms now decided, we are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterthis.domain, rf, sg, 10, 100, qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpData Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plots width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window again, filling columns first. The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method weve created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, youll note that a translucent filled area around each of the curves is present. This filledarea shows the 95 confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, youll find a number of other options that you can set, includingchanging the labels. Another important feature youll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it createdexpDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data even for the metrics that we did not plot. Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code youve created The complete set of code that we wrote in this tutorial is shownbelow for your convenience. You can also download the .java file direction from here . import java.awt.Colorimport java.util.Listimport burlap.behavior.singleagent.import burlap.domain.singleagent.gridworld.import burlap.oomdp.core.import burlap.oomdp.singleagent.import burlap.oomdp.singleagent.common.import burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.behavior.singleagent.learning.import burlap.behavior.singleagent.learning.tdmethods.import burlap.behavior.singleagent.planning.import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.singleagent.planning.deterministic.import burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIterationimport burlap.oomdp.visualizer.Visualizerimport burlap.oomdp.auxiliary.StateGeneratorimport burlap.oomdp.auxiliary.StateParserimport burlap.oomdp.auxiliary.common.ConstantStateGeneratorimport burlap.behavior.singleagent.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.import burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2D.PolicyGlyphRenderStyleimport burlap.oomdp.singleagent.common.VisualActionObserverpublic class BasicBehavior GridWorldDomain gwdgDomaindomainStateParser spRewardFunction rfTerminalFunctiontfStateConditionTestgoalConditionState initialStateDiscreteStateHashFactoryhashingFactorypublic static void mainString args BasicBehavior example new BasicBehaviorString outputPath output uncomment the example you want to see and comment-out the restexample.BFSExampleoutputPathexample.DFSExampleoutputPathexample.AStarExampleoutputPathexample.ValueIterationExampleoutputPathexample.QLearningExampleoutputPathexample.SarsaLearningExampleoutputPathexample.experimenterAndPlotterrun the visualizer only use if you dont use the experiment plotter exampleexample.visualizeoutputPathpublic BasicBehaviorcreate the domaingwdg new GridWorldDomain11, 11gwdg.setMapToFourRooms domain gwdg.generateDomaincreate the state parsersp new GridWorldStateParserdomain define the taskrf new UniformCostRF tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATION goalCondition new TFGoalConditiontfset up the initial state of the taskinitialState GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10set up the state hashing systemhashingFactory new DiscreteStateHashFactoryhashingFactory.setAttributesForClassGridWorldDomain.CLASSAGENT, domain.getObjectClassGridWorldDomain.CLASSAGENT.attributeList add visual observerVisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapSADomainthis.domain.setActionObserverForAllActionobserverobserver.initGUIpublic void visualizeString outputPathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapEpisodeSequenceVisualizer evis new EpisodeSequenceVisualizerv, domain, sp, outputPathpublic void BFSExampleString outputPathifoutputPath.endsWithoutputPath outputPath BFS ignores reward it just searches for a goal condition satisfying stateDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactory planner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sppublic void DFSExampleString outputPathifoutputPath.endsWithoutputPath outputPath DFS ignores reward it just searches for a goal condition satisfying stateDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryplanner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sppublic void AStarExampleString outputPathifoutputPath.endsWithoutputPath outputPath Heuristic mdistHeuristic new Heuristic Overridepublic double hState s String an GridWorldDomain.CLASSAGENTString ln GridWorldDomain.CLASSLOCATIONObjectInstance agent s.getObjectsOfTrueClassan.get0 ObjectInstance location s.getObjectsOfTrueClassln.get0 get agent positionint ax agent.getDiscValForAttributeGridWorldDomain.ATTXint ay agent.getDiscValForAttributeGridWorldDomain.ATTYget location positionint lx location.getDiscValForAttributeGridWorldDomain.ATTXint ly location.getDiscValForAttributeGridWorldDomain.ATTYcompute Manhattan distancedouble mdist Math.absax-lx Math.absay-lyreturn -mdistprovide A the heuristic as well as the reward function so that it can keeptrack of the actual costDeterministicPlanner planner new AStardomain, rf, goalCondition, hashingFactory, mdistHeuristicplanner.planFromStateinitialStatecapture the computed plan in a partial policyPolicy p new SDPlannerPolicyplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, sppublic void ValueIterationExampleString outputPathifoutputPath.endsWithoutputPath outputPath OOMDPPlanner planner new ValueIterationdomain, rf, tf, 0.99, hashingFactory,0.001, 100planner.planFromStateinitialStatecreate a Q-greedy policy from the plannerPolicy p new GreedyQPolicyQComputablePlannerplannerrecord the plan results to a filep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath planResult, spvisualize the value function and policythis.valueFunctionVisualizeQComputablePlannerplanner, ppublic void QLearningExampleString outputPathifoutputPath.endsWithoutputPath outputPath discount 0.99 initialQ0.0 learning rate0.9LearningAgent agent new QLearningdomain, rf, tf, 0.99, hashingFactory, 0., 0.9run learning for 100 episodesforint i 0 i 100 iEpisodeAnalysis ea agent.runLearningEpisodeFrominitialStateea.writeToFileString.formatse03d, outputPath, i, sp System.out.printlni ea.numTimeStepspublic void SarsaLearningExampleString outputPathifoutputPath.endsWithoutputPath outputPath discount 0.99 initialQ0.0 learning rate0.5 lambda1.0LearningAgent agent new SarsaLamdomain, rf, tf, 0.99, hashingFactory,0., 0.5, 1.0run learning for 100 episodesforint i 0 i 100 iEpisodeAnalysis ea agent.runLearningEpisodeFrominitialStateea.writeToFileString.formatse03d, outputPath, i, spSystem.out.printlni ea.numTimeStepspublic void valueFunctionVisualizeQComputablePlanner planner, Policy pList State allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactoryLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX, GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYspp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphRenderStyle.DISTSCALEDValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, plannergui.setSppsppgui.setPolicypgui.setBgColorColor.GRAYgui.initGUIpublic void experimenterAndPlottercustom reward function for more interesting resultsfinal RewardFunction rf new GoalBasedRFthis.goalCondition, 5., -0.1 Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-learningOverridepublic LearningAgent generateAgent return new QLearningdomain, rf, tf, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory Overridepublic String getAgentName return SARSAOverridepublic LearningAgent generateAgent return new SarsaLamdomain, rf, tf, 0.99, hashingFactory, 0.0, 0.1, 1.StateGenerator sg new ConstantStateGeneratorthis.initialStateLearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterSADomainthis.domain, rf, sg, 10, 100, qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpData End.", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 6"], "word_count": 1848, "token_count_estimate": 3965}}, "http://burlap.cs.brown.edu/tutorials_v1/cpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials v1 Creating a Planning and Learning Algorithm Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 1 if youd like the BURLAP 2 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP on domains in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here, such as support for planning and learning with Options temporally extended actions. Using options in BURLAP will be left for a future tutorial. Value Iteration Overview Value Iteration VI is an algorithm that finds the optimal value function the expected discounted future reward of being in a state an behaving optimally from it, and consequentially the optimal policy, for an MDPs entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return the action with the maximum Q-value where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In math where Ts s, a is the probability of transitioning to state s when taking action a in state s, Rs, a, s is the reward received for transitioning to state s after taking action a in state s, and gamma is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, its unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal Value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming DP planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function Vs arbitrarily for all states s. Repeat until convergence... For each state s Vs maxa sums Ts s, a Rs,a,s Vs Since there are a number of different DP algorithms that can be implemented, BURLAP includes a macro abstract planning algorithm class called ValueFunctionPlanner that includes a number of helpful methods for automatically performing Bellman Updates on states. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch. The only classes and interfaces well use are the OOMDPPlanner abstract class and the QComputablePlanner interface, which will set up a bunch of common data members for us and provide the common planning method interfaces that will let our planning algorithm implementation talk to other BURLAP tools. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 1"], "word_count": 729, "token_count_estimate": 874}}, "http://burlap.cs.brown.edu/tutorials_v1/cpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials v1 Creating a Planning and Learning Algorithm Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part Q-Learning Overview For our learning algorithm example, well be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning 1 to learn a model of the world from experience and then use planning with that learned model to dictate behavior model-based and 2 to learn a policy or value function directly from experience model-free. Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values Qs,a arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action a in the current world state s based on current Q-value estimates Qs,. Take the action a and observe the the outcome state s and reward r. Update Q-value estimate for previous state-action pair Qs,a based on observed next state s and reward r. The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates step 3, but one of the most common is to use an -greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction 1- of the time where is a fraction between 0 and 1, and randomly selected among all actions a fraction of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. For updating the Q-value of the last state-action pair s,a with respect to the observed outcome state s and reward r, Q-learning uses the following update rule where is a learning rate parameter between 0 and 1. Recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, were not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, well see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, its often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, well use a fixed value for the learning rate rather that one that changes with time though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface. Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend OOMDPPlaner and implement the QComputablePlanner and LearningAgent interfaces. It might seem strange that we will extend the OOMDPPlanner class, since this is a learning algorithm however, we sub class OOMDPPlanner because the class provides us a number of the same data members and methods well need. Moreover, Although not all planning algorithms could be used for learning, all learning algorithms can be used for planning, since learning problems could always be applied in simulation. Since Q-learning estimates Q-values, the QComputablePlanner interface lets that knowledge be conveyed to other BURLAP tools like Q-derived policies. Finally, the LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class, with the exception that we added an UnsupportedOperation exception to the planFromStateMethod. As noted above, we could implement planning by just simulating multiple learning episodes from the input state, but for this tutorial we will not bother. import java.util.Listimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.QValueimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.planning.OOMDPPlannerimport burlap.behavior.singleagent.planning.QComputablePlannerimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Statepublic class QLTutorial extends OOMDPPlanner implements QComputablePlanner,LearningAgent Overridepublic EpisodeAnalysis runLearningEpisodeFromState initialState TODO Auto-generated method stubreturn nullOverridepublic EpisodeAnalysis runLearningEpisodeFromState initialState,int maxSteps TODO Auto-generated method stubreturn nullOverridepublic EpisodeAnalysis getLastLearningEpisode TODO Auto-generated method stubreturn nullOverridepublic void setNumEpisodesToStoreint numEps TODO Auto-generated method stubOverridepublic ListEpisodeAnalysis getAllStoredLearningEpisodes TODO Auto-generated method stubreturn nullOverridepublic ListQValue getQsState s TODO Auto-generated method stubreturn nullOverridepublic QValue getQState s, AbstractGroundedAction a TODO Auto-generated method stubreturn nullOverridepublic void planFromStateState initialState throw new UnsupportedOperationExceptionWe are not supporting planning for this tutorial.Overridepublic void resetPlannerResults TODO Auto-generated method stub Similar to ValueIteration, the primary data we will want to store is a set of estimated Q-values for each state. Well also again let the user specify the Q-value function initialization with a ValueFunctionInitialization object. Well also need a learning rate parameter to be set. Finally, well need a learning policy to follow that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, well assume an -greedy policy and let the client specify the value for . Lets add data members for those elements now. import java.util.Mapimport burlap.behavior.singleagent.ValueFunctionInitializationimport burlap.behavior.statehashing.StateHashTupleimport burlap.behavior.singleagent.Policy protected MapStateHashTuple, ListQValue qValuesprotected ValueFunctionInitialization qinitprotected double learningRateprotected Policy learningPolicy Lets also add a constructor for all our data members. import java.util.HashMapimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.behavior.statehashing.StateHashFactory public QLTutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilonthis.plannerInitdomain, rf, tf, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMapStateHashTuple, ListQValuethis.learningPolicy new EpsilonGreedythis, epsilon Note that the EpsilonGreedy policy object we create takes as input the planninglearning algorithm that implements the QComputablePlanner interface, and the value for epsilon to use. One of the primary tools well need is a method that grabs our Q-values, or creates and stores them with the proper initialization value if its for an unseen state. Lets implement our Q-Value methods now. import java.util.ArrayListimport burlap.oomdp.singleagent.GroundedAction Overridepublic ListQValue getQsState s first get hashed stateStateHashTuple sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListGroundedAction actions this.getAllGroundedActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforGroundedAction ga actionsadd q with initialized valueqs.addnew QValues, ga, this.qinit.qValues, gastore this for laterthis.qValues.putsh, qsreturn qsOverridepublic QValue getQState s, AbstractGroundedAction a first get all Q-valuesListQValue qs this.getQsstranslate action parameters to source state for Q-values if neededa a.translateParameterss, qs.get0.siterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value. The only part of that code that probably needs any additional elaboration is the translate action parameters part. Recall that in an OO-MDP unless otherwise specified, two states can be identical even if the object namesreferences are different as long as there is a bijection between the objects of the states. refer back to the Building a Domain tutorial for more information. Therefore, its possible that the input state for which were trying to get the Q-values is equal to a stored state that has different object identifiers. If our actions are not parameterized, there is no issue here. However, if actions are parameterized to objects in the world, we may need to map the parameters from the input stateaction to the storedstate action before we can determine which corresponding action is a match. For example, if we were learning in a blocks world and the action was pickup block0 in our input state, but block0 corresponded to block6 in our stored stated, then wed want to return the Q-value for pickup block6 . The translateParameters method of our action takes as input a source state and a target state then it finds a mapping for the parameters of the action in the source state to the target state and returns a new GroundedAction using those parameters. That is, if applied to pickup block0, it would return pickup block6. For code clarity, lets also implement a method that takes a state and returns the maximum Q-value for the state. protected double maxQState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble max Double.NEGATIVEINFINITYforQValue q qsmax Math.maxq.q, maxreturn max One important element in that method to pay attention to is the fact that we first check if the input state is a terminal state and return 0 if it is. Like with our previous VI code, this check is important, because the definition of a terminal state is a state from which all action stops and we need to make sure they return max Q-values of of 0 when we update the Q-values for state action-pairs that lead to them. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We well have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an EpisodeAnalysis object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, well record the results to an EpisodeAnalysis object. Below is the learning algorithm code for Q-learning. Overridepublic EpisodeAnalysis runLearningEpisodeFromState initialState return this.runLearningEpisodeFrominitialState, -1Overridepublic EpisodeAnalysis runLearningEpisodeFromState initialState,int maxSteps initialize our episode analysis object with the given initial stateEpisodeAnalysis ea new EpisodeAnalysisinitialStatebehave until a terminal state or max steps is reachedState curState initialStateint steps 0whilethis.tf.isTerminalcurState steps maxSteps maxSteps -1select an actionAbstractGroundedAction a this.learningPolicy.getActioncurStatetake the action and observe outcomeState nextState a.executeIncurStatedouble r this.rf.rewardcurState, GroundedActiona, nextStaterecord resultea.recordTransitionToGroundedActiona, nextState, rupdate the old Q-valueQValue oldQ this.getQcurState, aoldQ.q oldQ.q this.learningRate r this.gamma this.maxQnextState - oldQ.qmove on to next statecurState nextStatestepsreturn ea You should notice that the code reflects our earlier written pseudocode for Q-learning quite closely One thing you might be wondering is whether any action parameter translation might have needed to occur in the action selection, similar to how it needed to happen when matching Q-values up with a given action. It would however, we actually do not have to worry, because our Q-value derived Policy classes e.g., EpsilonGreedy handle any necessary parameter translation from the Q-values to the input state automatically for us With that out of the way, were just about finished. The last things we want to do are largely auxiliary. In particular, LearningAgent classes are asked to store the last N learning episodes so that they can be retrieved later. Lets add a data member for storing a list of the last set of learning episodes, how many to store, and then add to the end of our runLearningEpisode method code that adds the last episode to the list of most recent episodes and removes old episodes if our storage is over the requested limit. import java.util.LinkedList protected LinkedListEpisodeAnalysis storedEpisodes new LinkedListEpisodeAnalysisprotected int maxStoredEpisodes 1 whilethis.storedEpisodes.size this.maxStoredEpisodesthis.storedEpisodes.pollthis.storedEpisodes.offerea Now we can implement the methods related to getting previous learning episodes. Overridepublic EpisodeAnalysis getLastLearningEpisode return this.storedEpisodes.getLastOverridepublic void setNumEpisodesToStoreint numEps this.maxStoredEpisodes numEpswhilethis.storedEpisodes.size this.maxStoredEpisodesthis.storedEpisodes.pollOverridepublic ListEpisodeAnalysis getAllStoredLearningEpisodes return this.storedEpisodes Finally, we can implement the resetPlannerResults method, which only needs to clear our Q-values. Overridepublic void resetPlannerResults this.qValues.clear Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates the same Grid World domain and task as the test code we wrote for our VI implementation. Also as before, after learning for a number of episodes, it will take the greedy policy, roll it out once, and print out the actions taken. You should again find that only north and east actions are taken. import burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.oomdp.singleagent.common.UniformCostRF public static void mainString argsGridWorldDomain gwd new GridWorldDomain3, 3gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup Q-learning with 0.99 discount factor, discrete state hashing factory, a valuefunction initialization that initializes all Q-values to value 0, a learning rateof 0.1 and an epsilon value of 0.1.QLTutorial ql new QLTutorialdomain, rf, tf, 0.99, new DiscreteStateHashFactory, new ValueFunctionInitialization.ConstantValueFunctionInitialization1., 0.1, 0.1run learning for 1000 episodesforint i 0 i 1000 iEpisodeAnalysis ea ql.runLearningEpisodeFromsSystem.out.printlnEpisode i took ea.numTimeSteps steps.get the greedy policy from itPolicy p new GreedyQPolicyqlevaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea p.evaluateBehaviors, rf, tfSystem.out.printlnea.getActionSequenceStringn Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 3"], "word_count": 2289, "token_count_estimate": 3575}}, "http://burlap.cs.brown.edu/tutorials_v1/cpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials v1 Creating a Planning and Learning Algorithm Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAPs existing implementations of Value Iteration and Q-Learning since they support a number of other features Options, learning rate decay schedules, etc.. If you would like to see all of the code that was written in this tutorial, we have provided it below first the Value Iteration code , then the Q-learning Code . Full VI Code import java.util.ArrayListimport java.util.HashMapimport java.util.LinkedListimport java.util.Listimport java.util.Mapimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.QValueimport burlap.behavior.singleagent.ValueFunctionInitializationimport burlap.behavior.singleagent.planning.OOMDPPlannerimport burlap.behavior.singleagent.planning.QComputablePlannerimport burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.behavior.statehashing.StateHashFactoryimport burlap.behavior.statehashing.StateHashTupleimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.Stateimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.UniformCostRFpublic class VITutorial extends OOMDPPlanner implements QComputablePlanner protected MapStateHashTuple, Double valueFunctionprotected ValueFunctionInitialization vinitprotected int numIterationspublic VITutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization vinit, int numIterationsthis.plannerInitdomain, rf, tf, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapStateHashTuple, DoubleOverridepublic ListQValue getQsState s ListGroundedAction applicableActions this.getAllGroundedActionssListQValue qs new ArrayListQValueapplicableActions.sizeforGroundedAction ga applicableActionsqs.addthis.getQs, gareturn qsOverridepublic QValue getQState s, AbstractGroundedAction a type cast to the type were usingGroundedAction ga GroundedActionawhat are the possible outcomesListTransitionProbability tps ga.action.getTransitionss, ga.paramsaggregate over each possible outcomedouble q 0.forTransitionProbability tp tpswhat is reward for this transitiondouble r this.rf.rewards, ga, tp.swhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.sadd contribution weighted by transition probabiltiy and discounting the next stateq tp.p r this.gamma vpcreate Q-value wrapperQValue qValue new QValues, ga, qreturn qValueprotected double bellmanEquationState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble maxQ Double.NEGATIVEINFINITYforQValue q qsmaxQ Math.maxmaxQ, q.qreturn maxQOverridepublic void planFromStateState initialState StateHashTuple hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforStateHashTuple sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, this.bellmanEquationsh.sOverridepublic void resetPlannerResults this.valueFunction.clearpublic void performReachabilityFromState seedStateStateHashTuple hashedSeed this.hashingFactory.hashStateseedStatemark our seed state as seen and set its initial value function valuethis.valueFunction.puthashedSeed, this.vinit.valuehashedSeed.sLinkedListStateHashTuple open new LinkedListStateHashTupleopen.offerhashedSeedwhileopen.size 0pop off a state and expand itStateHashTuple sh open.pollwhich actions can be applied on this stateListGroundedAction appliactionActions this.getAllGroundedActionssh.sfor each action...forGroundedAction ga appliactionActionswhat are the possible outcomesListTransitionProbability tps ga.action.getTransitionssh.s, ga.paramsfor each possible outcome...forTransitionProbability tp tpsadd previously unseed states to our open queue and set their initial value functionStateHashTuple shp this.hashingFactory.hashStatetp.sifthis.valueFunction.containsKeyshpthis.valueFunction.putshp, this.vinit.valueshp.sopen.offershppublic static void mainString argsGridWorldDomain gwd new GridWorldDomain3, 3gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup vi with 0.99 discount factor, discrete state hashing factory, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, rf, tf, 0.99, new DiscreteStateHashFactory, new ValueFunctionInitialization.ConstantValueFunctionInitialization0.0, 30run planning from our initial statevi.planFromStatesget the greedy policy from itPolicy p new GreedyQPolicyvievaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea p.evaluateBehaviors, rf, tfSystem.out.printlnea.getActionSequenceStringn Full Q-Learning Code import java.util.ArrayListimport java.util.HashMapimport java.util.LinkedListimport java.util.Listimport java.util.Mapimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.QValueimport burlap.behavior.singleagent.ValueFunctionInitializationimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.planning.OOMDPPlannerimport burlap.behavior.singleagent.planning.QComputablePlannerimport burlap.behavior.singleagent.planning.commonpolicies.EpsilonGreedyimport burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.behavior.statehashing.StateHashFactoryimport burlap.behavior.statehashing.StateHashTupleimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.Stateimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.UniformCostRFpublic class QLTutorial extends OOMDPPlanner implements QComputablePlanner,LearningAgent protected MapStateHashTuple, ListQValue qValuesprotected ValueFunctionInitialization qinitprotected double learningRateprotected Policy learningPolicyprotected LinkedListEpisodeAnalysis storedEpisodes new LinkedListEpisodeAnalysisprotected int maxStoredEpisodes 1public QLTutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization qinit,double learningRate, double epsilonthis.plannerInitdomain, rf, tf, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMapStateHashTuple, ListQValuethis.learningPolicy new EpsilonGreedythis, epsilonOverridepublic EpisodeAnalysis runLearningEpisodeFromState initialState return this.runLearningEpisodeFrominitialState, -1Overridepublic EpisodeAnalysis runLearningEpisodeFromState initialState,int maxSteps initialize our episode analysis object with the given initial stateEpisodeAnalysis ea new EpisodeAnalysisinitialStatebehave until a terminal state or max steps is reachedState curState initialStateint steps 0whilethis.tf.isTerminalcurState steps maxSteps maxSteps -1select an actionAbstractGroundedAction a this.learningPolicy.getActioncurStatetake the action and observe outcomeState nextState a.executeIncurStatedouble r this.rf.rewardcurState, GroundedActiona, nextStaterecord resultea.recordTransitionToGroundedActiona, nextState, rupdate the old Q-valueQValue oldQ this.getQcurState, aoldQ.q oldQ.q this.learningRate r this.gamma this.maxQnextState - oldQ.qmove on to next statecurState nextStatestepswhilethis.storedEpisodes.size this.maxStoredEpisodesthis.storedEpisodes.pollthis.storedEpisodes.offereareturn eaOverridepublic EpisodeAnalysis getLastLearningEpisode return this.storedEpisodes.getLastOverridepublic void setNumEpisodesToStoreint numEps this.maxStoredEpisodes numEpswhilethis.storedEpisodes.size this.maxStoredEpisodesthis.storedEpisodes.pollOverridepublic ListEpisodeAnalysis getAllStoredLearningEpisodes return this.storedEpisodesOverridepublic ListQValue getQsState s first get hashed stateStateHashTuple sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListGroundedAction actions this.getAllGroundedActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforGroundedAction ga actionsadd q with initialized valueqs.addnew QValues, ga, this.qinit.qValues, gastore this for laterthis.qValues.putsh, qsreturn qsOverridepublic QValue getQState s, AbstractGroundedAction a first get all Q-valuesListQValue qs this.getQsstranslate action parameters to source state for Q-values if neededa a.translateParameterss, qs.get0.siterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value.protected double maxQState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble max Double.NEGATIVEINFINITYforQValue q qsmax Math.maxq.q, maxreturn maxOverridepublic void planFromStateState initialState throw new UnsupportedOperationExceptionWe are not supporting planning for this tutorial.Overridepublic void resetPlannerResults this.qValues.clearpublic static void mainString argsGridWorldDomain gwd new GridWorldDomain3, 3gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup Q-learning with 0.99 discount factor, discrete state hashing factory, a valuefunction initialization that initializes all Q-values to value 0, a learning rateof 0.1 and an epsilon value of 0.1.QLTutorial ql new QLTutorialdomain, rf, tf, 0.99, new DiscreteStateHashFactory, new ValueFunctionInitialization.ConstantValueFunctionInitialization1., 0.1, 0.1run learning for 1000 episodesforint i 0 i 1000 iEpisodeAnalysis ea ql.runLearningEpisodeFromsSystem.out.printlnEpisode i took ea.numTimeSteps steps.get the greedy policy from itPolicy p new GreedyQPolicyqlevaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea p.evaluateBehaviors, rf, tfSystem.out.printlnea.getActionSequenceStringn End.", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 4"], "word_count": 975, "token_count_estimate": 2709}}, "http://burlap.cs.brown.edu/tutorials_v1/index.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorials v1 You are viewing the tutorials for BURLAP 1 if youd like the BURLAP 2 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. Video Tutorials Text Tutorials Hello Grid World - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorials (v1)", "Video Tutorials"], "word_count": 85, "token_count_estimate": 111}}, "http://burlap.cs.brown.edu/tutorials_v1/hgw/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Hello Grid World Tutorials v1 Hello Grid World Part 1 Tutorial Contents Introduction Acquiring BURLAP Dependencies Running the JAR Hello Grid World Code Testing Plotting Tools Notes on the Java Heap Size Conclusions You are viewing the tutorial for BURLAP 1 if youd like the BURLAP 2 tutorial, go here . Introduction In this tutorial we will walk you through downloading BURLAP and making sure you can run it. We willwalk through the instructions to both download the JAR from the precompiled source as wellas how to get the source code and compile it yourself. If you only want to do it one way, feel free to only look at that section. Either way, it should be very straightforward After thecode has been downloaded, well show you a simple way to make sure its working and then showyou how to easily create code that links to it. For more instructions on how write meaningfulcode with BURLAP and what it does, you should see the other tutorials. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Acquiring BURLAP There are two ways to acquire BURLAP. You can either download the pre-compiled JAR file either with or without dependencies includedor compile it from the source code. In general, the source code will have the latest versionand the pre-compiled JAR may be a bit older, but should be stable. Downloading the Pre-compiled JAR For the prec-compiled jar, you can either get one with the dependencies includein the jar, or without them included. You can get either from these locations the pre-compiled jar with dependencies included the pre-compiled jar with out dependencies. Use the jar without the dependencies if you are having library conflictsand need to manage them yourself. If you use the jar without dependencies,we will walk through how to include them manually in the below dependencies section . After downloading the BURLAP jar file, you can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it testcode, but you can name it anything you want. Within that directory, create a new subdirectory called lib and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following testcodelibburlap.jar Or burlapnodep.jar instead of burlap.jar if you downloaded the version without dependencies. Compiling From the source The easiest way to get the source is with git . If you do not have git installed, install it now. You can download git from here . To compile the code,you will also need ant installed, which you can get from here if you do not already have it. Create a directory where you will place the git distribution. You might have a git directory in your home directory already created for this, which you can use. From the command line, change directories there now. Now enter the following command git clone httpsgithub.comjmacglashanburlap.git You should have found that this created the directory named burlap. Change into that directory now and you should find the following files and subdirectories libsrcLICENSEREADME.mdbuild.xml Now type ant dist And you should find new subdirectories appear in particular, the dist directory whichwill contain the BURLAP JAR file. If there were compilation errors warnings should not be a concern its possible that you will need to re-download the dependencies. For convenience,BURLAPs git repository includes the dependencies that it needs, but its possible you may haveto install them yourself see the Dependencies section and place all the JARs on which BURLAP depends in the lib directory and try ant again. With the burlap.jar file created well now try working with it. You can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it testcode, but you can name it anything you want. Within that directory, create a new subdirectory called lib and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following testcodelibburlap.jar Dependencies Most of BURLAP can be run without any of its dependencies,but some of the algorithms and advanced tools will requireother libraries to be present. For example, the RLGluedependency allows BURLAP to communicate with other RLsoftware. If you are using the pre-compiled BURLAP jar that has dependencies included,you can skip this step. If you are using a compiled version of BURLAP or the jar without dependencesand you want to use all of BURLAPs features you should get the relevant JAR files and put them in the lib directory of the testcode directory thatwe created. If you compiled BURLAP from source, you can just copy the files in the BURLAP source lib directory into our testcode lib directory. Otherwise, you can download the dependencies and their dependencies from the below locations RLGlue Java Codec - You will need this if you plan on interfacing BURLAP with RLGLue . Apache Math Commons - For performance plotting tools. JFree Chart - For Performance Plotting tools. Snake YAML - For reading and writing states into the YAML format. Jackson - For reading and writing states into the JSON format. JOptimizer - For Max Margin Apprenticeship Learning SCPSolver - For Minmax, Coco-Q, and Correlated-Q algorithms. Our choice of underlying LP solver that it uses is lpsolve. After putting all the relevant dependencies in the lib folder,your directory structure should look something like the following. testcodelibburlap.jarJavaRLGlueCodec.jarLPSOLVESolverPack.jarSCPSolver.jarcolt-1.2.0.jarcommons-beanutils-1.6.jarcommons-collections-2.1.jarcommons-lang3-3.1.jarcommons-logging-1.1.1.jarcommons-math3-3.2.jarcsparsej-1.1.1.jarejml-0.25.jarhamcrest-core-1.3.jarjackson-annotations-2.2.3.jarjackson-core-2.2.3.jarjackson-databind-2.2.3.jarjcommon-1.0.21.jarjfreechart-1.0.17.jarjoptimizer-3.2.0.jarjoptimizer-3.3.0.jarjunit-4.11.jarlog4j-1.2.14.jarservlet.jarsnakeyaml-1.13.jarxml-apis-1.0.b2.jar Running the JAR The simplest way to test BURLAP is to run the default main method in the GridWorld domain generator, which will launch a simple interactive visualization of the GridWorld. From the command line, change directory into your testcode directory if youre not already there. Then enter java -cp lib. burlap.domain.singleagent.gridworld.GridWorldDomain Note the the . after lib which adds the current directory the class path. Some users have reported errors unless that is included, even though we havent actually written any of our own code yet If youre in the Windows command prompt and not cygwin, you may need to change the colon character to a semicolon. If a GUI of a simple GridWorld appears, as shown below, then everything is working There are two ways to control the agent in the GUI. One way is to use keystrokes, whichyou can perform by clicking on the visualization and then pressing either the w, a, s, or d keys you only need to click on the visualization once to get it to start acceptingkey strokes. Alternatively, you can use the execute text field and button. In the executetext field you can enter the name of the action you want the agent to perform and then pressthe execute button to have it performed. In GridWorld, the actions you can have the agentperform are named north, south, east, and west. Hello Grid World Code Were now going to write a simple BURLAP hello world program for you to test. Were not going to spend any time really explaining what the code does, its just a way to make sure that you can link to BURLAP with your own code. For a much more thorough explanation of the code, see the BURLAP java doc and other tutorials available. In your testcode directory, create a new file named HelloGridWorld.java. Inside the file, place the following code. import burlap.domain.singleagent.gridworld.import burlap.oomdp.core.import burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.Visualizerpublic class HelloGridWorldpublic static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success rateDomain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10create visualizer and explorerVisualizer v GridWorldVisualizer.getVisualizergw.getMapVisualExplorer exp new VisualExplorerdomain, v, sset control keys to use w-s-a-dexp.addKeyActionw, GridWorldDomain.ACTIONNORTHexp.addKeyActions, GridWorldDomain.ACTIONSOUTHexp.addKeyActiona, GridWorldDomain.ACTIONWESTexp.addKeyActiond, GridWorldDomain.ACTIONEASTexp.initGUI This code will effectively recreate the same GridWorld GUI that we launched straight from the BURLAP jar, with the exception that we made the GridWorld have stochastic transitions. This means that as you control the agent with the w-s-a-d keys, you may find that it sometimes goes in the wrong direction After saving the file, we will compile it with the command javac -cp lib. HelloGridWorld.java Now lets run it java -cp lib. HelloGridWorld If youre in the Windows command prompt and not cygwin, you may need to change the colon character to a semicolon and if youre using cygwin, then you need to specify it as a cygwin path java -cp cygpath -wp lib. HelloGridWorld If everything worked, then you should have seen the same GUI as the one you saw when we ran codedirectly from the BURLAP jar. Testing Plotting Tools In these section well provide some code to make sure that your dependencies for the BURLAP plotting tools are working correctly. If you dont care about this, naturally you can skip this section. Create a new file named PlotTest.java and put the following code in it. import burlap.domain.singleagent.gridworld.import burlap.oomdp.core.import burlap.behavior.singleagent.auxiliary.performance.import burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.behavior.singleagent.learning.import burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.behavior.singleagent.planning.deterministic.TFGoalConditionimport burlap.oomdp.auxiliary.common.ConstantStateGeneratorimport burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.oomdp.singleagent.import burlap.oomdp.singleagent.common.SinglePFTFpublic class PlotTestpublic static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success ratefinal Domain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10ends when the agent reaches a locationfinal TerminalFunction tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATION reward function definitionfinal RewardFunction rf new GoalBasedRFnew TFGoalConditiontf, 5., -0.1initial state generatorfinal ConstantStateGenerator sg new ConstantStateGeneratorsset up the state hashing system for looking up statesfinal DiscreteStateHashFactory hashingFactory new DiscreteStateHashFactory Create factory for Q-learning agent LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-learningOverridepublic LearningAgent generateAgent return new QLearningdomain, rf, tf, 0.99, hashingFactory, 0.3, 0.1define experimentLearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterSADomaindomain, rf, sg, 10, 100, qLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE, PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDstart experimentexp.startExperiment Then compile and run as before, except this time well specify the PlotTest class that we created javac -cp lib. PlotTest.javajava -cp lib. PlotTest If everything worked, then you should have seen a bunch of plots showing the performance of a Q-learning algorithm that were updated in semi real time, similar to what is shown below. If you did not see something like the above, you may need to make sure that you have all the dependencies you need in the lib folder see the Dependencies section for more details. Notes on the Java Heap Size Planning and learning algorithms often require a lot of memory for large problems, more than what java will typically use by default. Therefore, you may want to make sure that you increase javas heap size whenever you run BURLAP. You can do this with the -Xmx argument. For instance, to give java 2GB of memory to use, change the previous run commands to the following java -cp lib. -Xmx2048M HelloGridWorld Conclusions In this tutorial we walked you through acquiring BURLAP and provided some simple code to make sure you can compile your own code with it. We strongly encourage you to use a full IDE, however, such as Eclipse . Just make sure that you add the jar files that we put in the lib folder to your Eclipse projects build path. Since all of the BURLAP java doc comes with the jar,Eclipse will autocomplete methods and explain the parameters, which should be very helpful. Now that youve completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding End.", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Hello", "World!", ">", "> Part 1"], "word_count": 1961, "token_count_estimate": 3164}}, "http://burlap.cs.brown.edu/tutorials_v1/cpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials v1 Creating a Planning and Learning Algorithm Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part VI Code Lets start by creating our class for VI, which well call VITutorial, and all the methods it will need to implement to satisfy the OOMDPPlanner and QComputablePlanner classinterface. import burlap.behavior.singleagent.QValueimport burlap.behavior.singleagent.planning.OOMDPPlannerimport burlap.behavior.singleagent.planning.QComputablePlannerimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Statepublic class VITutorial extends OOMDPPlanner implements QComputablePlanner Overridepublic ListQValue getQsState s TODO Auto-generated method stubreturn nullOverridepublic QValue getQState s, AbstractGroundedAction a TODO Auto-generated method stubreturn nullOverridepublic void planFromStateState initialState TODO Auto-generated method stubOverridepublic void resetPlannerResults TODO Auto-generated method stub Because we are sub classing OOMDPPlanner, this object will auto create data members that define our domain and task the domain, reward function, terminal function, discount factor, andstate hashing factory that is used to hash and check the equality of states. However, the other critical data that VI needs to store are its estimates of the value function We can store the value function as a mapping from states to double values and we can use a provided StateHashFactory to create fast hashable states StateHashTuple s. Furthermore, it might be useful to have the value of each state be initialized to something sensible that the client can specify. We can accept a procedure for initializing the value function by using a ValueFunctionInitialization object. Lets add those data members to our class, and make sure you also add the requisite imports. Finally, as a parameter to the algorithm, well let the client specify for many iterations VI will run, so well also need a data member for that. We could also specify what the maximum allowable change in the value function was, but for simplicity for this tutorial well just use a fixed number of iterations. import java.util.Mapimport java.util.HashMapimport burlap.behavior.singleagent.ValueFunctionInitialization protected MapStateHashTuple, Double valueFunctionprotected ValueFunctionInitialization vinitprotected int numIterations Now lets add a constructor to accept and initialize all our data. Again, well need to add some imports too. import burlap.behavior.statehashing.StateHashFactoryimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.RewardFunction public VITutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, StateHashFactory hashingFactory, ValueFunctionInitialization vinit, int numIterationsthis.plannerInitdomain, rf, tf, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapStateHashTuple, Double Note that since our OOMDPPlanner superclass will hold our data members for the domain, reward function, terminal function, discount factor, and state hashing factory, we can initialize them with its plannerInit method. There is one other critical component VI needs that isnt part of the data weve given it in the constructor the full state space One reason we might not want to demand this upfront is because in an OO-MDP, it might be possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but its much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. In fact, there are planning algorithm independent tools in BURLAP that can find all reachable states from a seed state for us see the StateReachabilityClass for this purpose however, for the purposes of illustration, we will not make use of those tools and instead implement the reachability code ourselves. To find all possibly reachable states from a source seed state, we need to do a kind of breadth-first search where we start with a queue containing only our seed state. We then dequeue a state from the queue and expand it by checking what all the possible outcomes states are from all possible actions and add those states to our queue if weve never seen them before. The search is complete when the queue is empty and every expanded state represents a state in our reachable state space. VI will then be able to iterate over this space. Lets implement that method now. In our code, we will use our valueFunction data member to effectively be our test for whether a state has been seen before and add each expanded node with its value function initialization as we see it. We will also need to add a few new imports for this method. import java.util.LinkedListimport java.util.Listimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.singleagent.GroundedAction public void performReachabilityFromState seedStateStateHashTuple hashedSeed this.hashingFactory.hashStateseedStatemark our seed state as seen and set its initial value function valuethis.valueFunction.puthashedSeed, this.vinit.valuehashedSeed.sLinkedListStateHashTuple open new LinkedListStateHashTupleopen.offerhashedSeedwhileopen.size 0pop off a state and expand itStateHashTuple sh open.pollwhich actions can be applied on this stateListGroundedAction appliactionActions this.getAllGroundedActionssh.sfor each action...forGroundedAction ga appliactionActionswhat are the possible outcomesListTransitionProbability tps ga.action.getTransitionssh.s, ga.paramsfor each possible outcome...forTransitionProbability tp tpsadd previously unseed states to our open queue and set their initial value functionStateHashTuple shp this.hashingFactory.hashStatetp.sifthis.valueFunction.containsKeyshpthis.valueFunction.putshp, this.vinit.valueshp.sopen.offershp With the inline comments, most of this code should be self explanatory. However, there are a couple of things to which you should pay closer attention. In each state we want to know what all the possible actions are. For this, were using the OOMDPPlanner super class method getAllGroundedActions. We could have used the Action static method getAllApplicableActionsFromActionList in conjunction with the action list provided from our domain to get all grounded actions however, it possible to add high-level or otherwise actions to a planner that are not strictly part of the domain like options and using our OOMDPPlanner method will always return the possible actions it was given instead of the primitives defined with the domain, using its method is preferable. The other thing to pay attention to is how we get all possible state outcomes from applying an action in the state. For this request, we can get from our GroundedAction object the Action object reference and ask it to return a list of transition probabilities given the source state in question and any possible action parameters specified if there are any using the getTransitions method. The returned list from getTransitions is made up of TransitionProbability objects, which specify an outcome state and the probability of transitioning to it. As you may recall from our Building a Domain tutorial the getTransitons method will only return transitions to states that have non-zero probability so you dont have to worry about iterating over an unnecessarily large list of impossible transitions. However, it is worth pointing out that some domains may not implement the getTransitions method, particularly if there are an infinite number of states. Planners such as VI are not equipped to handle such domains especially since we will use the full set of possible transitions to compute Q-values, so we must assume that that method is implemented. The other method well need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states a requirement of implementing the QComputablePlannerInterface, we will implement those methods and a Bellman Equation method next. We will also need to add an import for ArrayList for these methods. import java.util.ArrayList Overridepublic ListValue getQsState s ListGroundedAction applicableActions this.getAllGroundedActionssListQValue qs new ArrayListValueapplicableActions.sizeforGroundedAction ga applicableActionsqs.addthis.getQs, gareturn qsOverridepublic QValue getQState s, AbstractGroundedAction a type cast to the type of grounded action were usingGroundedAction ga GroundedActionawhat are the possible outcomesListTransitionProbability tps ga.action.getTransitionss, ga.paramsaggregate over each possible outcomedouble q 0.forTransitionProbability tp tpswhat is reward for this transitiondouble r this.rf.rewards, ga, tp.swhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.sadd contribution weighted by transition probabiltiy and discounting the next stateq tp.p r this.gamma vpcreate Q-value wrapperQValue qValue new QValues, ga, qreturn qValueprotected double bellmanEquationState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble maxQ Double.NEGATIVEINFINITYforQValue q qsmaxQ Math.maxmaxQ, q.qreturn maxQ Youll note that the Q-value methods return QValue objects, which are just triples consisting of a State object, an AbstractGroundedAction object, and a double for the Q-value associated with them. In the getQs method, we simply find all possible grounded actions, ask our getQ method what the Q-value is, and then return the list of all those Q-values. In the getQ method, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. In the bellmanEquation method, we in general just return the maximum Q-value for the state however, there is a catch. That is, if the input state is a terminal state, then by definition of it being a terminal state the value is zero, because the idea of a terminal state is that no action can follow from it. Therefore, if the state is a terminal state, we return a value of 0 and ignore whatever the domain object would say the possible transitions would be. Note that this check is not just a performance saver all terminal states are specified by the TerminalFunction interface, so we must always refer to it to handle terminal states and cannot expect that a domains transition dynamics have it baked in. We now have all the tools we need to do planning, so its time to implement the planFromStateMethod. This method is called whenever a client wants to run planning from a given initial or seed state. What well do then is first check if weve already performed planning that includes that state. If so, well do nothing, having assumed to already have computed the value for it. However, if we havent seen it before, then well first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. Overridepublic void planFromStateState initialState StateHashTuple hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforStateHashTuple sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, this.bellmanEquationsh.s Were now just about finished The only thing left is that each OOMDPPlanner instance is asked to implement the method resetPlannerResults, which when called should have the effect of resetting all data so that its as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. Overridepublic void resetPlannerResults this.valueFunction.clear Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial. Youll note that since we implement the QComputablePlanner interface, we can use any existing Q-value derived policy, such as GreedyQ, EpsilonGreedy, etc. Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy. You should find that the agent takes north and east actions exclusively. import burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.statehashing.DiscreteStateHashFactoryimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.oomdp.singleagent.common.UniformCostRF public static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup vi with 0.99 discount factor, discrete state hashing factory, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, rf, tf, 0.99, new DiscreteStateHashFactory, new ValueFunctionInitialization.ConstantValueFunctionInitialization0.0, 30run planning from our initial statevi.planFromStatesget the greedy policy from itPolicy p new GreedyQPolicyvievaluate the policy with one roll out and print out the action sequenceEpisodeAnalysis ea p.evaluateBehaviors, rf, tfSystem.out.printlnea.getActionSequenceStringn If youre looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, its now time to move on to our Q-learning example If youd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 2"], "word_count": 2067, "token_count_estimate": 3164}}, "http://burlap.cs.brown.edu/tutorials_v1/scd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials v1 Solving Continuous Domains Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem for other variants, see the CartPoleDomain and its parameters, but in this example well be using one of the more simple forms. The problem is as follows a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole the inverted pendulum and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by a single object which is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling more on that in a moment. Let us start by making a method IPSS for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. import burlap.domain.singleagent.cartpole.InvertedPendulum public static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.Domain domain ip.generateDomainRewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.State initialState InvertedPendulum.getInitialStatedomain The line ip.physParams.actionNoise 0. sets our domain to have no noise in the actions. physParams is a data member containing all physics parameters that you can modify. The created reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than 8 radians. Specifically, the agent will receive zero reward everywhere except when the poles angle is greater than 8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm were going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every state, planning needs to happen all over again unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces. Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. import burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.behavior.statehashing.NameDependentStateHashFactory SparseSampling ss new SparseSamplingdomain, rf, tf, 1, new NameDependentStateHashFactory, 10, 1ss.setForgetPreviousPlanResultstruePolicy p new GreedyQPolicyss Note that were using a discount factor of 1 because we are computing the Q-values for a finite horizon rather than computing an infinite horizon, a discount factor of 1 will always result in finite Q-values. The state hashing factory that were using is a NameDependentStateHashFactory , which is a hashing factory that does not support object identifier invariance, but does support state equality for continuous attribute domains, provided the continuous values of each attribute between states are exactly the same. Since states of this domain only consist of a single object, losing object identifier invariance is irrelevant. Also note that we dont expect to ever see the same state twice in a continuous domain, even within the same planning horizon, but this hashing factory will provide detection of the same states should they ever been seen. The method call setForgetPreviousPlanResultstrue tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we dont expect to see the same state twice, this is useful to clean up memory that we dont expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed. The final thing youll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first unless we had let it remember past planning results and it was the same state as a state for which its planned before. At this point, were basically done. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode with a maximum of 500 steps to a file, and then visualize the episode using an EpisodeSequnceVisualizer like weve used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. import burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.EpisodeSequenceVisualizerimport burlap.domain.singleagent.cartpole.InvertedPendulumStateParserimport burlap.domain.singleagent.cartpole.InvertedPendulumVisualizerimport burlap.oomdp.auxiliary.StateParser EpisodeAnalysis ea p.evaluateBehaviorinitialState, rf, tf, 500StateParser sp new InvertedPendulumStateParserdomainea.writeToFileipssPlan, spSystem.out.printlnNum Steps ea.numTimeStepsVisualizer v InvertedPendulumVisualizer.getInvertedPendulumVisualizernew EpisodeSequenceVisualizerv, domain, sp, ip If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. Were now finished with the Sparse Sampling example If youre looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class. In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 2"], "word_count": 1294, "token_count_estimate": 1783}}, "http://burlap.cs.brown.edu/tutorials_v1/scd/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials v1 Solving Continuous Domains Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 1 if youd like the BURLAP 2 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planninglearning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means youre unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being ably to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen near by states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration LSPI. LSPI requires a collection of state-action-reward-state SARS transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data and therefore how it is collected is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values this change in policy is known as policy improvement . This process repeats until the approximate Q-value function and consequentially the policy stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. Well begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static method that demonstrates solving each domain and algorithm in this tutorial, so well start with our method for solving Mountain Car with LSPI using Fourier basis functions MCLSPIFB. public class ContinuousDomainTutorial public static void mainString argsMCLSPIFBpublic static void MCLSPIFBwell fill this in in a moment... Next well create an instance of the Mountain car domain and the typical reward function and terminal function that defines the task in our MCLSPIFB method. Well also need to add the requisite imports for this code. import burlap.behavior.singleagent.learning.GoalBasedRFimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.RewardFunction MountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100 Our MountainCar instance provides us a means to get a TerminalFunction that sets states in which the car is on the top of the slope on the right-side as terminal states. We then define a Goal-based reward function that returns a reward of 100 when the agent reaches the terminal state and 0 everywhere else 0 is the default reward for a GoalBasedRF , but that value can be changed with a different constructor. Note We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code and the imports for that now. import burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.oomdp.auxiliary.StateGenerator StateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, null The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, weve told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This processing a generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results and return it rather than adding to an existing SARSData instance. Note In this case were opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm it does implement the LearningAgent interface in which it starts with no data, acts in the world from whatever the worlds current state is and reruns LSPI as it experiences more transitions thereby improving the policy that it follows. However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider overriding LSPIs runLearningEpisodeFrom method to use an approach that is a better fit for your domain. To learn more about how LSPIs default runLearningEpisodeFrom method is used, see the classs documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a feature vector defining the state, where each attribute is normalized, and produces scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the FeatureDatabase interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions which grow exponentially with the dimension of input state feature vector and the more granular the representation becomes, allowing for a more precise linear value function approximation. Recall that BURLAP states are not defined with feature vectors, but with sets of objects adhering to the OO-MDP paradigm however, we can convert an OO-MDP state into a feature vector trivially since OO-MDPs tend to provide more information than a standard feature vector definition does. The simplest way to convert an OO-MDP state into a feature vector is to simply concatenate the feature vector of each object in the state into a single large feature vector. To do so, we can make use of the ConcatenatedObjectFeatureVectorGenerator , which asks for which object classes to concatenate and their concatenation order and whether to normalize the values or not which for Fourier basis functions we will want to do. Note If you need to define the feature vector conversion differently perhaps, for instance, you want to use relative features, or ignore certain attributes of the objects, you can always make your own feature vector conversion definition by implementing a StateToFeatureVectorGenerator , which takes as input a State object and returns a double array. In the Mountain Car domain, there is only one object classthe agentwhich defines the cars position and velocity, so we only need to tell the ConcatenatedObjectFeatureVectorGenerator to use the agent class values and to normalize its attribute values. With a feature vector conversion method in hand, lets create a set of 4th order Fourier basis functions to use as our state features for LSPI. import burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGeneratorimport burlap.behavior.singleagent.vfa.fourier.FourierBasis ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTFourierBasis fb new FourierBasisfeatureVectorGenerator, 4 Note that the true parameter in the ConcatenatedObjectFeatureVectorGenerator constructor tells it that all dimensions should be normalized in the returned feature vector, which is what Fourier basis functions expect. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions tell it to use a 0.99 discount factor set its SARS dataset to the datasetwe collected and run LSPI until the weight values of its fitted linear function change no more than 10-6 between iterations or until 30 iterationshave passed. import burlap.behavior.singleagent.learning.lspi.LSPI LSPI lspi new LSPIdomain, rf, tf, 0.99, fblspi.setDatasetdatasetlspi.runPolicyIteration30, 1e-6 After LSPI has run until convergence, we will want to analyze the policy is produced. Since LSPI implements QComputablePlanner which means it can return Q-values for state-action pairs, we can capture its policy by creating GreedyQ policy around it. To analyze the resulting policy, lets evaluate it from a start state in the bottom of the valley and animate the results say 5 times. To visualize the animated results, we can simply grab the existing visualizer from the domain MountainCarVisualizer , add a VisualActionObserver to the domain, and evaluate the policy from a start state. The state state in the valley can be retrieved from our Mountain Car domain generator instance. The code to do all that is provided below. import burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.core.Stateimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.visualizer.Visualizer GreedyQPolicy p new GreedyQPolicylspiVisualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vexp new VisualActionObserverdomain, vvexp.initGUISADomaindomain.addActionObserverForAllActionvexpState s mcGen.getCleanStatedomainforint i 0 i 5 ip.evaluateBehaviors, rf, tfSystem.out.printlnFinished. If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and youll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible even if unlikely that the car wont make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code resulting in a a new random data collection, you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features specifically, lets consider using radial basis functions. A radial basis function is defined with a center state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the functions center state. As the query state gets further away, the basis functions returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter as the bandwidth value increases, the less sensitive the function is to distance that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away. A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, well define radial basis functions. For the moment, the code below will create in instance of a radial basis function state feature database RBFFeatureDatabase , but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. import burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabase public static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100get a state definition earlier, well use it soon.State s mcGen.getCleanStatedomainStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullinstantiate an RBF feature database, well define it more in a momentRBFFeatureDatabase rbf new RBFFeatureDatabasetruenotice we pass LSPI our RBF features this timeLSPI lspi new LSPIdomain, rf, tf, 0.99, rbflspi.setDatasetdatasetlspi.runPolicyIteration30, 1e-6GreedyQPolicy p new GreedyQPolicylspiVisualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vexp new VisualActionObserverdomain, vvexp.initGUISADomaindomain.addActionObserverForAllActionvexpforint i 0 i 5 ip.evaluateBehaviors, rf, tfSystem.out.printlnFinished. Youll notice that we passed true to our RBFFeatureDatabase constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This is typically a good idea because it provides a Q-value y intercept value to the linear function that will be estimated. Note We did not need to specify the inclusions of a constant feature for the Fourier basis function feature database like we did for RBFs because the 0th order Fourier function is a constant always on feature. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the StateGridder class in BURLAP. StateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. StateGridder can even do things like include constant values for some attributes or objects that is, attribute values that remain fixed for every state in the grid. For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To get the set of states that span a 5x5 grid over the car position and velocity attributes for a total of 25 states, add the below code right below the instantiation of the RBFFeatureDatabase with the requisite imports going at the top of the file, of course. If you want to know how to set up a more specific grid e.g., an asymmetric grid like a 3x7, see the classs documentation import burlap.behavior.singleagent.auxiliary.StateGridderimport java.util.List RBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5ListState griddedStates gridder.gridInputStates Notice that the gridInputState method requires an example State object An example state is required because its what tells the gridder how many objects of each object class need to be gridded and what any constant ungridded objectsvalues are. Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Since a radial basis function also needs a distance metric between states, let us use a Euclidean distance metric. BURLAP already has an Euclidean distance metric implementation, but it requires that a state first be converted to a feature vector, which we can again do using the ConcatenatedObjectFeatureVectorGenerator and we will again normalize the attribute values. To instantiate the distance metric, add the below code. import burlap.behavior.singleagent.vfa.rbf.DistanceMetricimport burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistance DistanceMetric metric new EuclideanDistance new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENT Now we will add a radial basis function to our RBFFeatureDatabase for each state on the grid using the Euclidean distance metric and setting the bandwidth parameter to 0.2. In particular, we will use Gaussian radial basis functions . import burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBF forState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2 Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf mcGen.new ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100get a state definition earlier, well use it soon.State s mcGen.getCleanStatedomainStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullset up RBF feature databaseRBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5ListState griddedStates gridder.gridInputStatesDistanceMetric metric new EuclideanDistance new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTforState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2notice we pass LSPI our RBF features this timeLSPI lspi new LSPIdomain, rf, tf, 0.99, rbflspi.setDatasetdatasetlspi.runPolicyIteration30, 1e-6GreedyQPolicy p new GreedyQPolicylspiVisualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vexp new VisualActionObserverdomain, vvexp.initGUISADomaindomain.addActionObserverForAllActionvexpforint i 0 i 5 ip.evaluateBehaviors, rf, tfSystem.out.printlnFinished. If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time weve used radial basis functions Now that weve demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, well move on to a different algorithm, Sparse Sampling, and a different domain, the Inverted Pendulum. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 1", "Note", "Note", "Note", "Note"], "word_count": 3204, "token_count_estimate": 4719}}, "http://burlap.cs.brown.edu/tutorials_v1/scd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials v1 Solving Continuous Domains Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving Lunar Lander with SARSA In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and CMACTiling coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example LLSARSA and instantiating a Lunar Lander domain , task, and initial state. import burlap.domain.singleagent.lunarlander.LLStateParserimport burlap.domain.singleagent.lunarlander.LunarLanderDomainimport burlap.domain.singleagent.lunarlander.LunarLanderRFimport burlap.domain.singleagent.lunarlander.LunarLanderTF public static void LLSARSALunarLanderDomain lld new LunarLanderDomainDomain domain lld.generateDomainRewardFunction rf new LunarLanderRFdomainTerminalFunction tf new LunarLanderTFdomainStateParser sp new LLStateParserdomainState s LunarLanderDomain.getCleanStatedomain, 0LunarLanderDomain.setAgents, 0., 5.0, 0.0LunarLanderDomain.setPads, 75., 95., 0., 10. Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain but you can change various properties such as the force of gravity, thrust, etc.. The default reward function returns 1000 for landing, -100 for collisions, and -1 for regular transitions though these values can be changed with a different constructor . The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The getCleanState method, with the parameter 0 creates a state with an agent object the ship a landing pad object, and 0 obstacle objects. The setAgent method parameters specify the angle of the ship from the vertical axis in radians, the x position of the ship 5, and the y position of the ship 0, on the ground, respectively. The setPad method parameters define the landing pad dimensions in terms of the rectangular left, right, bottom, top boundaries, respectively. This will create an initial state that looks like the below as visualized in BURLAP. The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. Were going to solve this problem with gradient descent SARSA , which is a learning algorithm that behaves much like conventional tabular SARSA discussed in previous tutorials, except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA does not need to use a linear approximator however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is as with LSPI, a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA. However, this time well use a different basis function CMACs, also know in reinforcement learning literature as Tile Coding. CMACs address learning in continuous domains in a only slightly more complex way than merely discretizing the state space, yet also diminish the aliasing effects that discretization can incur. To describe how they work, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. Well let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile the larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. CMACs diminish this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 one for the tile in which the query state is contained for each tiling. Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on CMACs with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using CMACs is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation. Another advantage specific to OO-MDPs is that because each tile represents a discretized state, we can maintain object identifier independence, which is otherwise not always possible to do with a number of value function approximation methods. If you dont need object identifier independence, there is another implementation of CMACs in BURLAP called FVCMACFeatureDatabase that is slightly more CPU efficient and operates on state feature vectors which as before are produced with StateToFeatureVectorGenerator objects. For this tutorial, however, we will use the version that provides object identifier independence, which is called CMACFeatureDatabase . Lets continue our code implementation by instantiating a CMACFeatureDatabase object and defining the tiling of our state space. To implement CMAC basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each attribute. In this case, we will use 5 tilings with a width for each attribute that produces 10 tiles along each attribute range. We will limit this tiling to the Lunar Lander ship attribute values and ignore attributes for the landing pad. Since the agents ship is defined by 5 attributes x position, y position, x velocity, y velocity, and rotation angle from the vertical axis, this will produce 5 tilings that each define at most 105 tiles again though, we dont necessarily have to store weights for all tiles if the agent never visits them To do so, add the below code. import burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabase int nTilings 5CMACFeatureDatabase cmac new CMACFeatureDatabasenTilings, CMACFeatureDatabase.TilingArrangement.RANDOMJITTERdouble resolution 10.double angleWidth 2 lld.getAngmax resolutiondouble xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutioncmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.AATTNAME, angleWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.XATTNAME, xWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.YATTNAME, yWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.VXATTNAME, velocityWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.VYATTNAME, velocityWidth In the first line, we instantiate the CMACFeatureDatabase with 5 tilings, each offset by a random amount. Then we compute tile widths along each attribute such that it would produce at most 10 tile margins along each attribute. The methods lld.getXMin simply return the minimum x-value for our LunarLander instance and the other methods return their respective attributes value ranges. Finally, we inform the CMACFeatureDatabase of the width for each attribute that will be included in the tiling for each object class. In this case, we will only produce tilings over the agent class for its rotation angle x, y position and x, y velocity attributes and ignore the attributes for other object classes like the landing pad. Now that we have the CMACFeatureDatabase set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA. import burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam double defaultQ 0.5ValueFunctionApproximation vfa cmac.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, rf, tf, 0.99, vfa, 0.02, 10000, 0.5 Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value 0.5 by the number of tilings 5, because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.55, the linear estimate will predict our desired initial Q-value 0.5. We also set the learning rate for gradient descent SARSA to 0.02 in general, you should decrease the learning rate as the number of features increases, set a maximum learning episode size of 10000, and set to 0.5. With gradient descent SARSA instantiated, we can run learning episodes just like we do for typical SARSA. Lets run learning for 5000 episodes, record the episodes to files, and then visualize the results with an EpisodeSequenceVisualizer. import burlap.oomdp.visualizer.Visualizer forint i 0 i 5000 iEpisodeAnalysis ea agent.runLearningEpisodeFroms run learning episodeea.writeToFileString.formatlunarLandere04d, i, sp record episode to a fileSystem.out.printlni ea.numTimeSteps print the performance of this episodeVisualizer v LLVisualizer.getVisualizerlldnew EpisodeSequenceVisualizerv, domain, sp, lunarLander If you now point your main method to LLSARSA and run it, you should initially see a punch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizer GUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial Closing remarks and the full code we created can be found on the next page. Next Part", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 3"], "word_count": 1764, "token_count_estimate": 2621}}, "http://burlap.cs.brown.edu/tutorials_v2/bd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 3 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part Defining GridWorld Object Classes To begin implementing our grid world domain in BURLAP, we will create a class that in this tutorial we will call ExampleGridWorld. Furthermore, we will make it implement the DomainGenerator interface, which is a common convention in BURLAP when developing domains and requires implementing the generateDomain method. In that method, we will create an SADomain object that will keep track of all of our attributes, object classes, etc. that we define. Note that the Domain class that is returned by the method is the abstract superclass of SADomain. You should have code that looks like the below to make things easier for the future, the below code has all of the library imports that youll need for the rest of the tutorial. import burlap.oomdp.auxiliary.DomainGeneratorimport burlap.oomdp.core.import burlap.oomdp.core.objects.MutableObjectInstanceimport burlap.oomdp.core.objects.ObjectInstanceimport burlap.oomdp.core.states.MutableStateimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.import burlap.oomdp.singleagent.common.SimpleActionimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.singleagent.explorer.TerminalExplorerimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.ObjectPainterimport burlap.oomdp.visualizer.StateRenderLayerimport burlap.oomdp.visualizer.StaticPainterimport burlap.oomdp.visualizer.Visualizerimport java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.import java.util.Listpublic class ExampleGridWorld implements DomainGenerator Overridepublic Domain generateDomain SADomain domain new SADomainreturn domain The first thing that we will want to decide in the construction of our domain is what the object classes and attributes that define the domain are. For our grid world, we will define two object classes an agent class, to represent the agent in the world and a location class, which we can use to refer to special places in the world. The location class isnt necessary to define grid world problems, but were going to include it to help illustratehow to define propositional functions in BURLAP. Both the agent and location class will be defined by their x and y position in the 2D world. For convenience, it is often useful to define the names of all attributes, object classes, etc. that the domain definesas string constants so that they can be precisely referenced by code that uses the domain, so lets add those to our code now. public static final String ATTX xpublic static final String ATTY ypublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION location Next we will create the actual Attribute objects and the classes associated with them. Since grid worlds have discrete states, but our attributes represent numeric positions, we willset our attributes to be of type int. We will also construct a world that is 11x11 in size, so we will set the attribute limits to be from 0 to 10 inclusively. Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattreturn domain Notice how we never directly told the domain about the attributes or object classes that we created Thats because the constructor of the attributes and object classes will tell the domain about themselves automatically to streamline construction. With that code written, were already finished defining the state representation of the domain The next step will be to define actions. Defining GridWorld Actions Defining actions in BURLAP means specifying the actions the agent can take, their preconditions if any, their parameters if any, and their transition dynamics. We will construct four actions north, south, east, and west. None of these actions will have preconditions and they will not take any parameters. The transition dynamics we define for them will depend on the location of walls in the world. We could have potentially made the walls objects of the OO-MDP themselves,but for simplifying the state representation we will keep the walls embedded in our transition dynamics without explicit state representation. To facilitate the definition of the transition dynamics, we will create a 2D int matrix specifying the location of walls in each cell. We will also create a world withthe same wall layout shown in the image at the beginning of this tutorial. To do so, add the following code. ordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0, Next we will create our actions. We will define north, south, east, and west actions that have a probability of 0.8 of going in the intended direction and a probability of 0.2 of going in any other direction. To define single agent actions in BURLAP, we subclass the Action class. In this case, we will create a single subclass, called Movement, and instantiate it multiple times for each movement direction. Subclassing Action requires us to implement a number of abstract methods that describe and operationalize the action, such preconditions, parameters, and transition dynamics. Since movement acitons will not have any preconditions or parameters, we can subclass SimpleAction , which will handle the methods for no preconditions or parameters requiring us only to implement the performActionHelper method of Action. The method performActionHelper method is called whenever an action is applied in simulation to a State and must return the resulting state from applying the action. If our action is stochastic, then this method should randomly sample and return an outcome state according to the probability distribution. In addition to being able sample action transitions from our Action, we would like to specify the full probability distribution of action effects from our action, which means we will want to have our Action implement the FullActionModel interface. This interface requires implementing a getTransitions method, which returns a list of all possible outcome states when an action is applied and their probabiltiy of occurring. Implementing this interface will allow our domain to be solved by dynamic programming methods and other algorithms that require enumerating the full probability distribution, so its useful to implement. However, not all domains will be able to enumerate the full probabiltiy distribution for example, when its infinite so this remains an optional interface. In our case, the number of outcomes is finte and easy to specify, so we will implement it. Let us now write the skeleton of our Movement class as an inner class of our GridWorldExample protected class Movement extends SimpleAction implements FullActionModel Overrideprotected State performActionHelperState s, GroundedAction groundedAction return nullOverridepublic ListTransitionProbability getTransitionsState s, GroundedAction groundedAction return null So that we can reuse this Action class for each movement direction, lets define a data member that specifies the probability of going in each direction and let the intended direction which will succeed with probability 0.8 be specified in the constructor, along with a name for the action and the domain to which it belongs. protected class Movement extends SimpleAction implements FullActionModel 0 north 1 south 2east 3 westprotected double directionProbs new double4public MovementString actionName, Domain domain, int directionsuperactionName, domainforint i 0 i 4 iifi directiondirectionProbsi 0.8elsedirectionProbsi 0.23.Overrideprotected State performActionHelperState s, GroundedAction groundedAction return nullOverridepublic ListTransitionProbability getTransitionsState s, GroundedAction groundedAction return null Notice how we called a super constructor with the action name and domain Calling the super constructor will automatically connect the action with the domain object and set its name. Now well want to start defining our performActionHelper and getTransitions methods. To do so, lets add a helper method for getting the result of moving in a given direction. As long as the cell is free that is, there is no wall, the agent will move to that position if there is a wall there, the agent will stay in the same place. This method will then return the resulting x and y position of the agent. protected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or out of boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,ny With this helper method defined, all the performActionHelper method needs to do is determine the current position of the agent, sample from the direction distribution, call the moveResult method to get the new position, and set the agent attribute values to the new position. Getting the direction and setting the values can be performed by grabbing agent object instance in the state and using the pertinent value getter and setter methods. Since there is only ever one agent object instance in the state, we can retrieve the agent ObjectInstance using the getFirstObjectOfClass method that returns the first object instance of an object belonging to a specified class in the state. Overrideprotected State performActionHelperState s, GroundedAction groundedAction get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getIntValForAttributeATTXint curY agent.getIntValForAttributeATTYsample directon with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i this.directionProbs.length isumProb this.directionProbsiifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.setValueATTX, newPos0agent.setValueATTY, newPos1return the state we just modifiedreturn s The anatomy of performActionHelper You might have two questions about the performActionHelper method that we didnt explain first you might wonder what the GroundedAction method argument is for second you might wonder if its safe to directly modify the input State and return it, rather than making a new state and returning it. The GroundedAction argument is provided because BURLAP supports parameterized actions that is, actions that require the agent to select parameter values to execute the action. For example, in a blocks world, we can imagine a parameterized stack action that requires two block parameters to be specified which block to pick up and on which block to stack it. Since our Action definition is not parameterized, we do not have to worry about which parameter values were specified, but if it was, the GroundedAction class or rather subclasses of it that depend on the kind of parameterization used would contain all the parameter information needed to apply the action and in the performActionHelper method, we would look inside the provided GroundedAction to determine the outcome. Note that this paradigm is used for many other Action methods as well though they are not implemented here since we extended SimpleAction. Regarding modifying the input state directly, this is safe to do because performActionHelper is always called indirectly through the method perfomAction. The performAction method first makes a copy of its input state and then passes that to performActionHelper, thereby ensuring that performActionHelper cannot modify an important state used by the calling code. For the getTransition method, well do something similar, except in this case, well enumerate all possible outcomes, not just sample one, and create a new state object for each possible outcome. Each outcome will be also be associated with its probability of occurring, and we use the TransitionProbability class to store this paired outcome-probability association. As we assign the probabilities, we need to make sure they sum to one. We need to be careful here, because its possible for two directions to result in the same outcome state. For example, if the agent is adjacent to a wall to the west and south, then movements in the west and south direction would result in the same outcome no movement. Therefore, we sum together the probabilities of all movement directions that go into a wall and therefore result in no movement. Overridepublic ListTransitionProbability getTransitionsState s, GroundedAction groundedAction get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getIntValForAttributeATTXint curY agent.getIntValForAttributeATTYListTransitionProbability tps new ArrayListTransitionProbability4TransitionProbability noChangeTransition nullforint i 0 i this.directionProbs.length iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeState ns s.copyObjectInstance nagent ns.getFirstObjectOfClassCLASSAGENTnagent.setValueATTX, newPos0nagent.setValueATTY, newPos1create transition probability object and add to our list of outcomestps.addnew TransitionProbabilityns, this.directionProbsielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChangeTransition nullnoChangeTransition.p this.directionProbsielseotherwise create this new state and transitionnoChangeTransition new TransitionProbabilitys.copy,this.directionProbsitps.addnoChangeTransitionreturn tps With the Action class defined, well want to hook it up to our domain. First, lets add some string constants for the names of the actions. public static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST west Then we just need to call the constructor in our generateDomain method. As with the object classes and attributes, calling the constructor will automatically tell our domain about it, so we dont need to do anything further. new MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3 Defining Propositional Functions Although we have a functioning domain at this point, were going to add an optional propositional function to it to demonstrate how to use them. The propositional function we will create is atagent, location. Notice that it will take two parameters, one which is an OO-MDP object belonging to OO-MDP class agent and the other an OO-MDP object belonging to OO-MDP class location. The function should evaluate to true when the provided agent objects position is equal to the provided location objects position. To implement this function, we will need to subclass the PropositionalFunction class. Lets first create another string constant for the name of the function. public static final String PFAT at And then lets make the shell of the class implementation with a constructor. protected class AtLocation extends PropositionalFunctionpublic AtLocationDomain domainsuperPFAT, domain, new String CLASSAGENT,CLASSLOCATIONOverridepublic boolean isTrueState s, String params TODO Auto-generated method stubreturn false Inside the constructor we called a super constructor that takes as arguments the name of the propositional function, the domain with which it will be associated, and an array specifying the OO-MDP class types to which its parameters must adhere. Now lets implement the isTrue method, which is as simple as getting the object instances of the provided parameters and checking if the attributes are equal. The parameters that are provided to the method are the names or identifiers of the objects in the world that its referencing, so we can retrieve the objects from the provided state object by simply querying for the object with the given identifier. Overridepublic boolean isTrueState s, String params ObjectInstance agent s.getObjectparams0ObjectInstance location s.getObjectparams1int ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYint lx location.getIntValForAttributeATTXint ly location.getIntValForAttributeATTYreturn ax lx ay ly Finally, lets call the constructors from our generateDomain method. As before, the constructor will automatically tell the domain about the propositional function. Our final generateDomain method will look like the below. Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattnew MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3new AtLocationdomainreturn domain Getting all propositional function bindings Although we have defined a propositional function, you might be wondering how you can find all possible parameters in a state with which it can be evaluated. The PropositionalFunction super class provides a method for doing just this called getAllGroundedPropsForStateState , which will return a list of GroundedProp objects that can be evaluated. A GroundedProp is simply a PropositionalFunction object reference and parameters with which to evaluate it. Similarly, if you want all possible GroundedProp objects for a list of different PropositionalFunction objects, you can use the PropositionalFunction static method getAllGroundedPropsForStateState . Testing the Domain We now have a functional domain However, its probably important to test that the domain actually works as expected. By the end of this tutorial we will have created a visualizer for our domain that we can use to interactively visualize and test it, but we can also test it in the command line. To test our domain, lets first add a method to generate a state with the agent in the bottom left corner and a location object in the top right. public static State getExampleStateDomain domainState s new MutableStateObjectInstance agent new MutableObjectInstancedomain.getObjectClassCLASSAGENT, agent0agent.setValueATTX, 0agent.setValueATTY, 0ObjectInstance location new MutableObjectInstancedomain.getObjectClassCLASSLOCATION, location0location.setValueATTX, 10location.setValueATTY, 10s.addObjectagents.addObjectlocationreturn s Note that we made this method static and had it take as a parameter the domain object. We made the method static because the domain object is only ever created once the generateDomain method is called and that method can produce different Domain objects each time it is called. Although not especially important for our example, this is useful if you have parameterizable domains. Since ObjectInstance objects have to belong to a specific ObjectClass, we have to have the have the corresponding domain object from which to retrieve the ObjectClass. Since State and ObjectInstance are interface that can have any number of implementation, we need to choose one. Since were no doing anything fancy, we can use the simple MutableState and MutableObjectInstance implementations . In addition to taking an ObjectClass, the MutableObjectInstance constructor also takes as a parameter the name or identifier of the object instance. This name will be used to identify the object from other objects in the state and to further disambiguate it from multiple objects of the same class. This name is also what will be passed to the PropositionalFunction isTrue method parameters. Lets now add a main method that we will launch into to test our domain. To do the testing, we will make use the TerminalExplorer which lets us act as the agent through the command line. Create the main method as shown below. public static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainTerminalExplorer exp new TerminalExplorerdomain, initialStateexp.explore TerminalExplorer and Environment instances Its worth noting that the terminal explorer works by taking command line commands from a user, interpreting them into actions, and feeding them into an Environment it also has some other special commands you can give which youll see when you start it. When we use a constructor with just a domain and initial state, it creates a SimulatedEnvironment instance using that domain, but we could have provided any other Environment instead using a different constructor. When you run main in the command lineterminal you should see a print out describing the example state. If you now type the name of an action such as north and hit enter, it will change state and print out the new state. Remember that our actions are stochastic, so 20 of the time youll find yourself going in a different direction While using the TerminalExplorer works for all domains that you might create, as your domains get more complex it be can be difficult to make sense of them from text alone. Having a visualizer makes understanding whats happening in your domain much easier. Furthermore, you can reuse a visualizer not just for interacting in the world yourself, but for visualizing results of learning and planning algorithms. In the next sections, we will walk through how to create a state visualizer for this domain. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 3", "The anatomy of performActionHelper", "Getting all propositional function bindings", "TerminalExplorer and Environment instances"], "word_count": 3096, "token_count_estimate": 4752}}, "http://burlap.cs.brown.edu/tutorials_v2/bd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 2 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part OO-MDPs In the classic MDP formalism, each state is simply described by its identity. The cell in the bottom left corner of the grid world would simply be state 0 and the one above it might simply be state 11. This is known as a flat state representation because there is no other information about the states other than their identity. Although many planninglearning algorithms work just fine with flat representations, using a flat state representation makes defining transition dynamics and reward functions inconvenient. In fact, when we described the gridworld in the previous section, we used words regarding spatial adjacency and direction to explain it. It would similarly be nice to define the states, transitions, etc. using such concepts. For these reasons and others, it is oftenmuch easier to use a factored state representation, which can be exploited when defining the MDP transition dynamics and other properties. A classic way to define a factored state representation is with a set of state variables or attributes . In our grid world, for example, we would define the state by an x-position attribute and a y-position attribute. The bottom left cell of the world would be state 0, 0 the cell directly above it would be 0, 1 and so on. The factored representation that BURAP uses is the object-oriented MDP OO-MDP, which rather than representing states by a set of attributes, states are represented by a set of objects . Each object belongs to an object class, and each object class has an associated set of attributes. Each attribute can be of a different type with its own value domain. An object in a state is simply a value assignment to its class attributes. In our grid world, we can define an agent class that has two integer attributes associated with it with a value domain spanning the width and height of the grid world. In this definition, a state would contain an object instance belonging to the agent class with a value assignment specifying the agents x and y position. Although grid worlds are simple enough to describe without using an OO-MDP representation, there are a number of reasons why the OO-MDP representation is useful. For example, its trivial to define transition dynamics that create new objects in the world or remove them, merely by having the objects added or removed from the list of objects present in a state. If there are multiple objects belonging to the same class, states can also be defined invariantly to the identifier or order of the objects in the state. We call this kind of invariance object identifier independence . For example, consider a state s0 made up of two block objects block0 and block1 that are each defined by spatial position information an x and y attribute. Now imagine a new state s1 that is the result of swapping the positions of block0 and block1. Even though the object identifiers associated with the block positions block0 and block1 are different between s0 and s1, these really are the same state and when equality is object identifier independent they will be considered equal. The below illustration helps clarify this property. BURLAP supports both object idenitifer independence and dependence, depending on your needs. See the Basic Planning and Learning Tutorial for more information on using object identifier independence. Another advantage to the OO-MDP paradigm is that it leverages the object-oriented nature to provide additional high-level state features in the form of propositional functions that operate on objects in the world. In our grid world, we can introduce an additional object class for location objects similarly defined by x,y position attributes and then define a propositional function called at that operates on the agent object and a location object and evaluates to true when they are in the same location. Including propositional functions is useful for bridging the gap between MDPs and more classic AI approaches that are based on logical representations. In this tutorial we will implement the at propositional function in our grid world to demonstrate how to create them. BURLAP OO-MDP Java Class Overview BURLAP implements the OO-MDP paradigm in Java with the following class structure, which can be found in the packages burlap.oomdp.core and burlap.oomdp.singleagent . Attribute - this class defines an attribute name, data type, and value range. Attribute data types can be discrete categorical or integers, real-valued, relational, strings, or int and double arrays for very large data. ObjectClass - this class defines an object class name and is defined with an associated set of Attribute objects. Value - this class provides a value assignment for a specific attribute. There is a different Value subclass for each attribute data type, but management of it is handled behind the scenes. ObjectInstance - this interface is used to represent an OO-MDP object, which is defined by an ObjectClass and a set of Value assignments to each of the class Attribute objects. State - this interface provides methods to retrieve infromation about an OO-MDP state, such as getting the vairous ObjectInstance elements that define it. PropositionalFunction - this abstract class is subclassed to define propositional functions of an OO-MDP that operate on objects in State objects. Action - this abstract class is subclassed to provide the definitions of actions that an agent can take in the world. The action subclass defines the transition dynamics for the action, preconditions if any, and parameters the action takes if any. TransitionProbability - this class is a pair that defines the probability of transitioning to another state and is returned by the Action class when querying for its transition dynamics. GroundedAction - this class provides a reference to an action and the specific parameters if any with which it should be applied. GroundedProp - this class provides a reference to a PropositionalFunction and the parameters with which it will be evaluated. SADomain - this class provides the definition of an OO-MDP domain, and includes the references to all of the ObjectClass objects, Attribute objects, PropositionalFunction objects, and Action objects that define the domain. TerminalFunction - this interface is implemented to specify the terminal states of a task in a specific OO-MDP domain. RewardFunction - this interface is implemented to specify the rewards received for any state, action, next state transition. State implementations Because State and ObjectInstance are interfaces, you must choose a specific implementaiton that handles how they manage memory and datastructures for storing the information. All the included Domains in BURLAP make use of the MutableState and MuableObjectInstance implemenations, which is a good place to start. However, if your domain is computationally demanding, you may want to consider writing your own implementation that handles memory and allows access to information in the most efficient way possible. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 2", "State implementations"], "word_count": 1187, "token_count_estimate": 1444}}, "http://burlap.cs.brown.edu/tutorials_v2/bd/p1.html": {"text_content": "Building a Domain BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 1 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 2 if youd like the BURLAP version 1 tutorial, go here . Introduction This tutorial will cover three topics. First, we will discuss Markov Decision Processes MDPs and more specifically, Object-oriented MDPs OO-MDPs the decision making process that BURLAP uses to express single agent domains and decision making problems then we will discuss how BURLAP implements that OO-MDPs. Finally, we will cover how to create a domain, so that the planning and learning algorithms in BURLAP can be used on it, as well as how to visualize it, which is useful for testing and reviewing results. Other Problem Types Beyond MDPs, BURLAP also supportsstochastic games and partially observable MDPs, but a discussion of those problem types will be left for a different tutorial and many of the coreelements of the OO-MDP code that BURLAP uses is reused with the other problem types. If you are alreadyfamiliar with MDPs or OO-MDPs, or just want to get down to coding, feel free to skip the firstsections that discuss their mathematical description. For more information on how to useplanning and learning algorithms on the OO-MDP domains that you create or that are already in BURLAP, see the Basic Planning and Learning tutorial. Markov Decision Process To define worlds in which an agent can plan or learn, BURLAP uses the object-oriented Markov Decision Process OO-MDP formalism, which is an extension of the classic Markov Decision Process MDP formalism.An MDP provides a formal definition of a world, how it works, and how the agent who will be making decisions interacts with the world in a series of discretetime steps. In this tutorial we will formalize a grid world as an MDP. A grid world is a 2D world in which an agent can move north, south, east or west by one unit, provided there are no walls in the way. The below image shows a simple grid world with the agents position represented by a gray circle and walls of the world painted black. Typically, the goal in a grid world is for the agent to navigate to some location, but there are a number of variants. An example grid world. To define any world and task as an MDP, we will need to break down the problem into four components a set of possible states of the world S a set of actions that the agent can apply A a definition of how actions change the state of the world, known as the transition dynamics T and the rewards the agent receives for each of its actions R, known as the reward function, which will determine what the best behavior is that is, the agent will want to act in a way that maximizes the reward it receives. The transition dynamics are formulated as a probabilistic function Ts s, a, which defines the probability of the world changing to state s in the next discrete timestep when the agent takes action a in the current state s. The fact that the world can change stochastically is one of the unique properties of an MDP compared to more classic planningdecision making problems. The reward function is defined as Rs, a, s, which returns the reward received for the agent taking action a in state s and then transitioning to state s. Notice how both the transition dynamics and reward function are temporally independent from everything predating the most recentstate and action Requiring this level of temporal independence makes this a Markov system and is why this formalism is called a Markov decision process. In our grid world, the set of states are the possible locations of the agent. The actions are north, south, east, and west. We will make the transition dynamics stochastic so that with high probability 0.8 the agent will move in the intended direction, and with some low probability 0.2 move in a different direction. The transition dynamics will also encode the walls of our grid world by specifying that movement that would lead into a wall will result in returning to the same state. Finally, we can define a reward function that returns a high reward when the agent reaches the top right corner of the world and zero everywhere else. For various kinds of problems, the concept of terminal states is often useful. A terminal state is a state that once reached causes all further action of the agent to cease. This is a useful concept for defining goal-directed tasks i.e., action stops once the agent achieves a goal, failure conditions, or any number of other reasons. In our grid world, well want to specify the top right corner the agent is trying to get to as a terminal state. An MDP definition does not include a specific element for specifying terminal states because they can be implicitly defined in the transition dynamics and reward function. That is, a terminal state can be encoded in an MDP by being a state in which every action causes a deterministic transition back to itself with zero reward. However, for convenience and other practical reasons, terminal states in BURLAP are specified directly with a function more on that later. The goal of planning or learning in an MDP is to find the behavior that maximizes the reward the agent receives over time. More formally, wed say that the goal is to find a policy pi, that is a mapping from states in the MDP to actions that the agent takes pi S rightarrow A. Sometimes, the policy can also be defined as a probability distribution over action selection in each state and BURLAP supports this represenation, but for the moment we will consider the case when it is a direct mapping from states to actions. To find the policy that maximizes the reward over time, we must first define what it means to maximize reward over time and there are a number of different temporal objectives wecan imagine that change what the optimal policy is. Perhaps the most intuitive way to define the temporal reward maximization is to maximize thethe expected total future reward that is, the best policy is the one that results in largest possible sum of all future rewards. Although this metric is sometimes appropriate, its often problematic because it can result in policies that are evaluated to have infinite value or which do not discriminate between policies that receive the rewards more quickly. For example, in our grid world, any path the agent took to reach the top right would have a value 1 because they all would eventually reach the goal however, what wed probably want instead is for the agent to prefer a policy that reaches the goal as fast as possible. Moreover, if we didnt set the top right corner to be a terminal state, the agent could simply move away from it and back into it, resulting in any policy that reaches the goal having an infinite value, which makes comparisons between different policies even more difficult A commonalternative that is more robust is to define the objective to beto maximize the expected discounted future reward. That is, theagent is trying to maximize expected sumlarge sumt0infty gammat rt,where rt is the reward received at time t and gamma is the discount factor that dictates how much preference an agent has for more immediate rewards in other words, the agents patience. With gamma 1, the agent values distantrewards that will happen much further in the future as much as the reward the agent will receive in the next time step therefore, gamma 1 results in the same objective of summing all future rewards together and will have the same problems previously mentioned. With gamma 0 all the agent values only the next reward and does not care about anything that happens afterwards, thereby resulting in all policies having a finite value. This setting has the inverse effect of the agent never caring about our grid world goal location unless its one step away. However, a gamma value somewhere in between 0 and 1 often results in what we want. That is, for all values of 0 le gamma lt 1, the expected future discounted reward in an MDP when following any given policy is finite. If we set gamma to 0.99 in our grid world, the result is that the agent would want to get to the goal as fast as possible, because waiting longer would result in the eventual 1 goal reward being more heavily discounted. Although there are still other ways to define the temporal objective of an MDP, current learning and planning algorithms in BURLAP are based on usingthe discounted reward, with the geometric discout factor gamma left as a parameter that the user can specify. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 1", "Other Problem Types"], "word_count": 1526, "token_count_estimate": 1809}}, "https://blog.cs.brown.edu/2019/09/24/alum-aimee-lucido-publishes-young-adult-novel-about-her-two-loves-coding-and-writing/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Alum Aimee Lucido Publishes A Novel About Her Two Loves, Coding And Writing Posted by Jesse Polhemus on Sept. 24, 2019 Click the links that follow for more news items about recent accomplishments by our alums. Brown CS alums are often known for the diversity of their career paths and pursuing multidisciplinary work, and Aimee Lucido is no exception. A former software engineer and continuing crossword puzzle creator shes been featured five times by The New York Times , shes recently finished a middle grade novel, Emmy in the Key of Code . The story of a 12-year-old girl finding her voice in programming class, its been published by Houghton Mifflin HarcourtVersify and is available today. Its the book of my heart, she says. In so many ways it feels like a culmination of everything that has ever mattered to me music, friendships, family, and finally, the combination of writing and code. As an undergraduate, Aimee majored in both computer science and literary arts, and says that she spent much of her life during Brown and after wanting to pursue both tech and writing. In a way, she explains, I tried to make the real world mimic Browns open curriculum. Already the recipient of wide-ranging praise and a starred Kirkus review, Aimee says that writing her novel taught her that coding and writing have more in common than shed thought. When it comes down to it, both use words, symbols, and whitespace to convey meaning. Both are little more than a language used to encapsulate an idea, story or iPhone app. Initially intended as just a break from hours spent in the CIT, writing began to occupy more and more of Aimees life, eventually leading her to augment her Real Job as a software engineer with an MFA in writing and, more recently, leaving her tech job entirely to focus on writing full time. Both are things that are such a part of me, she says, that combining them once I gave myself permission felt as natural as breathing. You can read an excerpt from Emmy in the Key of Code and learn more about Aimee at her web site here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "Alum Aimee Lucido Publishes A Novel About Her Two Loves, Coding And Writing"], "word_count": 396, "token_count_estimate": 485}}, "http://burlap.cs.brown.edu/tutorials_v1/scd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials v1 Solving Continuous Domains Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP LSPI, Sparse Sampling, and gradient descent SARSA. We also demonstrated how to use these algorithms on three different continuous state domains Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions which can be used with LSPI and gradient descent SARSA Fourier basis functions, radial basis functions and CMACsTile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below. Final Code import burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.Policyimport burlap.behavior.singleagent.auxiliary.StateGridderimport burlap.behavior.singleagent.learning.GoalBasedRFimport burlap.behavior.singleagent.learning.lspi.LSPIimport burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLamimport burlap.behavior.singleagent.planning.commonpolicies.GreedyQPolicyimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.behavior.singleagent.vfa.ValueFunctionApproximationimport burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabaseimport burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGeneratorimport burlap.behavior.singleagent.vfa.fourier.FourierBasisimport burlap.behavior.singleagent.vfa.rbf.DistanceMetricimport burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabaseimport burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBFimport burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistanceimport burlap.behavior.statehashing.NameDependentStateHashFactoryimport burlap.domain.singleagent.cartpole.InvertedPendulumimport burlap.domain.singleagent.cartpole.InvertedPendulumStateParserimport burlap.domain.singleagent.cartpole.InvertedPendulumVisualizerimport burlap.domain.singleagent.lunarlander.import burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.oomdp.auxiliary.StateGeneratorimport burlap.oomdp.auxiliary.StateParserimport burlap.oomdp.core.Domainimport burlap.oomdp.core.Stateimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.visualizer.Visualizerimport java.util.Listpublic class ContinuousDomainTutorial public static void mainString argsuncomment the example you want to see and comment out the rest.MCLSPIFBMCLSPIRBFIPSSLLSARSApublic static void MCLSPIFBMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100StateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullConcatenatedObjectFeatureVectorGenerator featureVectorGenerator new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTFourierBasis fb new FourierBasisfeatureVectorGenerator, 4LSPI lspi new LSPIdomain, rf, tf, 0.99, fblspi.setDatasetdatasetlspi.runPolicyIteration30, 1e-6GreedyQPolicy p new GreedyQPolicylspiVisualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vexp new VisualActionObserverdomain, vvexp.initGUISADomaindomain.addActionObserverForAllActionvexpState s mcGen.getCleanStatedomainforint i 0 i 5 ip.evaluateBehaviors, rf, tfSystem.out.printlnFinished.public static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100get a state definition earlier, well use it soon.State s mcGen.getCleanStatedomainStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullset up RBF feature databaseRBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5ListState griddedStates gridder.gridInputStatesDistanceMetric metric new EuclideanDistancenew ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTforState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2notice we pass LSPI our RBF features this timeLSPI lspi new LSPIdomain, rf, tf, 0.99, rbflspi.setDatasetdatasetlspi.runPolicyIteration30, 1e-6GreedyQPolicy p new GreedyQPolicylspiVisualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vexp new VisualActionObserverdomain, vvexp.initGUISADomaindomain.addActionObserverForAllActionvexpforint i 0 i 5 ip.evaluateBehaviors, rf, tfSystem.out.printlnFinished.public static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.Domain domain ip.generateDomainRewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.State initialState InvertedPendulum.getInitialStatedomainSparseSampling ss new SparseSamplingdomain, rf, tf, 1,new NameDependentStateHashFactory, 10, 1ss.setForgetPreviousPlanResultstruePolicy p new GreedyQPolicyssEpisodeAnalysis ea p.evaluateBehaviorinitialState, rf, tf, 500StateParser sp new InvertedPendulumStateParserdomainea.writeToFileipssPlan, spSystem.out.printlnNum Steps ea.numTimeStepsVisualizer v InvertedPendulumVisualizer.getInvertedPendulumVisualizernew EpisodeSequenceVisualizerv, domain, sp, ippublic static void LLSARSALunarLanderDomain lld new LunarLanderDomainDomain domain lld.generateDomainRewardFunction rf new LunarLanderRFdomainTerminalFunction tf new LunarLanderTFdomainStateParser sp new LLStateParserdomainState s LunarLanderDomain.getCleanStatedomain, 0LunarLanderDomain.setAgents, 0., 5.0, 0.0LunarLanderDomain.setPads, 75., 95., 0., 10.int nTilings 5CMACFeatureDatabase cmac new CMACFeatureDatabasenTilings,CMACFeatureDatabase.TilingArrangement.RANDOMJITTERdouble resolution 10.double angleWidth 2 lld.getAngmax resolutiondouble xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutioncmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.AATTNAME,angleWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.XATTNAME,xWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.YATTNAME,yWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.VXATTNAME,velocityWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.VYATTNAME,velocityWidthdouble defaultQ 0.5ValueFunctionApproximation vfa cmac.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, rf, tf, 0.99,vfa, 0.02, 10000, 0.5forint i 0 i 5000 iEpisodeAnalysis ea agent.runLearningEpisodeFroms run learning episodeea.writeToFileString.formatlunarLandere04d, i, sp record episode to a fileSystem.out.printlni ea.numTimeSteps print the performanceVisualizer v LLVisualizer.getVisualizerlldnew EpisodeSequenceVisualizerv, domain, sp, lunarLander End.", "metadata": {"last_modified": "2016-03-04T22:05:08+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 4"], "word_count": 511, "token_count_estimate": 2058}}, "http://burlap.cs.brown.edu/tutorials_v2/bd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 4 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Next Part The Components of a Visualizer Different visualization components in BURLAP are built around implementing the RenderLayer interface, which requires being passed a graphics context on which the implementing class will paint. Having everything built around RenderLayer objectsmeans you can trivially stack different kinds of information ontop of each other. For example, you might have a render layer to display a state, and another one to display value function information, layered on top. In this tutorial we will focus onrendering the state, for which there is a specific implementation of the RenderLayer interface that we can use called StateRenderLayer , which after constructing we can pass to the Visualizer class, which will create a Java canvas to which are StateRenderLayer can paint. The StateRenderLayer is provided a number of different subpainters that it will call sequentially to paint to the canvas. Each subpainter is either a StaticPainter or an ObjectPainter . The StaticPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP State object, and the width and height of the canvas that then paints to the canvas information about the overall state or the domain to which the state belongs. For example, in the grid world weve been creating, walls are not explicitly represented in our OO-MDP state object, but when rendering a state, wed like to paint where the walls are. The ObjectPainter is an interface that requires implementing a method that takes a graphics context, an OO-MDP state, a specific OO-MDP ObjectInstance from that state, and the width and height of the canvas that then paints to the canvas information about that specific object instance. In our GridWorld, we would want to provide a different ObjectPainter forthe agent class objects and location class objects. When our StateRenderLayer object is provided a bunch of StaticPainter and ObjectPainter objects, during its state paint method it will first paint to the graphics context with the StaticPainter objects. Then for each OO-MDP object in the state, it will paint to the canvas using the corresponding ObjectPainterthat we will associate with that class. Implementing the Painters To implement a StaticPainter for painting the walls of our grid world as black rectangles, add the below inner class to the ExampleGridWord class code weve been writing. public class WallPainter implements StaticPainterOverridepublic void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on our cavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left corrdinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, height The main idea of this code is to first determine how wide and tall cells in our grid world will be rendered on a canvas of the given size. This is simply with widthheight of the canvas dividedby the number of cells in our grid world along each dimension.Then we iterate through our map and draw a rectangle in the corresponding position when the map has a wall listed as being there. The only extra thing to take care of is that the Javapainting coordinate system is in the top left corner, whereasweve defined our map with a bottom left coordinate system, so we perform a coordinate system switch in the rendering as shown. Now lets create a painter for the OO-MDP agent class, which well represent as a gray circle in the word. This codewill look almost identical to our map painter code except instead of iterating through the map, well get the agent x and y position from the OO-MDP ObjectInstance our painter is provided and instead of painting a black rectangle well paint a gray circle. As before add the below class inside our ExampleGridWorld class. public class AgentPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getIntValForAttributeATTXint ay ob.getIntValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, height Well also do the same for a location object, but well use a blue rectangle instead. public class LocationPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getIntValForAttributeATTXint ay ob.getIntValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvas origin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, height Finally, well want to add some methods to our ExampleGridWorld domain generator to create a StateRenderLayer and correspondingVisualizer to hold it. The StateRenderLayer merely needs to be given a WallPainter instance and told to use a AgentPainter instance for objects of OO-MDP class agent and a LocationPainter instance for objects of OO-MDP class location. Once a StateRenderLayer object is created, a Visualizer object merely needs to be pointed to it. To do so, add the following methods to our ExampleGridWorld class. public StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStaticPainternew WallPainterrl.addObjectClassPainterCLASSLOCATION, new LocationPainterrl.addObjectClassPainterCLASSAGENT, new AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayer Note that in the getStateRenderLayer method we added the location object painter before the agent object painter. This implicitly tells the StateRenderLayer the order in which objects should be painted first objects of class location and then objects of class agent. The result is that when an agent is at the same position as a location, the agent will be rendered on top of it. Now that we can construct a visualizer, lets swap out our TermainalExplorer in our main method for a VisualExplorer . The VisualExplorer can be controlled by manually typing in actions into a text field, but its often easier to control the agent with the keyboard. To do so, we can specify a binding between a key press and an action name with the addKeyAction method. In this case, well set w to correspond to north s south d east and a west. Change your main method to now look like the below. public static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainTerminalExplorer exp new TerminalExplorerdomainexp.exploreFromStateinitialStateVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, v, initialStateexp.addKeyActionw, ACTIONNORTHexp.addKeyActions, ACTIONSOUTHexp.addKeyActiond, ACTIONEASTexp.addKeyActiona, ACTIONWESTexp.initGUI Now when you run your code, youll be presented a visualization of the state and you can interact with it with the wasd keys, similar to what you see in the below image. Note that you may need to click on the image for it to begin accepting key presses. Remember, since we made movement stochastic, you may find the agent moving in unintended directions some of the time. Also note that when the agent enters the same position as the location object that in the bottom text box in the window youll see atagent0, location0 appear. This text box always lists all propositional functions that are true in the current state automatically. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 4"], "word_count": 1385, "token_count_estimate": 1970}}, "http://burlap.cs.brown.edu/tutorials_v2/bd/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Building a Domain Tutorials Building a Domain Part 5 Tutorial Contents Introduction Markov Decision Process OO-MDPs BURLAP OO-MDP Java Class Overview Defining GridWorld Object Classes Defining GridWorld Actions Defining Propositional Functions Testing the Domain The Components of a Visualizer Implementing the Painters Reward Functions and Terminal Functions Conclusions Final Code Previous Part Reward Functions and Terminal Functions Now that youve created a world, youll want to definetasks for the world so that you can run planning and learningalgorithms on it. Tasks in BURLAP are typically defined with RewardFunction and TerminalFunction implementations. The former specifies the reward received by the agent for transition tuples previous state, action taken, resulting state the later specifies which states are terminal states that cause all further action to cease. While we wont be using any planning or learning algorithms in this tutorial, we will briefly cover how to create your own reward functions and terminal state functions so that you can run planning and learning algorithms on your domain. Before you make your own RewardFunction and TerminalFunction,it is sometimes worth checking to see if BURLAP already has an implementation that you can use. For example, many different problems use a reward function that returns -1 everywhere.For problems like these, you can use the UniformCostRF object. If your domain is continuing i.e., non-terminating, thenyou can use the NullTermination object. It also not uncommon to have a goal condition that is satisfied whenever any object grounding of a propositional function returns true. In our grid world, for example, if we let location objects indicate goal locations, we might want a terminal function that returns true for any state in which the agent is at a location. In such a case you can use the SinglePFTF TerminalFunction and point it to the atLocation propositional function. If none of the existing RewardFunction or TerminalFunction objects in BURLAP suit your needs, you can always create your own. For example, suppose we wanted a reward function that returned -1 everywhere, except when the agent reached a designated x, y position at which point it returned a reward of 100. We can implement such a reward function as shown below. public static class ExampleRF implements RewardFunctionint goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, GroundedAction a, State sprime get location of agent in next stateObjectInstance agent sprime.getFirstObjectOfClassCLASSAGENTint ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1 Notice that when we get the agent position, we get it from the sprime variable Thats because parameter s represents the previous state, a represents the action the agent took in the previous state, and sprime represents the state the agent ended up in as a result. Since we want to return 100 when the agent reaches our goal location, we care about where the agent ended up, which is held in sprime. If we wanted to make a similar TerminalFunction that marked our goal state as a terminal state, we would do so with the similar below code. public static class ExampleTF implements TerminalFunctionint goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn truereturn false And that is all there is to defining reward functions and terminal states If youd like to test them, you can use the TerminalExplorer and VisualExploer to do so since they ultimately interact with Environment instances. To do that, well first create an instance of SimulatedEnvironment using our reward function and terminal function, and then well provide the TerminalExplorer and VisualExplorer the Environment instance. For the TerminalExporler it will print out the last reward receieved and whether the current state is terminal. For the VisualExplorer, you can open up the console by pressing the button at the bottom and youll find at the bottom of the print the last reward received and whether the current state is terminal. Adjust your main method to the below to test that. public static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainRewardFunction rf new ExampleRF10, 10TerminalFunction tf new ExampleTF10, 10SimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, initialStateTerminalExplorer exp new TerminalExplorerdomain, envexp.exploreVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTHexp.addKeyActions, ACTIONSOUTHexp.addKeyActiond, ACTIONEASTexp.addKeyActiona, ACTIONWESTexp.initGUI You may now notice that when you reach the goal location in the VisualExplorer that you can no longer act. This frezzing occurs because now that weve defined a TerminalFunction, you can no longer act once you reach it However, you can press the key to send the resetEnvironment message to the Environment, which will place you back in the beginning. Conclusions In this tutorial we showed you how to create a domain, visualize it, interact with it, and how to define tasks for it. With a domain and task in hand youre now ready to use the planning and learning algorithms in BURLAP on it, which you will learn about in the next tutorial . Although we showed you how to create a grid world domain in this tutorial, if you do want to run experiments on a grid world, we highly recommend that you use the GridWorldDomain already in BURLAP. It will support many more features than we covered in this tutorial including 1 dimensional walls, location types, and more flexible transition dynamics. Final Code For reference, you can find all of the code we wrote below. import burlap.oomdp.auxiliary.DomainGeneratorimport burlap.oomdp.core.import burlap.oomdp.core.objects.MutableObjectInstanceimport burlap.oomdp.core.objects.ObjectInstanceimport burlap.oomdp.core.states.MutableStateimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.import burlap.oomdp.singleagent.common.SimpleActionimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.singleagent.explorer.TerminalExplorerimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.ObjectPainterimport burlap.oomdp.visualizer.StateRenderLayerimport burlap.oomdp.visualizer.StaticPainterimport burlap.oomdp.visualizer.Visualizerimport java.awt.import java.awt.geom.Ellipse2Dimport java.awt.geom.Rectangle2Dimport java.util.import java.util.Listpublic class ExampleGridWorld implements DomainGeneratorpublic static final String ATTX xpublic static final String ATTY ypublic static final String CLASSAGENT agentpublic static final String CLASSLOCATION locationpublic static final String ACTIONNORTH northpublic static final String ACTIONSOUTH southpublic static final String ACTIONEAST eastpublic static final String ACTIONWEST westpublic static final String PFAT atordered so first dimension is xprotected int map new int0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,Overridepublic Domain generateDomain SADomain domain new SADomainAttribute xatt new Attributedomain, ATTX, Attribute.AttributeType.INTxatt.setLims0, 10Attribute yatt new Attributedomain, ATTY, Attribute.AttributeType.INTyatt.setLims0, 10ObjectClass agentClass new ObjectClassdomain, CLASSAGENTagentClass.addAttributexattagentClass.addAttributeyattObjectClass locationClass new ObjectClassdomain, CLASSLOCATIONlocationClass.addAttributexattlocationClass.addAttributeyattnew MovementACTIONNORTH, domain, 0new MovementACTIONSOUTH, domain, 1new MovementACTIONEAST, domain, 2new MovementACTIONWEST, domain, 3new AtLocationdomainreturn domainpublic static State getExampleStateDomain domainState s new MutableStateObjectInstance agent new MutableObjectInstancedomain.getObjectClassCLASSAGENT, agent0agent.setValueATTX, 0agent.setValueATTY, 0ObjectInstance location new MutableObjectInstancedomain.getObjectClassCLASSLOCATION, location0location.setValueATTX, 10location.setValueATTY, 10s.addObjectagents.addObjectlocationreturn spublic StateRenderLayer getStateRenderLayerStateRenderLayer rl new StateRenderLayerrl.addStaticPainternew WallPainterrl.addObjectClassPainterCLASSLOCATION, new LocationPainterrl.addObjectClassPainterCLASSAGENT, new AgentPainterreturn rlpublic Visualizer getVisualizerreturn new Visualizerthis.getStateRenderLayerprotected class Movement extends SimpleAction implements FullActionModel 0 north 1 south 2east 3 westprotected double directionProbs new double4public MovementString actionName, Domain domain, int directionsuperactionName, domainforint i 0 i 4 iifi directiondirectionProbsi 0.8elsedirectionProbsi 0.23.Overrideprotected State performActionHelperState s, GroundedAction groundedAction get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getIntValForAttributeATTXint curY agent.getIntValForAttributeATTYsample directon with random rolldouble r Math.randomdouble sumProb 0.int dir 0forint i 0 i this.directionProbs.length isumProb this.directionProbsiifr sumProbdir ibreak found directionget resulting positionint newPos this.moveResultcurX, curY, dirset the new positionagent.setValueATTX, newPos0agent.setValueATTY, newPos1return the state we just modifiedreturn sOverridepublic ListTransitionProbability getTransitionsState s, GroundedAction groundedAction get agent and current positionObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint curX agent.getIntValForAttributeATTXint curY agent.getIntValForAttributeATTYListTransitionProbability tps new ArrayListTransitionProbability4TransitionProbability noChangeTransition nullforint i 0 i this.directionProbs.length iint newPos this.moveResultcurX, curY, iifnewPos0 curX newPos1 curYnew possible outcomeState ns s.copyObjectInstance nagent ns.getFirstObjectOfClassCLASSAGENTnagent.setValueATTX, newPos0nagent.setValueATTY, newPos1create transition probability object and add to our list of outcomestps.addnew TransitionProbabilityns, this.directionProbsielsethis direction didnt lead anywhere newif there are existing possible directionsthat wouldnt lead anywhere, aggregate with themifnoChangeTransition nullnoChangeTransition.p this.directionProbsielseotherwise create this new state and transitionnoChangeTransition new TransitionProbabilitys.copy,this.directionProbsitps.addnoChangeTransitionreturn tpsprotected int moveResultint curX, int curY, int directionfirst get change in x and y from direction using 0 north 1 south 2east 3 westint xdelta 0int ydelta 0ifdirection 0ydelta 1else ifdirection 1ydelta -1else ifdirection 2xdelta 1elsexdelta -1int nx curX xdeltaint ny curY ydeltaint width ExampleGridWorld.this.map.lengthint height ExampleGridWorld.this.map0.lengthmake sure new position is valid not a wall or off boundsifnx 0 nx width ny 0 ny height ExampleGridWorld.this.mapnxny 1nx curXny curYreturn new intnx,nyprotected class AtLocation extends PropositionalFunction public AtLocationDomain domainsuperPFAT, domain, new String CLASSAGENT,CLASSLOCATIONOverridepublic boolean isTrueState s, String params ObjectInstance agent s.getObjectparams0ObjectInstance location s.getObjectparams1int ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYint lx location.getIntValForAttributeATTXint ly location.getIntValForAttributeATTYreturn ax lx ay lypublic class WallPainter implements StaticPainter Overridepublic void paintGraphics2D g2, State s, float cWidth, float cHeight walls will be filled in blackg2.setColorColor.BLACKset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cellon our canvas such that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightpass through each cell of our map and if its a wall, paint a black rectangle on ourcavas of dimension widthxheightforint i 0 i ExampleGridWorld.this.map.length iforint j 0 j ExampleGridWorld.this.map0.length jis there a wall hereifExampleGridWorld.this.mapij 1left coordinate of cell on our canvasfloat rx iwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - jheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic class AgentPainter implements ObjectPainterOverridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in grayg2.setColorColor.GRAYset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getIntValForAttributeATTXint ay ob.getIntValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Ellipse2D.Floatrx, ry, width, heightpublic class LocationPainter implements ObjectPainter Overridepublic void paintObjectGraphics2D g2, State s, ObjectInstance ob,float cWidth, float cHeight agent will be filled in blueg2.setColorColor.BLUEset up floats for the width and height of our domainfloat fWidth ExampleGridWorld.this.map.lengthfloat fHeight ExampleGridWorld.this.map0.lengthdetermine the width of a single cell on our canvassuch that the whole map can be paintedfloat width cWidth fWidthfloat height cHeight fHeightint ax ob.getIntValForAttributeATTXint ay ob.getIntValForAttributeATTYleft coordinate of cell on our canvasfloat rx axwidthtop coordinate of cell on our canvascoordinate system adjustment because the java canvasorigin is in the top left instead of the bottom rightfloat ry cHeight - height - ayheightpaint the rectangleg2.fillnew Rectangle2D.Floatrx, ry, width, heightpublic static class ExampleRF implements RewardFunction int goalXint goalYpublic ExampleRFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic double rewardState s, GroundedAction a, State sprime get location of agent in next stateObjectInstance agent sprime.getFirstObjectOfClassCLASSAGENTint ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn 100.return -1public static class ExampleTF implements TerminalFunction int goalXint goalYpublic ExampleTFint goalX, int goalYthis.goalX goalXthis.goalY goalYOverridepublic boolean isTerminalState s get location of agent in next stateObjectInstance agent s.getFirstObjectOfClassCLASSAGENTint ax agent.getIntValForAttributeATTXint ay agent.getIntValForAttributeATTYare they at goal locationifax this.goalX ay this.goalYreturn truereturn falsepublic static void mainString argsExampleGridWorld gen new ExampleGridWorldDomain domain gen.generateDomainState initialState ExampleGridWorld.getExampleStatedomainRewardFunction rf new ExampleRF10, 10TerminalFunction tf new ExampleTF10, 10SimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, initialStateTerminalExplorer exp new TerminalExplorerdomain, envexp.exploreVisualizer v gen.getVisualizerVisualExplorer exp new VisualExplorerdomain, env, vexp.addKeyActionw, ACTIONNORTHexp.addKeyActions, ACTIONSOUTHexp.addKeyActiond, ACTIONEASTexp.addKeyActiona, ACTIONWESTexp.initGUI End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Building a Domain", ">", "> Part 5"], "word_count": 1789, "token_count_estimate": 3701}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 3 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with BFS One of the most basic deterministic planning algorithms is breadth-first search, which we will demonstrate first. Since we willbe testing a number of different planning and learning algorithms in this tutorial, we will define a separate methodfor using each planning or learning algorithm and then you can simply select which one you want to try in the mainmethod of the class. We will also pass each of these methods the output path to record itsresults. Lets start by defining the BFS method. public void BFSExampleString outputPathDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath bfs The first part of the method creates an instance of the BFS planning algorithm, whichitself is a subclass of the DeterministicPlanner class. To instantiate BFS, it only requires a reference to the domain,the goal condition for which it should search, and the HashableStateFactory. Because BFS implements the Planner interface, planning can be initiated by callingthe planFromState method and passing it the initial state form which it should plan. The planFromState method automatically returns a Policy object, which can be used to query and execute the results of the planning in simulation or in an environment. Using non-default policies Each Planner implementation will return a different kind of Policy from planFromState that is relevant for the results the Planner stores. However, often times, after calling the planFromState method, you can wrap a different policy than the one that is returned around your planner instance to get slightly different behavior. For example, BFSs planFromState will return an SDPlannerPolicy instance, which will return the action the planner selected for any states on its solution path if the policy is queried for a state not on the solution path, it will throw a runtime exception. However, you might choose to wrap a DDPlannerPolicy around BFS instead of using the returned SDPlannerPolicy, it will act the same except rather than throw a runtime exception if an action selection is queried for a state not on the current solution path, it will transparently recall planFromState on the new state to get an action to return that is, it will perform replanning. Once you have a Policy object, you can roll out the behavior and extract the resulting episode sequence of state-action-reward tuples from it in simulation by calling the evaluateBehavior method. There are a few different versions of the evaluateBehavior method which take different parameters to determine theanalysis and stopping criteria. In this case, however, we are passing it the initial state from which the policy shouldstart being followed, the reward function used to assess the performance and the the termination function whichspecifies when the policy should stop. The method will return an EpisodeAnalysis object which will containall of the states visited, actions taken, and rewards received when following that policy. You can investigate these individual elements of the episode if you like,but for this tutorial were just going to save the results of this episode to a file and then use the offlinevisualizer we previously defined to view it. An EpisodeAnalysis objectcan be written to a file by calling the writeToFile method on it and passing it a path to the file.Note that the method will automatically append a .episode extension to the file path if you did not specify it yourself and will create any directories in the path that do not already exist. Executing policies in environments The evaluateBehavior method can also take as input an Environment rather than a State. When given an environment, the policy is followed in the environment rather than simulation unless of course the environment is a simulation itself. This is very useful if you need to run planning in a model of the world, and then execute the results of that plan on something real or external from your model. And thats all you need to code to plan with BFS on a defined domain and task Using the EpisodeSequenceVisualizer GUI Now that the method to perform planning with BFS is defined, add a method call to it in your main method. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultsrun exampleexample.BFSExampleoutputPathrun the visualizerexample.visualizeoutputPath Note that our output path ended with a . Whatever path you use, you should include the trailing since the code we wrote to write the file will automatically append to that path name. With the planning method hooked up, run the code Because the task is simple, BFS should find a solution veryquickly and print to the standard output the number of nodes it expanded in its search. Following that, the GUIshould be launched for viewing the EpisodeAnalysis object that was recorded to a file. You should see something like the belowimage appear. The main panel in the center of the window is used to render the current state selected. The text box at thebottom of the window will list all of the propositional functions that are true in that state. The leftmostlist on the right side of the window lists all of the episode files that were recorded in the directory passed to theEpisodeSequenceVisualizer constructor. After selecting one of those instances, the list of actions taken in theepisode are listed on the right-most list. Note that the actioncorresponds to the action that will be taken in the statethat is currently visualized, so the result of the actionwill be seen in the next state. In the GridWorldDomain visualizer, the black cells represent walls, the grey circlerepresents the agent, and the blue cell represents the location object that we made. Planning with DFS Another common search-based planning algorithm is depth-first search DFS. Define the below method to providea means to solve the task with DFS. public void DFSExampleString outputPathDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath dfs You will notice that the code for DFS is effectively identical to the previous BFS code that we wrote, only this timethe DeterministicPlanner is instantiated with a DFS object instead of a BFS object. DFS has a number of other constructorsthat allow you to specify other parameters such a depth limit, or maintaining a closed list. Feel freeto experiment with them. After you have defined the method, you can call it from the main method like we did the BFS method and visualize theresults in the same way. Since DFS is not an optimal planner, it is likely that the solution it gives you will bemuch worse than the one BFS gave you Planning with A One of the most well known optimal search-based planning algorithms is A. A is an informed planner because it takesas input an admissible heuristic which estimates the cost to the goal from any given state. We can also use A to plan a solution for our taskas long as we also take the additional step of defining a heuristic to use or you can use a NullHeuristic which will make A uninformed. The below code defines a methodfor using A with a Manhattan distance to goal heuristic. public void AStarExampleString outputPathHeuristic mdistHeuristic new Heuristic Overridepublic double hState s ObjectInstance agent s.getFirstObjectOfClassGridWorldDomain.CLASSAGENTObjectInstance location s.getFirstObjectOfClassGridWorldDomain.CLASSLOCATIONint ax agent.getIntValForAttributeGridWorldDomain.ATTXint ay agent.getIntValForAttributeGridWorldDomain.ATTYint lx location.getIntValForAttributeGridWorldDomain.ATTXint ly location.getIntValForAttributeGridWorldDomain.ATTYdouble mdist Math.absax-lx Math.absay-lyreturn -mdistDeterministicPlanner planner new AStardomain, rf, goalCondition, hashingFactory, mdistHeuristicPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath astar There are two main differences between this method and the methods that we wrote for BFS and DFSplanning. The smaller difference is that the A constructor includes a reward function in its parameters. The reward function is needed because it is what A uses to keep trackof the actual cost of any path it is exploring. Rewards and Costs A is an algorithm that operates on costs and is not an algorithm that can workwith negative costs. BURLAP in general represents state-action evaluations as rewards ,rather than costs. However, a cost can be represented as a negative reward therefore,the reward function provided to A should return negative values. If the rewardfunction returns any positive values, A will not function properly. Since our examples reward functionreturns only negative values it returns -1 for every state-action pair, our reward function will workfine with A. The bigger difference between the previous planning code and A is in defining theheuristic, which we do by implementing the Heuristic interface. The h method of the Heuristic interfaceis passed a state object and the method should return the estimated reward to the goal fromthat state which should be a non-positive value. Since we have opted to use the Manhattan distance as our heuristic, this will involvecomputing the distance between the agent position and the location position for which we will assumethere is only one. To compute this difference, the method will first need to extract the agentobject instance and the location object instance out of the state, which is done in lines 7 and 8.Specifically, the getFirstObjectOfClass method of a state will return the first object in the state that belongs to the OO-MDP class with the given name. Lines 10-14 then extract the integer values for theX and Y attributes of both the agent and location objects. Once those attribute values are retrieved, the Manhattan distanceis computed and returned in lines 16 and 17. Note that the negative distance is returned, because our reward functionreturns -1 for each step. With the rest of the code being the same, you can have the main method call the A method for planningand view the results in the usual way Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 3", "Using non-default policies", "Executing policies in environments", "Rewards and Costs"], "word_count": 1639, "token_count_estimate": 2119}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 2 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Initializing the data members Now that we have the structure of our class, well need to initialize our data membersto instances that will create our domain and define our task. First, create a default constructor. The first thing well do in the constructor is create our domain. public BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRooms domain gwdg.generateDomainmore to come... The first line will create an 11x11 deterministic GridWorld. The second line sets up the map to a pre-canned layoutthe four rooms layout. This domain layout was used in Option learning work from Sutton, Precup, and Singh 1999and it presents a simple environment for us to do some tests. Alternatively, you could also define your ownmap layout by either passing the constructor a 2D integer array with 1s specifying the cells with walls and 0sspecifying open cells, or you could simply specify the size of the domain like we did and then use the GridWorldDomainobjects horiztonalWall and verticalWall methods to place walls on it. The GridWorldDomain also supports1 dimensional walls between cells that you can set, if youd prefer that kind of domain. For simplicity, well stick with thefour rooms layout. The third line will produce the Domain object for the grid world. Recall from the previouspart of the tutorial that Domain objects hold references to all the attributes, object classes, propositional functions, and actionsalong with the actions transition dynamics. How a GridWorldDomain Domain is defined A GridWorldDomain has two primary attributes, an X attribute anda Y attribute. There are also two classes an AGENT class and a LOCATION class, each of which is defined by theX and Y attributes. While there could potentially be any number of AGENT object instantiations in a state, inthis domain we expect only one to ever be defined. The location objects will be used for points of interest.Specifically, we will use a single location object to represent a goal location. The GridWorld domain also definesfive propositional functions atLocationAGENT, LOCATION wallToNorthAGENT wallToSouthAGENTwallToEastAGENT wallToWestAGENT. The first of those returns true when the specified AGENT object is at thesame location as the specified LOCATION object. The latter four propositional functions return true when there is a wall in the immediate cell of the defined direction of the specified AGENT object. Finally, the GridWorld domain defines four actions to move north, south, east, or west of the agents current position.Although we could have told the GridWorldDomain generator to make these movements stochastic that is, specify a probability in which the agent moves in an unintended direction, in our specific examplewe have left them as the default deterministic actions. If an agent moves into a wall, then its position does notchange. Although this domain instantiation has specific settings for grid worlds, differentdomains in BURLAP follow similar conventions. That is, you create an instanceof a domain generator specify the parameters of the domain through mutators,and then finally extract the domain with a call to a generateDomain method.For example, the LunarLander domain generator lets you set properties like themaximum velocity and the force of gravity. Next we will want to define the actual task to be solved for this domain. We will do this by specifyinga reward function, a termination function, and a goal condition the latter of which we will use exclusively for search-based deterministic planners that this tutorial will cover. In general,you can always define your own reward functions, terminal functions, and goal conditions by implementing the RewardFunction , TerminalFunction , and StateConditionTest interfaces, respectively, yourself. However, BURLAPalso comes packaged with a bunch of standard instances as well as various domain-specific implementations that we will use here. If you want to know moreabout defining your own, consult the Building a Domain tutorial. rf new UniformCostRF tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATION goalCondition new TFGoalConditiontf The first line will create a reward function that always returns -1 for every state-action-state transition. The next line defines a terminal function that identifies terminal states as states in which the agent is at the same position as locaion object. When the reward function -1 everywhere is taken together with this terminal function everything ends when the agent reaches a location, it motivates the agent to reach a location object as soon as possible. How SinglePFTF works The TerminalFunction is created as an instance of SinglePFTF . SinglePFTF is a terminal function that takes as input a PropositionalFunction and sets any state in which the propositional function is true for any valid objects as terminal states. In this case, we provided it the GridWorldDomains atLocation propositional function. This propositional function operates on two objects the agent and a location object. For example, we might see the function evaluated on agent0 and location2 atLocationagent0, location2. The propositional function returns true whenever the input agent is at the same position as the input location object. Therefore, for any input state, SinglePFTF finds all possible agent and location pairs and checks whether atLocation is true for any of them. If it is, then SinglePFTF returns evaluates that state as a terminal state. Note that we are using UniformCostRF and SinglePFTF to illustrate some of the more general approaches in BURLAP to defining reward functions and terminal functions. However, GridWorldDomain also has specific reward function GridWorldRewardFunction and terminal function GridWorldTerminalFunction designed for grid world problems that in practice you may want to use instead for grid worlds. The final line sets up the goal condition to be synonymous with the termination function. Note that goal stateswill not always be the same as terminal states there may beterminal states that are not goal states, such as failure states, but in this example they are. The next step will be to define the initial state of this task. We could either do thisby creating an empty State object and then manually adding object instantiations for each object class,or we could use some methods of the GridWorldDomain class to facilitate the process. We will do the latterfor brevity, but if you want a more complete description of creating astate object by hand, consider looking in the Building a Domain tutorial. initialState GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10 The first line will return a state object with a single instance of the AGENT class and a single instanceof the LOCATION class. The second line of code then sets the agent to be at position 0,0. The third line ofcode sets the location to be at position 10,10. The first zero you see in the parameters indicates whichLOCATION object index position to set. Since there is only one LOCATION object, we are setting the positionof the 0th indexed LOCATION object. Next we will instantiate the HashableStateFactory that we wish to use. Since we are not doing anything fancy like state abstraction, we will use SimpleHashableStateFactory, which when we provide no constructor arguments will also use object identifier independence as discussed previously. hashingFactory new SimpleHashableStateFactory Finally, we will instantiate an Environment with which the agent will interact in our learning algorithm demonstrations. Since we will be using BURLAPs simulation of the environment, we will use a SimulatedEnvironment, which along with the domain, needs to be told about the reward function, terminal function and initial state for the environment. env new SimulatedEnvironmentdomain, rf, tf, initialState At this point you should have initialized all of the data members for the class and the final constructor will look something like the below. public BasicBehaviorcreate the domaingwdg new GridWorldDomain11, 11gwdg.setMapToFourRoomsdomain gwdg.generateDomaindefine the taskrf new UniformCostRFtf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATIONgoalCondition new TFGoalConditiontfset up the initial state of the taskinitialState GridWorldDomain.getOneAgentNLocationStatedomain, 1GridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10set up the state hashing system for tabular algorithmshashingFactory new SimpleHashableStateFactoryset up the environment for learning algorithmsenv new SimulatedEnvironmentdomain, rf, tf, initialState Setting up a result visualizer Before we get to actually running planning and learning algorithms, were going to want a way to visualizethe results that they generate. While there are a few different ways to do this, for now we willdefine an offline visualizer that will allow us to run planning or learning completely, and then visualizethe results after its finished. Offline visualization has the advantage of not bogging down the runtime of planninglearning algorithms with time allocated for visualization. To create our offline visualizer, we will need to define a state Visualizer and pass it to an EpisodeSequenceVisualizer . A Visualizer is a Java canvas that can render State objects. An EpisodeSequenceVisualizer lets you view and explore episode state-action-reward sequences that an agent took and can either load the episodes from files or be provided them programmatically. In this example, we will save results to file and load them back up. To handle this kind of result visualization, create the below method. public void visualizeString outputPathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapnew EpisodeSequenceVisualizerv, domain, outputPath Note that the outputPath parameter specifies the directory where our planninglearning results were storedwell get to this when we actually apply a planninglearning algorithm. The state Visualizer we will use is the one designed for rendering grid world states. It takes as input the map of the world a 2D int array, which we retrieve from our GridWorldDomain instance. Note that other domains included in BURLAP have their own Visualizers that you can use for them. Before moving on to the next part of the tutorial, lets also hook up our class constructor and visualizer methodto the main method. public static void mainString args BasicBehavior example new BasicBehaviorString outputPath output directory to record resultswe will call planning and learning algorithms hererun the visualizerexample.visualizeoutputPath Note that you can set the output path to whatever you want. If it doesnt already exist, the codethat saves the results will automatically created it more on that next. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 2", "How a GridWorldDomain Domain is defined", "How SinglePFTF works"], "word_count": 1668, "token_count_estimate": 2271}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 4 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Planning with Value Iteration A common stochastic domain planner is Value Iteration VI. An advantage of VI is that it will compute thepolicy for the entire state space that is reachable from the initial state thatis passed to the planFromState method. To set up a VI planner, define the following method. public void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, rf, tf, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath vi VI is a planning method defined for the classic MDP formalism, so unlike the previousdeterministic planners, its constructor takes as input the reward function and terminal function,rather than a goal condition. VI also takes as a parameter a discount factor which specifies how much future rewards are favored over immediate rewards. In this case,a fairly large value of 0.99 is set which means the agent will prefer later future rewards almost as much asimmediate rewards. The last two parameters to the constructor specify stopping conditions for theplanning. The second to last parameter specifies that when the maximumchange in the value function of any state is less than that specified threshold value 0.001 in this case, planning will stop. The last parameter specifies a maximumnumber of updates for each state that can happen before planning is stopped 100 in this case, regardlessof whether the maximum value function change threshold was crossed. Since VI is a stochastic domain planning algorithm, rather than a deterministic one like the previous algorithms weused, its planFromState method returns a GreedyQPolicy . This policy looks at the Q-values the planner computes and returns the action with the maximium Q-value and breaks ties randomly. A Q-value represents the expected future discounted reward for taking each action in each state and then following the optimal policy thereafter and this policy can be used with any planning or learning algorithm that returns Q-values by implementing the QFunction interface. Trysetting the main method to call our newly defined VI example method now. Learning with Q-Learning All of the previous examples were examples of using planning algorithms to solve our task. In this section,we will diverge from that and use a learning algorithm, Q-learning, to solve the task. Ultimately, learningalgorithms are utilized in much the same way as planning algorithms, except you will run multipleepisodes of learning in which the agent interacts with an Environment instance to solve it or one very long episode if it is a continuing task rather than an episodictask. The method you should define to utilize Q-learning is shown below. public void QLearningExampleString outputPathLearningAgent agent new QLearningdomain, 0.99, hashingFactory, 0., 1.run learning for 50 episodesforint i 0 i 50 iEpisodeAnalysis ea agent.runLearningEpisodeenvea.writeToFileoutputPath ql iSystem.out.printlni ea.maxTimeStepreset environment for next learning episodeenv.resetEnvironment Lets first look at the constructor. Rather than a planning instance, were creating a LearningAgent instance which provides some methods for learning with an environment. QLearning is an instance of the LearningAgent interfaceand takes parameters for the domain, a discount factor, a HashableStateFactory, an initial value for the Q-values, and a learning rate which for a deterministic domain, 1.0 is a good choice. Note that unlike the planning algorithms we did not have to specify the reward function or terminal function. These elements can be omitted because the agent will learn by interacting with an Environment that is responsible for telling the agent about the reward it received for an interaction and whether that next state is a terminal state. Also note that thisconstructor will by default set Q-learning to use a 0.1 epsilon greedy policy. There are other constructorsthat allow you to set which learning policy to use and there is also a setter that allows you to set itif youd like to use a different policy. Other parameters for Q-learning could also be set, but we will not detail them here. With the QLearning instance created, next we will run 50 learning episodes, so we set up a for loop.To run a learning episode, we call the method runLearningEpisode method on the LearningAgent instanceand pass it the Environment in which learning will be performed. The method also returns an EpisodeAnalysis object similar to policies so that a record of the interactions can be examined. As before, we can then write the returned episode to disk for viewing later. Finally, at the end of the loop, we call the resetEnvironment method on the Environment. This method is the typical way to signal that an Environment needs to reset to an initial state from its current state, which may be a terminal state. When the method returns, it is expected that the environment in a non-terminal state from which an agent can act again. After that, you can call this method from your main method and run the agents behavior for each of the 50 episodes of learning Should find that as learning progessed, the agent got better. By the end, the agents behavior will still be slightly random since its follow an epislon greedy policy that always takes some random actions. However, since QLearning implements the QFunction interface, you could always wrap a GreedyQPolicy around it, like with VI, and gets its performance from that. Learning with Sarsa A similar learning algorithm to Q-learning is Sarsa. The first difference between the twoalgorithms is that Sarsa updates Q-values with respect to the Q-value of the next action taken,rather than the maximum Q-value of the next state see Wikipedia for more information. The second, and larger, difference is that at every time step, Sarsa will also update the Q-valuesfor state-action pairs experienced previously in an episode with respect to the amount specified by and how long ago the experiences occurred. Define the below method to solve ourtask with Sarsa. public void SarsaLearningExampleString outputPathLearningAgent agent new SarsaLamdomain, 0.99, hashingFactory, 0., 0.5, 0.3run learning for 50 episodesforint i 0 i 50 iEpisodeAnalysis ea agent.runLearningEpisodeenvea.writeToFileoutputPath sarsa iSystem.out.printlni ea.maxTimeStepreset environment for next learning episodeenv.resetEnvironment You will notice that this method looks pretty identical to the Q-learning example, except this timea SarsaLam instance is constructed. Additionally, we lowered the learning rate to 0.5 typicallyyou should use lower learning rates when you have a higher value of . The last parameter ofthe constructor is the value which we set to 1.0. A value of 1.0 effectively makes algorithm run anonline Monte Carlo in which the effects of all future interactions are fully considered in updating each Q-valueof an episode. Otherwise, the rest is the same you can call this method from the main method and give it shot Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 4"], "word_count": 1147, "token_count_estimate": 1525}}, "https://blog.cs.brown.edu/2020/10/20/read-more-brown-cs-alums-follow-diverse-career-paths/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Read More Brown CS Alums Follow Diverse Career Paths Posted by Jesse Polhemus on Oct. 20, 2020 From creating a computer camp for girls in Rwanda to founding a company that uses machine learning to produce 3D models based on satellite photos, maps, and laser scans, Brown CS alums are known for career paths that often take them far beyond Silicon Valley, with a particular focus on CS education and socially responsible computing. Click any of the headlines below to read a full story in CS News or CS Blog Diverse Career Paths Brown CS Alum Lisa Gelobter Focuses Her Career On Technology For Equitable Workplaces And Doing Good Diverse Career Paths Jonah Kagan Discusses Meaningful Impact Through CS Diverse Career Paths How Brown CS Alum Edwina Rissland Has Melded Math, CS, And Law Diverse Career Paths Brown CS Alum Eleanor Tursmans Fellowship Integrates Tech Into Policy Diverse Career Paths Brown CS Alum Jemma Issroff Works On Ruby And Strives For Ethical Impact Diverse Career Paths Brown CS Alum Sky Adams Aims To Increase Diversity In K-12 CS Diverse Career Paths Brown CS Alum Sharon Lo Ponders How Products Can Harm Society Alum Entrepreneurs Genevive Patterson Brings AI-Powered Video Editing To Millions Diverse Career Paths Brown CS Alum Karen Smith Catlin Helps Build Better Allies Brown CS Alum Morgan McGuire Makes An Impact In Academia And Industry Brown CS Alum Thomas Dickerson Helps Replicate Brown In Minecraft For Virtual Visitors Brown Executive Master In Cybersecurity Alum Ernesto Zaldivar Is A Finalist For The Bracken Bower Prize Brown CS Alum Evan Wallace Has Been Named An INC 2019 Rising Star Brown CS Alum Victoria Chvez 18 Makes An Impact On The Rhode Island Community Alum Aimee Lucido Publishes A Novel About Her Two Loves, Coding And Writing BAM Asks Two Alums About A Startup Dedicated To Ethical CS Brown CS Alum danah boyd Wins An Electronic Frontier Foundation Pioneer Award Look Where Our 2019 Graduates Are Headed Tech For Social Good Spotlight Ruby Goldberg 17 Tech For Social Good Spotlight Priya Patel 16 Tech For Social Good Spotlight Ben Spector 17 Alums In Academia Brown CS Alum Michael Horn Makes An Impact On The Learning Sciences Field Alum Adventures Brown CS Alums David Simons, Daniel Wilk, And Michael Natkin Have Won An Academy Award For Work On Adobe After Effects danah boyd Has Been Named Among Forbes Top 50 Women In Tech Mentor Alum Deb Mills-Scofield Inspires And Empowers Brown Students Tellexs Outreach Inspires A High School Student To Study CS, Then Teach Alum Adventures Harry Li Helps The Chan Zuckerberg Initiative Improve K-12 Education A Member Of The First EMCS Cohort Wins Browns Masters Award For Professional Excellence Artemis Project Alum Nirva LaFortune Advocates For Her Community On The Providence City Council Alum Tushar Bhargava Wins A 2017 Undergraduate Award For Work With Tim Edgar Brown CS Alum James Hendler Has Been Honored By The Association Of Moving Image Archivists Geopipe, Co-Founded By Thomas Dickerson, Wins 100K At The NYU 300K Entrepreneurs Challenge Brown CS Alum Hoon Ik Chang Has Been Named A 2017 Schwarzman Scholar The Atlantic Features Brown CS Alum Lyla Fujiwaras Use Of CS In The Peace Corps Brown Alumni Magazine Features CS Alum Scott Anderson TechCrunch Features Former Student Dylan Fields Design Collaboration Tool, Figma Brown CS Alum Masi Oka 97 Returns To Hiro Role In Upcoming Series Alum Update Sunil Mallya 11 Brown CS Alum Michael Horn 97 Wins An NSF Grant To Bring Programming To Museums And Homes Artemis Alum Keeps Looking For Opportunities To Code", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "Read More: Brown CS Alums Follow Diverse Career Paths"], "word_count": 607, "token_count_estimate": 813}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p6.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 6 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Experimenter Tools and Performance Plotting In the previous section you learned how to use an EnvironmentObserver to perform live visualization of the agentin the state space as it was learning. In this section we will make use another EnvironmentObserver called PerformancePlotter to record a learning algorithms performance and compare it to another learning algorithm. ThePerformacnePlotter has a lot of powerful tools to display lots of important experimental results. To streamlinethe construction process, we will make use of the LearningAlgorithmExperimenter class, which is convenient for comparingthe performance of multiple learning algorithms over many trials. If youd prefer to run your own experiment using adifferent design flow, however, you could make use of the PerformancePlotter directly yourself. To demonstrate the LearningAlgorithmExperimenter, we will compare the learning performance of a Q-learning algorithmwith the performance of a SARSA algorithm. To make the results a bit more interesting to visualize,we will also use a different reward function than we have been that returns a reward of 5 when the goal is reached and -0.1for every other step. Lets then begin by adding a new method to our BasicBehavior class to call totest the experimenter tools. Inside the method, we will change our SimulateEnvironment objects reward function to an instance of the GoalBasedRF which takes a StateConditionTest object to specify goal conditions which we have already set up previously in the tutorial for our search algorithms like BFS, a goal reward, and a default reward for all non-goal states. public void experimenterAndPlotterdifferent reward function for more interesting resultsSimulatedEnvironmentenv.setRfnew GoalBasedRFthis.goalCondition, 5.0, -0.1 For the LearningAlgorithmExperimenter to report an average performance of each algorithm,it will test the algorithm over multiple trials. Therefore, at the start of each trial a cleanagent instance of the algorithm without knowledge of any of the previous trials must be generated. To easily get a clean version of each agent, the LearningAlgorithmExperimenter will request a sequence of LearningAgentFactory objects thatcan be used to generate a clean version of each agent on demand. In the following code, we create aLearningAgentFactory for a Q-learning algorithm and a SARSA algorithm. Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-LearningOverridepublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory Overridepublic String getAgentName return SARSAOverridepublic LearningAgent generateAgent return new SarsaLamdomain, 0.99, hashingFactory, 0.0, 0.1, 1. Note that the factory also requires a getAgentName method to be implemented. The LearningAgentExperimenter classwill use this name to label the results of each learning algorithms performance. We are just about ready to create our experimenter, but firstwe will need to decide how many trials we want to test, the length of the trials, and what performance data wewant to plot. There are six possible performance metrics we could plot cumulative reward per step, cumulative reward per episode, average reward per episode, median reward per episode, cumulative steps per episode, and steps per episode. Furthermore, we could also have our plotter display the results from the most recent trial only,the average performance across all trials, or both. For this tutorial, we will plot both the most recent trial andaverage trial performance for the cumulative steps per episode and the average reward per episode. We will alsotest the algorithms for 10 trials that last 100 episodes each. The below code will create our experimenter,start it, and also save all the data for all six metrics to CSV files. LearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv, 10, 100, qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpData Note that in the constructor, the LearningAgent factories are the last parameters, of whicha variable number of factories could be provided we could have tested just one agent, or we could have tested many more, but thereshould naturally always be at least one LearningAgentFactory provided. The other important part of the code is the setUpPlottingConfiguration method, which is used to define what resultsare plotted and how they are displayed. The first four parameters specify a plots width and height, the number of columnsof plots, and the maximum window height. In this case, plots are set to be 500x200, with two columns of plots. Plotsare placed columns first, wrapping down to a new row as needed. The window size will be scaled to the width of plots times the number of columns the height will scale to the height of the plots times the number of rows, unless thatheight is greater than the maximum window height, in which case the plots will be placed in a scroll view. The nextparameter specifies whether to show plots for only the most recent trial, the average performance over all trials, orboth. We have selected to show both. The remaining parameters are variable in size and specify which performance metrics will be plotted. The order of the performance metrics providedalso dictates the order that the plots will fill the window again, filling columns first. The startExperiment method begins the experiment which will run all trials for all learning algorithms provided. Once you point our BasicBevhavior main method to the new method weve created and run the code, A GUI should appear with the plots requested,displaying the performance as it is available. When the experiment is complete, you should be left with an image like the below. In the trial average plots, youll note that a translucent filled area around each of the curves is present. This filledarea shows the 95 confidence interval. You can change the significance level used before running the experimentusing the setPlotCISignificance method. Note that these plots are not static and you can interact with them. If you click drag in a region, it will cause the plotto zoom into the selected area. If you right click, youll find a number of other options that you can set, includingchanging the labels. Another important feature youll see from the contextual menu is an option to save plot image to disk. Since we also told the LearningAlgorithmExperimenter object to save the data to csv files, you should find two files that it createdexpDataSteps.csv and expDataEpisodes.csv. The first contains all trial data for the cumulative reward per stepmetric. The latter contains all of the episode-wise metric data even for the metrics that we did not plot. Thesefiles will make interacting with the data in another program, such as R, convenient. Conclusion This ends our tutorial on implementing basic planning and learning algorithms in BURLAP. There areother planning and learning algorithms in BURLAP, but hopefully this tutorial has explained the core conceptswell enough that you should be able to try different algorithms easily. As a future exercise, we encourage youto try just that within this code youve created The complete set of code that we wrote in this tutorial is shownbelow for your convenience. The full code is also in the BURLAP code libary under the examples package. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyphimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolationimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2Dimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2Dimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.behavior.singleagent.learning.tdmethods.SarsaLamimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.singleagent.planning.deterministic.DeterministicPlannerimport burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIterationimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.auxiliary.common.SinglePFTFimport burlap.oomdp.auxiliary.stateconditiontest.StateConditionTestimport burlap.oomdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.objects.ObjectInstanceimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.common.UniformCostRFimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.singleagent.environment.Environmentimport burlap.oomdp.singleagent.environment.EnvironmentServerimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.HashableStateFactoryimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.awt.import java.util.Listpublic class BasicBehavior GridWorldDomain gwdgDomain domainRewardFunction rfTerminalFunction tfStateConditionTest goalConditionState initialStateHashableStateFactory hashingFactoryEnvironment envpublic BasicBehaviorgwdg new GridWorldDomain11, 11gwdg.setMapToFourRoomsdomain gwdg.generateDomainrf new UniformCostRFtf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATIONgoalCondition new TFGoalConditiontfinitialState GridWorldDomain.getOneAgentNLocationStatedomain, 1GridWorldDomain.setAgentinitialState, 0, 0GridWorldDomain.setLocationinitialState, 0, 10, 10hashingFactory new SimpleHashableStateFactoryenv new SimulatedEnvironmentdomain, rf, tf, initialStateVisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapobserver.initGUIenv new EnvironmentServerenv, observerSADomaindomain.addActionObserverForAllActionobserverpublic void visualizeString outputpathVisualizer v GridWorldVisualizer.getVisualizergwdg.getMapnew EpisodeSequenceVisualizerv, domain, outputpathpublic void BFSExampleString outputPathDeterministicPlanner planner new BFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath bfspublic void DFSExampleString outputPathDeterministicPlanner planner new DFSdomain, goalCondition, hashingFactoryPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath dfspublic void AStarExampleString outputPathHeuristic mdistHeuristic new Heuristic Overridepublic double hState s ObjectInstance agent s.getFirstObjectOfClassGridWorldDomain.CLASSAGENTObjectInstance location s.getFirstObjectOfClassGridWorldDomain.CLASSLOCATIONint ax agent.getIntValForAttributeGridWorldDomain.ATTXint ay agent.getIntValForAttributeGridWorldDomain.ATTYint lx location.getIntValForAttributeGridWorldDomain.ATTXint ly location.getIntValForAttributeGridWorldDomain.ATTYdouble mdist Math.absax-lx Math.absay-lyreturn -mdistDeterministicPlanner planner new AStardomain, rf, goalCondition, hashingFactory, mdistHeuristicPolicy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath astarpublic void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, rf, tf, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath visimpleValueFunctionVisValueFunctionplanner, pmanualValueFunctionVisValueFunctionplanner, ppublic void qLearningExampleString outputPathLearningAgent agent new QLearningdomain, 0.99, hashingFactory, 0., 1.run learning for 50 episodesforint i 0 i 50 iEpisodeAnalysis ea agent.runLearningEpisodeenvea.writeToFileoutputPath ql iSystem.out.printlni ea.maxTimeStepreset environment for next learning episodeenv.resetEnvironmentpublic void sarsaLearningExampleString outputPathLearningAgent agent new SarsaLamdomain, 0.99, hashingFactory, 0., 0.5, 0.3run learning for 50 episodesforint i 0 i 50 iEpisodeAnalysis ea agent.runLearningEpisodeenvea.writeToFileoutputPath sarsa iSystem.out.printlni ea.maxTimeStepreset environment for next learning episodeenv.resetEnvironmentpublic void simpleValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactoryValueFunctionVisualizerGUI gui GridWorldDomain.getGridWorldValueFunctionVisualizationallStates, valueFunction, pgui.initGUIpublic void manualValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactorydefine color functionLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEdefine a 2D painter of state values, specifying which attributes correspond to the x and y coordinates of the canvasStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYcreate our ValueFunctionVisualizer that paints for all statesusing the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, valueFunctiondefine a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYspp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALEDadd our policy renderer to itgui.setSppsppgui.setPolicypset the background color for places where states are not rendered to greygui.setBgColorColor.GRAYstart itgui.initGUIpublic void experimentAndPlotterdifferent reward function for more interesting resultsSimulatedEnvironmentenv.setRfnew GoalBasedRFthis.goalCondition, 5.0, -0.1 Create factories for Q-learning agent and SARSA agent to compare LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-LearningOverridepublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1LearningAgentFactory sarsaLearningFactory new LearningAgentFactory Overridepublic String getAgentName return SARSAOverridepublic LearningAgent generateAgent return new SarsaLamdomain, 0.99, hashingFactory, 0.0, 0.1, 1.LearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv, 10, 100, qLearningFactory, sarsaLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000,TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE,PerformanceMetric.AVERAGEEPISODEREWARDexp.startExperimentexp.writeStepAndEpisodeDataToCSVexpDatapublic static void mainString args BasicBehavior example new BasicBehaviorString outputPath outputexample.BFSExampleoutputPathexample.DFSExampleoutputPathexample.AStarExampleoutputPathexample.valueIterationExampleoutputPathexample.qLearningExampleoutputPathexample.sarsaLearningExampleoutputPathexample.experimentAndPlotterexample.visualizeoutputPath End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 6"], "word_count": 1640, "token_count_estimate": 3805}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 1 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Next Part You are viewing the tutorial for BURLAP 2 if youd like the BURLAP version 1 tutorial, go here . Introduction The purpose of this tutorial is to get you familiar with using some of the planning and learning algorithmsin BURLAP. Specifically, this tutorial will cover instantiating a GridWorld domain bundled with BURLAP,creating a task for it, having the task solved with Q-learning, Sarsa learning, BFS, DFS, A, and ValueIteration. The tutorial will also show you how to visualize these results in various ways using tools in BURLAP. The take home message you should get from this tutorial is that using different planningand learning algoritms largely amounts to just changing the algorithm object you instantiate, with everythingelse being the same. You are encouraged to extend this tutorial on your own using some of the other planningand learning algorithms in BURLAP. At the conclusion section of this tutorial, you will find all of the code we created, so if youd prefer to jumpt rightin, only coming back to this tutorial as questions arise, feel free to do so Creating the class shell For this tutorial, we will start by making a class that has data members for all the domain and task relevantproperties. In the tutorial we will call this class BasicBehavior but feel free to name it to whatever you like.Since we will also be running the examples from this class, well include a main method. For convenience, we have also included at the start all of the class imports you will need for this tutorial. If you have a good IDE, like IntelliJ or Eclipse, those can auto importing the classes as you go so that you never have to write an import line yourself. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.ValueFunctionVisualizerGUIimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.ArrowActionGlyphimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.LandmarkColorBlendInterpolationimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.PolicyGlyphPainter2Dimport burlap.behavior.singleagent.auxiliary.valuefunctionvis.common.StateValuePainter2Dimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.behavior.singleagent.learning.tdmethods.SarsaLamimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.singleagent.planning.deterministic.DeterministicPlannerimport burlap.behavior.singleagent.planning.deterministic.informed.Heuristicimport burlap.behavior.singleagent.planning.deterministic.informed.astar.AStarimport burlap.behavior.singleagent.planning.deterministic.uninformed.bfs.BFSimport burlap.behavior.singleagent.planning.deterministic.uninformed.dfs.DFSimport burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIterationimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.ValueFunctionimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.auxiliary.common.SinglePFTFimport burlap.oomdp.auxiliary.stateconditiontest.StateConditionTestimport burlap.oomdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.objects.ObjectInstanceimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.common.UniformCostRFimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.singleagent.environment.Environmentimport burlap.oomdp.singleagent.environment.EnvironmentServerimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.HashableStateFactoryimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerpublic class BasicBehavior GridWorldDomain gwdgDomain domainRewardFunction rfTerminalFunction tfStateConditionTest goalConditionState initialStateHashableStateFactory hashingFactoryEnvironment envpublic static void mainString args well fill this in later If youre already familiar with MDPs in general, the importance of some of these data members will beobvious. However, we will walk through in detail what each data member is and why were going to need it. GridWorldDomaingwdg A GridWorldDomain is a DomainGenerator implementation for creating grid worlds. Domain domain A Domain object is a fundamental class for defining problem domains. In short Domain objects define how states in a problem are representedand how the physics of the problem environment work. BURLAP represents states in a problem as a collection of objects, each with their own state. Therefore, a Domain object defines a set ofattributes, object classes, propositional functions, and actions along with the actions transition dynamics that define the problem. RewardFunction rf A RewardFunction is an interface that has a method for returning a double valued reward for any given state-action-state sequence. This is a fundamental component of every MDP and its what an agent tries to maximize. That is, the goalof an agent is acquire as much reward from the world as possible. TerminalFunction tf A common form of MDPs are episodic MDPs MDPs that end in some specific state or set of states. A typicalreason to define an episodic MDP is when there is a goal state the agent is trying to reach. In such cases, the goalstate is a terminal state, because once the agent reaches it, there is nothing left to do. Inversely, some states may be fail states that prevent the agent continuing these too would be terminal states. There may also be other reasons to provide termination states, but whatever you reason may be, a TerminalFunction is an interface with a boolean method that defines which states are terminal states. StateConditionTest goalCondition Not all planning algorithms are designed to maximize reward functions. Manyare instead defined as search algorithms that seek action sequences that will cause the agent to reach specific goal states. A StateConditionTest is an interface with a boolean method that takes a state as an argument similar to aTerminalFunction, only it can be used as a means to specify any kind of state test rather than just terminal states. In this tutorial we willuse it to specify goal states for planning algorithms that search for action sequences to reach goals rather thanplanning algorithms that try to maximize reward. State initialState To perform any planning or learning, we will generally need to specify an initial statefrom which to perform it and to reason about the different states that the agent encounters as it acts. In BURLAP, we use the State interface for providing this information, which has various methods for accessing information about the state. In particular, BURLAP uses the object-oriented MDP representation formalism, which represents states as a collection of objects, each which belongs to an object class and has a set of attributes. This is a very powerful representation that can handle a number of different kinds of problems. In this tutorial, you will not need to think much about the internal structure of the state, because we will use the GridWorldDomain class to produce initial state objects for us. For more information on it, see the State Java doc , or read the Building a Domain tutorial. HashableStateFactory hasingFactory In this tutorial, we will be covering planning and learning algorithms that solve problems that have a finite number of states that the algorithm can enumerate and reason about directly these are sometimes called tabular algorithms. To enumerate and look up different states efficiently, algorithms typically store them in a hash-backed data structure like a HashMap, or a dictionary for those of you who are new to Java. Using these data structures requires a means to compute hash codes for States and, depending on the kind of problem, some ways of computing hash codes may be more efficient than others. Furthermore, It is not uncommon that your may want handle state equality in different ways depending on the problem for example, maybe you want to perform an abstraction that ignores certain attribute values or objects in the state. For these reasons, BURLAP allows you to provide tabular algorithms a HashableStateFactory . A HashableStateFactory has a method that takes as input a State object and returns a HashableState . A HashableState stores a reference to the source state and can compute an efficient hash code for the state and perform state equality checks with other HashableState instances. More on HashableStateFactory While BURLAP provides a number of different HashableStateFactory classes for handling common ways of performing hashing and state equality checking see the statehashing package Java doc for a list, when it doubt you can typically use the SimpleHashableStateFactory , which we will use in this tutorial. One of the advantages of SimpleHashableStateFactory is that when it checks state equality between two states or computes the hash code for a state, it will by default be object identifier independent . Object identifier independence means that when a state is made up of multiple objects of the same class, the order of the objects and the names that identify them does not affect whether two states are equal. That is, as long as the states have a set of equivalent objects, they will be considered the same state. For example, consider a state s0 made up of two block objects block0 and block1 that are defined by spatial positioninformation. Now imagine a new state s1 that is the result of swapping the positions of block0 and block1.Even though the object identifiers associated with the block positions block0 and block1 are different between s0 and s1, these really are the same state and when equality is object identifier independent they will be considered equal. The below illustration helps clarify this property. Sometimes the name of objects does matter, for example in relational domains in which the goal state refers to a specific object. In these cases, SimpleHashableStateFactory can be told in a constructor not to use object identifier independence. And since many of the HashableStateFactory classes in BURLAP inherit from SimpleHashableStateFactory, they can all have object identifier independence toggled. Environment env Learning algorithms address a problem in which the agent observes its environment, makes a decision, and then observes how the environment changes. This is a challenging problem because initially, an agent will not know how the environment works or what a good decision is, but must live with the consequences of their decision. To facilitate the construction of this problems, all learning algorithms in BURLAP algorithms that implement the LearningAgent interface, interact with an implementation of the Environment interface. In BURLAP, there exists a SimulatedEnvironment implementation for when the environment dynamics are defined by a BURLAP Domain, but since Environment is an interface, you can easily implement your own version if you need a BURLAP agent to interact with external code or systems for example, robotics, which BURLAP has an extension for supporting on ROS.. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 1", "More on HashableStateFactory"], "word_count": 1576, "token_count_estimate": 2538}}, "http://burlap.cs.brown.edu/tutorials_v2/bpl/p5.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Basic Planning and Learning Tutorials Basic Planning and Learning Part 5 Tutorial Contents Introduction Creating the class shell Initializing the data members Setting up a result visualizer Planning with BFS Planning with DFS Planning with A Planning with Value Iteration Learning with Q-Learning Learning with Sarsa Live Visualization Value Function and Policy Visualization Experimenter Tools and Performance Plotting Conclusion Previous Part Next Part Live Visualization Although we showed how to visualize learning or planning results after they had been performed, sometimes when setting upa new problem and experiment it is useful to watch what is happening immediately. In this part of the tutorial weshow how to set up a live visualization of learning algorithms or planning algorithms that operate by trying actions in theworld more on that in a bit. To present a live visualization we make use of the ActionObserver and EnvironmentObserver interfaces. Objects that implement the ActionObserver interface can be notified about action execution results in simulation objects that implement the EnvironmentObserver interface can be told about agent interactions with an Environment. In this example, we will instantiate a VisualActionObserver and which implements both interfaces and visualizes state changes. The scope of ActionObserver It is worth noting that an ActionObserver is only notifed when the performAction method ofAction instances is called. This method is used by various sample based planning algorithms and detemrinistic planning algorithms. However, algorithms like VI do not use this method because they instead operate on the full action probability distribution returned by the getTransitions method rather than simulating actions. To add a VisualActionObserver, we can modify our constructor by adding the following lines to then end of it VisualActionObserver observer new VisualActionObserverdomain, GridWorldVisualizer.getVisualizergwdg.getMapobserver.initGUIenv new EnvironmentServerenv, observerSADomaindomain.addActionObserverForAllActionobserver The first line creates a VisualActionObserver for visualizing our domain with a provided domain state visualizerwe use the same kind of state visualizer that we used for our EpisodeSequenceVisualizer. The second line initializes the Java GUI for its visualization. You can then choose whether to use the third line or the commented out fourth line. The third line is how we set up the VisualActionObserver to receive events from an Environment and requires changing our Environment to an EnvironmentServer . An EnvironmentServer takes as input a source environment, and a list of EnvironmentObservers. Normal operations for the environment are delegated to the source environment, but the outcomes of the interaction are intercepted and sent to all observers before returning control to the client. The commented out fourth line would tell all the Action objects in the domain to add the action observer that is notified whenever the action is run in simulation. If you want to test the action observer out with a learning algorithm use the EnvironmentObserver paradigm third line. If you want to test it with one of the deterministic planners, comment out the third line and uncomment the fourth. Which ever you choose, you should find that when you run the algorithm you observe the agent moving through the environment Performance with VisualActionObservers By default, the VisualActionObserver will render frames at about 60FPS. You can modify this rate with thesetFrameDelaylong delay method, which takes as an argument the number of milliseconds that must pass for the renderingof an event and before the next action can be taken. Note that this delay also places a cap on the speed at which learning or planning occurs since it stalls everything for that frame delay. Typically,learning in BURLAP occurs at speeds orders of magnitude faster than 60FPS, so using the visual observer willslow down your algorithm considerably. For these reasons, you may prefer the offline visualization. Nevertheless, live visualization is often a useful as a way to confirm that your experimentis working as planned. Value Function and Policy Visualization While visualizing the agent in the state space is useful, in this next section, we will show how to visualize the value function that is estimatedfrom value function estimating planning or learning algorithms, along with the corresponding policy. The value function assigns a value to each state that represents the expected future discounted reward when following the optimal policy from that state. In particular,we will show how to visualize the value function for the ValueIteration results, but you could do the same with Q-Learning, or anyplanninglearning algorithm that implements the ValueFuncton interface which the QFunction interface extends. We will show you how to construct a value function visualizer in two ways. In the first way, we will make use of a GridWorldDomain method that will put all the pieces together for you and is very simple. However, since not all domains have automated code for that, we will also show you how to put all the pieces together manually. Lets start with the simple way, which requires adding the following method to your code. public void simpleValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactoryValueFunctionVisualizerGUI gui GridWorldDomain.getGridWorldValueFunctionVisualizationallStates, valueFunction, pgui.initGUI Note that this method takes as input a ValueFunction instance and a Policy object since along with the value function, we will also render the policy. Before we do anything with it, we are going to have to tell the renderer for which states wed like to visualize the value function. Although Domain objects are not required to enumerate the entire state space since for many domains that might be impossible, we can use the BURLAP tool StateReachability to find all states that are reachable from some input state. Algorithms like ValueIteraiton also have a method to return all states that they enumerated that we could have used. Next we call the GridWorldDomain method getGridWorldValueFunctionVisualization , which takes the set of states for which the value function will be rendered, the ValueFunction instance, and the Policy to render and returns a ValueFunctionVisualizationGUI instance that will do it for us. Finally, we launch the return GUI with the initGUI method. The last step is to direct our value iteration method to this method once planning is complete. Your new value iteration method should look like the following. public void valueIterationExampleString outputPathPlanner planner new ValueIterationdomain, rf, tf, 0.99, hashingFactory, 0.001, 100Policy p planner.planFromStateinitialStatep.evaluateBehaviorinitialState, rf, tf.writeToFileoutputPath vivisualize the value function and policy.simpleValueFunctionVisValueFunctionplanner, p If you now point your main method to run the valueIterationExample, you should find that after planning completes, it launches a GUI like the below note that you can toggle the policy visualization with the check box in the bottom left. Now that weve shown you how to easily create a value function and policy visualization for grid worlds, lets walk through the process of manually creating one so that you know how to do so for other domains. Add the following method to your code. public void manualValueFunctionVisValueFunction valueFunction, Policy pListState allStates StateReachability.getReachableStatesinitialState, SADomaindomain, hashingFactorydefine color functionLandmarkColorBlendInterpolation rb new LandmarkColorBlendInterpolationrb.addNextLandMark0., Color.REDrb.addNextLandMark1., Color.BLUEdefine a 2D painter of state values, specifying which attributes correspond to the x and y coordinates of the canvasStateValuePainter2D svp new StateValuePainter2Drbsvp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYcreate our ValueFunctionVisualizer that paints for all statesusing the ValueFunction source and the state value painter we definedValueFunctionVisualizerGUI gui new ValueFunctionVisualizerGUIallStates, svp, valueFunctiondefine a policy painter that uses arrow glyphs for each of the grid world actionsPolicyGlyphPainter2D spp new PolicyGlyphPainter2Dspp.setXYAttByObjectClassGridWorldDomain.CLASSAGENT, GridWorldDomain.ATTX,GridWorldDomain.CLASSAGENT, GridWorldDomain.ATTYspp.setActionNameGlyphPainterGridWorldDomain.ACTIONNORTH, new ArrowActionGlyph0spp.setActionNameGlyphPainterGridWorldDomain.ACTIONSOUTH, new ArrowActionGlyph1spp.setActionNameGlyphPainterGridWorldDomain.ACTIONEAST, new ArrowActionGlyph2spp.setActionNameGlyphPainterGridWorldDomain.ACTIONWEST, new ArrowActionGlyph3spp.setRenderStylePolicyGlyphPainter2D.PolicyGlyphRenderStyle.DISTSCALEDadd our policy renderer to itgui.setSppsppgui.setPolicypset the background color for places where states are not rendered to greygui.setBgColorColor.GRAYstart itgui.initGUI The method signature looks the same as before and also as before we will use StateReachability to get all the states for which the value function will be rendered. Since we will be rendering the value of a cell of the grid world with a color that blends from red to blue, we will create an instance of the ColorBlend interface. In particular, we will use the LandmarkColorBlendInterpolation . This class lets you input a real value that spits out a color that is interpolated between various specified colors. So in this case, we defined the interpolation to blend from red to blue we could have added additional points of color in between feel free to experiment. The numeric values to which we assign these colors are normalized, so 0 is the minimum value and 1 is the maximum. Next we want to define a StateValuePainter instance, which is an interface that has a method that takes as input a graphics context, a State and a value for that state and renders it to the graphics context. In particular, we will use the StateValuePainter2D implementation, which will rendered colored cells for each state where the color to render is based on a ColorBlend instance which we defined above. For this class to determine where in a graphics context to render a states cell, it needs to be told what object class and attributes in the state represent the x and y position in the 2D world. So in this case, we tell it to use the agents x and y positions. At this point, we create our ValueFunctionVisualizerGUI instance, which takesthe states for which to render the value, the StateValuePainter to use, and the sourceValueFunction that specifies the value for the states. However, before we finish, we also added a Policy renderer that can overlay the value function visualization. For this rendering, we will need a StatePolicyPainter implementation and in the code we use a PolicyGlyphPainter2D that renders a policy at some position in a 2D graphics context by drawing glyphs for the selected action or actions if there are a set of actions that the policy selects. Like the StateValuePainter2D, this class needs to be told what the object class attributes in a State indicate the 2D position in the graphics context. It also needs to be told which ActionGlyphPainter to use to paint a glyph for each action by action name. Here we used the existing ArrowActionGlyph for each action, where the parameter in its constructor for 0 to 3 indicates a north, south east, and west arrow respectively. The PolicyGlyphPainter2D also have various ways to render the glyphs. Here we use DISTSCALED which means each action glyph is rendered at a size proportional to the probability that the agent will select that action. Finally, we set the ValueFunctionVisualizerGUI to use the StatePolicyPainter we created, and set the Policy it should render. Then we set the background color to gray, and launch the GUI. If you now point the value iteration method to this value function visualization method instead of the simple one, you should find that your get the same visualization. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Basic Planning and Learning", ">", "> Part 5", "The scope of ActionObserver", "Performance with VisualActionObservers"], "word_count": 1748, "token_count_estimate": 2436}}, "http://burlap.cs.brown.edu/tutorials_v2/cpl/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 1 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Next Part You are viewing the tutorial for BURLAP 2 if youd like the BURLAP version 1 tutorial, go here . Introduction In the previous tutorials, we walked through how you can use existing planning and learning algorithms in BURLAP on domains in BURLAP and how to create your own domains on which you can use those algorithms. However, you may also want to extend or create your own planning or learning algorithm in BURLAP that can either be used on existing domains or novel BURLAP domains and be easily compared against existing algorithms. In this tutorial, we will show you how to create both a planning algorithm and a learning algorithm. In particular, we will be reimplementing versions of Value Iteration and Q-learning since they are conceptually simple algorithms to implement, but will expose the various properties of BURLAP you would want to use. In general, however, you should defer to using the existing implementations of these algorithms in BURLAP since they will support more features than we will cover here. Value Iteration Overview Value Iteration VI is an algorithm that finds the optimal value function the expected discounted future reward of being in a state an behaving optimally from it, and consequentially the optimal policy, for an MDPs entire state space. Central to the idea of VI is the Bellman Equation, which states that the optimal value of a stateis the value of the action with the maximum expected discounted future return the action with the maximum Q-value where the Q-value for a state-action pair is defined as the expected value over allpossible state transitions of the immediate reward summed with the discounted value of the resulting state. In mathlarge Vs maxa Qs,alarge Qs,a sums Ts s,a left Rs, a, s gamma Vs right, where Ts s, a is the probability of transitioning to state s when taking action a in state s, Rs, a, s is the reward received for transitioning to state s after taking action a in state s, and gamma is a discount factor affecting how much immediate rewards are preferred to later ones. This equation presents some issues in that if an MDP has cycles, its unclear what the values should be. However, the Value Iteration algorithm will converge to the optimal Value function if you simply initialize the value for each state to some arbitrary value, and then iteratively use the Bellman equationto update the the value for each state. Planning algorithms that make use of the Bellman equation to estimate the Value function are known as Dynamic Programming DP planning algorithms. Different DP algorithms specify different priorities for when the estimated value of each state is updated with the Bellman equation. In the case of VI, Bellman updates are performed in entire sweeps of the state space. That is, at the start, the value for all states is initialized to some arbitrary value. Then, for each state in the state space, the Bellman equation is used to update the value function estimate. Sweeps over the entire state space are repeated for some fixed number of iterations or until the maximum change in the value function is small. The algorithm is summarized in the below pseudocode. Value Iteration Initialize value function Vs arbitrarily for all states s. Repeat until convergence... For each state s Vs maxa sums Ts s, a leftRs,a,s Vsright Since there are a number of different DP algorithms that can be implemented, BURLAP includes a class called DynamicProgramming that includes a number of helpful methods for automatically performing Bellman Updates on states and which is extended by many of the DP algorithms included in BURLAP. However, to give a better sense of howto use the more fundamental parts of a planning algorithm in BURLAP, we will instead write our VI algorithm from scratch without using the DynamicProgramming class. However, we will extend the MDPSolver class since it provides a number of useful datamemb ers and setter and getting methods that you will commonly want to have for algorithms that solve MDPs. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 1"], "word_count": 721, "token_count_estimate": 871}}, "http://burlap.cs.brown.edu/tutorials_v2/cpl/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 2 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part VI Code Lets start by creating our class for VI, which well call VITutorial. Our class will extend MDPSolver , to gain many of the useful datastructures used in solving an MDP, and it will implement the Planner and QFunction interfaces. The former because we will implement the planFromState method and the latter because ValueIteration computes and ValueFunction and QFunction the QFunction interface extends the ValueFunction interface. We will also add all the imports we will need in developing this class. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QValueimport burlap.behavior.valuefunction.ValueFunctionInitializationimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.common.UniformCostRFimport burlap.oomdp.statehashing.HashableStateimport burlap.oomdp.statehashing.HashableStateFactoryimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.util.public class VITutorial extends MDPSolver implements Planner, QFunctionOverridepublic double valueState s return 0.Overridepublic ListQValue getQsState s TODO Auto-generated method stubreturn nullOverridepublic QValue getQState s, AbstractGroundedAction a TODO Auto-generated method stubreturn nullOverridepublic Policy planFromStateState initialState TODO Auto-generated method stubOverridepublic void resetSolverResults TODO Auto-generated method stub Because we are sub classing MDPSolver, this object will auto create data members that define our domain and task the Domain, RewardFunction, TerminalFunction, discount factor, andHashableStateFactory that is used to hash and check the equality of states. However, the other critical data that VI needs to store are its estimates of the value function A value function is ultimately a mapping from states to a real value. Therefore, for fast access we can use a HashMap and use a HashableStateFactory to provide HashableState instances from states. One way to make VI run faster is to inititialize its value funciton to something close to the optimal value function. BURLAP has a ValueFuncitonInitialization interface that can be provided to our code for choosing initialization values. Well also have a parameter that specifies how long value iteration should run before it terminates there are others to test for convergence that we will not cover here. Lets create datamembers for these elements and create a constructor. protected MapHashableState, Double valueFunctionprotected ValueFunctionInitialization vinitprotected int numIterationspublic VITutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization vinit, int numIterationsthis.solverInitdomain, rf, tf, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapHashableState, Double Note that since our MDPSolver superclass will hold our data members for the domain, reward function, terminal function, discount factor, and HashableStateFactory, we can initialize them with its solverInit method. There is one other critical component VI needs that isnt part of the data weve given it in the constructor the full state space One reason we might not want to demand this upfront is because in an OO-MDP, it is possible for the state space to be infinite even though for any given input state there may only be a finite set of states that are reachable. We could require the user to provide to our algorithm up front what the state space is, but its much easier on the client if we determine the set of possible reachable states for any given seed state ourself and only perform this procedure when planning is requested for a previously unseen state. Lets define a method to get all reachable states from an input state and initialize the value for them with our ValueFunctionInitialization object. Add the below method. public void performReachabilityFromState seedStateSetHashableState hashedStates StateReachability.getReachableHashedStatesseedState, SADomain this.domain, this.hashingFactoryinitialize the value function for all statesforHashableState hs hashedStatesifthis.valueFunction.containsKeyhsthis.valueFunction.puths, this.vinit.valuehs.s In the first line, we make use of BURLAPs StateReachability tool to do the heavy lifting of finding all reachable states. Then we simply iterate through the list, and for every HashableState for which we do not already have an entry, we initialize it with the value returned from the ValueFunctionInitialization. You may notice that the value function is passed hs.s. Since our set of states are actually a set of HashableState instances, we retrieve the underlying State object stored in the HashableState by its .s member. The other method well need to implement is the Bellman Equation. As noted on the previous page, the Bellman Equation is just a max over the Q-values and since we already have methods defined for getting the Q-value of states a requirement of implementing the QFunction interface, we will implement those methods and a Bellman Equation method next. Overridepublic ListQValue getQsState s ListGroundedAction applicableActions this.getAllGroundedActionssListQValue qs new ArrayListQValueapplicableActions.sizeforGroundedAction ga applicableActionsqs.addthis.getQs, gareturn qsOverridepublic QValue getQState s, AbstractGroundedAction a type cast to the type were usingGroundedAction ga GroundedActionawhat are the possible outcomesListTransitionProbability tps ga.getTransitionssaggregate over each possible outcomedouble q 0.forTransitionProbability tp tpswhat is reward for this transitiondouble r this.rf.rewards, ga, tp.swhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.sadd contribution weighted by transition probabiltiy anddiscounting the next stateq tp.p r this.gamma vpcreate Q-value wrapperQValue qValue new QValues, ga, qreturn qValueprotected double bellmanEquationState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble maxQ Double.NEGATIVEINFINITYforQValue q qsmaxQ Math.maxmaxQ, q.qreturn maxQ Youll note that the Q-value methods return QValue objects, which are just triples consisting of a State object, an AbstractGroundedAction object, and a double for the Q-value associated with them. AbstractGroundedAction versus Action You might wonder why were using AbstractGroundedAction references for actions, rather than a Action instance that we subclassed to define actions in the Building a Domain Tutorial . However, recall that the Action class is used for defining actions, whereas the GroundedAction class is a reference to an Action definition that also contains any action parameter selections necessary to execute the action. Since actions could be parameterized, we use implementations of the general AbstractGroundedAction interface, of which GroundedAction is an implementation, to reason about decisions, or in this case, estimate the Q-value for the action selection. In the getQs method, we simply find all possible grounded actions using a method ineheretied from MDPSolver which we extended alternatively, we could use an Action static method that takes is list of Aciton objects and State and returns all applicable groundings, ask our getQ method what the Q-value is, and then return the list of all those Q-values. In the getQ method, we find all possible transitions from the input state and weigh the value of those outcomes by the probability of the transition occurring. The value of each outcome is the reward received, and the discounted value we have estimated for the outcome state. In the bellmanEquation method, we in general just return the maximum Q-value for the state however, there is a catch. That is, if the input state is a terminal state, then by definition of it being a terminal state the value is zero, because the idea of a terminal state is that no action can follow from it. Therefore, if the state is a terminal state, we return a value of 0 and ignore whatever the domain object would say the possible transitions would be. Note that this check is not just a performance saver all terminal states are specified by the TerminalFunction interface, so we must always refer to it to handle terminal states and cannot expect that a domains transition dynamics have it baked in. We now have all the tools we need to do planning, so its time to implement the planFromStateMethod. This method is called whenever a client wants to run planning from a given initial or seed state. What well do then is first check if weve already performed planning that includes that state. If so, well do nothing, having assumed to already have computed the value for it. However, if we havent seen it before, then well first find all reachable states from it, and then run value iteration for a given number of iterations. As a reminder, running value iteration means making iterative sweeps over the entire state space in which the value of each state is re-estimated to what the Bellman equation says it is given the previously estimated value of the states. Finally, all planFromState methodsrequire return a suitable Policy object to use the planning results. For value iteration, assuming it converged, the optimal policy is to select the action with the highest Q-value therefore well return a GreedyQPolicy object. GreedyQPolicy objects need to be told what their QFunction source is, which in this case, is the instance of our class. Overridepublic GreedyQPolicy planFromStateState initialState HashableState hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn new GreedyQPolicythis already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforHashableState sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, this.bellmanEquationsh.sreturn new GreedyQPolicythis Were now just about finished The only thing left is that each MDPSolver instance is asked to implement the method resetSolverResults, which when called should have the effect of resetting all data so that its as if no planning calls had ever been made. For our VI implementation, all this requires is clearing our value function. Overridepublic void resetSolverResults this.valueFunction.clear Testing VI To test our code, you can try using this planning algorithm with the grid world task created in the previous Basic Planning and Learning tutorial.Alternatively, below is a main method that you can add to test your VI implementation that creates a stochastic grid world, plans for it, and evaluates a single rollout of the resulting policy and visualizes the results. public static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup vi with 0.99 discount factor, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, rf, tf, 0.99, new SimpleHashableStateFactory,new ValueFunctionInitialization.ConstantValueFunctionInitialization0.0, 30run planning from our initial statePolicy p vi.planFromStatesevaluate the policy with one roll out visualize the trajectoryEpisodeAnalysis ea p.evaluateBehaviors, rf, tfVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, Arrays.asListea If youre looking to extend this tutorial on VI a little more, you might consider implementing a more intelligent VI termination condition so that rather than always running VI for a fixed number of iterations, VI terminates if the maximum change in the value function is smaller than some small threshold. Otherwise, its now time to move on to our Q-learning example If youd like to see the full code we wrote all together, jump to the end of this tutorial . Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 2", "AbstractGroundedAction versus Action"], "word_count": 1748, "token_count_estimate": 2842}}, "http://burlap.cs.brown.edu/tutorials_v2/cpl/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 3 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Next Part Q-Learning Overview For our learning algorithm example, well be implementing Q-learning. The difference between a learning algorithm and a planning algorithm is that a planning algorithm has access to a model of the world, or at least a simulator, whereas a learning algorithm involves determining behavior when the agent does not know how the world works and must learn how to behave from direct experience with the world. In general, there are two approaches to reinforcement learning 1 to learn a model of the world from experience and then use planning with that learned model to dictate behavior model-based and 2 to learn a policy or value function directly from experience model-free. Q-learning belongs to the latter. As the name suggests, Q-learning learns estimates of the optimal Q-values of an MDP, which means that behavior can be dictated by taking actions greedily with respect to the learned Q-values. Q-learning can be summarized in the following pseudocode. Q-Learning Initialize Q-values Qs,a arbitrarily for all state-action pairs. For life or until learning is stopped... Choose an action a in the current world state s based on current Q-value estimates Qs,cdot. Take the action a and observe the the outcome state s and reward r. Update Qs,a Qs,a alpha left r gamma maxa Qs, a - Qs,a right The two key steps in the above pseudocode are steps 3 and 5. There are many ways to choose actions based on the current Q-value estimates step 3, but one of the most common is to use an epsilon-greedy policy. In this policy, the action is selected greedily with respect to the Q-value estimates a fraction 1-epsilon of the time where epsilon is a fraction between 0 and 1, and randomly selected among all actions a fraction epsilon of the time. In general, you want a policy that has some randomness to it so that it promotes exploration of the state space. The update rulelarge Qs,a Qs,a alpha left r gamma maxa Qs, a - Qs,a rightupdates the Q-value of the last state-action pair s,a with respect to the observed outcome state s and reward r, where alpha in 0, 1 is a learning rate parameter. To unpack this update, recall from the Bellman equation that the Value of a state is the maximum Q-value and the Q-value is the expected sum of the reward and discounted value of the next state, where the expectation is with respect to the probability of each state transition. In the Q-learning update rule, the reward plus the discounted max Q-value in the observed next state is effectively what the Bellman equation tells us the Q-value is, except in this case, were not marginalizing over all possible outcome states, we only have the one observed state and reward that we happened to get. However, because our learning rate only allows our Q-value to change slightly from its old estimate to a new estimate in the direction of the observed state and reward, as long as we keep retrying that action in the same state, well see the other possible states that could have occurred and move in their direction too. In aggregate over multiple tries of the action then, the Q-value will move toward the true expected value, even though we never directly used the transition probabilities. To have guaranteed convergence to the true Q-value, we should actually be slowly decreasing the learning rate parameter over time. However, in practice, its often sufficient to simply use a small learning rate parameter, so for simplicity in our implementation, well use a fixed value for the learning rate rather that one that changes with time though in the full Q-learning algorithm provided in BURLAP, you can use different schedules for decreasing the learning rate, including client-provided custom schedules with the LearningRate interface. Q-Learning Code Lets begin implementing our Q-learning algorithm code. Our class, called QLTutorial, will extend MDPSolver and implement the LearningAgent and QFunction interfaces. The LearningAgent interface specifies the common methods a learning algorithm is expected to implement so that it can be used by other BURLAP tools. Below is the skeleton code that is created when we created our class. import burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QValueimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.environment.Environmentimport java.util.Listpublic class QLTutorial extends MDPSolver implements LearningAgent, QFunction Overridepublic EpisodeAnalysis runLearningEpisodeEnvironment env return nullOverridepublic EpisodeAnalysis runLearningEpisodeEnvironment env, int maxSteps return nullOverridepublic void resetSolver Overridepublic List getQsState s return nullOverridepublic QValue getQState s, AbstractGroundedAction a return nullOverridepublic double valueState s return 0 Similar to VI, the primary data we will want to store is a set of estimated Q-values for each state and action pair. Well also again let the user specify the Q-value function initialization with a ValueFunctionInitialization object. Well also need a learning rate parameter to be set. Finally, well need a learning policy to follow that is, a policy that dictates how the agent chooses actions at each step. For this tutorial, well assume an epsilon-greedy policy and let the client specify the value for epsilon. Lets add data members for those elements now, as well as the value function which needs to return the maximum Q-value. protected MapStateHashTuple, ListQValue qValuesprotected ValueFunctionInitialization qinitprotected double learningRateprotected Policy learningPolicy Lets also add a constructor to initialize our data members and some of those that we inherit from MDPSolver. public QLTutorialDomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilonthis.solverInitdomain, null, null, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMap this.learningPolicy new EpsilonGreedythis, epsilon Note that we did not have to initialize the reward function or terminal function for the MDPSolver the two null parameters since these will be handled by the Environment object with which the learning algorithm will interact. The EpsilonGreedy policy object we create takes as input a QFunction, which this class will provide, and the value for epsilon to use. One of the primary tools well need is a method that grabs our Q-values, or creates and stores them with the proper initialization value if its for an unseen state. Lets implement our Q-Value methods now as well as the value method which returns the state value the maximum Q-value of all actions applicable in the state. Overridepublic ListQValue getQsState s first get hashed stateStateHashTuple sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListGroundedAction actions this.getAllGroundedActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforGroundedAction ga actionsadd q with initialized valueqs.addnew QValues, ga, this.qinit.qValues, gastore this for laterthis.qValues.putsh, qsreturn qsOverridepublic QValue getQState s, AbstractGroundedAction a first get all Q-valuesList qs this.getQssiterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value.Overridepublic double valueState s return QFunctionHelper.getOptimalValuethis, s Note that for the value method, we used the QFunciton helper class QFunctionHelper whose method getOptimalValue will return the maximum Q-value in a QFunction object by querying its getQs method and returning the maximum Q-value value. Now that we have all of our helper methods, lets implement the learning algorithm. The LearningAgent interface requires us to implement two methods that cause learning to be run for one episode in some Environment one that will run learning until the agent reaches a terminal state and one that will run learning for a maximum number of steps or until a terminal state is reached. We will have the former call the latter with a -1 for the maximum number of steps to indicate that it should never stop until the agent reaches a terminal state. Both methods also require returning an EpisodeAnalysis object, which is a recording of all the states, actions, and rewards that occurred in an episode, so as we write the code to have the agent iteratively select actions, well record the results to an EpisodeAnalysis object. Below is the learning algorithm code for Q-learning. Overridepublic EpisodeAnalysis runLearningEpisodeEnvironment env return this.runLearningEpisodeenv, -1Overridepublic EpisodeAnalysis runLearningEpisodeEnvironment env, int maxSteps initialize our episode analysis object with the initial state of the environmentEpisodeAnalysis ea new EpisodeAnalysisenv.getCurrentObservationbehave until a terminal state or max steps is reachedState curState env.getCurrentObservationint steps 0whileenv.isInTerminalState steps maxSteps maxSteps -1select an actionGroundedAction a GroundedActionthis.learningPolicy.getActioncurStatetake the action and observe outcomeEnvironmentOutcome eo a.executeInenvrecord resultea.recordTransitionToa, eo.o, eo.rget the max Q value of the resulting state if its not terminal, 0 otherwisedouble maxQ eo.terminated 0. this.valueeo.opupdate the old Q-valueQValue oldQ this.getQcurState, aoldQ.q oldQ.q this.learningRate eo.r this.gamma maxQ - oldQ.qmove on to next statecurState eo.opstepsreturn ea The beginning of the code is fairly straightforward we construct a new EpisodeAnalysis object rooted in the current state of the environment, which we get back from the Environment method getCurrentObservation. We then begin an execution loop that lasts either until the Environment reaches a terminal state or until the number of steps weve taken exceeds the number requested. Inside the execution loop, we first select an action using our learning policy. Then we execute the action in the environment using the GroundedAction method executeInEnvironment,which returns to us an EnvironmentOutcome object. This object is tuple with the following datamembers. a - a GroundedAction specifying the action taken in the Environment o - the observation, represented by a State, from the Environment when the action was taken. op - the next observation from the Environment after the action was taken. r - a double value specifying the reward returned from the Environment terminated - a boolean specifying whether the Environment is now in a terminal state Environment Observations You may have noticed that the Environment uses observation terminology instead of state terminology. This choice is because Environment objects are not under obligation to return to the agent a full state, only an observation. Typically, for MDPdomains you can expect it to be a full State, and regardless of whether it is a partial observation or not, the observation itself will always be represnted by a BURLAP State object. Note that the use of this terminology is especially useful if you begin using BURLAPs POMDP framework. Using the new observations from the environment, we record the transition in our EpisodeAnalysis and update the previous Q-Value. To update the previous Q-value, we need to get the maximum Q-value for the next state we encounted. However, if that state is a terminal state, then the value should always be zero, because the agent cannot act further from that state. Otherwise, we can get the maximum value by using value method that we previously defined. Finally, we can implement the resetSoverResults method, which only needs to clear our Q-values. Overridepublic void resetSolverResults this.qValues.clear Testing Q-Learning As before, you can now test your learning algorithm with the previous code developed in the Basic Planning and Learning tutorial . Alternatively, you can use the below main method which creates a similar Grid World domain and task as the test code we wrote for our VI implementation, except applies the Q-Learning algorithm to it in a simulated environment. The results of each leaning episode will be presented for you after learning completes. Note that because the domain is stochastic and follows a nosiy exploration policy, it can take much longer to learn and the resulting policy will not be a straight shot to the goal. public static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsgwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10create environmentSimulatedEnvironment env new SimulatedEnvironmentdomain,rf, tf, screate Q-learningQLTutorial agent new QLTutorialdomain, 0.99, new SimpleHashableStateFactory,new ValueFunctionInitialization.ConstantValueFunctionInitialization, 0.1, 0.1run Q-learning and store results in a listList episodes new ArrayList 1000forint i 0 i 1000 iepisodes.addagent.runLearningEpisodeenvenv.resetEnvironmentVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, episodes Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 3", "Environment Observations"], "word_count": 1976, "token_count_estimate": 2867}}, "http://burlap.cs.brown.edu/tutorials_v2/cpl/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Creating a Planning and Learning Algorithm Tutorials Creating a Planning and Learning Algorithm Part 4 Tutorial Contents Introduction Value Iteration Overview VI Code Testing VI Q-Learning Overview Q-Learning Code Testing Q-Learning Conclusions Full VI Code Full Q-Learning Code Previous Part Conclusions In this tutorial we showed you how to implement your own planning and learning algorithms. Although these algorithms were simple, they exposed the necessary BURLAP tools and mechanisms you will need to use to implement your own algorithms and should enable you to start writing your own code. In general, we highly recommend that you use BURLAPs existing implementations of Value Iteration and Q-Learning since they support a number of other features Options, learning rate decay schedules, etc.. If you would like to see all of the code that was written in this tutorial, we have provided it below first the Value Iteration code , then the Q-learning Code . Full VI Code import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateReachabilityimport burlap.behavior.singleagent.planning.Plannerimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QValueimport burlap.behavior.valuefunction.ValueFunctionInitializationimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.TransitionProbabilityimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.SADomainimport burlap.oomdp.singleagent.common.UniformCostRFimport burlap.oomdp.statehashing.HashableStateimport burlap.oomdp.statehashing.HashableStateFactoryimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.util.public class VITutorial extends MDPSolver implements Planner, QFunctionprotected MapHashableState, Double valueFunctionprotected ValueFunctionInitialization vinitprotected int numIterationspublic VITutorialDomain domain, RewardFunction rf, TerminalFunction tf, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization vinit, int numIterationsthis.solverInitdomain, rf, tf, gamma, hashingFactorythis.vinit vinitthis.numIterations numIterationsthis.valueFunction new HashMapHashableState, DoubleOverridepublic double valueState s Double d this.valueFunction.gethashingFactory.hashStatesifd nullreturn vinit.valuesreturn dOverridepublic ListQValue getQsState s ListGroundedAction applicableActions this.getAllGroundedActionssListQValue qs new ArrayListQValueapplicableActions.sizeforGroundedAction ga applicableActionsqs.addthis.getQs, gareturn qsOverridepublic QValue getQState s, AbstractGroundedAction a type cast to the type were usingGroundedAction ga GroundedActionawhat are the possible outcomesListTransitionProbability tps ga.getTransitionssaggregate over each possible outcomedouble q 0.forTransitionProbability tp tpswhat is reward for this transitiondouble r this.rf.rewards, ga, tp.swhat is the value for the next statedouble vp this.valueFunction.getthis.hashingFactory.hashStatetp.sadd contribution weighted by transition probabiltiy anddiscounting the next stateq tp.p r this.gamma vpcreate Q-value wrapperQValue qValue new QValues, ga, qreturn qValueprotected double bellmanEquationState sifthis.tf.isTerminalsreturn 0.ListQValue qs this.getQssdouble maxQ Double.NEGATIVEINFINITYforQValue q qsmaxQ Math.maxmaxQ, q.qreturn maxQOverridepublic GreedyQPolicy planFromStateState initialState HashableState hashedInitialState this.hashingFactory.hashStateinitialStateifthis.valueFunction.containsKeyhashedInitialStatereturn new GreedyQPolicythis already performed planning hereif the state is new, then find all reachable states from it firstthis.performReachabilityFrominitialStatenow perform multiple iterations over the whole state spaceforint i 0 i this.numIterations iiterate over each stateforHashableState sh this.valueFunction.keySetupdate its value using the bellman equationthis.valueFunction.putsh, this.bellmanEquationsh.sreturn new GreedyQPolicythisOverridepublic void resetSolver public void performReachabilityFromState seedStateSetHashableState hashedStates StateReachability.getReachableHashedStatesseedState, SADomain this.domain, this.hashingFactoryinitialize the value function for all statesforHashableState hs hashedStatesifthis.valueFunction.containsKeyhsthis.valueFunction.puths, this.vinit.valuehs.spublic static void mainString argsGridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsonly go in intended directon 80 of the timegwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10setup vi with 0.99 discount factor, a valuefunction initialization that initializes all states to value 0, and which willrun for 30 iterations over the state spaceVITutorial vi new VITutorialdomain, rf, tf, 0.99, new SimpleHashableStateFactory,new ValueFunctionInitialization.ConstantValueFunctionInitialization0.0, 30run planning from our initial statePolicy p vi.planFromStatesevaluate the policy with one roll out visualize the trajectoryEpisodeAnalysis ea p.evaluateBehaviors, rf, tfVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, Arrays.asListea Full Q-Learning Code import burlap.behavior.policy.EpsilonGreedyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.MDPSolverimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.valuefunction.QFunctionimport burlap.behavior.valuefunction.QValueimport burlap.behavior.valuefunction.ValueFunctionInitializationimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldTerminalFunctionimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.core.AbstractGroundedActionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.GroundedActionimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.UniformCostRFimport burlap.oomdp.singleagent.environment.Environmentimport burlap.oomdp.singleagent.environment.EnvironmentOutcomeimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.HashableStateimport burlap.oomdp.statehashing.HashableStateFactoryimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.util.public class QLTutorial extends MDPSolver implements LearningAgent, QFunction MapHashableState, ListQValue qValuesValueFunctionInitialization qinitdouble learningRatePolicy learningPolicypublic QLTutorialDomain domain, double gamma, HashableStateFactory hashingFactory, ValueFunctionInitialization qinit, double learningRate, double epsilonthis.solverInitdomain, null, null, gamma, hashingFactorythis.qinit qinitthis.learningRate learningRatethis.qValues new HashMapHashableState, ListQValuethis.learningPolicy new EpsilonGreedythis, epsilonOverridepublic EpisodeAnalysis runLearningEpisodeEnvironment env return this.runLearningEpisodeenv, -1Overridepublic EpisodeAnalysis runLearningEpisodeEnvironment env, int maxSteps initialize our episode analysis object with the initial state of the environmentEpisodeAnalysis ea new EpisodeAnalysisenv.getCurrentObservationbehave until a terminal state or max steps is reachedState curState env.getCurrentObservationint steps 0whileenv.isInTerminalState steps maxSteps maxSteps -1select an actionGroundedAction a GroundedActionthis.learningPolicy.getActioncurStatetake the action and observe outcomeEnvironmentOutcome eo a.executeInenvrecord resultea.recordTransitionToa, eo.op, eo.rget the max Q value of the resulting state if its not terminal, 0 otherwisedouble maxQ eo.terminated 0. this.valueeo.opupdate the old Q-valueQValue oldQ this.getQcurState, aoldQ.q oldQ.q this.learningRate eo.r this.gamma maxQ - oldQ.qmove on to next statecurState eo.opstepsreturn eaOverridepublic void resetSolver this.qValues.clearOverridepublic ListQValue getQsState s first get hashed stateHashableState sh this.hashingFactory.hashStatescheck if we already have stored valuesListQValue qs this.qValues.getshcreate and add initialized Q-values if we dont have them stored for this stateifqs nullListGroundedAction actions this.getAllGroundedActionssqs new ArrayListQValueactions.sizecreate a Q-value for each actionforGroundedAction ga actionsadd q with initialized valueqs.addnew QValues, ga, this.qinit.qValues, gastore this for laterthis.qValues.putsh, qsreturn qsOverridepublic QValue getQState s, AbstractGroundedAction a first get all Q-valuesListQValue qs this.getQsstranslate action parameters to source state for Q-values if neededa GroundedActiona.translateParameterss, qs.get0.siterate through stored Q-values to find a match for the input actionforQValue q qsifq.a.equalsareturn qthrow new RuntimeExceptionCould not find matching Q-value.Overridepublic double valueState s return QFunctionHelper.getOptimalValuethis, spublic static void mainString args GridWorldDomain gwd new GridWorldDomain11, 11gwd.setMapToFourRoomsgwd.setProbSucceedTransitionDynamics0.8Domain domain gwd.generateDomainget initial state with agent in 0,0State s GridWorldDomain.getOneAgentNoLocationStatedomainGridWorldDomain.setAgents, 0, 0all transitions return -1RewardFunction rf new UniformCostRFterminate in top right cornerTerminalFunction tf new GridWorldTerminalFunction10, 10create environmentSimulatedEnvironment env new SimulatedEnvironmentdomain,rf, tf, screate Q-learningQLTutorial agent new QLTutorialdomain, 0.99, new SimpleHashableStateFactory,new ValueFunctionInitialization.ConstantValueFunctionInitialization, 0.1, 0.1run Q-learning and store results in a listListEpisodeAnalysis episodes new ArrayListEpisodeAnalysis1000forint i 0 i 1000 iepisodes.addagent.runLearningEpisodeenvenv.resetEnvironmentVisualizer v GridWorldVisualizer.getVisualizergwd.getMapnew EpisodeSequenceVisualizerv, domain, episodes End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Creating a Planning and Learning Algorithm", ">", "> Part 4"], "word_count": 843, "token_count_estimate": 2459}}, "http://burlap.cs.brown.edu/tutorials_v2/index.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorials You are viewing the tutorials for BURLAP 2 if youd like the BURLAP version 1 tutorials, go here . This page provides a list of all available BURLAP tutorials. There are both short video tutorials and more explanatory and detailed text tutorials. You can find code for all of the tutorials and more in our examples repository httpsgithub.comjmacglashanburlapexamples Video Tutorials Text Tutorials Hello Grid World - a tutorial on acquiring and linking with BURLAP Building a Domain Using Basic Planning and Learning Algorithms Creating a Planning and Learning Algorithm Solving Continuous Domains", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorials", "Video Tutorials"], "word_count": 101, "token_count_estimate": 138}}, "http://burlap.cs.brown.edu/tutorials_v2/hgw/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Hello Grid World Tutorials Hello Grid World Part 1 Tutorial Contents Introduction Compiling from Source Hello Grid World Project Conclusion You are viewing the tutorial for BURLAP 2 with Maven. If youd like the BURLAP 2 ant compiling and manual execution instructions, go here . If youd like the BURLAP version 1 tutorial, go here . Introduction In this tutorial we will walk you through getting started with BURLAP. We will assume that you have Maven installed for this process, since it will make management of dependencies very straightforward. If you do not already have Maven installed, you can probably get it from your favorite package manager. For example, on Debian systems, sudo apt-get install maven Or on Mac OS with homebrew brew install maven Alternatively, you can manually install it from httpsmaven.apache.orgdownload.cgi . Be sure to follow their installtion instructions. To verify that you have maven installed try the following from the command line mvn -v We also highly recommend that you use an IDE for your work, which will make working with the library substantially easier. If you do not have an IDE we recommend either IntelliJ or Eclipse . Both will have tools for working with Maven projects. That said, for this tutorial we will give instructions using just the command line and your favorite text editor. You can probably follow along in an IDE if you prefer. In this tutorial you will have two options. You can either build and install BURLAP from its source, or you can simply use the released version of BURLAP from Maven Central. The latter will require the least work, but if youd like to be able to modify BURLAP at all, it may be worth checkout out the code and manually compiling it. If you prefer to simply use the Maven Central copy, skip the next section. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Compiling from Source To compile the code from source, you will probably want to have git installed, or you can manually download the source from github. If you have git installed, navigate from your command line to a directory where you would like to place the code. Then type the following git clone httpsgithub.comjmacglashanburlap.git If you do not have git installed on your computer, then you can manually download the files by navigating to the website httpsgithub.comjmacglashanburlap and clicking on download zip to save it and unarchive it at a desired location. Whether you used git to clone the source, or manually downloaded it, navigate into the directory with your command line. The directory should look something like the following LICENSEREADME.mdbuild.xmlburlap-repolibpom.xmlsrctesting Now we can compile using Maven, which you should have installed on the previous step. You can use the standard Maven methods for compilation. That is, to simply compile the code, use mvn compile To create a jar file and Java doc in the target directory as well as jar file that includes all dependencies use mvn package And to install BURLAP to your local Maven repository, use mvn install Thats it Hello Grid World Project Whether you compiled and installed BURLAP from source in the prior step or not, this next section is the same because BURLAP is available on Maven Central, which means Maven will automatically download it and install it if you did not compile it from source. To begin our example project, create a directory somewhere on your file system where you will store the project code and navigate into it on your command line. If youve used Maven before, you may want to create your project by generating an archetype. Feel free to do so if you, like. However, we will manually set up the project from the command line and text editors here. First create a file named pom.xml. With your favorite text editor, insert the following 4.0.0 com.mycompany.app myProj 1 edu.brown.cs.burlap burlap 2.1.0 org.codehaus.mojo exec-maven-plugin 1.2.1 java You should set the group id at the top to anything that seems relevant for you, and you can also rename the artifact id to something else if you prefer. Note the dependencies section with the BURLAP dependency, which tells Maven that your project depends on BURALP. As of writing this tutorial, the latest version of BURLAP is 2.1.0. However, you may want to change this value to whatever the latest is, or to a version you prefer especially if youve installed your own custom version with its own version number. You can see the list of all release versions of BURLAP from here . The plugin we added will also allow us to use Maven to easily run code that we write. Now create the following directory tree srcmainjavamyProj. Inside the nested myProj folder, we will create two text files, HelloGridWorld.java and PlotTest.java. HelloGridWorld.java should have the following contents. package myProjimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.core.Domainimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.Visualizerpublic class HelloGridWorldpublic static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success rateDomain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10create visualizer and explorerVisualizer v GridWorldVisualizer.getVisualizergw.getMapVisualExplorer exp new VisualExplorerdomain, v, sset control keys to use w-s-a-dexp.addKeyActionw, GridWorldDomain.ACTIONNORTHexp.addKeyActions, GridWorldDomain.ACTIONSOUTHexp.addKeyActiona, GridWorldDomain.ACTIONWESTexp.addKeyActiond, GridWorldDomain.ACTIONEASTexp.initGUI And PlotTest.java should have the contents package myProjimport burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.oomdp.auxiliary.common.ConstantStateGeneratorimport burlap.oomdp.auxiliary.common.SinglePFTFimport burlap.oomdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.SimpleHashableStateFactorypublic class PlotTest public static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success ratefinal Domain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10ends when the agent reaches a locationfinal TerminalFunction tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATIONreward function definitionfinal RewardFunction rf new GoalBasedRFnew TFGoalConditiontf, 5., -0.1initial state generatorfinal ConstantStateGenerator sg new ConstantStateGeneratorsset up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory new SimpleHashableStateFactory Create factory for Q-learning agent LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-learningOverridepublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1define learning environmentSimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, sgdefine experimentLearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv,10, 100, qLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDstart experimentexp.startExperiment Your directory structure should now look like the following. pom.xmlsrcmainjavamyProjHelloGridWorld.javaPlotTest.java Were now ready to compile and run In the command line, make sure youre in the same directory as your pom.xml file. Then, to compile, run mvn compile Maven should download BURLAP if you did not manually compile it and other information, and then compile your two sources. To run the HelloGridWorld code, use the following command mvn execjava -Dexec.mainClassmyProj.HelloGridWorld Running this code should launch a GUI with a grid world, similar to the image below. If you click on the image and then use the w-a-s-d keys, youll be able to control the agents movements. Note, however, that we made this a stochastic grid world in the code, which means some of the time you may find the agent going in a different direction than the one you intended We can similarly run our PlotTest code with mvn execjava -Dexec.mainClassmyProj.PlotTest Which will run Q-learning on the same grid world 10 times, plotting the most recent trial and average performance. It should look something like the below image. Conclusion In this tutorial we walked you through compiling BURLAP and setting up your own Maven project that uses BURLAP. We used the command line to set everything up, but we strongly encourage you to use a full IDE for most projects, such as IntelliJ or Eclipse . You can initialize your projects the way we did here and then import the code into the IDE, or you can have these IDEs create a new Maven project themselves. Now that youve completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Hello", "World!", ">", "> Part 1"], "word_count": 1329, "token_count_estimate": 2297}}, "http://burlap.cs.brown.edu/tutorials_v2/scd/p1.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 1 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Next Part You are viewing the tutorial for BURLAP 2 if youd like the BURLAP version 1 tutorial, go here . Introduction In the Basic Planning and Learning tutorial we walked through how to use a number of different planning and learning algorithms. However, all the algorithms we covered were exclusively for finite state planninglearning problems and it is not uncommon in real world problems to have to deal with an infinite or continuous state space. Continuous state problems are challenging because there is an infinite number of possible states, which means youre unlikely to ever visit the same state twice. Since many of the previous algorithms rely on being ably to exhaustively enumerate the states or revisit them multiple times to estimate a value function for each state, having an infinite number of states presents a problem that requires a different set of algorithms. For example, methods that generalize the value function to unseen near by states is one approach to handling continuous state space problems. In this tutorial, we will explain how to solve continuous domains, using the example domains Mountain Car , Inverted Pendulum , and Lunar Lander , with three different algorithms implemented in BURLAP that are capable of handling continuous domains Least-Squares Policy Iteration , Sparse Sampling , and Gradient Descent Sarsa Lambda . As usual, if you would like to see all the finished code that we will write in this tutorial, you can jump to the Final Code section at the end. Solving Mountain Car with Least-Squares Policy Iteration The Mountain Car domain is a classic continuous state RL domain in which an under-powered carmust drive up a steep mountain. However, because the mountain is so steep, the car cannot justaccelerate straight up to the top. Since car is in valley, it can, however, make it to its destination by first moving backwards up the opposite slope, and then accelerate down to gain enoughmomentum to get up the intended slope. An illustration of the Mountain Car problem, courtesy of Wikipedia . To solve this problem, we will use Least-Squares Policy Iteration LSPI. LSPI requires a collection of state-action-reward-state SARS transition tuples that are sampled from the domain. In some domains, like Mountain car, this data can be collected rather straight forwardly with random sampling of actions in the world. In other domains, the set of SARS data and therefore how it is collected is critical to getting good results out of LSPI, so it is important to keep that in mind. LSPI starts by initializing with a random policy and then uses the collected SARS samples to approximate the Q-value function of that policy for the continuous state space. Afterwards, the policy is updated by choosing actions that have the highest Q-values this change in policy is known as policy improvement . This process repeats until the approximate Q-value function and consequentially the policy stops changing much. LSPI approximates the Q-value function for its current policy by fitting a linear function of state basis features to the SARS data it collected, similar to a typical regression problem, which is what enables the value function to generalize to unseen states. Choosing a good set of state basis functions that can be used to accurately represent the value function is also critical to getting good performance out of LSPI. In this tutorial, we will show you how to set up Fourier basis functions and radial basis functions , which tend to be good starting places. Lets start coding now. Well begin by making a class shell, called ContinuousDomainTutorial. In it, we will create a different static method that demonstrates solving each domain and algorithm in this tutorial, so well start with our method for solving Mountain Car with LSPI using Fourier basis functions MCLSPIFB. As usual, weve preemptively included all imports that youll use in the rest of this tutorial. import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateGridderimport burlap.behavior.singleagent.learning.lspi.LSPIimport burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLamimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.behavior.singleagent.vfa.DifferentiableStateActionValueimport burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabaseimport burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGeneratorimport burlap.behavior.singleagent.vfa.fourier.FourierBasisimport burlap.behavior.singleagent.vfa.rbf.DistanceMetricimport burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabaseimport burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBFimport burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistanceimport burlap.domain.singleagent.cartpole.InvertedPendulumimport burlap.domain.singleagent.cartpole.InvertedPendulumVisualizerimport burlap.domain.singleagent.lunarlander.LLVisualizerimport burlap.domain.singleagent.lunarlander.LunarLanderDomainimport burlap.domain.singleagent.lunarlander.LunarLanderRFimport burlap.domain.singleagent.lunarlander.LunarLanderTFimport burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.oomdp.auxiliary.StateGeneratorimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.singleagent.environment.EnvironmentServerimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ContinuousDomainTutorial public static void mainString argsMCLSPIFBpublic static void MCLSPIFBwell fill this in in a moment... Next well create an instance of the Mountain car domain and the typical reward function and terminal function that defines the task in our MCLSPIFB method. MountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100 Our MountainCar instance provides us a means to get a TerminalFunction that sets states in which the car is on the top of the slope on the right-side as terminal states. We then define a Goal-based reward function that returns a reward of 100 when the agent reaches the terminal state and 0 everywhere else 0 is the default reward for a GoalBasedRF , but that value can be changed with a different constructor. Other Mountain Car Parameters We could have also changed parameters of the Mountain car domain, such as the strength of gravity, which is found in the physParams MountainCar data member, but without any modifications, it will automatically use the default parameterizations. The next thing we will want to do is collect SARS data from the Mountain Car domain for LSPI to use for fitting its linear function approximator. For Mountain car, it is sufficient to randomly draw a state from the Mountain Car state space, sample a trajectory from it by selecting actions uniformly randomly, and then repeat the process over again from another random state. Lets collect data in this way until we have 5000 SARS tuple instances for our dataset. To accomplish this data collection, we can make use of a random StateGenerator to select random initial states, and perform random trajectory roll outs from them using a UniformRandomSARSCollector . Lets add code for that now. StateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, null The MCRandomStateGenerator class provides a means to generate Mountain Car states with random positions and velocities. The collectNInstances methods will collect our SARS data for us. Specifically, weve told it to perform rollouts from states generated from our Mountain Car state generator for no more than 20 steps at a time or until we hit a terminal state. This process of generating a random state, rolling out a random trajectory for it, and collecting all the observed SARS tuples repeats until we have 5000 SARS instances. The null parameter at the end of the method call means we want it to create a new SARSData instance and fill it up with the results and return it rather than adding to an existing SARSData instance. LSPI as a LearningAgent In this case were opting to collect all the data LSPI will use ahead of time. Alternatively, LSPI can be used like a standard learning algorithm it does implement the LearningAgent interface in which it starts with no data, acts in the world from whatever the worlds current state is and reruns LSPI as it experiences more transitions thereby improving the policy that it follows. However, this approach to acquiring SARS data is often not as efficient and there may be better means to acquire data when the agent is forced to experience the world as it comes rather than being able to manually sample the state space as we have in this tutorial. Therefore, if you are facing a problem in which you cannot manually control how states are sampled ahead of time, you may want to consider subclassing and overriding LSPIs runLearningEpisode method to use an approach that is a better fit for your domain. To learn more about how LSPIs default runLearningEpisode method is used, see the classs documentation . The next thing we will want to define is the state basis features LSPI will use for its linear estimator of the value function. As noted previously, we will use Fourier basis functions. Fourier basis functions are very easy to implement without having to set many parameters, which makes it a good first approach to try. Each Fourier basis function takes as input a state variable vector, where each element is a normalized scalar value. Each basis function corresponds to a state feature that LSPI will use for its linear function. The BURLAP FourierBasis class is an implementation of the FeatureDatabase interface and will automatically make multiple Fourier basis functions based on the order you choose. The larger the order, the more basis functions which grow exponentially with the dimension of input state feature vector and the more fine grained the representation becomes, allowing for a more precise linear value function approximation. Recall that BURLAP states are not defined with state variable vectors, but with sets of objects adhering to the OO-MDP paradigm however, we can convert an OO-MDP state into a vector trivially since OO-MDPs tend to provide more information than a standard variable vector definition does. The simplest way to convert an OO-MDP state into a variable vector is to simply concatenate the attributes values of each object in the state into a single large vector. To do so, we can make use of the ConcatenatedObjectFeatureVectorGenerator , which asks for which object classes to concatenate and their concatenation order and whether to normalize the values or not is required by Fourier basis funcitons. Custom Vector Conversions If you need to define the vafriable vector conversion differently perhaps, for instance, you want to use relative variables, or ignore certain attributes of the objects, you can always make your own vector conversion definition by implementing a StateToFeatureVectorGenerator , which takes as input a State object and returns a double array. In the Mountain Car domain, there is only one object classthe agentwhich defines the cars position and velocity, so we only need to tell the ConcatenatedObjectFeatureVectorGenerator to use the agent class values and to normalize its attribute values. With a state vector conversion method in hand, lets create a set of 4th order Fourier basis functions to use as our state features for LSPI. ConcatenatedObjectFeatureVectorGenerator featureVectorGenerator new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTFourierBasis fb new FourierBasisfeatureVectorGenerator, 4 Note that the true parameter in the ConcatenatedObjectFeatureVectorGenerator constructor tells it that all dimensions should be normalized in the returned vector, which is what Fourier basis functions expect. Now lets instantiate LSPI on our Mountain Car domain and task with our Fourier basis functions tell it to use a 0.99 discount factor set its SARS dataset to the datasetwe collected and run LSPI until the weight values of its fitted linear function change no more than 10-6 between iterations or until 30 iterationshave passed. LSPI lspi new LSPIdomain, 0.99, fb, datasetPolicy p lspi.runPolicyIteration30, 1e-6 After LSPI has run until convergence, we will want to analyze the policy is produced. To analyze the resulting policy, we could roll it out and load an EpisodeSequenceVisualizer, as we have in prior tutorials. But for fun, lets watch it in real time. To visualize the animated results, we can simply grab the existing visualizer from the domain MountainCarVisualizer , create a SimulatedEnvironment in which to evaluate the policy, and add a VisualActionObserver to the to the environment. Note that we can add an EnvironmentObserver to a SimulatedEnvironment, because it implements the EnvironmentServerInterface otherwise we could use an EnvironmentServer wrapper for Environment instances that do not implement the observer interface. Specifically, well let it run for five policy rollouts. Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObserverdomain, vvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf,MountainCar.getCleanStatedomain, mcGen.physParamsenv.addObserversvobforint i 0 i 5 ip.evaluateBehaviorenvenv.resetEnvironmentSystem.out.printlnFinished If you now run the main method, you see at the start a bunch of print outs to the terminal specifying the maximum change in weight values after each policy iteration. When the change is small enough, LSPI will end and youll get a window animating the the mountain car task using the results of LSPI. That is, you should see something like the below image. A screen cap from the animation of the Mountain car task Although the settings we used are pretty robust to failure, it is possible even if unlikely that the car wont make it to the right side, which indicates that LSPI failed to find a good policy from the valley of the hill. LSPI can fail if your dataset collection happened to be unluckily bad. However, if you rerun the code resulting in a a new random data collection, you should find that it works. Radial Basis Functions Before we leave Mountain Car and LSPI for the next example, lets consider running LSPI on Mountain Car with a different kind of state basis features specifically, lets consider using radial basis functions. A radial basis function is defined with a center state, a distance metric, and a bandwidth parameter. Given an input query state, the basis function returns a value between 0 and 1 with a value of 1 when the query state has a distance of zero from the functions center state. As the query state gets further away, the basis functions returned value degrades to a value of zero. The sensitivity of the basis function to the distance is defined by its bandwidth parameter as the bandwidth value increases, the less sensitive the function is to distance that is, a large bandwidth will result in it returning a value near 1 even when the query state is far away. A set of state features defined by a set of radial basis functions distributed across the state space gives an approximation of where a given state is. You can think of the set of radial basis function outputs as compressing the state space. As a consequence, a common approach to using radial basis functions is set up a coarse multi-dimensional grid over the state space with a separate radial basis function centered at each intersection point of the grid. BURLAP provides us tools to easily accomplish such a construction of radial basis functions. Lets start by a creating a new method for running LSPI with radial basis functions. It will look almost identical to the previous Fourier Basis LSPI method we created, except instead of defining Fourier basis functions, well define radial basis functions. For the moment, the code below will create an instance of a radial basis function state feature database RBFFeatureDatabase , but we will need to add code to actually add the set of radial basis functions it uses. Also note that we moved the initial state object instantiation to earlier in the code, because we will use it to help define the center states of the radial basis functions we will create. The differencesare highlighted with comments in the code. public static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100get a state definition earlier, well use it soon.State s mcGen.getCleanStatedomainStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullinstantiate an RBF feature database, well define it more in a momentRBFFeatureDatabase rbf new RBFFeatureDatabasetruenotice we pass LSPI our RBF features this timeLSPI lspi new LSPIdomain, rf, tf, 0.99, rbflspi.setDatasetdatasetLSPI lspi new LSPIdomain, 0.99, rbf, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObserverdomain, vvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, senv.addObserversvobforint i 0 i 5 ip.evaluateBehaviorenvenv.resetEnvironmentSystem.out.printlnFinished Youll notice that we passed true to our RBFFeatureDatabase constructor. The true flag indicates that that the feature database should include a constant feature that is always on. This is typically a good idea because it provides a Q-value y intercept value to the linear function that will be estimated. To construct a set of radial basis functions over a grid, we will first want to generate the states that lie at the intersection of grid points on a grid. To construct the set of states, we will make use of the StateGridder class in BURLAP. StateGridder allows you to set up arbitrarily specified grids over a state space and return the set of states that lie on the intersection points of the grid. StateGridder can even do things like include constant values for some attributes or objects that is, attribute values that remain fixed for every state in the grid. For our current purposes, we just want a fairly simple grid that spans the full state space of Mountain Car. To get the set of states that span a 5x5 grid over the car position and velocity attributes for a total of 25 states, add the below code right below the instantiation of the RBFFeatureDatabase. If you want to know how to set up a more specific grid e.g., an asymmetric grid like a 3x7, see the classs documentation RBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5ListState griddedStates gridder.gridInputStates Notice that the gridInputState method requires an example State object An example state is required because its what tells the gridder how many objects of each object class need to be gridded and what any constant ungridded objectsvalues are, if any. Now that we have a bunch of states distributed over a uniform grid of the state space, we will want to create radial basis functions centered at each of those states. Since a radial basis function also needs a distance metric between states, let us use a Euclidean distance metric. BURLAP already has an Euclidean distance metric implementation, but it requires that a state first be converted to a variable vector, which we can again do using the ConcatenatedObjectFeatureVectorGenerator and we will again normalize the attribute values. To instantiate the distance metric, add the below code. DistanceMetric metric new EuclideanDistance new ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENT Now we will add a radial basis function to our RBFFeatureDatabase for each state on the grid using the Euclidean distance metric and setting the bandwidth parameter to 0.2. In particular, we will use Gaussian radial basis functions . forState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2 Our final Mountain Car LSPI radial basis function method should now look like the below. public static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100State s MountainCar.getCleanStatedomain, mcGen.physParamsStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullRBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5List griddedStates gridder.gridInputStatesDistanceMetric metric new EuclideanDistancenew ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTforState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2LSPI lspi new LSPIdomain, 0.99, rbf, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObserverdomain, vvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, senv.addObserversvobforint i 0 i 5 ip.evaluateBehaviorenvenv.resetEnvironmentSystem.out.printlnFinished If you now point your main method to call the MCLSPIRBF method, you should see similar results as before, only this time weve used radial basis functions Now that weve demonstrated how to use LSPI on the mountain car domain with Fourier basis functions and radial basis functions, well move on to a different algorithm Sparse Sampling and a different domain the Inverted Pendulum. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 1", "Other Mountain Car Parameters", "LSPI as a LearningAgent", "Custom Vector Conversions"], "word_count": 3158, "token_count_estimate": 4902}}, "http://burlap.cs.brown.edu/tutorials_v2/hgw/p1_ant.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Hello Grid World Tutorials Hello Grid World Part 1 Tutorial Contents Introduction Acquiring BURLAP Dependencies Running the JAR Hello Grid World Code Testing Plotting Tools Notes on the Java Heap Size Conclusions You are viewing the tutorial for BURLAP 2 with ant compilation and manual execution. If youd like the BURLAP 2 Maven instructions, go here . If youd like the BURLAP version 1 tutorial, go here . Introduction In this tutorial we will walk you through downloading BURLAP and making sure you can run it. We willwalk through the instructions to both download the JAR from the precompiled source as wellas how to get the source code and compile it yourself. If you only want to do it one way, feel free to only look at that section. Either way, it should be very straightforward After thecode has been downloaded, well show you a simple way to make sure its working and then showyou how to easily create code that links to it. For more instructions on how write meaningfulcode with BURLAP and what it does, you should see the other tutorials. We will make use of the command line to test things out and compile everything. On the Mac and Linux you can just use the terminal. If you are windows, you can use either the command prompt something like Cygwin . Acquiring BURLAP There are two ways to acquire BURLAP. You can either download the pre-compiled JAR file either with or without dependencies includedor compile it from the source code. In general, the source code will have the latest versionand the pre-compiled JAR may be a bit older, but should be stable. Downloading the Pre-compiled JAR For the prec-compiled jar, you can either get one with the dependencies includein the jar, or without them included. You can get either from these locations the pre-compiled jar with dependencies included the pre-compiled jar with out dependencies. Use the jar without the dependencies if you are having library conflictsand need to manage them yourself. If you use the jar without dependencies,we will walk through how to include them manually in the below dependencies section . After downloading the BURLAP jar file, you can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it testcode, but you can name it anything you want. Within that directory, create a new subdirectory called lib and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following testcodelibburlap.jar Or burlapnodep.jar instead of burlap.jar if you downloaded the version without dependencies. Compiling From the source The easiest way to get the source is with git . If you do not have git installed, install it now. You can download git from here . To compile the code,you will also need ant installed, which you can get from here if you do not already have it. Create a directory where you will place the git distribution. You might have a git directory in your home directory already created for this, which you can use. From the command line, change directories there now. Now enter the following command git clone httpsgithub.comjmacglashanburlap.git You should have found that this created the directory named burlap. Change into that directory now and you should find the following files and subdirectories libsrcLICENSEREADME.mdbuild.xml Now type ant dist And you should find new subdirectories appear in particular, the dist directory whichwill contain the BURLAP JAR file. If there were compilation errors warnings should not be a concern its possible that you will need to re-download the dependencies. For convenience,BURLAPs git repository includes the dependencies that it needs, but its possible you may haveto install them yourself see the Dependencies section and place all the JARs on which BURLAP depends in the lib directory and try ant again. With the burlap.jar file created well now try working with it. You can either install it into a system level path that java will always search or your can place it in a local directory. In this tutorial we will just use it locally and point java to it. Create a directory in which you will run your tests. In this tutorial,we will name it testcode, but you can name it anything you want. Within that directory, create a new subdirectory called lib and place the burlap.jar file that you downloaded inside it. The directory structure should look like the following testcodelibburlap.jar Dependencies Most of BURLAP can be run without any of its dependencies,but some of the algorithms and advanced tools will requireother libraries to be present. For example, the RLGluedependency allows BURLAP to communicate with other RLsoftware. If you are using the pre-compiled BURLAP jar that has dependencies included,you can skip this step. If you are using a compiled version of BURLAP or the jar without dependencesand you want to use all of BURLAPs features you should get the relevant JAR files and put them in the lib directory of the testcode directory thatwe created. If you compiled BURLAP from source, you can just copy the files in the BURLAP source lib directory into our testcode lib directory. Otherwise, you can download the dependencies and their dependencies from the below locations RLGlue Java Codec - You will need this if you plan on interfacing BURLAP with RLGLue . Apache Math Commons - For performance plotting tools. JFree Chart - For Performance Plotting tools. Snake YAML - For reading and writing states into the YAML format. Jackson - For reading and writing states into the JSON format. JOptimizer - For Max Margin Apprenticeship Learning SCPSolver - For Minmax, Coco-Q, and Correlated-Q algorithms. Our choice of underlying LP solver that it uses is lpsolve. Weka - For providing a range of regression algorithms for Fitted Value Iteration. JOptSimple - For handling command line arguments in the BURLAP shell. After putting all the relevant dependencies in the lib folder,your directory structure should look something like the following. testcodelibburlap.jarJavaRLGlueCodec.jarLPSOLVESolverPack.jarSCPSolver.jarcolt-1.2.0.jarcommons-beanutils-1.6.jarcommons-collections-2.1.jarcommons-lang3-3.1.jarcommons-logging-1.1.1.jarcommons-math3-3.2.jarcsparsej-1.1.1.jarejml-0.25.jarguava-18.0.jarhamcrest-core-1.3.jarjackson-annotations-2.2.3.jarjackson-core-2.2.3.jarjackson-databind-2.2.3.jarjcommon-1.0.21.jarjfreechart-1.0.17.jarjopt-simple-4.9.jarjoptimizer-3.2.0.jarjoptimizer-3.3.0.jarjunit-4.11.jarlog4j-1.2.14.jarservlet.jarsnakeyaml-1.13.jartrove.jarweka-src.jarweka.jarxml-apis-1.0.b2.jar Running the JAR The simplest way to test BURLAP is to run the default main method in the GridWorld domain generator, which will launch a simple interactive visualization of the GridWorld. From the command line, change directory into your testcode directory if youre not already there. Then enter java -cp lib. burlap.domain.singleagent.gridworld.GridWorldDomain Note the the . after lib which adds the current directory the class path. Some users have reported errors unless that is included, even though we havent actually written any of our own code yet If youre in the Windows command prompt and not cygwin, you may need to change the colon character to a semicolon. If a GUI of a simple GridWorld appears, as shown below, then everything is working There are two ways to control the agent in the GUI. One way is to use keystrokes, whichyou can perform by clicking on the visualization and then pressing either the w, a, s, or d keys you only need to click on the visualization once to get it to start acceptingkey strokes. Alternatively, you can use the execute text field and button. In the executetext field you can enter the name of the action you want the agent to perform and then pressthe execute button to have it performed. In GridWorld, the actions you can have the agentperform are named north, south, east, and west. Hello Grid World Code Were now going to write a simple BURLAP hello world program for you to test. Were not going to spend any time really explaining what the code does, its just a way to make sure that you can link to BURLAP with your own code. For a much more thorough explanation of the code, see the BURLAP java doc and other tutorials available. In your testcode directory, create a new file named HelloGridWorld.java. Inside the file, place the following code. import burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.domain.singleagent.gridworld.GridWorldVisualizerimport burlap.oomdp.core.Domainimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.explorer.VisualExplorerimport burlap.oomdp.visualizer.Visualizerpublic class HelloGridWorldpublic static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success rateDomain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10create visualizer and explorerVisualizer v GridWorldVisualizer.getVisualizergw.getMapVisualExplorer exp new VisualExplorerdomain, v, sset control keys to use w-s-a-dexp.addKeyActionw, GridWorldDomain.ACTIONNORTHexp.addKeyActions, GridWorldDomain.ACTIONSOUTHexp.addKeyActiona, GridWorldDomain.ACTIONWESTexp.addKeyActiond, GridWorldDomain.ACTIONEASTexp.initGUI This code will effectively recreate the same GridWorld GUI that we launched straight from the BURLAP jar, with the exception that we made the GridWorld have stochastic transitions. This means that as you control the agent with the w-s-a-d keys, you may find that it sometimes goes in the wrong direction After saving the file, we will compile it with the command javac -cp lib. HelloGridWorld.java Now lets run it java -cp lib. HelloGridWorld If youre in the Windows command prompt and not cygwin, you may need to change the colon character to a semicolon and if youre using cygwin, then you need to specify it as a cygwin path java -cp cygpath -wp lib. HelloGridWorld If everything worked, then you should have seen the same GUI as the one you saw when we ran codedirectly from the BURLAP jar. Testing Plotting Tools In these section well provide some code to make sure that your dependencies for the BURLAP plotting tools are working correctly. If you dont care about this, naturally you can skip this section. Create a new file named PlotTest.java and put the following code in it. import burlap.behavior.singleagent.auxiliary.performance.LearningAlgorithmExperimenterimport burlap.behavior.singleagent.auxiliary.performance.PerformanceMetricimport burlap.behavior.singleagent.auxiliary.performance.TrialModeimport burlap.behavior.singleagent.learning.LearningAgentimport burlap.behavior.singleagent.learning.LearningAgentFactoryimport burlap.behavior.singleagent.learning.tdmethods.QLearningimport burlap.domain.singleagent.gridworld.GridWorldDomainimport burlap.oomdp.auxiliary.common.ConstantStateGeneratorimport burlap.oomdp.auxiliary.common.SinglePFTFimport burlap.oomdp.auxiliary.stateconditiontest.TFGoalConditionimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.SimpleHashableStateFactorypublic class PlotTest public static void mainString argsGridWorldDomain gw new GridWorldDomain11,11 11x11 grid worldgw.setMapToFourRooms four rooms layoutgw.setProbSucceedTransitionDynamics0.8 stochastic transitions with 0.8 success ratefinal Domain domain gw.generateDomain generate the grid world domainsetup initial stateState s GridWorldDomain.getOneAgentOneLocationStatedomainGridWorldDomain.setAgents, 0, 0GridWorldDomain.setLocations, 0, 10, 10ends when the agent reaches a locationfinal TerminalFunction tf new SinglePFTFdomain.getPropFunctionGridWorldDomain.PFATLOCATIONreward function definitionfinal RewardFunction rf new GoalBasedRFnew TFGoalConditiontf, 5., -0.1initial state generatorfinal ConstantStateGenerator sg new ConstantStateGeneratorsset up the state hashing system for looking up statesfinal SimpleHashableStateFactory hashingFactory new SimpleHashableStateFactory Create factory for Q-learning agent LearningAgentFactory qLearningFactory new LearningAgentFactory Overridepublic String getAgentName return Q-learningOverridepublic LearningAgent generateAgent return new QLearningdomain, 0.99, hashingFactory, 0.3, 0.1define learning environmentSimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, sgdefine experimentLearningAlgorithmExperimenter exp new LearningAlgorithmExperimenterenv,10, 100, qLearningFactoryexp.setUpPlottingConfiguration500, 250, 2, 1000, TrialMode.MOSTRECENTANDAVERAGE,PerformanceMetric.CUMULATIVESTEPSPEREPISODE, PerformanceMetric.AVERAGEEPISODEREWARDstart experimentexp.startExperiment Then compile and run as before, except this time well specify the PlotTest class that we created javac -cp lib. PlotTest.javajava -cp lib. PlotTest If everything worked, then you should have seen a bunch of plots showing the performance of a Q-learning algorithm that were updated in semi real time, similar to what is shown below. If you did not see something like the above, you may need to make sure that you have all the dependencies you need in the lib folder see the Dependencies section for more details. Notes on the Java Heap Size Planning and learning algorithms often require a lot of memory for large problems, more than what java will typically use by default. Therefore, you may want to make sure that you increase javas heap size whenever you run BURLAP. You can do this with the -Xmx argument. For instance, to give java 2GB of memory to use, change the previous run commands to the following java -cp lib. -Xmx2048M HelloGridWorld Conclusions In this tutorial we walked you through acquiring BURLAP and provided some simple code to make sure you can compile your own code with it. We strongly encourage you to use a full IDE, however, such as IntelliJ or Eclipse . Just make sure that you add the jar files that we put in the lib folder to your Eclipse projects build path. Since all of the BURLAP java doc comes with the jar,Eclipse will autocomplete methods and explain the parameters, which should be very helpful. Now that youve completed this tutorial, you are encouraged to check out the other BURLAP tutorials that are available. Happy coding End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Hello", "World!", ">", "> Part 1"], "word_count": 2013, "token_count_estimate": 3368}}, "http://burlap.cs.brown.edu/tutorials_v2/scd/p2.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 2 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving the Inverted Pendulum with Sparse Sampling In this part of the tutorial we will be solving the Inverted Pendulum problem. There are actually a number of different versions of this problem for other variants, see the CartPoleDomain and its parameters, but in this example well be using one of the more simple forms. The problem is as follows a cart exists on an infinite track on which force can be applied to move the cart left or right on the track. On top of the cart is a pole the inverted pendulum and the goal is to keep the pole balanced and pointing up by using left, right, or no force actions. If the angle between the pole and the vertical axis is larger than some threshold, the task is considered to have been failed. The state is defined by a single object which is defined by the pole angle and its angular velocity. An illustration of the problem, as visualized in BURLAP, is shown below. The BURLAP visualization of the Inverted Pendulum problem We are going to solve this problem using Sparse Sampling more on that in a moment. Let us start by making a method IPSS for solving this problem and filling it in with code to instantiate the InvertedPendulum domain and task. public static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.Domain domain ip.generateDomainRewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.State initialState InvertedPendulum.getInitialStatedomain The line ip.physParams.actionNoise 0. sets our domain to have no noise in the actions. physParams is a data member containing all physics parameters that you can modify. The created reward function and terminal function specify task failure conditions to be when the angle between the pole and vertical axis is greater than 8 radians. Specifically, the agent will receive zero reward everywhere except when the poles angle is greater than 8, at which point it will receive -1 reward. The initial state we retrieved from the InvertedPendulum class will return a state in which the pole is balanced with no initial angular velocity. The algorithm were going to use to solve this problem is Sparse Sampling. Instead of trying to approximate the value function for all states, Sparse Sampling will estimate Q-values for only one state a time, with the exception that the Q-values estimated are for a finite horizon , which means it only considers the possible reward received up to a specific number of steps from the current state and then ignores everything that might happen after that point. The approach is called Sparse Sampling, because if the set of possible transition dynamics are very large or infinite, it will only use a small sample from the transition dynamics when computing the Q-values. A disadvantage of Sparse Sampling is that for every new state encountered in the real world, planning needs to happen all over again unless the agent happens to arrive in the same exact state, which is often uncommon in continuous state spaces. Furthermore, the computational complexity grows exponentially with the size of the horizon used, so if a large horizon is necessary to achieve a reasonable policy, Sparse Sampling may be prohibitively expensive. However, for our Inverted Pendulum domain, failing the task is only a few easy mistakes away, which means we can use a tractably small horizon to solve the problem. Lets now instantiate SparseSampling and set up a GreedyQ policy to follow from it. SparseSampling ss new SparseSamplingdomain, rf, tf, 1, new SimpleHashableStateFactory, 10 ,1ss.setForgetPreviousPlanResultstruess.toggleDebugPrintingfalsePolicy p new GreedyQPolicyss Note that were using a discount factor of 1 because we are computing the Q-values for a finite horizon rather than computing an infinite horizon and a discount factor of 1 with a finite horizon will always result in finite Q-values. The method call setForgetPreviousPlanResultstrue tells Sparse Sampling to forget the previous planning tree it created every time planning for a new state is begun. Since we dont expect to see the same state twice, this is useful to clean up memory that we dont expect to use again. The last parameters of the SparseSampling constructor are the horizon size and the number of transition samples. We set the horizon to 10 and the number of transition samples to 1. Using only 1 transition sampling might be problematic in general, but since we simplified by the problem by removing action noise, everything is deterministic and so we only need one sample anyway Later, feel free to add back noise and increase the number samples, though you will find that a fair bit more computation time is needed. The final thing youll notice in the code is that we never make an explicit call to planning from a state. There is a lack of an explicit planning call because whenever the GreedyQPolicy queries for the Q-values of a state, SparseSampling will automatically plan from that state first unless we had let it remember past planning results and it was the same state as a state for which its planned before. At this point, were basically done. All we need to do now is evaluate the policy that we created. We could have an animated visualization, like we did for the Mountain Car domain with LSPI, but since Sparse Sampling requires a bit more computation per step, lets let it cache an episode with a maximum of 500 steps to a file, and then visualize the episode using an EpisodeSequnceVisualizer like weve used in previous tutorials. Add the following code to evaluate the policy for at most 500 steps from the initial state, create a visualizer, and load up a EpisodeSequenceVisualizer to review the results. EpisodeAnalysis ea p.evaluateBehaviorinitialState, rf, tf, 500System.out.printlnNum steps ea.maxTimeStepVisualizer v InvertedPendulumVisualizer.getInvertedPendulumVisualizernew EpisodeSequenceVisualizerv, domain, Arrays.asListea If you now point the main method to IPSS and run it, you should first see printed to the console the number of Bellman backups that were performed in the planning for each step of the episode. After 500 steps, it will launch the EpisodeSequenceVisualizer that you can use to review the steps it took. You should have found that it successfully balanced the pole for all 500 steps and the interface should look something like the below. The EpisodeSequenceVisualizer GUI after solving the Inverted Pendulum with Sparse Sampling. Were now finished with the Sparse Sampling example If youre looking for an additional exercise, consider trying to solve this problem with LSPI using what you learned from the previous part of the tutorial. If you do so, we recommend using 5th order Fourier basis functions and collecting 5000 SARS instances by performing random trajectories from the initial balanced state. To create a StateGenerator that always returns the same initial state for use with the SARS collector, see the ConstantStateGenerator class. In the final part of this tutorial, we will show how to solve the Lunar Lander domain with gradient descent SARSA lambda. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 2"], "word_count": 1186, "token_count_estimate": 1527}}, "http://burlap.cs.brown.edu/tutorials_v2/scd/p3.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 3 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Next Part Solving Lunar Lander with SARSA In our final example of this tutorial we will solve a simplified Lunar Lander domain using gradient descent Sarsa Lambda and CMACTiling coding basis functions. The Lunar Lander domain is a simplified version of the classic 1979 Atari arcade game by the same name. In this domain the agent pilots a ship that must take off from the ground and land on a landing pad. The agent can either use a strong rocket thruster to push the ship in the direction the ship is facing, use a weak rocket thruster that is equal magnitude to the force of gravity, rotate clockwise or counterclockwise, or coast. The agent will receive a large reward for landing on the landing pad, a large negative reward for colliding with the ground or an obstacle, and a small negative reward for all other transitions. As with the previous examples, let us begin by making a method for this example LLSARSA and instantiating a Lunar Lander domain , task, and initial state. public static void LLSARSALunarLanderDomain lld new LunarLanderDomainDomain domain lld.generateDomainRewardFunction rf new LunarLanderRFdomainTerminalFunction tf new LunarLanderTFdomainState s LunarLanderDomain.getCleanStatedomain, 0LunarLanderDomain.setAgents, 0., 5.0, 0.0LunarLanderDomain.setPads, 75., 95., 0., 10. Most of this code should be fairly self explanatory. Using a default construct for LunarLanderDomain and not setting anything else with it will use default parameters for the domain but you can change various properties such as the force of gravity, thrust, etc.. The default reward function returns 1000 for landing, -100 for collisions, and -1 for regular transitions though these values can be changed with a different constructor . The terminal function sets all states in which the ship has landed on the landing pad as terminal states. The getCleanState method, with the parameter 0 creates a state with an agent object the ship a landing pad object, and 0 obstacle objects. The setAgent method parameters specify the angle of the ship from the vertical axis in radians, the x position of the ship 5, and the y position of the ship 0, on the ground, respectively. The setPad method parameters define the landing pad dimensions in terms of the rectangular left, right, bottom, top boundaries, respectively. This will create an initial state that looks like the below as visualized in BURLAP. The initial stated used in Lunar Lander. The red box is the ship, the blue box the landing pad. Were going to solve this problem with gradient descent SARSA , which is a learning algorithm that behaves much like conventional tabular SARSA discussed in previous tutorials, except it learns an approximation of the value function, much like LSPI. Unlike LSPI, gradient descent SARSA does not need to use a linear approximator however, in practice it is usually a good idea to use a linear approximator because there are much stronger learning convergence guarantees with linear approximators. When using a linear approximator, it is a good idea then to use some kind of basis functions. Like in the LSPI example, we could use the same Fourier basis or radial basis functions for gradient descent SARSA. However, this time well use a different basis function CMACs, also know in reinforcement learning literature as Tile Coding. CMACs create a set of features by generating multiple tilings over the state space. Each tile represents a features and that feature is on if the state falls within that tile. CMACs in detail CMACs address learning in continuous domains in a only slightly more complex way than merely discretizing the state space, yet also diminish the aliasing effects that discretization can incur. To describe how they work, lets start by thinking about how a state discretization can be used to create a set of binary basis functions. First imagine a discretization of the state space as a process that creates large bins, or tiles , across the entire state space. Well let each tile represent a different binary basis function. For a given input continuous state, all basis functions return a value of 0, except the function for the tile in which the continuous state is contained, which will return a value of 1. By then estimating a linear function over these features, we generalize the observed rewards and transitions for one state to all states that are contained in the same tile the larger the tiles we use, the larger the generalization. A disadvantage of using such a simple discretization is that it produces aliasing effects. That is, two states may be very similar but reside on opposite sides of the edge of a tile, which results in none of their experience being shared, despite the fact that they are similar and do share experiences with other states that are more distant but happen to be in the same tile. CMACs diminish this aliasing effect by instead creating multiple offset tilings over the state space and creating a basis function for each tile in each of the tilings. If there are n tilings, then any given input state will have n basis functions with a value 1 one for the tile in which the query state is contained for each tiling. Because the tilings are offset from each other, two states may be contained in the same tile of one tiling, but in different tiles for a different tiling. As a consequence, experience generalization still occurs between states in the same tiling, but the differences between different tilings regains specificity and removes aliasing effects. For more information on CMACs with some good illustrations, we recommend the Generalization and Function Approximation chapter in the book Reinforcement Learning An Introduction , by Sutton and Barto. An online version of the chapter can be found here . An advantage of using CMACs is that you only need to store weight values in the fitted linear function for tiles that are associated with states that the agent has experienced thus far the basis function for all other tiles would return a value of zero and therefore contribute nothing to the value function approximation. Another advantage specific to OO-MDPs is that because each tile represents a discretized state, we can maintain object identifier independence, which is otherwise not always possible to do with a number of value function approximation methods. If you dont need object identifier independence, there is another implementation of CMACs in BURLAP called FVCMACFeatureDatabase that is slightly more CPU efficient and operates on state feature vectors which as before are produced with StateToFeatureVectorGenerator objects. For this tutorial, however, we will use the version that provides object identifier independence, which is called CMACFeatureDatabase . Lets continue our code implementation by instantiating a CMACFeatureDatabase object and defining the tiling of our state space. To implement CMAC basis functions, we will need to decide on the number of tilings that we use and the width of each tile along each attribute. In this case, we will use 5 tilings with a width for each attribute that produces 10 tiles along each attribute range. We will limit this tiling to the Lunar Lander ship attribute values and ignore attributes for the landing pad. Since the agents ship is defined by 5 attributes x position, y position, x velocity, y velocity, and rotation angle from the vertical axis, this will produce 5 tilings that each define at most 105 tiles again though, we dont necessarily have to store weights for all tiles if the agent never visits them To do so, add the below code. int nTilings 5CMACFeatureDatabase cmac new CMACFeatureDatabasenTilings, CMACFeatureDatabase.TilingArrangement.RANDOMJITTERdouble resolution 10.double angleWidth 2 lld.getAngmax resolutiondouble xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutioncmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.AATTNAME, angleWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.XATTNAME, xWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.YATTNAME, yWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.VXATTNAME, velocityWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS, domain.getAttributeLunarLanderDomain.VYATTNAME, velocityWidth In the first line, we instantiate the CMACFeatureDatabase with 5 tilings, each offset by a random amount. Then we compute tile widths along each attribute such that it would produce at most 10 tile margins along each attribute. The methods lld.getXMin simply return the minimum x-value for our LunarLander instance and the other methods return their respective attributes value ranges. Finally, we inform the CMACFeatureDatabase of the width for each attribute that will be included in the tiling for each object class. In this case, we will only produce tilings over the agent class for its rotation angle x, y position and x, y velocity attributes and ignore the attributes for other object classes like the landing pad. Now that we have the CMACFeatureDatabase set up, we can create a linear value function approximator for it and pass it along to gradient descent SARSA. double defaultQ 0.5DifferentiableStateActionValue vfa cmac.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, 0.99, vfa, 0.02, 0.5 Note that to set the initial default Q-values to be predicted to 0.5, we set the value of each feature weight to 0.5 divided by the number of tilings. We divide the desired initial Q-value 0.5 by the number of tilings 5, because for any given state there will only be n features with a value of 1 and the rest 0, where n is the number of tilings. Therefore, if the initial weight value for all those features is 0.55, the linear estimate will predict our desired initial Q-value 0.5. We also set the learning rate for gradient descent SARSA to 0.02 in general, you should decrease the learning rate as the number of features increases, and set to 0.5. With gradient descent SARSA instantiated, we can run learning episodes wtih an Environment just like we do for typical SARSA. Lets create a SimulatedEnvironment, run learning for 5000 episodes, and then visualize the results with an EpisodeSequenceVisualizer. SimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, sList episodes new ArrayList forint i 0 i 5000 iEpisodeAnalysis ea agent.runLearningEpisodeenvepisodes.addeaSystem.out.printlni ea.maxTimeStepenv.resetEnvironmentVisualizer v LLVisualizer.getVisualizerlld.getPhysParamsnew EpisodeSequenceVisualizerv, domain, episodes If you now point your main method to LLSARSA and run it, you should initially see a bunch of text after each episode stating how long the learning episode lasted followed by the EpisodeSequenceVisualizerGUI, which should look something like the below. The EpisodeSequenceVisualizer GUI showing the learning results on Lunar Lander You should find that as more learning episodes are performed, the agent becomes progressively better at piloting to the landing pad. That concludes all of our examples for this tutorial Closing remarks and the full code we created can be found on the next page. Next Part", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 3", "CMACs in detail"], "word_count": 1762, "token_count_estimate": 2521}}, "http://burlap.cs.brown.edu/tutorials_v2/scd/p4.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc Tutorial Solving Continuous Domains Tutorials Solving Continuous Domains Part 4 Tutorial Contents Introduction Solving Mountain Car with Least-Squares Policy Iteration Solving the Inverted Pendulum with Sparse Sampling Solving Lunar Lander with SARSA Conclusions Final Code Previous Part Conclusions In this tutorial we showed you how to solve continuous state problems with three different algorithms implemented in BURLAP LSPI, Sparse Sampling, and gradient descent SARSA. We also demonstrated how to use these algorithms on three different continuous state domains Mountain Car, Inverted Pendulum, and Lunar Lander. And finally, we also explained how to use three different basis functions which can be used with LSPI and gradient descent SARSA Fourier basis functions, radial basis functions and CMACsTile coding. Hopefully these examples have made clear the kinds of tools you need to use solve any other continuous state problems. As usual, you can find all of the code developed in this tutorial below. Final Code import burlap.behavior.policy.GreedyQPolicyimport burlap.behavior.policy.Policyimport burlap.behavior.singleagent.EpisodeAnalysisimport burlap.behavior.singleagent.auxiliary.EpisodeSequenceVisualizerimport burlap.behavior.singleagent.auxiliary.StateGridderimport burlap.behavior.singleagent.learning.lspi.LSPIimport burlap.behavior.singleagent.learning.lspi.SARSCollectorimport burlap.behavior.singleagent.learning.lspi.SARSDataimport burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLamimport burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSamplingimport burlap.behavior.singleagent.vfa.DifferentiableStateActionValueimport burlap.behavior.singleagent.vfa.cmac.CMACFeatureDatabaseimport burlap.behavior.singleagent.vfa.common.ConcatenatedObjectFeatureVectorGeneratorimport burlap.behavior.singleagent.vfa.fourier.FourierBasisimport burlap.behavior.singleagent.vfa.rbf.DistanceMetricimport burlap.behavior.singleagent.vfa.rbf.RBFFeatureDatabaseimport burlap.behavior.singleagent.vfa.rbf.functions.GaussianRBFimport burlap.behavior.singleagent.vfa.rbf.metrics.EuclideanDistanceimport burlap.domain.singleagent.cartpole.InvertedPendulumimport burlap.domain.singleagent.cartpole.InvertedPendulumVisualizerimport burlap.domain.singleagent.lunarlander.LLVisualizerimport burlap.domain.singleagent.lunarlander.LunarLanderDomainimport burlap.domain.singleagent.lunarlander.LunarLanderRFimport burlap.domain.singleagent.lunarlander.LunarLanderTFimport burlap.domain.singleagent.mountaincar.MCRandomStateGeneratorimport burlap.domain.singleagent.mountaincar.MountainCarimport burlap.domain.singleagent.mountaincar.MountainCarVisualizerimport burlap.oomdp.auxiliary.StateGeneratorimport burlap.oomdp.core.Domainimport burlap.oomdp.core.TerminalFunctionimport burlap.oomdp.core.states.Stateimport burlap.oomdp.singleagent.RewardFunctionimport burlap.oomdp.singleagent.common.GoalBasedRFimport burlap.oomdp.singleagent.common.VisualActionObserverimport burlap.oomdp.singleagent.environment.SimulatedEnvironmentimport burlap.oomdp.statehashing.SimpleHashableStateFactoryimport burlap.oomdp.visualizer.Visualizerimport java.util.ArrayListimport java.util.Arraysimport java.util.Listpublic class ContinuousDomainTutorial public static void MCLSPIFBMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100StateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullConcatenatedObjectFeatureVectorGenerator featureVectorGenerator newConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTFourierBasis fb new FourierBasisfeatureVectorGenerator, 4LSPI lspi new LSPIdomain, 0.99, fb, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObserverdomain, vvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, senv.addObserversvobforint i 0 i 5 ip.evaluateBehaviorenvenv.resetEnvironmentSystem.out.printlnFinishedpublic static void MCLSPIRBFMountainCar mcGen new MountainCarDomain domain mcGen.generateDomainTerminalFunction tf new MountainCar.ClassicMCTFRewardFunction rf new GoalBasedRFtf, 100State s MountainCar.getCleanStatedomain, mcGen.physParamsStateGenerator rStateGen new MCRandomStateGeneratordomainSARSCollector collector new SARSCollector.UniformRandomSARSCollectordomainSARSData dataset collector.collectNInstancesrStateGen, rf, 5000, 20, tf, nullRBFFeatureDatabase rbf new RBFFeatureDatabasetrueStateGridder gridder new StateGriddergridder.gridEntireDomainSpacedomain, 5ListState griddedStates gridder.gridInputStatesDistanceMetric metric new EuclideanDistancenew ConcatenatedObjectFeatureVectorGeneratortrue, MountainCar.CLASSAGENTforState g griddedStatesrbf.addRBFnew GaussianRBFg, metric, .2LSPI lspi new LSPIdomain, 0.99, rbf, datasetPolicy p lspi.runPolicyIteration30, 1e-6Visualizer v MountainCarVisualizer.getVisualizermcGenVisualActionObserver vob new VisualActionObserverdomain, vvob.initGUISimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, senv.addObserversvobforint i 0 i 5 ip.evaluateBehaviorenvenv.resetEnvironmentSystem.out.printlnFinishedpublic static void IPSSInvertedPendulum ip new InvertedPendulumip.physParams.actionNoise 0.Domain domain ip.generateDomainRewardFunction rf new InvertedPendulum.InvertedPendulumRewardFunctionMath.PI8.TerminalFunction tf new InvertedPendulum.InvertedPendulumTerminalFunctionMath.PI8.State initialState InvertedPendulum.getInitialStatedomainSparseSampling ss new SparseSamplingdomain, rf, tf, 1, new SimpleHashableStateFactory, 10 ,1ss.setForgetPreviousPlanResultstruess.toggleDebugPrintingfalsePolicy p new GreedyQPolicyssEpisodeAnalysis ea p.evaluateBehaviorinitialState, rf, tf, 500System.out.printlnNum steps ea.maxTimeStepVisualizer v InvertedPendulumVisualizer.getInvertedPendulumVisualizernew EpisodeSequenceVisualizerv, domain, Arrays.asListeapublic static void LLSARSALunarLanderDomain lld new LunarLanderDomainDomain domain lld.generateDomainRewardFunction rf new LunarLanderRFdomainTerminalFunction tf new LunarLanderTFdomainState s LunarLanderDomain.getCleanStatedomain, 0LunarLanderDomain.setAgents, 0., 5., 0.LunarLanderDomain.setPads, 75., 95., 0., 10.int nTilings 5CMACFeatureDatabase cmac new CMACFeatureDatabasenTilings,CMACFeatureDatabase.TilingArrangement.RANDOMJITTERdouble resolution 10.double angleWidth 2 lld.getAngmax resolutiondouble xWidth lld.getXmax - lld.getXmin resolutiondouble yWidth lld.getYmax - lld.getYmin resolutiondouble velocityWidth 2 lld.getVmax resolutioncmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.AATTNAME,angleWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.XATTNAME,xWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.YATTNAME,yWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.VXATTNAME,velocityWidthcmac.addSpecificationForAllTilingsLunarLanderDomain.AGENTCLASS,domain.getAttributeLunarLanderDomain.VYATTNAME,velocityWidthdouble defaultQ 0.5DifferentiableStateActionValue vfa cmac.generateVFAdefaultQnTilingsGradientDescentSarsaLam agent new GradientDescentSarsaLamdomain, 0.99, vfa, 0.02, 0.5SimulatedEnvironment env new SimulatedEnvironmentdomain, rf, tf, sListEpisodeAnalysis episodes new ArrayListEpisodeAnalysisforint i 0 i 5000 iEpisodeAnalysis ea agent.runLearningEpisodeenvepisodes.addeaSystem.out.printlni ea.maxTimeStepenv.resetEnvironmentVisualizer v LLVisualizer.getVisualizerlld.getPhysParamsnew EpisodeSequenceVisualizerv, domain, episodespublic static void mainString args MCLSPIFBMCLSPIRBFIPSSLLSARSA End.", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Tutorial: Solving Continuous Domains", ">", "> Part 4"], "word_count": 471, "token_count_estimate": 2002}}, "http://burlap.cs.brown.edu/updates.html": {"text_content": "BURLAP Home Updates Information F.A.Q. Tutorials Java Doc June 17, 2016 BURLAP 3 is Here If youve been following git or the google groups page, you may be aware of or were even following the development of BURALP 3, which is now finally ready for a more full release, replacing the master branch of the github repo BURLAP 3 changes can be summarized as follows. a more simple and flexible State interface a more simple and flexible action interface and model definition stochastic games agent indexing by ints shorter method names andor classes in some cases abstract classes converted to interfaces abstract methodsinterfaces restructured to be more functional slight package reorganizations and a license change to Apache 2.0. A good way to acquaint yourself with the changes in BURLAP 3 is to review the tutorials which have all been updated for BURALP 3 or to scan the code in the examples repository . In particular, you may want to review the updated Building a Domain tutorial which will cover the most significant changes to how BURLAP works. State interface Previously in BURALP 2 and 1, all states in BURLAP were OO-MDP states, and although State was an interface in BURLAP 2 that allowed you to ignore OO-MDP related methods, there were a very large number of methods for which youd have to throw unsupported operation exceptions if you didnt want your state to be an OO-MDP state, making what was expected rather unclear. Furthermore, all variable values were pushed through nested class wrappers and you had to specify these types and various information about them very explicitly in the domain construction. In BURLAP 3, OO-MDPs are no longer a requirement. State is now a simple interface that you implement for your problem, making the state definition equivalent to defining a Java class. The State interface only requires you to implement three methods variableKeys, getObject key, and copy. variableKeys requires you to return a list of Java type Object that are keys that can be used to refer to variables in your state. Because the list is of type Object, your keys can be any kind of structure that is most convenient for you be it an int, a String, or something else entirely. The get method takes in a variable key and returns the variable value for that key. The value is also of type Object, meaning your state variables can be any data type you want Because the key is an Object, you can also handle support for multiple key data representations e.g., maybe strings and ints. Finally, the copy method simply creates a copy of your State and returns it. If you want to provide more standard functionality with your state, you can also implement MutableState , which adds a setObject key, Object value method to State. Doing so will let things like standard BURALP shell commands change the value of states, or create an set of states centered on grid intersection points. And if you do want to use OO-MDP representations, there are special interfaces for that too, but its optional. If you want to use OO-MDPs, you should look at the new tutorial specifically about that Building and OO-MDP Domain . One of the auxiliary advantages of this new state interface compared to the old methods is that it makes serialization very trivial. As long as your State implementations are JavaBeans has a default constructor and getter and setters for all relevant non-public data fields, you can use the Yaml package to save and load data that includes states. For example String strRep new Yaml.dumpstateObject Where stateObject is the State instance you want to serialize. Naturally, this also works for serializing more complex data structures that contain State objects. And to parse a yaml string of a State, youd do State s Statenew Yaml.loadstateStr Action interfaces In BURLAP 2 and 1, there were a number of action interfaces and abstract classes and it was often unclear to new users what piece was responsible for what. In BURLAP 3, the Action interface defines a decision and is most similar to a GroundedAction in BURALP 2 and 1 it does not request code for transition dynamics or preconditions. Implementing an Action requires implementing only two methods actionName and copy. Anything else you need to distinguish an action is entirely up to you. Although Action is quite simple now, that doesnt mean BURLAP no longer has a means to handle preconditions or parameterized actions. Along with Action is the interface ActionType . ActionType serves as a generator for Actions and requires three methods typeName, associatedActionString, and allApplicableActionsState. The associatedAction method takes a string representation of the action and generates the corresponding Action object. allApplicableActions is the main method of interest, which takes as input a State and returns all applicable actions of that ActionType. This method would handle determining which possible parameterizations there were and checking any preconditions you want to define. Although you can implement your own Action and ActionType classes, when you have an unparameterized action set that you can execute anywhere as is most common in MDPs, you can define the action set using the UniversalActionType , where you create a new UniversalActionType with a different name for each of your actions. Alternatively, you can manually give a UniversalActionType your own Action instance that it will always generate. For example, for a grid world, defining the action set would look something like this in code domain.addActionTypesnew UniversalActionTypenorth,new UniversalActionTypesouth,new UniversalActionTypeeast,new UniversalActionTypewest In the previous version of BURLAP an MDPs state transition dynamics model was stored in one of the Actions. Since the Action interfaces are much simpler now, the model is now its own interface, with SampleModel , and FullModel the former if you can only generate samples from the transition dynamics, and the latter if you can enumerate the probability distribution. The nice thing about this factoring is that for real RL problems you dont have to provide a model at all, and can just specify the action set. Additionally, it makes working with model-based RL algorithms easier, and enables you to easily change the model youre using with an algorithm, independent of even those provided with an existing simulated domain. Finally, this change to a more simple interface also provides trivial serialization in the same way states do. Since Actions are simple objects, you can serialize data that includes them with standard Yaml serialization methods. Stochastic games agent indexing by int Previously, agents in a stochastic game were identified by a name. This formulation led to more book keeping because you may have needed to ensure that your state representation was compatible with the names of the agents selecting actions. It also required duplication of existing data structures. For example, there needed to be special agent-wise action interfaces that kept track of their name and state generators that were dependent on the names of the agents being used. In BURLAP 3, agents are primarily identified by their int index in the set of agents in the game with an agent name only providing descriptive information. That means that joint actions now consist of a list of regular Action objects, and you select an agents action by the index of the agent in that list. Similarly, a joint reward return is a double array with each entry being the reward for each agent in the game. License change to Apache 2.0 Previously, BURALP was licensed under LGPL 3, but we have changed licenses to the more permissive Apache 2.0 license. In short, this change allows you to create modified versions of BURLAP and license your changes under a different license. February 26, 2016 Changes to BURLAP Master BURLAP master and the pre-compiled jar files have been updated with some changes, one of which may require some very minor changes to your code. The primary changes of note consist of 1 a new set of interfaces for general function approximation and 2 a new experiment shell for interactively controlling experiments at runtime. If you need to get the prior version of BURLAP, you can get it from the v2 branch on github. Function approximation BURLAP has always supported function approximation for various algorithms. However, for standard value function approximation, there was often a notational an implementation slant toward linear function approximation, even though it could in principle support non-linear function approximation. This slant also made it less clear how to implement your own non-linear function approximators. At a high-level there is an interface named ParametricFunction that is used to provide general interfaces for getting and setting parameter values of the function. Common interface extensions include interfaces for parametric state and state-action value functions ParametricStateFunction and ParametricStateActionFunction .Furthermore, inverse reinforcement learning parameterized reward functions also extend ParametricFunction to unify how you work these two kinds of objects. There, there are also interface extensions for parametric functions that are differentiable DifferentiableStateValue , DifferentiableStateActionValue , DifferentiableRF , etc.. These interfaces include a method that allows the gradient, with respect to the function parameters, to be returned. Gradients are provided via the interface FunctionGradient . This interface allows the retrieval and storing of partial derivatives for each parameter and also allows a list of the non-zero partial derivatives to be returned. Currently there is one concrete implementation of FunctionGradient SparseGradient which only stores the gradient for parameters with non-zero partial derivatives with a Java hash map. This sparse data structure is especially for convenient for function approximation like tile coding. However, in principle you can implement your own FunctionGradient data structures for your own differentiable ParametricFunctions if there is a data structure that is more efficient for your needs. With these more simple interfaces, hopefully it is more clear how to implement your own custom forms of function approximation. All the previous function approximation methods in BURLAP have been converted to this new interface. Because of that conversion, in previous client code you may have developed, there shouldnt be much changes other the names of the data types. That is, Whereas before you may have had a ValueFunctionApproximtion object, it is now probably DifferentiableStateActionValue. Correspondingly, the tutorial code has been updated to reflect these changes. Shell The next change is more of an additional tool to BURLAP a framework for setting up an interactive shell that you can use to control your experiments at runtime. Note that this shell does not provide arbitrary java code execution. Instead its more similar to a light weight bash for BURLAP. At a high-level there is a class called BurlapShell that takes as input an input stream and output stream on which the shell will operate. The shell is then started with the method start which runs the shell in a separate thread, which begins an input output sequence. The shell has some basic universal commands that allow you to do things like set aliases for commands. There are two primary subclasses for this shell, EnvironmentShell and SGWorldShell . The former is a shell that contains a reference to an Environment instance so that you can perform various controls with an environment and comes with a number of standard commands for interacting with an environment such as executing actions, recording episodes, visualizing episodes, etc.. Analogously, the SGWorldShell contains a reference to a stochastic games World and has various similar commands for interacting with it. Although the EnvironmentShell and SGWorld Shell come with many convenient commands you can use for these cases, any BurlapShell can be extended by giving it your own implementations of the interface ShellCommand . Being able to extend the commands allows you to create your own experiment specific controllers. Most of the existing commands make use of the JOptSimple library so that they handle standard formats for command line arguments, and you may want to make use of it as well for your own custom commands. Its is also worth noting that the TerminalExplorer class is now just a wrapper for an EnvironmentShell that is initialized on the the standard input and output streams. Similarly for SGTerminalExplorer. The console that is accessible from a VisualExplorer or SGVisualExplorer now also makes use of the corresponding EnvironmentShell or SGWorldShell using a output and input stream from GUI elements. This inclusion allows you to have a lot of control over an experiment while its being visualized. Currently the shell framework does not support conditionals or looping mechanisms, but we may add these capabilities in a future version. September 19, 2015 BURLAP version 2 is live In the last update, we mentioned that BURLAP would be getting some more significant changes that turned the State class into an interface so that it opened the door for custom implementations for domains that needed more specific memory management. Since then we also began to implement a number of other changes that taken together are sufficient enough to be a new version since they may require some code changes by users. These changes make BURLAP in many cases easier to use, more flexible, and in some cases faster. BURLAP version 1 is still available for download, both the pre-compiled JAR and the source code in the github which is on branch v1, but from now on, master will point to version 2. All tutorials have also been updated to reflect the changes in BURLAP 2 and also received some other tuning, but the version 1 tutorials are also still available. In the remainder of this update we will review some of the main highlights of the changes in BURLAP 2. Most Significant Changes State interface As discussed in the previous update, the State class has now become an interface. Most of the domains in BURLAP will make use of the MutableState implementation, which is the same kind of implementation BURLAP version 1 used. However, by making State an interface, it opens the door for domain-specific memory optimization in which you can implement your own State class specific for your domain and even provide methods that are useful for quickly retrieving information. Environment interface Although an Environment class was included in the previous version of BURLAP, it was auxiliary for very specific purposes and did not strongly integrate with the rest of the BURLAP tools. Environment is now a central interface in BURLAP and used by many classes. The Environment interface provides methods for getting observations and rewards from some environment and receiving actions from an agent. There is also a standard SimulatedEnvironment class for using BURLAP domains to simulate the environment. The Environment interface is now integrated into other BURLAP tools in a variety of ways. First, learning algorithms that implement the LearningAgent interface now all learn by interacting with the Environment. This change removes the burden of current state book keep from the learning algorithm moreover, it provides state safety in that the learning algorithms cannot accidentally change what the state or outcome of the Environment is and are forced to take it as it comes. This is particularly useful for model-based RL algorithms in which a separate modeled domain is learned in which planning is performed. When the agent executes an action selected from the learned model policy in an environment, there is no confusion over whether its executed the model of the action or actually executing the action in the world, because it will be executing the action through the Environment interface when it need to apply it in the world. Second, Policy objects can now be trivially rolled out in an Environment. This paradigm is useful for using BURLAP with robotics or other external systems, since you can build a model in BURLAP, produce a policy with that model, and then roll that policy out in the external worldsystem by rolling it out in an Environment that interfaces with the external worldsystem. For example, the burlaprosbrige extension provides an Environment implementation that interfaces with ROS so that you can have a BURLAP policy control a ROS robot by rolling out the policy in the Environment. Third, the VisualExplorer and TerminalExplorer now operate on Environment implementations, which means you can use them to manually control external systems that are interfaced with an Environment. Action organization The Action, GroundedAction, and the stochastic games equivalents have been a refactored. In the previous version of BURLAP, many of the critical methods of the Action class took as a method argument a String array that was used for specifying parameters. By default, these parameters were considered to be STRIPs-like OO-MDP object references, and although other kinds of parameters could be used, it was a hacky implementation. In the new version of BURLAP, Action methods now take a GroundedAction as an argument, instead of a String array. The motivation is that if you have a special of kind of action parameterization you would like to use, you can subclass GroundedAction to contain whatever kind of data structures you want to specify any kind of parameters that you want. For example, it would now be trivial to implement continuous valued parameterized actions. Along with that, two of the methods that you must implement for the Action class are used to generate your instances of GroundedAction. This way, planning and learning algorithms never need to know about your parameterization types they simply ask your Action definition to generate the permissible parameterizations and hand them back to your appropriate methods when they want to execute them or query the transition dynamics. Along with these changes, all Action methods that are used to define an Action are all now abstract so its entirely clear what would be expected of you to define an Action. However, if you simply want to define parameter-less actions without any preconditions, you can always just subclass the SimpleAction class which will implement those details for you. Similar changes were made for the stochastic games classes. POMDP support added BURLAP now has support for POMDP problem definitions. Currently the space of implemented solvers is limited there is a Belief MDP conversion tool so that you use standard MDP algorithms to solve the POMDP an exact finite horizon solver, by using the Belief MDP conversion with Sparse Sampling and QMDP. However, other algorithms are currently being implemented, including POMCP and PBVI, which will hopefully be available soon. Less Significant Changes StateHashFactoryStateHashTuple - HashableStateFactoryHashableState and revised For the most part there has merely been a renaming of the StateHashFactoryStateHashTuple to HashableStateFactoryHashableState however, the code for these classes have been significantly streamlined with better support. When in doubt, you can simply use the SimpleHashableStateFactory implementation, which has much better support and which other implementations for state abstraction or value discretization extend. StateParser deprecated for Java bean serialization The StateParser in version 1 was used for serializing State objects by allowing them to be turned to and from String representations. Although the code is still there, it is now in a legacy package and should not be used going forward. Instead, it is recommended that you use the SerializableState and SerializableStateFactory classes if at all. A SerializableState is a Java Bean class representation of a state that can be trivially serialized using any number of standard Java serialization methods as well as providing a method for turning it back into a standard State, such as JSON or YAML. There is a standard serialization class called SimpleSerializableState that in general you can always use. In fact, now when you write an EpisodeAnalysis file to disk, it saves it in a YAML format and by default uses the SimpleSerializableState so that you never have to think about it. However, you can also always pass it a more compact SerializableState representations through the SerializableStateFactory if youre looking to keep your files compressed. Domains that previously had their own StateParser implementations now have corresponding SerializableStateFactory classes that you can use instead though in general, you dont really need to think about state serialization anymore. Package and class name refactoring, as well as class hierarchy refactoring The class names and organization for a number of classes has changed. For example, OOMDPPlanner is now simply MDPSolver, which inherits from an MDPSolverInterface interface. The new Planner interface extends MDPSolverInterface, giving it the planFromState method, which now also returns a policy so that you dont have to think about what Policy to wrap around your planning algorithm. Similarly, the QComputablePlanner interface is now simply QFunction and it extends a ValueFunction interface. Other minor reorganization changes also exist. If you are migrating your code, many of the changes may simply require using different imports and changing the name of some elements. However, it may be worthwhile to rescan the updated tutorials to see how things have changed. Additionally, all tutorial code on the website has been included in the main distribution under the package burlap.tutorials. May 29, 2015 The latest version of BURLAP has had various changes. Most changes will be transparent or are feature additions. For example, domains for BlockDude and Frostbite have been added, and terminal explorers now accept console commandsfor directly modifying states, similar to what you will find in the VisualExplorerconsole. However, there is one change that may require some small changes to yourcode. Specifically, all domains DomainGenerators can have their physicsmodel parameters modified to generate a new domain, without affecting the behavior of previously generated domains from the same DomainGenerator instance. For many domains, like MountainCar, InvertedPendulum, LunarLander, etc., this change wasimplemented by storing all physics parameters in a data member called physParams.physParams has public data members for each physics parameter that was normally part ofits corresponding DomainGenerator, so if you have code that changes a physics parameter, you will now need to reference it from the physParams data member. Note that physParams gets fully copied whenever generateDomain is called so that future changes will not affect previously generated domains. Along with embedding physicsmodel parameters inside a single object that is copied, the MountainCar ClassicMCTF class is now a static class. To see how these changes affect code, see the Solving a Continuous Domain Tutorial which has had its code updated to reflect the changes. Also be sure to examine the Java doc for each DomainGenerator you are using. Finally, we are planning a fairly significant change to BURLAPs statedefinitions. Currently, State is a mutable class for defining OO-MDP states with alist of ObjectInstance objects that are also hash-indexed by their name. Although this works fine for many domains, we have found that more complex domains we are investigating would benefit from different state memory management and indexing methods. Therefore, we are planning on changing Stateto become an interface with the current State being a standard implementation that is available. This will enable users freedom to optimize their state definitions for the needs of their domain, providing increased CPU performance and reduced memory usage. If you would like to track the progress of this work, see the stateinterface branch on git. Once that branch is fully developed, we willbranch the current version of master to something else so its always there and then pull stateinterface into master. If you have comments about this new direction, please share them on the BURLAP google group .", "metadata": {"last_modified": "2016-06-20T16:16:02+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["June 17, 2016", "BURLAP 3 is Here!", "February 26, 2016", "Changes to BURLAP Master", "September 19, 2015", "BURLAP version 2 is live!", "Most Significant Changes", "Less Significant Changes", "May 29, 2015"], "word_count": 3845, "token_count_estimate": 4686}}, "http://caps.cs.brown.edu": {"text_content": "CAPS Brown Cryptography Anonymity Privacy Security CAPS", "metadata": {"last_modified": "2022-06-08T17:33:33+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["CAPS @ Brown"], "word_count": 7, "token_count_estimate": 12}}, "https://cc2007.cs.brown.edu/": {"text_content": "CC 2007 16th International Conference on C ompiler C onstruction A member conference of ETAPS 2007 March 26-30, 2007 Braga, Portugal Program CC is on March 26-27 . People Invited Speakers The CC invited speaker is Don Batory .Additionally, there are two ETAPS invited speakersRance Cleaveland and Bertrand Meyer. Program Chairs Shriram Krishnamurthi , Brown University Martin Odersky , Ecole Polytechnique Fdrale de Lausanne Program Committee Eric Allen , Sun Microsystems, Inc. Emery Berger , University of Massachusetts Amherst Rastislav Bodik , University of California, Berkeley William Cook , University of Texas at Austin Chen Ding , University of Rochester Sabine Glesner , Technical University of Berlin Dan Grossman , University of Washington Rajiv Gupta , University of Arizona Andrew Kennedy , Microsoft Research Cambridge Christian Lengauer , University of Passau Cristina Videira Lopes , University of California, Irvine Todd Millstein , University of California, Los Angeles G. Ramalingam , Microsoft Research India Vijay Saraswat , IBM TJ Watson Research Center Zhong Shao , Yale University Yannis Smaragdakis ,University of Oregon Gregor Snelting , University of Passau Joost Visser , Universidade do Minho Reinhard Wilhelm , Saarland University Archival Information Call for Papers CC is interested in work on processing programs in the most generalsense analyzing, transforming or executing input that describes how asystem operates, including traditional compiler construction as aspecial case. Topics of interest include, but are not limited to compilation and interpretation techniques , includingprogram representation and analysis, code generation and codeoptimization run-time techniques , including memory management anddynamic and just-in-time compilation programming tools , from refactoring editors tocheckers to compilers to virtual machines to debuggers techniques for specific domains , such as secure,parallel, distributed, embedded or mobile environments design of novel language constructs and theirimplementation The proceedings are published in the Springer LNCS series.Please follow their instructions for manuscript preparation. If you have questions about the suitability of a submission, pleasedont hesitate to contact the program chairs Submission Types CC accepts both research papers and tool demonstration papers. Research papers cover one or more of the topicsabove, including reports on tool development and case studies thatfocus on scientific contributions. All such papers should clearlystate the problem under study, propose a solution, and evaluate thesolution. Tool demonstration papers focus on noveland useful tools. Both types of contributions will appear in theproceedings and have oral presentations during the conference. Bothwill be evaluated by the CC Program Committee. All papers must be in English present original work that is unpublished and has not submittedelsewhere conferences or journals, including other ETAPSvenues be prepared using the Springer-Verlag LNCS style come in PDF format viewable and printable by Acrobat Reader be submitted in full by the date given below Research papers can use a maximum of 15 fifteenpages, including figures, bibliography, and appendices. Tool Demonstration papers must consist of two parts The first part, at most 4 four pages, should describe thetool. Please include the URL of the tool if available and provideinformation that illustrates the maturity and robustness of the tool.This part will be included in the proceedings. The second part, at most 6 six pages, should explain how thedemonstration will be carried out and what it will show, includingscreen dumps and examples. This part will be not be included in theproceedings, but will be evaluated for acceptance. Submissions that deviate from these parameters will be rejectedwithout review. Dates Submissions due October 13 , 2006 Acceptance notification December 8, 2006 Camera-ready papers due January 5, 2007 CC conference TBD between March 26 and 30, 2007 The submission deadline is strict . We will notgrant any extensions.", "metadata": {"last_modified": "2007-02-26T22:03:21+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": [], "word_count": 594, "token_count_estimate": 802}}, "https://blog.cs.brown.edu/2020/12/11/diverse-career-paths-brown-cs-alum-karen-smith-catlin-helps-build-better-allies/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Diverse Career Paths Brown CS Alum Karen Smith Catlin Helps Build Better Allies Posted by Jesse Polhemus on Dec. 11, 2020 in Diversity Click the links that follow for more news about Karen Smith Catlin , recent accomplishments by Brown CS alums , and their diverse career paths . Something about Brown CS influenced me, says alum Karen Smith Catlin, whose distinctive career path has taken her from working at Browns Institute for Research in Information and Scholarship IRIS to Vice-President of Engineering at Adobe to a new phase as acclaimed author and speaker on inclusive workspaces. Its a fearlessness and an idealism that says, If not us, then who Lets get this done. When you graduate with a CS degree from Brown , nobody can take that credibility away from you. That opened a lot of doors for me. So much of Karens career has focused on mentorship and positive connection between people that her advice to students looking for a more unusual career may come as no surprise Reach out to the people you might want to talk to Get their insight and think about different product spaces, different applications of technology. Be curious. Learn about possibilities. Brown was the only institution that Karen, a self-described crafter and maker who was good at math and loved puzzles, applied to after high school. She took on a CS concentration with no prior computing experience whatsoever. My father had been hearing a lot about computer science and thought Id enjoy it, she remembers. It seemed like fun and I thought itd allow me to support myself. I came from modest means, so that was important. Starting out with what was Professor Andy van Dams CS 11 at the time now CSCI 0150 , Karen hadnt expected to be enthralled The community was amazing. It was hard, and I struggled, but I loved it. When Andy began devoting more of his time to educational computing, Karen became one of the first developers for the Brown ALgorithm Simulator and Animator BALSA, a cutting-edge electronic classroom, running software that demonstrated introductory concepts. Educational software became a passion, and she used a group independent study program with Elisabeth Waymire and Janine Roeth to create a new seminar class. It was the first of its kind, Karen says, an entire curriculum around educational software with readings, guest speakers, and design projects. What thrilled me was that other students continued the Educational Software Seminar for more than a decade after we graduated just a great leveling-up of collective knowledge. In her last summer before graduating, Karen continued her interest in applied research with a job at IRIS, a new group at Brown that focused on hypertext and combining object-oriented programming with modern user interface technology. This was long before todays browsers, she says, and it makes me happy that our work had an influence on HTML and the Internet that followed. Happy to be coding for a living, she signed on full-time with IRIS after graduating and stayed with the organization for a half-decade. Was all of this something that shed anticipated I never had a five-year plan, Karen says. The landscape changes so frequently five, ten, and let alone 35 years ago, many of us couldnt have predicted the careers we have now. My best advice is to make sure your work aligns with your values. Stay agile while following your interests. Eventually, an economic downturn caused a funding shortage for IRIS, and Karen and her husband moved to England, where hed grown up. But it felt like a move to the service sector after years of doing cutting-edge research, and Karen put California in her sights. It was 1991, and Silicon Valley was the absolute center of the technology world. She found a job at GO Corporation, a pen-based computing pioneer whose OS predated even Apples early Newton tablet by two years. At that point, Karen admits, I was intimidated by the myth of Silicon Valley engineers. Even with my strong background in advanced object-oriented programming from Brown, I had impostor syndrome. Instead of creating apps, she took a job writing documentation on how to create them, writing sample code. A few years later, a startup called Macromedia beckoned, and Karen began working in their localization department. It was project management at its finest, she says, and she built a reputation for being someone who partners well with different project teams, eventually founding their usability testing and product security groups. When Macromedia was bought by Adobe, she continued to move up the ranks, ending up as Vice-President of Engineering. It was during her Adobe days that Karen first attended the Grace Hopper Celebration of Women in Computing. It was still small then, she remembers, but I wish Id been involved years before. She returned to work with new energy, quickly founding a womens employee resource group at Adobe, where she helped equip women for career success. Mentorship quickly became a new love. Its what truly made her happy, Karen says, more than her ascent to the top echelons of the company. And so she did a career pivot and started a business as a leadership coach. I left tech, she says, but not innovation, not that mindset. Instead of building software myself, I wanted to help women who are doing it. I still feel that way today. But she soon realized that there was a problem companies that thought of themselves as meritocracies really werent, and her role as coach didnt feel like enough. Reform was needed to bring about real inclusivity, and as Karen contemplated her next step, she settled on the word allies to reflect a new trend of men taking action in support of diversity. Her initial focus was on male allies, but when she found that a hoped-for Twitter handle had already been taken, she realized that BetterAllies was a superior choice, and the Better Allies Initiative was born Its not just something that men can do anyone with privilege and power can use it on behalf of others. For example, as a white woman I can help Black women, and as a straight woman I can advocate for LGBTQ-friendly policies. The initial premise of the Better Allies Initiative was to share everyday actions that anyone could take to be a better ally for someone in a historically underrepresented group HUG. It proved popular, and public speaking requests began flowing in. And almost every time I spoke, Karen says, someone in the audience would ask if I had a book, because they wanted more. She published Better Allies Everyday Actions to Create Inclusive, Engaging Workplaces in 2019 a second edition is due out in January and a companion volume, The Better Allies Approach to Hiring , followed a year later. Two years later, the work continues. Asked for her latest thoughts on how our field can improve gender diversity, Karen cites the importance of expectations. When parents buy toys or send kids to summer camp, she says, theyre making decisions on their childs behalf, and I dont think my daughter would like to code might be one of them. As parents, we can do more we can tell our young women to try tech on for size. There are also societal expectations about what girls should be good at. In Turkey, female computer scientists outnumber the men. Why cant that be us But given the events of 2020, is she still hopeful for societal change Theres a shift toward equity and social justice that Im optimistic about, Karen says. Whatever the area, Im seeing an appetite for individuals wanting to take action in a way that wasnt there years ago. In tech, some of this is because men are finally listening to all the stories of discrimination that have been shared. Anti-racism books are at the top of the bestseller lists, and people are voting in record numbers. But theyre saying that diversity and inclusion statements arent enough. Were all demanding to see results, the impact. As we start to wrap up, Karen lights upon an unexpected topic that ties together multiple threads of her work and life. I firmly believe, she says, that public speaking is a multivitamin for any career. My first exposure to it was as a UTA, getting up in front of a class. I started my career writing code, and on my way to becoming a VP, I got the stage fright that most people get. Later, I was told that the best way to start a coaching business was to go out and talk from your own experience, so I started doing a lot of public speaking, even though I hated it. But when you get comfortable talking to others, says Karen, you get visibility for what you do that could otherwise get missed. One of the reasons I wrote my book Present A Techies Guide to Public Speaking was to help everyone improve their public speaking skills and to make sure that women and people from HUGs are getting the information that I got. I want them to be onstage, getting the visibility they deserve, so we can keep disrupting the stereotypes about who belongs in our industry. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "Diverse Career Paths: Brown CS Alum Karen Smith Catlin Helps Build Better Allies"], "word_count": 1569, "token_count_estimate": 1849}}, "https://blog.cs.brown.edu/2024/02/02/more-100-brown-cs-utas-start-semester-dodgeball-tournament/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles Brown CS UTAs Start The Semester With A Dodgeball Tournament Posted by Jesse Polhemus on Feb. 2, 2024 At Brown CS , the undergraduate teaching assistant UTA program is unlike any other. It employs more than 400 undergraduates each semester, and each of these students is given the chance to effect change, working closely with the professor, other UTAs, and other students. Last month, when this semesters UTAs returned to campus for TA Camp, which helps prepare them for their work ahead, the Meta TAs who supervise the program held a dodgeball tournament. More than 100 UTAs took part. It was a really fun way to give the UTAs an opportunity to get some energy out while working hard during camp says Meta TA Tyler Gurth, I think the competition demonstratres a lot of the energy, positivity, and fun in the UTA program. At the end of the tournament, the staff of CSCI 0220 Discrete Structures and Probability was declared the winners. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "Brown CS UTAs Start The Semester With A Dodgeball Tournament"], "word_count": 196, "token_count_estimate": 249}}, "https://ccmb.brown.edu/": {"text_content": "Skip to Main Content Brown University Data Science Insitute Center for Computational Molecular Biology Search Menu Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News Events Software CCMBs 20th Anniversary SorinFest Search Data Science Insitute Center for Computational Molecular Biology CCMB Celebrating 20 years of promoting the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences CCMB Celebrating 20 years of promoting the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences The prime intellectual mission is to promote the development, implementation, and application of analytical and computational methods to foundational questions in the biological and medical sciences. The research programs of the Core Faculty in CCMB lie fundamentally at the intersection of computer science, evolutionary biology, mathematics, and molecular and cellular biology. Biological questions Biological questions that currently unite the CCMB Core and Associate Faculty are How do genotypes and genes interact to produce phenotypes, and how does this happen from womb to tomb What drives the formation, maintenance and evolutionary transformations of communities of organisms over time Quantitative questions that currently unite the CCMB faculty are how can we design powerful algorithms to make sense of the sea of data produced in the genomic era What principles are required for a theoretical framework to completely model cellular systems Research challenges The research challenges at the heart of CCMB are a rich source of mathematical problems motivated by the complex nature of genomes, disease processes and evolutionary relationships. These challenges are both multi-scale with units of interest ranging from molecules to communities of organisms and large-scale data-intensive, due to advances in sequencing technologies. Explore CCMB Undergraduate Program Visit Page Open details for Undergraduate Program Graduate The Center for Computational Molecular Biology CCMB offers Ph.D. degrees in Computational Biology to train the next generation of scientists to perform cutting-edge research in the multidisciplinary field of Computational Biology. Visit Page Open details for Graduate Contact Administration Contact information, mailing address and directions. Visit Page Open details for Contact amp Administration NIH Graduate Training Program The Predoctoral Training Program T32 in Biological Data Science is funded by the National Institutes of HealthNIGMS award T32GM128596 Visit Page Open details for NIH Graduate Training Program Partnering CCMB rounds out the broader landscape of research in methodological development at Brown University by partnering with and complementing Data Science Institute Brown Center for Biomedical Informatics COBRE Center for the Computational Biology of Human Disease httpswww.youtube.comembedp3zBdW-ENtU Ph.D. program in Computational Biology Stay Connected XTwitter Brown University Providence RI 02912 401-863-1000 Quick Navigation Visit Brown Campus Map A to Z Contact Us Footer Navigation News Events Campus Safety Accessibility Careers at Brown The campaign for building on distinction Give To Brown Brown University Brown University For You Search Menu Mobile Site Navigation Mobile Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News Events Software CCMBs 20th Anniversary SorinFest This Site Only All of Brown.edu People Search Search people Advanced Search Search Close Search CCMB Open details for CCMB Bookmark this Page", "metadata": {"last_modified": "2024-03-13T16:41:00+00:00", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["", "", "", "", "Site Navigation", "CCMB", "CCMB", "Biological questions", "Research challenges", "Explore CCMB", "Partnering", "Stay Connected", "Quick Navigation", "Footer Navigation", "Mobile Site Navigation", "Mobile Site Navigation"], "word_count": 563, "token_count_estimate": 693}}, "https://blog.cs.brown.edu/2024/02/27/the-computer-history-museums-40th-anniversary-celebration-of-the-macintosh-includes-a-shoutout-to-brown-cs/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles The Computer History Museums 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS Posted by Jesse Polhemus on Feb. 27, 2024 by Norm Meyrowitz 81 On January 24 of 2024, I attended the Computer History Museum CHMs huge celebration in Silicon Valley for the 40th anniversary of the launch of the Apple Macintosh, where Brown CS got a shoutout during the two-hour program. Why would that be I thought it would be interesting to those who werent around to learn about how universities Brown in particular were instrumental to the success of the computer that many now take for granted. Today, virtually all of Browns current undergraduates and a good number of current faculty and staff dont think twice about the introduction of personal computers, especially Macintoshes, any more than they think about the invention of televisions or microwave ovens they just have always been around. Contrast that to faculty, staff, and alums who were at Brown more than 40 years ago, who inhabited a world where Macintoshes did not yet exist and a campus where most computing was done through dumb terminals dialed into the campus mainframe. On January 24, 1984, that changed. Apple introduced the first mass-market personal computer with a graphical user interface. For most of the world, it was astonishing. It had a mouse, which virtually no one had seen or even heard of. Most other personal computers of the time had screens that only printed characters in a matrix of 24 lines of 80 characters each, while the Macintosh allowed one to draw graphics at a resolution of 512 x 342. Apple did not have the ironclad security we dont tell anyone anything before launch policy they have today they often gave sneak peeks of future products in advance of launch. Danl Lewin, the Sales and Market Development Manager for the Macintosh and Mike Murray, its Vice-President of Marketing, explained to the audience at the CHM celebration that they first sneaked to the Mac to New York City business executives in a formal focus group. How did it work First, the execs used their familiar IBM PCs and then were given a pre-launch Mac to try. The hardened business people started giggling at how much fun they were having. To wrap up, a focus group leader asked them which was easier to use Mac. Which was more productive Mac Which was more effective Mac What will you recommend your purchasing department buy IBM PCs. Danl and his colleagues realized that the product was going to fail if they relied on big corporations to be early adopters. They had noticed when they tested the Mac on friends and family that those who were creative and artistic were captivated by what they could do with it. So where did Danl and colleagues go to find a concentration of those types of folks Universities So in the fall of 1983, Andy van Dam, the late Bill Shipp Associate Provost of Computing, Tom Doeppner, Provost Maurice Glicksman, and I and a few others that cant be recalled were some of the lucky few who got to take an early look at the Mac in all of its original 128 K yes, K of RAM splendor. This didnt involve flying out to Cupertino. This involved three folks from Apple Andy Hertzfeld 75 referred to as AndyH henceforth, one of the key members of the Mac development team and former student of Andys, Danl, and none other than Steve Jobs himself . Why was this visit important enough for Steve Jobs to visit Brown was one of the three schools that were widely known as leaders in putting computers and networks across the campus the other two were Carnegie Mellon University and Massachusetts Institute of Technology. Andy had a reputation for his work in graphics, so Steve thought it would be a trip worth taking Brown was the only school he visited. Brown CS had a lab full of Apollo workstations with bitmap screens and a much less polished interface than the Mac and cost 35,000 110,000 today. The Brown folks who saw the sneak peek of the Macintosh that day were uniformly blown away by the price 2,495 - 7,000 in todays dollars and functionality even though they had seen Xerox PARC Alto workstations and their successors, so they knew what state-of-the-art WIMP windows, icons, mouse, pointer interfaces looked like. And Universities would get a discount off the Mac list price In true Andy style, after singing the praises of the Mac, he told Steve that the machine wouldnt be useful without a hard disk or network. The original Mac had just a single drive for a 400 KB yup, thats K again removable diskette. Part of the system software and some apps were on the diskette, so if you wanted to use an app or store documents on another disk, the current disk would be ejected so you could put the other one in. When the operating system needed more code to continue running, that disk was ejected so you could put the system disk back. This sometimes led to absurd situations similar to thrashing in virtual memory you would pop one disk in and it would be used for 5 seconds, then ejected so you could put the other disk in for 5 seconds, and then that was ejected, ad infinitum. Andy called this milking, since it appeared that one was treating the Mac like a cow, albeit one lying on its side. As one might expect, Steve preferred praise to criticism. He and Andy went back and forth, with Steve saying something to the effect of people dont need a network, theyll just pass diskettes back and forth SneakerNet is just fine. Lo and behold, Apple soon came out with a hard disk and a network. AndyH told me that the network hardware had already been completed before Andy and Steve had their tete-a-tete, but the software wasnt ready at launch, so Steve pooh-poohed the entire notion of networks. Steve had a habit of dismissing anything Apple didnt yet have as stupid or useless. After my time at Brown, in a meeting Macromedia had with Steve when the touch-screen iPod came out but before touch-based phones, I said to him, You should make this into a phone. Steve replied that Apple would never, ever, ever make a phone, that the carriers were just too hard to deal with. The iPhone launched soon after, so either he changed his mind and had the fastest hardware and software development in history or it was already in process. After the meeting, the Provost took Andy aside and said he had never seen two people go at it as vehemently as Andy and Steve. Andy told him not to worry, that they were both enjoying it. Soon, Danl and his crew formally created the Apple University Consortium, a group of 24 schools that would be the key to the Macs initial success, with Brown amongst the first. Those schools all pledged that they would buy 2M worth of Macs over three years. Andy, Bill, and I went about getting approval from Howard Swearer, Browns President at the time, to start an effort that would put computers across campus Macs and IBM workstations and raising 15M to make it happen. President Swearer signed off on the 2M deal with Danl. Both Swearer and Danl were Princeton grads, and Swearer said that since he was a Princeton man with Brown furniture, then Danl should have the same, and the President sent Danl a Brown-crested spindle chair that he still has. Today, it seems incomprehensible that there was a point in time when nobody had a Mac, but without the help of Brown and other universities, the Macintosh might not still exist. Brown CSs pre-introduction support of the Macintosh was important and memorable enough that it was called out in particular during a two-hour 40th anniversary celebration that included most of the original Mac team and hundreds of other industry and press luminaries. So, the next time youre using your MacBook Pro or iMac, remember that youre part of the lineage that helped move the Macintosh from obscurity to ubiquity.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "The Computer History Museum\u2019s 40th Anniversary Celebration Of The Macintosh Includes A Shoutout To Brown CS"], "word_count": 1384, "token_count_estimate": 1678}}, "https://blog.cs.brown.edu/2024/02/01/brown-daily-herald-meets-csci-0150s-new-ai-powered-chatbot-teaching-assistant/": {"text_content": "Brown CS Blog Categories Awards 23 articles Diversity 72 articles Socially Responsible Computing 17 articles The Brown Daily Herald Meets CSCI 0150s New AI-Powered Chatbot Teaching Assistant Posted by Jesse Polhemus on Feb. 1, 2024 Click the links that follow for more news about CSCI 0150 , Andy van Dam , our Undergraduate Teaching Assistants UTAs, and other recent accomplishments by our faculty and students . If you dont know the fundamentals, says Andy van Dam , Thomas J. Watson, Jr. University Professor of Technology and Education and Professor of Computer Science at Brown University , you cant debug what the generative AI produces. In a new article by Leah Koritz, The Brown Daily Herald interviews Andy and CSCI 0150 Introduction to Object-Oriented Programming and Computer Science UTA Brandon Diaz about their decision to create GPTA, a chatbot teaching assistant for the course. The full story is available here . For more information, click the following link to contact Brown CS Communications Manager Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Brown CS Blog", "The Brown Daily Herald Meets CSCI 0150's New AI-Powered Chatbot Teaching Assistant"], "word_count": 167, "token_count_estimate": 217}}, "https://ccmb.brown.edu/software": {"text_content": "Skip to Main Content Brown University Data Science Insitute Center for Computational Molecular Biology Search Menu Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News Events Software CCMBs 20th Anniversary SorinFest Search Data Science Insitute Center for Computational Molecular Biology Software Software CCMB Research is interdisciplinary involving interactions between faculty, students, and postdoctoral researchers in multiple participating departments. Several of the research groups develop software for biomedical researchers. Themes Algorithms, Statistics, Computation RNA Biology Epigenetics Evolutionary Ecological Genomics Genomics of Human Disease Labs Crawford Lab - Marginal Epistasis Test Fairbrother Lab - Spliceman Istrail Lab Lawrence Lab Raphael Lab Brown University Providence RI 02912 401-863-1000 Quick Navigation Visit Brown Campus Map A to Z Contact Us Footer Navigation News Events Campus Safety Accessibility Careers at Brown The campaign for building on distinction Give To Brown Brown University Brown University For You Search Menu Mobile Site Navigation Mobile Site Navigation Home Academics Graduate Program Undergraduate Program Courses People Contact Administration Core Members Affiliate Members Postdocs Graduate Students Ph.D. Alumni Becoming an Affiliate NIH Graduate Training Program T32 Trainees T32 Faculty Trainers Gallery News Events Software CCMBs 20th Anniversary SorinFest This Site Only All of Brown.edu People Search Search people Advanced Search Search Close Search Software Open details for Software Bookmark this Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["", "", "", "", "Site Navigation", "Software", "Software", "Themes", "Labs", "Quick Navigation", "Footer Navigation", "Mobile Site Navigation", "Mobile Site Navigation"], "word_count": 237, "token_count_estimate": 309}}, "https://cs.brown.edu/": {"text_content": "Brown CS Students Earn CRA Outstanding Undergraduate Researcher Honors The Telepresence Of Furniture In Extended Reality CHMs 40th Anniversary Celebration For The Macintosh Includes A Brown CS Shoutout Nora Ayanian Will Present Swarming Drones At SXSW 2024 Brown CS PhD Student Eric Ewing Helps Multi-Robot Research Lift Off At Brown And Beyond Introductory Courses Customized for students of all interests Undergraduate Program Numerous opportunities to contribute to research and teaching Masters Programs Computer Science and Cybersecurity degrees PhD Program Strong research with low student-faculty ratios Brown CS Blog Brown Alumni Monthly Looks At Suresh Venkatasubramanians New Course, CSCI 1951-Z Fairness In Automated Decision-Making Diverse Career Paths Brown CS Alum Lisa Gelobter Focuses Her Career On Technology For Equitable Workplaces And Doing Good The Telepresence Of Furniture In Extended Reality Awards Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors John Hughes Ranks In The Top 0.21 Of Stack Exchanges Math Users Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Events Konstantinos Kallas Programmable Software Systems for Correct High-performance Applications Wed, 313 12PM, 368, CIT Computational Infrastructures for Consolidating our Knowledge Regarding the Human Genome Wed, 313 4PM, Rm 302, None Computational Biology Seminar Jie Liu, Ph.D. Wed, 313 4PM, 302, None Brown CS News Brown University Master Of Science In Cybersecurity Alum Bill Marino Is A Fulbright Finalist Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker Nora Ayanian Will Present Swarming Drones At SXSW 2024", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:14+00:00", "headings": ["Information for:", "Introductory Courses", "Undergraduate Program", "Master's Programs", "PhD Program"], "word_count": 257, "token_count_estimate": 366}}, "https://cs.brown.edu/~mlittman/": {"text_content": "Forwarding...", "metadata": {"last_modified": "2020-11-06T22:50:02+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 1, "token_count_estimate": 3}}, "https://cs.brown.edu/~rfonseca/": {"text_content": "Rodrigo Fonseca Top News Teaching Research Students Publications Service Personal email office 329, CIT Building. Office hours by appointment. mail Box 1910, Brown University 115 Waterman St Providence , RI 02912 phone 401-863-6533 voice 401-863-7657 fax DBLP Google Scholar MSFT Academic Search About I am an associate professor at Brown University s Computer Science Department . My work revolves around distributed systems, networking, and operating systems. Broadly, I am interested in understanding the behavior of systems with many components for enabling new functionality, and making sure they work as they should. In particular, Im interested in how to build, operate, and diagnose large scale Internet systems and in networking and power management in embedded distributed systems such as sensor networks. Im updating this page. Take a look at my CV for the authoritative information. News Feb-2020 Im starting as a Principal Researcher at Microsoft Research Nov-2019 Im the General Chair for SoCC2020 Stay tuned. Nov-2019 Was PC co-chair for HotNets 2019 , with Sylvia Ratnasamy. The workshop was a big success May-2019 Congratulations to Dr. Da Yu, PhD 5 Going to Microsoft, to work on Azure Networking. May-2019 Congratulations to Dr. Jeff Rasley, PhD 4 Going to Microsoft, to work on AI Infrastructure at Bing. Jan-2019 Going for an 8-month visit to Microsoft Research in Redmond, WA Oct-2018 New NSF grant Network-centric IoT Security, with Theo Benson May-2018 Congratulations to Dr. Jonathan Mace , PhD 3 He is starting as a tenure track faculty at MPI-SWS Oct-2017 Keynote at The 17th International Conference on Runtime Verification, RV17. Seattle, WA Jul-2017 Now Associate Professor with Tenure Jun-2017 Busy summer Ill be spending the summer in Palo Alto, with Flowtune . Jeff will be at MSR in Seattle, Da at Alibaba, Seattle, and Jon at Facebook in Cambridge Apr-2017 Congratulations to Dr. Marcelo Martins, PhD 2 Mar-2017 NSDI Test of Time Award for X-Trace With George Porter, Ion Stoica, Scott Shenker, and Randy Katz Nov-2016 Switches are Monitors Too presented at HotNets Oct-2016 Raja presented our paper Principled Workflow-centric Tracing of Distributed Systems at SoCC. Aug-2016 Went to Floripa, Brasil for Sigcomm. We had a paper at the main conference, a paper in the Workshop on QoE, and I gave an invited talk at NetPL. May-2016 cDVD, on fair bandwidth allocation for competing DASH video streams, accepted at Internet-QoE 2016 Apr-2016 2DFQ accepted to Sigcomm 2016, which will be in Brazi Apr-2016 Teaching Networking in the Fall Apr-2016 NetEx pdf , our architecture for a network marketplace inside of a datacenter, accepted for HotCloud Feb-2016 Teaching Distributed Systems with Tom Doeppner Jan-2016 Yak, joint work with my student Jeff Rasley and Microsoft, accepted into Eurosys 2016 Oct-2015 Pivot Tracing gets best paper award at SOSP Oct-2015 Presented We are Tracing like its 1973 pptx at the Open Zipkin workshop in San Francisco Sep-2015 Presented We are Losing Tack a Case for Causal Metadata in Distributed Systems at the 16th Asilomar HPTS May-2015 Good Summer looking ahead Jeff and Jonathan will have internships at Microsoft Research, Da will go to HP Labs May-2015 Jonathan will be presenting our work Retro Targeted Resource Management in Multi-tenant Distributed Systems at NSDI 2015 This is join work with Peter Bodik and Madan Musuvathi from Microsoft Research. Apr-2015 Our paper Simon Scriptable Interactive Monitoring for SDNs, accepted at SOSR15 Joint work with Da Yu , Yiming Li, Tim Nelson , and Shriram Krishnamurthi . Apr-2015 Our paper Exodus Toward Automatic Migration of Enterprise Network Configurations to SDNs accepted at SOSR15 Joint work with Tim Nelson , Andrew Ferguson, and Shriram Krishnamurthi . Apr-2015 Marcelo s paper Selectively Taming Background Android Apps to Improve Battery Lifetime accepted at USENIX ATC, joint work with Justin Cappos . Mar-2015 Won an NSF CAREER Award on Understanding the Performance of Distributed Systems Through Causal Tracing Feb-2015 Teaching CS-138 Distributed Systems with Tom Doeppner. Oct-2014 Co-organizing the first New England Networking and Systems Day , Oct 24th, at the Hariri Institute at BU. We will gather more than 90 participants with many talks, posters, and much discussion time. Sep-2014 I recently documented in Portuguese an attack to a bank website in Brazil that got some media attention Sep-2014 The Brown-Brazil Initiative is hosting my former advisor Prof. Virgilio Almeida for the innaugural talk of the Fall Lecture Series. Sep-2014 Our paper Towards General-Purpose Resource Management in Shared Cloud Services with my PhD student Jon Mace , Peter Bodik , and Madan Musuvathi was accepted for publication at HotDep14, the 10th Workshop on Hot Topics in System Dependability Sep-2014 Teaching Computer Networks this fall Aug-2014 Jeff Rasley successfully presented Planck Millisecond-scale Monitoring and Control for Commodity Networks at Sigcomm 2014. Apr-2014 Our paper Planck Millisecond-scale Monitoring and Control for Commodity Networks was accepted for publication at Sigcomm 2014. See you in Chicago Apr-2014 Very proud of my first minted PhD student, Andrew Ferguson . Congrats, Andrew Mar-2014 Jeff Rasley will be interning at VMWare, and Marcelo at Intel. Feb-2014 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Jan-2014 Ill be part of the Program Committees for Sigcomm 2014 and IMC 2014 Dec-2013 Im part of the Program Committee for HotMobile 2014 July-2013 NSF NeTS Grant on Participatory Networking, to advance SDNs northbound APIs July-2013 Our paper Growth Analysis of a Large ISP was accepted at IMC May-2013 Highly successful internship season for students Andrew is going to the SDN group at Google with Amin Vahdat, Jeff is going to IBM Research in Austin with Collin Dixon, Jonathan is going to MSR Redmond with Peter Bodik Apr-2013 We are going to Sigcomm 2013 to present our paper on Participatory Networking Congrats to Andrew Ferguson, Arjun Guha, Chen Liang, and Shriram Krishnamurthi Apr-2013 Chen Liang accepted as a PhD student at Duke University Congrats, Chen Jan-2013 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Dec-2012 Our paper Application Modes accepted for publication at HotMobile 2013 Sep-2012 Big welcome to Jeff Rasley new PhD student, Jonathan Mace new advisee, and Matheus Caldas visiting PhD student from UFMG, Brazil Sep-2012 Teaching CS168, Computer Networks this spring. Jul-2012 Spending the summer at MSR Redmond, with Victor Balhs group Jul-2012 Our paper PARMA A Parallel Randomized Algorithm for Approximate Association Rule Mining in MapReduce accepted at CIKM 2012 Jun-2012 Program Committee Member for NSDI13 May-2012 Our paper Hierarchical Policies for Software Defined Networks accepted for publication at the HotSDN 2012 workshop, co-held with Sigcomm 2012 Apr-2012 Nathans paper C-MR Continuously Executing MapReduce Workflows on Multi-Core Processors accepted for publication at the MAPREDUCE 2012 workshop Apr-2012 Andrew presented Jockey Guaranteed Job Latency in Data Parallel Clusters at Eurosys 2012 . Work with Srikanth Kandula and Peter Bodk from Microsoft Research. Mar-2012 Our paper Participatory Networking accepted for publication at HotICE12 , co-held with NSDI12. Mar-2012 External Review Committee Member for OSDI 2012 Feb-2012 Google funds research on distributed tracing Sep-2011 Teaching CSCI2950-U in Fall 2011, focusing on Large-scale data intensive computing Jul-2011 I will be co-chairing HotClouds12 with Dave Maltz, from MSR May-2011 Solomon Award from Brown University to work on energy managdtent in Wireless Sensor Networks Sep-2010 NSF funds research on security in Cloud Computing . Jun-2010 Program committee for NSDI11 Jun-2010 Intel funds research on Whole-platform Energy Usage of Software Activities Jun-2010 Andrews poster on block placdtent in Hadoop accepted at the USENIX ATC May-2010 Teaching CSCI1680 Computer Networks in Spring 2011 May-2010 Teaching CSCI2950-U Special Topics on Networking and Distributed Systdts in Fall 2010 Apr-2010 Experiences with X-Trace paper presented on INMWREN 2010 More... Teaching Fall 2019 CSCI1680 Computer Networks . Previous F16 , F16 , F16 , F14 , F12 , S12 , S11 Spring 2018 CSCI1380 Distributed Systems . Previous S17 S15 Spring 2017 Advanced Networking . Previous S14 - CSCI2950-U Advanced Networking SDNs and Datacenter Networking , S13 , F11 , F10 , F09 Research Projects Participatory Networking The PANE project aims to allow end-user applications to help in the configuration of a network. PANE is both a paradigm and a prototype SDN controller that solves the problem of privilege delegation and conflict resolution when unprivileged users are given read and write access to network services, configuration, and state. Read more... Mobile Device Energy We are interested in improving the battery life of mobile devices. Todays mobile devices need for energy far surpasses their battery capacity to allow for unrestricted use and long battery life. Users must prioritize their usage to avoid running out of battery. However, for a user to do this efficiently is almost impossible it requires knowledge of the energy and power characteristics of the applications and of the hardware components of the particular phone. This leads to a poor experience and to frustration. We propose an OS abstraction, Application Modes, that allow applications and the OS to collaborate in exposing to the user only what she cares about and understands the tradeoff between battery lifetime and functionality. Read our HotMobile paper for an introduction to our approach. Tracing Distributed Systems Distributed systems are growing ever more complex, spanning many layers of abstraction, machines, and administrative domains, and integrating code written, deployed, and operated by different people. In these scenarios it becomes increasingly difficult to understand how a system behaves, and, especially, how and why it fails. Causal tracing is a technique that captures the causality of events across all of these components, layers, and machines, and eases the task of understanding complex distributed systems. There are a multitude of causal tracing systems and frameworks, including many research and industry projects. Examples include our own X-Trace project GitHub , as well as systems such as Googles Dapper, Twitters Zipkin, and Clouderas HTrace. We are interested in how to extract information from both complex individual traces and across traces, to identify root causes of problems, detect unexpected anomalies, and make tracing more efficient, by biasing trace sampling and detail capture to maximize trace information on a fixed performance budget. Older Projects Quanto Fine-grained tracking of energy usage in wireless sensor networks, Quanto determines which applications used how much energy on each hardware component, even for applications that span multiple network nodes. Collection Tree Protocol Robust all-to-few routing in wireless sensor networks, CTP is de-facto routing protocol for TinyOS 2.x, and formed the basis for IETFs RPL Routing over Low Power and lossy networks - RFC 6550 . Beacon Vector Routing BVR is an anchor-based pseudo-geographical any-to-any routing protocol for wireless sensor networks. Students I am really very fortunate to work with an amazing set of students Graduate Students Michael Markovitch PhD Alumni Linnan Wang PhD 2021. Now at NVidia Nicholas DeMarinis PhD 2021. Now at Brown Jeff Rasley - PhD 2019. Now at Microsoft. Da Yu - PhD 2019. Now at ByteDance Jonathan Mace - PhD 2018. Now at MPI-SWS Marcelo Martins - PhD 2017 Sofware Analysis and Development for Energy Effciency in Mobile Devices . Now at Apple. Andrew D. Ferguson - PhD 2014 Policy Delegation and Migration for Software-Defined Networks . Now at Google. Junyang Chen - ScM 2016 George Hongkai Sun - ScM 2016 Wilson Cusack - AB 2016 - Honors Rui Zhou - ScM 2014 Datacenter Network Large Flow Detection and Scheduling from the Edge . Now at Google. Jonathan Leavitt - ScB 2014. Honors Thesis End-to-End Tracing Models Analysis and Unification. Now at Google. Matheus Caldas Visiting PhD from UFMG Chen Liang - ScM 2013, now a PhD student at Duke. ScM Project Software Defined Network Support for Real Distributed Systems Basil Crow - ScM 2012, now at Delphix. Thesis Time and Energy Profiling in Production Sensor Networks with Quanto Sunil Mallya - ScM 2011, co-founder at Neon Labs , now at Amazon. Thesis Entracker Energy Tracker for Homes Jake Eakle ScM 2011, now at Teespring. Sandy Ryza - ScB 2012, now at Cloudera. Honors Thesis Solving Hard Problems with Lots of Computers Walter Blaurock - ScB 2011, now at Next Big Sound. Project Automatic Scaling of Cloud-Based Web Applications Selected Publications All Publications . . , , pp. , In , pp. , , Eds., , , . ISBN . BibTex pdf talk video doi Professional Activities Conference Organization 2015 Co-Organizer, 2nd New England Networking and Systems Day 2014 Co-Organizer, 1st New England Networking and Systems Day Doctoral Symposium, IC2E 2014 2012 Program Co-Chair HotCloud12 Technical Program Committee 2016 Eurosys16, USENIX ATC16, NSDI16, SBRC16 2015 SBRC15, DCOSS15, NSDI15, HotCloud15, DSN15 2014 SIGCOMM14 PC, IMC14 PC, HotMobile 2014, Eurosys14 Ext. Review Committee 2013 NSDI13 PC, TRIOS, SOCC13 2012 OSDI12 Ext. Review Committee, Middleware12, HotDep12, MAD12, IGCC12, DSN12 2011 NSDI11, DSN11, CoNEXT11, HotPower11, HotCloud11, NetDB11 2010 ... Personal You can find some of my photography as 319studio on Instagram, or at 500px . I almost never tweet as rodrigofonseca . My wife Paula runs an amazing party design business, Festiva Party Design , check it out Back to top Template and css from Twitter bootstrap. Publications list automatically generated from BibTeX using Exhibit .", "metadata": {"last_modified": "2022-06-27T23:34:19+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["About", "News", "Teaching", "Research Projects", "Participatory Networking", "Mobile Device Energy", "Tracing Distributed Systems", "Older Projects", "Students", "Graduate Students", "", "Alumni", "", "", "Selected Publications", "Professional Activities", "Personal"], "word_count": 2158, "token_count_estimate": 3248}}, "https://cs.brown.edu/~mph/": {"text_content": "Maurice Herlihy An Wang Professor of Computer Science mphcs.brown.edu CIT 341 Bio Maurice Herlihy has an A.B. in Mathematics from Harvard University, and aPh.D. in Computer Science from M.I.T. He has served on the faculty of CarnegieMellon University and the staff of DEC Cambridge Research Lab. He is therecipient of the 2003 Dijkstra Prize in Distributed Computing, the 2004 GdelPrize in theoretical computer science, the 2008 ISCA influential paper award,the 2012 Edsger W. Dijkstra Prize, and the 2013Wallace McDowell award. He received a 2012 Fulbright Distinguished Chair in theNatural Sciences and Engineering Lecturing Fellowship, and he is fellow of the ACM, a fellow of the National Academy ofInventors, the National Academy of Engineering, and the National Academy ofArts and Sciences. In 2022, he won his third Dijkstra Prize. CV ACM author profile Google Scholar Profile Selected Talks PODC 2017 Keynote Blockchains and the Future of DistributedComputing . Undergraduate course on Blockchains and Cryptocurrencies CS176 MultiprocessorSynchronization 2011course on Combinatorial Topology and Distributed Computing YouTube 2011 FulbrightDistinguished Chair lecture YouTube 2004Gdel Prize lecture slides Books TheArt of Multiprocessor Programming Courseslides DistributedComputing Through Combinatorial Topology Courseslides", "metadata": {"last_modified": "2022-05-02T21:25:29+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 183, "token_count_estimate": 300}}, "https://cs.brown.edu/about/conduit/": {"text_content": "Conduit Conduit is the Brown CS annual magazine, distributed to our extended family of faculty, staff, students, alums, and industry partners. Click any link below to download any issue in Adobe Acrobat format. Current Issue Conduit Volume 33 2023 Back Issues Conduit Volume 32 2022 Conduit Volume 31 2021 Conduit Volume 30 2020 Conduit Volume 29 2019 Conduit Volume 28 2018 Conduit Volume 27 Winter, 2017 Conduit Volume 26 Spring, 2017 Conduit Volume 25 2016 Conduit Volume 24 Spring, 2015 Conduit Volume 23, Number 1 SpringSummer, 2014 Conduit Volume 22, Number 1 SpringSummer, 2013 Conduit Volume 21 Number 2, FallWinter 2013 Conduit Volume 21 Number 1, SpringSummer 2012 Conduit Volume 20 Number 2, FallWinter 2012 Conduit Volume 20 Number 1, SpringSummer 2011 Conduit Volume 19 Number 2, Fall 2010 Conduit Volume 19 Number 1, SpringSummer 2010 Conduit Volume 18 Number 2, FallWinter 2009 Conduit Volume 18 Number 1, SpringSummer 2009 Conduit Volume 17 Number 2, FallWinter 2008 Conduit Volume 17 Number 1, SpringSummer 2008 Conduit Volume 16 Number 2, FallWinter 2007 Conduit Volume 16 Number 1, SpringSummer 2007 Conduit Volume 15 Number 2, FallWinter 2006 Conduit Volume 15 Number 1, Spring 2006 Conduit Volume 14 Number 2, FallWinter 2005 Conduit Volume 14 Number 1, Spring 2005 Conduit Volume 13 Number 1, Summer 2004 Conduit Volume 12 Number 2, Fall 2003 Conduit Volume 12 Number 1, Spring 2003 Conduit Volume 11 Number 2, Fall 2002 Conduit Volume 11 Number 1, Spring 2002 Conduit Volume 10 Number 2, Fall 2001 Conduit Volume 10 Number 1, Spring 2001 Conduit Volume 9 Number 2, Fall 2000 Conduit Volume 9 Number 1, Spring 2000 Conduit Volume 8 Number 2, Fall 1999 Conduit Volume 8 Number 1, Spring 1999 Conduit Volume 7 Number 2, Fall 1998 Conduit Volume 7 Number 1, Spring 1998 Conduit Volume 6 Number 2, Fall 1997 Conduit Volume 6 Number 1, Spring 1997 Conduit Volume 5 Number 2, Fall 1996 Conduit Volume 5 Number 1, Spring 1996 Conduit Volume 4 Number 2, Fall 1995 Conduit Volume 4 Number 1, Spring 1995 Conduit Volume 3 Number 2, Fall 1994 Conduit Volume 3 Number 1, Spring 1994 Conduit Volume 2 Number 2, Fall 1993 Conduit Volume 2 Number 1, Spring 1993 Conduit Volume 1 Number 2, September 1992 Conduit Volume 1 Number 1, March 1992", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:15+00:00", "headings": ["Information for:", "Conduit", "Current Issue", "Back Issues"], "word_count": 381, "token_count_estimate": 709}}, "https://cs.brown.edu/about/directions/": {"text_content": "Directions To Brown CS Brown is located in Providence, Rhode Island, in the northeast of the USA. Providence is just an hour south of Boston and three hours north of New York City, with good connectivity by rail in addition to car and air. You can also visit Providence virtually . Were located on the Brown University campus in the Thomas J. Watson Sr. Center for Information Technology the CIT. Our address is 115 Waterman Street, Providence, RI 02912. You can enter through a door or loading dock at this address, but if theyre locked, the main entrance is located in the quadrangle off Brook Street. Our reception desk is on the fourth floor. If youre traveling by car, be sure to read the Parking and Road Construction And Traffic Alerts sections of the Car page. If youre going to have some leisure time during your stay, be sure to check out this helpful guide the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. Directions Electric ScootersBikes Car Cab Train Bus Plane Public Transit From Boston", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:15+00:00", "headings": ["Information for:", "Directions To Brown CS"], "word_count": 180, "token_count_estimate": 213}}, "https://cs.brown.edu/about/directions/boston/": {"text_content": "Getting To Brown CS From Boston From Boston, there are three ways to travel to Brown CS Car be sure to read the Parking and Road Construction and Traffic Alerts sections before you depart Train Bus", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:15+00:00", "headings": ["Information for:", "Getting To Brown CS From Boston"], "word_count": 36, "token_count_estimate": 37}}, "https://cs.brown.edu/people/jsavage/": {"text_content": "John Savage Send me email at johnsavagebrown.edu Biographical Sketch MIT By the early 1970s his research interests changed from coding andcommunication theory to theoretical computer science. He has done research incomputational complexity, circuit complexity, space-time tradeoffs, VLSIsynthesis and theory, parallel algorithms and theory, scientific computation,reliable computation with unreliable components, computational nanotechnology,efficient cache management on multicore chips, and IO complexity. Hiscurrent research interests are in cybersecurity technology and policy. He haspublished more than 100 research articles and given more than 185 invited technicalpresentations worldwide. He is a Fellow of AAAS and ACM, a Life Fellow of IEEE, and aGuggenheim Fellow. He is a recipient of a Fulbright-Hays ResearchAward. He served as a Jefferson Science Fellow in the U.S. State Department during the 2009-2010academic year and as a member of the RhodeIsland Cybersecurity Commission in 2015. He served as a ProfessorialFellow of the EastWest Institute from 2014 to 2020 when it was dissolved. His professional service has included service on the editorial boardof the Journal of Computer and Systems Sciences and as a memberof the MIT CorporationVisiting Committee for the Department of Electrical Engineering andComputer Science from 1991-2002. He gave testimony before the Subcommitteeon Crime and Terrorism of the Senate Judiciary Committee on April 12, 2011. A more comprehensive , but incomplete, biographical statement can be found here . A complete vitae can be found here . Books Security in the Cyber Age An Introduction to Policy and Technology with Derek S. Reveron, Cambridge University Press, 2023 to appear. Models of Computation Exploring the Power of Computing Addison-Wesley, 1998. Freely available electronically The Mystical Machine with S. Magidson and A. Stein, Addison-Wesley, 1986. The Complexity of Computing , John Wiley and Sons, 1976 Robert E. KreigerPublishing Company, 1987 Russian Translation. by Factorial Publishing, 1998 Recently Taught Courses CSCI 0510, Models of Computation CSCI 1951-E, Computer Systems Security Principles and Practice CSCI 1800,Cybersecurity and International Relations Faculty Bulletin Articles TheGrowth of Brown University Since 1955 , October 1996 The Role of Tenure in Higher Education , May 1998 Representative Brown Service Activities Secretary of the Faculty 2015, Secretary of the Faculty Forum 2014-2016 Vice Chair 2000-2001, Chair 2001-2002, and Past Chair 2002-2003 of the Faculty and the Faculty Executive Committee Chair 2002-2003 of the Task Force on Faculty Governance President 1999-2002 of the Board of Managers of the Brown Faculty Club Distance Learning Web Pages prepared for The Committee on Electronically Mediated Instruction Source Material on Topics of Current Interest Cybersecurity and International Relations Encryption and the FBIApple Dispute Blockchain Technologies and Cryptocurrencies Deterrence in Cyberspace Talks, Interviews, Congressional Testimony b Blockchain Governance Lessons learned from Internet Governance ,A summary of a talk given at ETH Zurich, March 8, 2018 Silver Bullet Interview of John Savage by Gary McGraw, a podcast posted January 24, 2011. The transcript appears in IEEE Security Privacy magazine, JulyAugust 2011. Cyberspace - Taming the Wild West , Jefferson Science Fellow Distinguished Lecture, US State Department,March 23, 2010 Hearing of the U.S. Senate Committee on the Judiciary, Subcommittee on Crime andTerrorism on Cyber Security Responding to the Threat of Cyber Crime andTerrorism, April 12, 2011. John Savage is on thesecond panel which begins at 141 minutes. Cyberspace Policy and Technology , The Sarah and John Graves Distinguished Cybersecurity Lecture, University of Tulsa, Tulsa, OK, October 14, 2016 Technology and the Future of Work Part 1 , White House Chronicle , February 2, 2018 Guests Thomas Kochan, MIT Sloan School of Management John Savage, Brown University Technology and the Future of Work Part 2 , White House Chronicle , February 9, 2018 Guests Thomas Kochan, MIT Sloan School of Management John Savage, Brown University Humanizing the internet of things , White House Chronicle , October 5, 2018 Guest John Savage, Brown University Cyber Security A Societal Grand Challenge , John Savages retirement lecture, Department of Computer Science, Brown University, December 13, 2018 Technology and the Future of Work Part 2 , White House Chronicle , February 9, 2018 John Savage", "metadata": {"last_modified": "2023-12-06T18:50:02+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["John Savage", "Biographical Sketch", "Books", "Recently Taught Courses", "Faculty Bulletin Articles", "Representative Brown Service Activities", "Source Material on Topics of Current Interest", "Talks, Interviews, Congressional Testimony"], "word_count": 660, "token_count_estimate": 970}}, "https://cs.brown.edu/about/diversity/health-wellness-student-advocates/": {"text_content": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity Inclusion Action Plan DIAP Phase II Draft is now available Diversity Home Who We Are Resources Action Plan Initiatives Diversity Advocates Wellness Advocates Data Demographics Student Groups Mosaic Transition Program Health Wellness Student Advocates Our Mission is improve the mental and physical health, accessibility and disability rights with the CS department on an individual and systemic level, as well as increase the sense of departmental community. We connect students with campus resources that are relevant to the issues or pressures they may be facing. Additionally, we collaborate with department to develop better policies and function as a facilitator between students and faculty. If you would like to talk to one of us, we hold office hours upon request and can be reached at wellness.advocateslists.cs.brown.edu Check out the Brown CS Health Wellness Advocates website to learn more The Advocates Cristian Loor 23 Anna Ohrt 23 Kiran Rodrigues 24 Shravya Sompalli 25 2022-2023 Projects Cristian Loor My project is to revamp the UTA Diversity, Inclusion, and Accessibility training modules, according to the CS DDIAP Phase II Section 8.4.A TA Training Enhanced Actions and Goals and Priorities. I began partial revisions in the fall of 2022 with a full synchronous training session redesign according to the themes of setting boundaries and preventing burnout.. Additionally, I helped redesign the New TA Training module 3 accessibility universal design on Canvas by incorporating a self-reflection prompt, giving it parity with the other two. Preliminary feedback assessments suggested that these revisions were effective. Next steps for the project will be to collate and analyze survey responses from different iterations of the training to produce a succinct report. In combination with any departmental climate data, this report will inform precise changes to ALL and NEW TA training occurring in fall 2023 and later. I will also revise module 3 quiz for spring 2023 New TA training by replacing inaccessible materials, editing quiz questions, and updating the UDL presentation. By the end of spring 2023, the Health and Wellness portion of the ALL TA training should have at least two swappable versions addressing distinct themes derived from previous iterations content. I will enlist Professor Christina Smiths help in designing these versions. Revisions to the Health and Wellness HTA training are also in the pipeline. Kiran Rodrigues My project goal would be to assist in the creation of course material that can be used for a Race Power, and Privilege RPP designated CS course. With the release of the DIAP II Plan in the coming months, the department is in a unique position to critically evaluate existing practices and devise ways in which the department can build upon its practices. Brown Universitys Seminar for Transformation Around Anti-Racist Teaching START provides an opportunity to improve upon the existing Socially Responsible Computing content by laying the groundwork for the creation of a RPP course to acknowledge the social and political impacts of computer science. What perspectives and voices have been historically excluded from computer science How has it participated in and enabled systems of oppression How can we think holistically about the legacies of technology In a theoretical course we would recognize that computer science is not an innocent endeavor. Shravya Sompalli My project is to create a zine that acts as a central base for navigating the computer science department at Brown, particularly through a wellness lens. Students often rely upon word of mouth and connections to upperclassmen in order to obtain information needed to navigate department resources. This zine will centralize essential information about the department that students may need to thrive here Furthermore, this zine could serve as another form of communicating important information on the departments progress on DI goals and receiving feedback from the community, as noted in section 9.4 E of DIAP II. 2021-2022 Projects Cristian Loor project continuing in 2022-23 academic year My task is to revamp the UTA Diversity, Inclusion, and Accessibility DIA training modules, by assessing the modules effectiveness. This will include reviewing feedback surveys and holding TA focus groups to identify attitudes toward the trainingprogram. I hope the resulting data will help me design interventions for Spring 2023s course iteration. I would then assess their effectiveness by correlating them with departmental climate data changes. Before I graduate, I hope to establish data collection and evaluation standards my successors will find robust and easy to implement as they assess the ongoing impacts of UTA DIA training in the CS department. Anna Ohrt I propose working with Kathi Fisher to ensure that their new intro course- CS200, is UDL centered. Because course planning has already taken place, this involves providing feedback on assignments and lecture materials. At the same time, researching what CS UDL guidelines already exist through sources like AccessComputing and leveraging other universities best practices. From there, this effort would serve as a pilot for integrating health wellness consultation support into CS accessible course design. David Moon The goal of this project is to investigate mental health policy and best practices in two ways a Intra-university investigation connect with other departments at Brown to learn about how they approach mental health and what we could take away from them, send out survey to assess current state of mental health in CS department b Inter-university investigation connect with other universities CS departments to learn about how they approach mental health and what we could take away from them. The data collected will inform a mental health best practices document. Interviews of best practices can be found here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:15+00:00", "headings": ["Information for:", "Health & Wellness Student Advocates"], "word_count": 962, "token_count_estimate": 1170}}, "https://cs.brown.edu/about/diversity/": {"text_content": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity Inclusion Action Plan DIAP Phase II Draft is now available Diversity Home Who We Are Resources Action Plan Initiatives Diversity Advocates Wellness Advocates Data Demographics Student Groups Mosaic Transition Program How To Get Involved CS Diversity Committee Diversity Inclusion Action Plan Phase II Draft is now available for member of the Brown CS community to review. Please click this link to read the DIAP Phase II Draft . Please click this link to share anonymous feedback about the draft. CS Diversity Committee Monthly Meeting Summaries are now available for Brown University community members on the Action Plan Initiatives page. CS DIAP Phase II Town Hall Our semesterly Town Hall was held on Tuesday October 25 at 4P-5P in CIT 368 3rd Floor Atrium 2023-2024 Student Advocates for Diversity Inclusion, and Health Wellness Applications for 2023-2024 Student Advocates positions are now open. To apply complete the Health Wellness form or the Diversity Inclusion form.. CS Diversity Conferences The CS Department offers student scholarships to attend the Grace Hopper and Richard Tapia conferences. Student scholarship applications for fall 2023 conference attendance will open in spring 2023. Please check back fot the application form. If you would like to request funding to attend a different diveristy, equity and inclusion related CS conference, please email lauradoblerbrown.edu Socially Responsible Computing The SRC program strives to reimagine CS education to not only familiarize future engineers with the ethical, and political challenges and social impacts of modern digital technology, but to provide them with the tools to reason critically about those challenges. Students can apply to become Socially Resoponsible TAs STAs andor join the ARG reading group. You can learn more about this program here . Visiting Undergraduate Research We offer two immersive research opportunities for visiting udnergraduate sudenfts interested in artificial intelligence reseach exploreCSR spring 2023 and REU Site summer 2023. exploreCSR 2023 Socially Responsible AI for Computational Creativity January 2023 - May 2023 5 hours per week, virtual program, compensation 300 travel stipend to attend the Undergraduate Research Symposium in May. REU Site 2023 AI for Computational Creativity June 2023 - August 2023 7 weeks, 40 hours per week, in-person, compensation 6,000 housing and travel stipend. If You Need Help Our Email Diversity Inclusion Student Advocates diversity.advocateslists.cs.brown.edu Health Wellness Student Advocates wellness.advocateslists.cs.brown.edu Diversity Committee diversitylists.cs.brown.edu Have questionsconcerns about mentalphysical health, accessibility, disability rights, andor diversity, equity inclusion within the department OpenOffice Hours provide students with 11 peer mentorship, problem-solving, advocacy, and guidance on student resources and centers available to them on campus. Undergraduate Health Wellness Student Advocate Office Hours Fall 2022, in-person hours are available throughout the week, please feel free to just stop by. Link to Google Calendar hours schedule. Undergraduate Diversity Student Advocates Office Hours Fall 2022, hours are by appointment please email diversity.advocateslists.cs.brown.edu or complete the contact form below to schedule. Loading... Diversity Events Thursday October 25, 4P-5P CS DIAP II Town Hall . CIT 368 and Zoom. For a list of Brown Computer Science Department events visit the CS Events Calendar . For a full list of Women in Computer Science WiCS events visit the WiCS Calendar . For a full list of Mosaic events visit the Mosaic Calendar . Past Events No events Diversity News No entries found", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:"], "word_count": 585, "token_count_estimate": 808}}, "https://cs.brown.edu/about/diversity/student-advocates-diversity-and-inclusion/": {"text_content": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity Inclusion Action Plan DIAP Phase II Draft is now available Diversity Home Who We Are Resources Action Plan Initiatives Diversity Advocates Wellness Advocates Data Demographics Student Groups Mosaic Transition Program Diversity Inclusion Student Advocates Our Mission Our primary mission as Student Advocates for Diversity and Inclusion is to improve how our department handles academic and social diversity issues. We hope to increase the retention number of HUGs historically underrepresented groups in upper level computer science classes, as well as increase the number of students concentrating in computer science. We also hope to raise awareness of the issues that are ongoing in our department such as the lack of diversity among our TA program, which is the main source of instruction for our introductory classes. We hope that our initiative creates a more inclusive environment that allows students to thrive academically while also creating a diverse social atmosphere that is welcoming to all. Confidentiality When students are in their roles as student advocates they are not required to share any information disclosed. They will not answer questions about people with whom they may have spoken, or disclose an individuals name or specific issue unless during the course of the discussion, the student advocate is given explicit permission by the individual to do so. The only exception to this is if the student advocate determines that there is an imminent risk of serious harm. Student advocates will, however, keep statistical information for analyzing and reporting trends of issues, and provide recommendations to the diversity committee. Student advocates are not Title IX mandatory reporters. The Student Advocates Afia Akosah-Bempah 23.5 Valerie Aguilar Dellisanti 23 Fernanda Chavez Zapata 25 Arman Deendar 25 Contact Email diversity.advocateslists.cs.brown.edu OR Contact Form 2022-2023 Projects Afia Akosah-Bempah Arman Deendar In line with section 7.4 E K-12 Outreach New or Enhanced Action of Phase II of the Diversity and Inclusion Action Plan DIAP, this project aims to expand and consolidate the community outreach initiatives already taken by the department. Given the scale and access to resources of Browns Computer Science Department, the department has a great opportunity to serve and become accountable to local communities. We wish to implement a program that centers community needs for continued engagement and dedication of resources in Providence, Central Falls, and Pawtucket. In the short-term this involves beginning conversations with local community leaders, organizations, and educational centers, Brown CS stakeholders faculty, graduate students, undergraduate students, and existing outreach groups, ie IgniteCS and adjacent Brown community-oriented departments Annenberg Institute, Swearer Center, Bonner Fellows, BRYTE. Then using information gleaned from these conversations to inform outreach initiative and policy proposals submitted to Brown CS Valerie Aguilar-Dellisanti Fernanda Chavez Zapata The goal of this project is to create a resource for underrepresented communities in the CS department to connect with Brown CS alumni, create impactful relationships, and gain valuable knowledge. Building a database of underrepresented CS alumni is now possible given the increased number of diverse student that have graduated and will graduate from Brown University with a CS Degree. Mosaic is one of the largest reasons for attracting interest and retention in the department, as well as the creation of the Diversity and Inclusion student advocates. We aspire to use these programs to create a database of alumni in order to create a program like the Womens Launch Pad or Women in Business External Internal Mentorship Initiative. We would develop an alum mentor-student mentee program with guides, coffee chats and alum meet-ups during commencement. 2021-2022 Projects Valerie Aguilar Dellisanti Across campuses, students and their Computer Science departments have different approaches to improving diversity and support for their members. This project evaluates different policies, clubs and initiatives in different universities, both in Rhode Island and at other schools with top CS departments. Additionally, an emphasis is given to universities with high diversity and hiring rates, especially for HUGs. There are two main purposes of this study. The first one is to analyze how initiatives already taken at Brown are implemented somewhere else, identify key differences and similarities. The second goal is to identify good practices that could be replicated here on campus. Both of these goals will help improve and strengthen the impact of current initiatives. The analysis was presented at a Diversity Committee meeting in spring 2022, and best practices were integrated into the DIAP II Draft. The presentation can be viewed here . Evan Dong This project focused on the creation of an LGBTQIA umbrella affinity group, Spectrum. Growing from a queer mentorship program started last year, activities expanded to include partnerships with recruiters for career development opportunities, community-building events, and facilitated spaces for transgender students. With an eye toward sustainability, this years activities focused on building capacity and leadership for future generations of LGBTQIA students in Brown CS. Amal Dualeh This project documents high level practices for supporting first generationlow incomeundocu students UFLi who experience unique challenges coming into CS as an academic field and as a department here at Brown. The goal is to create programming recommendations focused on providing UFLi students in CS with spaces of community and support with other students of shared lived experiences. Elements of the report, which can be viewed here , were integrated into the DIAP Phase II Draft. Charlotte Lee My observation is that the student culture among the CS concentrators cohort is relatively homogenous in terms of background, academic interests, and career path considerations. In order to improve recruitment and retention of CS concentrators, I believe that we need to offer more interdisciplinary educational approaches or opportunities that cater to students who are not interested in working at big tech companies Facebook, Amazon, Apple, Netflix, Google. The goal of my project is to increase the number of opportunities for students who are interested in CS for social good. I believe that increasing the number of these opportunities will shift the student culture in a healthier, more inclusive direction by attracting a more diverse group of students, and allowing these students to pursue integrate their other passions in the study of Computer Science. The plan is for this work to continue in 2022-2023 with the development of a Socially Responsible Computing opportunitiescareers database, as Charlotte assumes a new role of IPP Ambassador.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Diversity & Inclusion Student Advocates"], "word_count": 1082, "token_count_estimate": 1318}}, "https://cs.brown.edu/about/diversity/resources/": {"text_content": "Diversity and Inclusion As a department, we have made it our mission to create and sustain a diverse and inclusive environment in which all students, faculty, and staff can thrive. The Broadening Participation in Computing BPC 2022-2024 Department Plan has been verified by BPCnet.org. The CS Diversity Inclusion Action Plan DIAP Phase II Draft is now available Diversity Home Who We Are Resources Action Plan Initiatives Diversity Advocates Wellness Advocates Data Demographics Student Groups Mosaic Transition Program Resources If You Need Help If you have an emergency that needs immediate attention contact the Department of Public Safety at 401-863-4111 . For any other incidents that you would like addressed reach out to the Diversity Committee diversitylists.cs.brown.edu , the Student Advocates for Diversity Inclusion diversity.advocateslists.cs.brown.edu , the Student Advocates for Health Wellness, wellness.advocateslists.cs.brown.edu or the Diversity Committee staff member, Laura Dobler lauradoblerbrown.edu 401 863 7611 The Office of Instutional Equity and Diversity OIED also has an online Bias Incident Report Form that can be completed by members of the community who wish to report incidents or issues of discrimination andor harassment. Submissions are always confidential and can also be anonymous should the submitter choose. Emergency Contacts Emergency Medical Services EMS 401 863 4111 - Physical evaluations, hospital transports, medical emergencies Student Support Deans Dean of the Day DOD 401 863-3145 - Addresses academic and personal emergencies during business hours Administrator on Call AOC 401 863-3322 - 247365 support for students in need of immediate assistance Sexual Assault Response Line 401 863-6000 - Immediate support in conjunction with DPS, EMS and CAPS confidential Helping a Student in Distress - For a full list of student support resources Academic Support and Tutoring Dean of the College DOC - Addresses academic concerns including open curriculum, grading, independent concentrations, gap years, leave-taking, among others Curricular Resource Center CRC - Part of the Dean of the College, Peer Advising supports students navigating independent concentrations, gap years, leave-taking, DUGs, fellowships, internships and research Sheridan Center - Provides resources for teaching and learning Advising Sidekick - a common on-line space for students and advisors that includes advising materials, information about the Writing Requirement, email announcements, and the Concentration declaration process. Math Resource Center - Provides tutoring for math courses during the year Student Conduct and Community Standards - Addresses student conduct and policy concerns SAS Student Accessibility Services - Provides students including graduate students and postdoctoral trainees, faculty or staff members who may need accommodations or services due to a disability or medical condition Student Centers Undocumented, First-Generation College and Low-Income Student Center U-FLi Center The U-FLi Center , founded in the fall of 2016, is a communal, learning, and advocacy center for members of the Brown community who identify with the undocumented, first-generation college andor low-income student experience U-FLi. The U-FLi Center aims to contribute to the endurance of U-FLi students by providing them with a dedicated space and programming that values their lived experiences as they navigate an elite, historically white institution and acknowledges the impact of the current socio-political climate on their academic well-being. Brown Center for Students of Color BCSC The BCSC , established in 1976, serves as a gathering place for communities of color. Students are encouraged to build meaningful relationships across difference, develop racial and ethnic consciousness, and enact change at Brown and beyond. The BCSC advances the Universitys mission of educating and preparing students to discharge the offices of life with usefulness and reputation by empowering students of color, cultivating leadership, facilitating critical reflection, fostering informed action, and promoting social justice. The LGBTQ Center The LGBTQ Center established at Brown in 2004, provides a comprehensive range of educationtraining, cultural, social and educational programming, support services and advocacy services to the entire Brown Community. The Center works to create and maintain an open, safe, and inclusive environment for lesbian, gay, bisexual, transgender, queer and questioning students, faculty, and staff, their families and friends, and the campus community at large. Sarah Doyle Center for Women and Gender SDC The SDC , established at Brown in 1974, seeks to provide a comfortable yet challenging place for students, faculty, and staff to examine the multitude of issues around gender. The Sarah Doyle Center offers programs and services for all members of the Brown community, and is a site for research into and exploration of gender issues that extend into and beyond the classroom. Brown Muslim Student Association BMSA and Student Center BMSC BMSA was founded in the early 1990s. They are a student-led group at Brown University working to meet the needs of our Muslim community while maintaining an open and inviting space. They host a range of events from spiritual to social to interfaith and work closely with the Office of Chaplains and Religious Life. Student Activities Office SAO As part of the Division of Campus Life, the Student Activities Office leads campus efforts to support 400 student groups. For a full list of student groups BearSync Student Group List . Student Support Student Accessibility Services SAS SAS coordinates and facilitates services for students including graduate students and postdoctoral trainees, faculty, staff and visitors with physical, psychological, and learning disabilities. Students including graduate students and postdoctoral trainees, faculty or staff members who may need accommodations or services due to a disability or medical condition should contact Student and Employee Accessibility Services to discuss their needs and begin the registration process. Disability related requests for accommodations and services are evaluated individually, based on documentation and completion of the registration process. Counseling and Psychological Services CAPS CAPS provides a range of mental health services to the Brown community, including individual counseling, medication management, skills workshops, referral services, mental health assessment, trainings and consultation for faculty and staff, crisis stabilization, after hours assessment and urgent care, outreach programming, and groups. If you have any questions that are not answered on this page, please contact us so we can help. For those looking to help students the B.E.A.R. Project is a training run by CAPS to help members of our community identify and support students in distress. Projet LETS Peer Mental Health Advocates PMHA Project LETS is a national 501c3 grassroots organization led by and for folks with lived experience of mental illness, disability, trauma, neurodivergence. We establish peer-led communities of advocacy support produce resources and educational materials and aim to protect the civil and human rights of mentally ill folks through policy change especially those who experience multiple forms of oppression and therefore are rendered especially vulnerable. Disability Justice at Brown DJAB advocates for disability justice at Brown by holding space for a broad coalition of voices in the disabled community. We seek to foster connections between disabled people across all identities and experiences, provide resources and education for each other and the broader Brown community, and serve as a seat of power to amplify our individual voices into a collective force. By creating a space for organizing and solidarity, we aim to address the pressing issues facing all disabled students at Brown and cement disability as an important part of the campus discussion on diversity and inclusion. Health Services Health Services and its affiliated departments aim to provide primary care that is patient-centered, high-quality, confidential, easily accessible and responsive to students needs. Health Services recognizes that physical and emotional health and well-being are necessary for the student to devote meaningful efforts to the stated goals of education and self-discovery. Partnering with students, we provide holistic care that is respectful of students personal, cultural and social identities thus becoming a space for education, self-discovery and intellectual growth. BWell Health Promotion BWell is dedicated to facilitating interactive workshops that provide accurate health information in a non-judgmental, inclusive style. Learn about the programs we offer and request a program for your group. Sexual Harassment Assault Resources Education SHARE Advocates The SHARE Advocates in BWell Health Promotion are confidential resources on campus that can provide support to any student from any part of the University undergraduate, graduate, and medical students affected by issues or experiences related to Sexual Assault Sexual andor Gender-based Harassment DomesticDating Violence Relational Abuse Stalking Title IX Gender Equity Brown University Title IX is committed to providing an adequate, impartial, and reliable response to Complaints pursuant to the University Sexual and Gender-Based Harassment, Sexual Violence, Relationship and Interpersonal Violence and Stalking Policy. The Universitys process for addressing Prohibited Conduct are grounded in fairness and support for all parties, include procedural protections that ensure notice and meaningful opportunities to participate, and recognize the dynamics involved in Prohibited Conduct. Office of the Chaplains and Religious Life The Office of the Chaplains and Reglious Lifes mission is to ensure that a diversity of beliefs have voice and vitality throughout the University community. This website will introduce you to our work, programs and religious life colleagues, as well as resources available to undergraduate, graduate, medical students, staff, faculty, and alumniae. The Office of Residential Life The Office of Residential Life is responsible for maintaining student residences which support the educational mission of Brown University and are designed to provide a variety of learning opportunities that promote students academic endeavors, and which encourage their growth and development. The Office of Residential Life at Brown recognizes that learning is not solely academic in nature. A large part of learning inevitably takes place outside the classroom. We are committed to supporting that learning through the residential experiences we provide. Office of International Student and Scholar Services OISSS The mission of the Office of International Student and Scholar Services OISSS is to support the Universitys internationalization and to facilitate the integration of international students and scholars into the Brown community. In that, OISSS serves as a resource to admitted international students, faculty and researchers and their families as well as academic departments, and other administrative offices on and off campus. OISSS provides advising services with respect to immigration and visa matters, work permission, orientation, cultural adjustment and personal concerns. OISSS provides consulting services to hiring academic departments, and handles the immigration related aspects of the hiring process for nonimmigrant faculty, researchers, and staff. OISSS is organized under the Office of Global Engagement OGE . Office of Military-Affiliated Students OAMS OAMS supports all students -- undergraduate, graduate, and medical -- and also is available as a resource to faculty, staff, alumniae, and families of students. While initiated by Browns response to a review of ROTC, the Office is a campus resource for not just ROTC but for all United States military officer commissioning programs. Additionally, the Office serves student veterans, whether of the United States military or military service in other countries. The Office of Institutional Equity Diversity OIED OIED serves as a critical leader, resource, and support in sponsoring programs and events related to diversity and inclusion at Brown University. OIED helps lead inclusion efforts across campus through Accountability Compliance Fostering Academic Diversity Promoting Diversity and Inclusion. Community members can report bias incident reports using the new form on OIEDs website. Brown University Ombuds Office The Ombuds Office provides an independent, confidential, neutral and informal resource for faculty, staff, postdoctoral fellows and associates, graduate students and medical students who have concerns arising from or affecting their work and studies at Brown. Technical Financial Support Computing Information Services Loaner Laptops CIS Help Desk Need a loaner The following equipment can be signed out at the IT Service Center. For current models and availability, please get in touch. Windows laptops, Mac laptops, Webcams, Video cameras, Audio Recorders, Projectors. Stop by the IT Service Center in the Page-Robinson 510 69 Brown Street during business hours M-F 830A-9P, Sa closed, Sun 4P-9P Financial Services Financial Aid Financial aid at Brown is a partnership that draws on the combined resources of the student, his or her family, federal and state governments, and the University itself. Loan Office As part of Financial Services, the Loan Office assists students in meeting the cost of education and managing the repayment of educational loans. We help students make informed borrowing decisions, complete loan requirements, and understand the loan process. UFunds UFunds coordinates applications for funding from offices at Brown. You will find opportunities here for members of the Brown community, including undergraduate students, graduate students and faculty. Short-Term Loans The Brown University Short-Term Loan Program is a zero interest loan made available to students to assist in emergencies. Computer Information Systems Services CIS Services Accounts Passwords, Computer Printer Repair, Computer Installation Set Up, Computer Training Consultation Sessions, Computer Training Workshops, Data Recovery, IT Knowledgebase, IT Service Center, Lynda.com Online Training, Mobile Device Repaid, On-Site Support, Undergraduate Computer Training Classes PASS, Women and Technology Group Graduate Student Resources Graduate School Student Services Academics, Health Wellness, Student Experience, directory of support services for graduate students oSTEM Out in Science, Technology, Engineering, and Mathematics oSTEM at Brown is a chapter of the national non-profit professional society oSTEM Incorporated with more than 75 chapters across the United States. Our overarching mission is to empower LGBTQIA folks at Brown University studying or working in STEM fields to succeed personally, academically, and professionally. GSOC Graduate Students of Color community Our mission aims to build a communuty of graduate students of color in STEM, increase interaction between faculty and students of color in STEM, and encourage a pipeline for underrepresented groups in STEM to increase their representation in STEM fields. SACNAS Brown Universitys Chapeter of the Society of Advancement of ChicanosHispanics and Native Americans in Science work to foster an includive community and resilient network of scientists from underrepresented identities in STEM at Brown University and behyond.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Resources"], "word_count": 2256, "token_count_estimate": 2825}}, "https://cs.brown.edu/about/partners/": {"text_content": "Industry Partners Program Advantages About Brown CS Become a Partner Current Partners Symposia Tech Fair Membership Levels The Department of Computer Science at Brown University runs an industry partners program that offers corporations and non-profit organizations opportunities to collaborate with faculty, learn about Browns research, and meet Brown students who are looking for employment. The Department seeks partners whose activities are aligned with Browns mission of education and research. Brown CS celebrates diversity and is committed to creating an inclusive environment for all our constituents. Membership in the IPP is by invitation. We welcome organizations whose business practices align with our expectation for equal opportunity and fair employment, as well as the responsible, transparent, and accessible use of technology, which precludes racial profiling, mass surveilllance and other forms of discrimination and violation of civil rights. If you have questions, we are happy to discuss this with you. Industry Partners are introduced to the Departments research and development efforts and to our students. We seek to develop relationships with a limited number of Partners who share an interest in supporting faculty and students. The full scope of the Departments research interests are listed here . Member institutions are encouraged to recruit our students, participate in the selection of topics for our IPP symposia, and advise on the employment and research needs of corporations. The IPP Director and the Program Manager stay in regular contact with participating companies, arrange campus visits, identify faculty to serve as consultants, and respond to specific requests. We encourage our students to thoughtfully consider their career interests and goals, and decide for themselves which companies they should engage with. Please contact us if you have any input regarding our program. Students If you want to receive notifications of IPP events please click this link to be added to the mailing list httpbit.lybrownipp Click here for upcoming IPP events Recruiting policies 2021-2022 113.5 KB . Recruiting Events No events Job Listing No entries found", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Industry Partners Program"], "word_count": 326, "token_count_estimate": 377}}, "https://cs.brown.edu/about/partners/symposia/": {"text_content": "Industry Partners Program Advantages About Brown CS Become a Partner Current Partners Symposia Tech Fair Membership Levels IPP Symposia 1989 - Present DATE TOPIC SPEAKER ORGANIZATIONS BROWN ORGANIZERS 42414 Social Computing danah boyd, Ed Chi, Mike Develin, Connor Gramazio, Hak Rim Kim, Merrie Ringel Morris, Alexandra Papoutsaki, Genevieve Patterson, Hannah Quay-de la Vallee, Michael Stoppelman, Sizhao Yang Prof. Jeff Huang 42513 Putting Big Data to Work Tim Kraska, Nadathur Satish, Daniela Florescu, Fabio Vandin, Andrew Ferguson, Matteo Riondato, Mike Hughes, Dae Il Kim, Piero P. Bonissone, Amr Awadallah, Ionnis Tollis, Casey Dunn, Meenakshi Narain, Thomas Trikalinos, Derek Aguiar, Andy Pavlo Profs. Tim Kraska Ugur Cetintemel 22312 Security Privacy in the Cloud Ben Livshits, Michael Coates, Tao Stein, Kevin DeLange, Denis Pilipchuk, Roberto Tamassia, Arjun Guha, Joe Gibbs Politz, Feng-Hao Liu Prof. Anna Lysyanskaya 42811 Visual Computing Andy Gallagher, Sanjiv Kumar, Iain Matthews, Caroline Pantofaru, Sylvain Paris, Xiaofeng Ren, Bryan Russell, Larry Zitnick Profs. James Hays Erik Sudderth 51310 Cloud Computing Jeff Hammerbacher, Joseph L. Hellerstein, Srikanth Kandula, Orran Krieger, Harry Li, Adam Silberstein Prof. Rodrigo Fonseca 43009 Standardizing Transactional Memory Ali-Reza Adl-Tabatabai, David Christie, Yossi Lev, Maged Michael, Mark Moir, Vijay Saraswat, Srinivas Sridharan, Ben L. Titzer Industry Partners Program 92208 Technology Showcase Stan Zdonik, John Jannotti, Pascal Van Hentenryck Industry Partners Program 5808 Web Programming Technologies David Ellis, Arjun Guha, Erik Meijer, Mark S. Miller Prof. Shriram Krishnamurthi 111507 Security Privacy Seth Proctor, David Croston, Steve Weis, Moti Yung, and Blair Semple Prof. Roberto Tamassia 5307 Operating Systems Technology and Brown Alumni Bryan Cantrill, Michael Shapiro, Adam Leventhal, Jeffrey Korn, Jason Lango, Matthew Ahrens, and Eric Schrock Prof. Tom Doeppner 120606 to 120806 The Genome and the Computational Sciences The Next Paradigms Leon Cooper, David Barker, Craig Venter, Stephen Hoffman, Jeffrey Skolnick, Jonathan King, David Shaw, Eric Kronstadt, Pavel Pevzner, Jonathan Yewdell, Jeremy Smith, Christopher Johnson, David Altshuler, Prof. Sorin Istrail 50106 Do We Need a Next-Generation Internet IBM, Microsoft Mazu Networks, CMU, Akamai Prof. John Jannotti 120605 Managing the Fire Hose GTECH, HBK, IBM, MIT Prof. Stan Zdonik 50405 Combinatorial Optimization - State of the Art and Future Trends ILOG, IBM, SAP,Carmen Systems, Georgia Tech, Universit de Montral Prof. Meinolf Sellmann 102904 Natural Language Processing Google, ISI, Microsoft, IBM Prof. Eugene Charniak 32504 Trusted Computing Group Goals, Achievements, and Controversies Hewlett Packard Labs, IBM, Intel, Microsoft Prof. Anna Lysyanskaya 5603 Mobile and Pervasive Computing Middleware and Technologies Fidelity Investments, Hewlett Packard, IBM Watson, Intel, InvensysFoxboro, Sun Microsystems Prof. Ugur Cetintemel 111402 Symposium on Information Knowledge Management Hewlett-Packard, Fidelity Investments, Microsoft Research, IBM, MERL, Sun Microsystems Prof. Thomas Hofmann 42502 Symposium on Computer and Network Security Hewlett-Packard, BBN, EMC, GTECH, Sun Microsystems Prof. Tom Doeppner 11101 Component Software Technologies Northeastern University, IBM, University of Utah, GTECH, Sun Microsystems Prof. Shriram Krishnamurthi 5301 Vision-Based Interfaces Microsoft Research, Compaq, MERL, IBM, Intel Corporation, Prof. Michael Black 11200 Web Technologies Akamai Technologies, Alta Vista Company, InterTrust Technologies, Latitude Communications, Verity, Inc., Sun Microsystems Prof. Eli Upfal 4600 E-Commerce American Mgt. Systems, Andersen Consulting, Ariba, Compaq, GTECH, IBM, Microsoft Research Profs. Greenwald Savage 111199 Computing in a Wireless World Microsoft, Compaq, GTE Labs, Foxboro, GTECH, IBMLotus Prof. Doeppner 42999 Web-Based Natural Language TechnologySearch, Translation and Analysis IBM Almaden, IBM Watsun, Sun, Brown Prof. Charniak 111298 Realizing the Potential of Java ATT Research, Brown, Compaq, Lotus, Sun, WorldStreet Prof. Herlihy 5798 Design Patterns DIGITAL, IBM, ATT Labs, Sun, Brown, Independent Consultant Prof. Van Hentenryck 112097 Web Technology Usability, Security, Reliability Commerce DIGITAL, INSO Corp. Dynamic, Diagrams, IBM, Freelance Journalist Prof. Hughes 4397 NT vs. UNIX Whither the Future ATT Labs, Bell Labs, DIGITAL, Linux Internl, Microsoft, Sun Profs. Reiss Doeppner 102496 Machine Learning Data Mining Silicon Graphics, Microsoft Research, ATT Research, NYNEX Sci Tech, Honeywell Prof. Kaelbling 5396 A Technical Retrospective on Paris Kanellakis Stanford, MIT, Brandeis, INRIA, Rocquencourt Profs. Van Hentenryck Zdonik 102695 Parallel Architectures for Todays Marketplace Sun Microsystems, Motorola, IBM, DEC, Microsoft Prof. Herlihy 41395 Architectures for Interoperating Software Components OMG, DEC, IBM, GTE, Brown, EASEL Prof. Wegner 111094 Nexal Computing Bellcore, DEC, IBM, Sun Microsystems, Corp. for Natl Research Initiatives Prof. Savage 42694 Ubiquitous Computing DEC, Xerox PARC, Brown CS, IBM Watson, Locus Computing Corp. Prof. Doeppner 101593 Frontiers in Visualization Brown CS, Xerox PARC, Columbia U., Bellcore Prof. Hughes 42793 Object-Oriented Database Systems Brown CS, DEC, GTE Labs., Bellcore, Object Design, Inc. Prof. Zdonik 10192 Progress in Distributed Object- Oriented Computing Brown CS, IBM Yorktown, Sun Microsystems, DEC Professor Wegner 31992 Software Development and CASE Cadre, IBM, Brown CS, Siemens Prof. Reiss 11791 Privacy Security IBM, Citibank. DEC, Sun, Brown Philosophy Prof. Doeppner 71891 Programming Techniques for Constraint Problems Combinatorial Optimization IBM, Siemens, Bellcore, Motorola, Brown CS Profs. Kanellakis, Van Hentenryck 31491 Parallel Distributed Systems DEC, Citibank, IBM, HP, Motorola, Transarc Prof. Savage 101790 OSF and UI Operating Systems Brown Tutorial, OSF, Sun, Bellcore, DEC, IBM, Unix International, GTech Prof. Doeppner 71290 Robotic Systems Design Denning Robotics, Transitions Research, Design Lab, Brown Linguistics, Engineering CS Prof. Dean 5390 Experiences with the Object Paradigm Texas Instruments, Siemens, Bellcore, Codex, Brown CS Messrs. Lejter, Kirman Shewchuk Grad Students 22190 Scientific Visualization Stardent, Sun, HP, Bellcore, Brown CS, Brown Applied Math Prof. van Dam Prof. Hughes 71389 Prototyping Environments Object Design, Inc., Siemens, Brown IRIS, Brown CS Prof. Reiss Prof. Zdonik", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Industry Partners Program", "IPP Symposia 1989 - Present"], "word_count": 879, "token_count_estimate": 1708}}, "https://cs.brown.edu/about/praise/praise-brown-cs/": {"text_content": "Praise For Brown CS Brown University s Department of Computer Science is known for inspiring innovation, fostering a tight-knit community, and engaging its students. Click the links below to learn more about why were one of the best places to study CS. College Facutal Ranks Brown Fifth For Best CS Schools Brown CS Wins Browns Diversity And Inclusion Action Plan DIAP Community Award GradReports Ranks Brown CS First In Colleges For Computer Science SR Education Group Ranks Brown CS Third Nationwide For Graduate CS Education Brown CS Has Been Rated The Fifth Most Advanced CS Department In America Humanities Magazine Features Browns Revolutionary 1976 Use Of Hypertext In Education BDH Names Google And Microsoft The Top Two Employers Of Brown Graduates Brown Ranks 8 For Graduating Female Founders Of VC-Funded Companies Digital Den Cites Brown CS As A Well Recognized VR Leader LinkedIn Rates Brown CS 1 For Launching Graduates Into Successful Software Development Careers Brown Rated 3 In USA For Software Developers At Startups", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Praise For Brown CS"], "word_count": 165, "token_count_estimate": 199}}, "https://cs.brown.edu/about/pvd/": {"text_content": "Praise For Providence Providence is a city known for its great quality of life, cultural attractions, and you guessed our favorite food. Click the links below to learn more about why we love calling it home. If youre coming for a visit, be sure to check out this helpful guide the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. Youre also welcome to visit Providence virtually . The New York Times Recommends Rhode Island In The Fall Gondolas A Great Way To Enjoy And Tour Providence Cond Nast Traveler Calls Providence New Englands New Cultural Hub Providence Is Americas 8th Best City To Go Carless Providence Has Two Restaurants In Yelps Top 100 Providence Has One Of Americas Top 50 Best New Restaurants Smart, Urbane, Wonderfully Weird The Washington Post Shares Some Must-See Providence Attractions More Raves For Providence As A Foodie Mecca CNN Names Providence The USAs Most Artsy City Bostonians Find Providence Divine And Offer A Day Trip Guide Money Magazine Names T.F. Green Americas Sixth Best Airport Providence Will Be Shiru Cafes First US Location Providence Has Been Named Americas Fourth Quirkiest City PureWow Offers A Guide To Providence As Your Next Weekend Escape Considering A Visit Or A Move To RI Boston.com Gives 100 Reasons Travel And Leisure And Conde Nast Rank T.F. Green Airport One Of The Nations Best Providence Is Home To One Of Bon Appetits Ten Best Restaurants Parade Names Providence The Best Kept Secret On The East Coast Travel And Leisure Names Providence The Third Most Charming City In America Providences RISD Museum Tops Architectural Digests List Of Americas Best University Art Museums Travel And Leisure Calls Providence Americas Third Favorite City And Second Best For Food Brown CS Is Within An Hours Drive Of One Of The USAs Best Beaches NYT Ranks Providence With Global Peers As A Place To Go In 2016 Providence Declared Best City To Raise Kids In America DataFox Lists Providence As One Of 2015s Best Cities To Found A Startup Outside Of Silicon Valley And New York GQ Raves About Providence The Coolest City Providence Ranked Americas Eighth Best College Town For People Who Arent In College", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:16+00:00", "headings": ["Information for:", "Praise For Providence"], "word_count": 365, "token_count_estimate": 441}}, "https://cs.brown.edu/about/rooms/368/": {"text_content": "CIT 368 Equipped with HDMI and VGA connection at the podium Projector and two 70 display with independent inputs Overhead audio Microphones ceiling, handheld and lavalier Crestron Touch Panel with matrix style input-to-output mapping Extron recording from one or two video sources and all microphones, concurrently Excluding HDCP protected content Live Streaming Zoom Rooms control panel for Zoom video conferencing Apple TV Multiple Whiteboards Removable back wall for larger events needing to overflow into the atrium Schedule Please do not invite yourself to events on this calendar or create reservations for yourself. Reservation requests must be made through the reception receptioncs.brown.edu and all others will be deleted.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "CIT 368", "Schedule"], "word_count": 107, "token_count_estimate": 136}}, "https://cs.brown.edu/about/rooms/": {"text_content": "Rooms This page lists the rooms that we use to hold classes, TA hours, labs, and many other scheduled events. A few Brown CS-operated classrooms and labs have their own web pages with information for the people who use them. CIT 101 A meeting room that features audio-visual capability with Zoom. Schedule Contact reception at cs.brown.edu to reserve Capacity 25 CIT 102 A meeting room that features audio-visual capability with Zoom. Schedule Contact reception at cs.brown.edu to reserve Capacity 10 CIT 143, The Sunlab A lab consisting of 73 Maxbuilt PCs running Linux and two running Windows 7, the Sunlab is the primary computing resource for computer science undergraduates. The lab is available days and evenings and sometimes around the clock. Schedule Contact problem at cs.brown.edu to reserve Capacity 135 CIT 165, Motorola A lecture hall with rows of seats. Often used for lectures, recitations, and review sessions. This room is managed by CIS, so please contact Media Services 3-3600 for any audio-visual or Zoom problems. Capacity 73 CIT 167, The MLab A classroom and cluster of Maxbuilt PCs running Mac and Linux. The MLab is a common location for large labs and for courses which use MacOS. Schedule Contact problem at cs.brown.edu to reserve Capacity 22 CIT 201, Undergrad Computing Lab A large room with Linux Machines and also desks with monitors, keyboards, and mice that students can hook their laptops up to. This room follows the Sunlab hours. CIT 203 TA-Lab A computer lab used for hours and course development by TAs. CIT 205 TA-Lab A computer lab used for hours and course development by TAs. CIT 207 TA Room A room used by TAs for course development and hours. There are no computers in this room. CIT 209 This is a small lab used by UTAs. UTAs are allowed to reserve this room through the MTAs. CIT 210 A meetingconference room. It doesnt have full Zoom room capabilities, but occupants can still use Zoom with their laptops and take advantage of the Owl, which can be thought of as a webcam. If you run into any problems with the Owl, contact Anthony Silva or Media Services. You can connect a laptop or use airmedia to the display only. This room also has a white board and large 70-inch monitor. Unfortunately, the monitor isnt fully viewable at the far end of the table. Before booking a meeting, we suggest visiting the room in person to make sure its suitable. Brown card swipe access is required please contact dawnreedbrown.edu or call at 863-7612 for more information. Schedule Contact reception at cs.brown.edu to reserve Capacity 18 CIT 219 A classroom with rolling whiteboards, small tables, projector, and audio-visual capability. Sometimes used for TA hours. This room is managed by CIS, so please contact Media Services 3-3600 for any audio-visual or Zoom problems. Capacity 48 CIT 227, Moonlab A small classroom which is used by classes and for TA hours. This room is managed by CIS, so please contact Media Services 3-3600 for any audio-visual or Zoom problems. Capacity 85 CIT 241, Swig Board Room A classroomconference room that features audio-visual capability with Zoom. Its set up with tables and chairs. Brown card swipe access is required please contact dawnreedbrown.edu or call 863-7612 for more information. Schedule Contact reception at cs.brown.edu to reserve Capacity 45 CIT 271, Fishbowl This room contains a cluster of Linux machines used by Mosaic members. CIT 316 A meeting room and classroom that features audio-visual capability with Zoom. Capacity 25 Schedule Contact reception at cs.brown.edu to reserve CIT 348, TA-Lab A computer lab used for course development by the undergraduate TA program. CIT 367, J-Lab A computer lab used by the undergraduate TA program for course development and interactive grading sessions. CIT 368 A classroom and conference room that features audio-visual capability with Zoom. Schedule Contact reception at cs.brown.edu to reserve. CIT 368 cannot be booked during the spring semester. This room is being reserved for our faculty search talks and for thesis defenses. Capacity 56 CIT 410, The Library Meeting room and conference room and no longer a Zoom room with all its capabilities. Occupants can still use Zoom with their laptops and take advantage of the Owl, which can be thought of as a sophisticated webcam. If anyone runs into any problems with the Owl, they can contact Anthony Silva or Media Services. Schedule Contact reception at cs.brown.edu to reserve Capacity 25 CIT 477, Lubrano Conference Room A classroom and conference room that features audio-visual capability with Zoom. Schedule Contact reception at cs.brown.edu to reserve Capacity 65 CIT 506 A classroom and conference room that features audio-visual capability with Zoom. Smaller and less formal than Lubrano. Schedule Contact reception at cs.brown.edu to reserve Capacity 30 CIT 508 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule Contact reception at cs.brown.edu to reserve Capacity 4 CIT 510 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule Contact reception at cs.brown.edu to reserve Capacity 4 CIT 512 A conference room that can be reserved by students for one-on-one meetings, private calls, or Zooms, but NOT for recurring meetings. Please note that they have no technological capabilities and feature only a table, four chairs, and a whiteboard. Schedule Contact reception at cs.brown.edu to reserve Capacity 4 CIT Atrium3 Open area on the 3rd floor, sometimes used for overflow from Room 368. Schedule Contact reception at cs.brown.edu to reserve CIT Atrium4 Open area on the 4th floor. Schedule Contact reception at cs.brown.edu to reserve SciLi 804 Conference room on the 8th floor of the SciLi. Brown card swipe access is required for all those attending a meeting or engaging in research on the Sciences Library 8th floor. Please send a list of meeting participant names and their Brown ID numbers at least 3 days in advance of your reservation date to SuzanneAldenbrown.edu or DawnReedbrown.edu to ensure their access to the space. Schedule Contact reception at cs.brown.edu to reserve Capacity 20", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "Rooms"], "word_count": 1054, "token_count_estimate": 1391}}, "https://cs.brown.edu/about/rooms/sunlab/hours/": {"text_content": "Sunlab Hours Sunlab Hours Opening Closing Mon-Thurs 9am midnight Fri 9am 10pm Sat noon 10pm Sun noon midnight", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "Sunlab Hours"], "word_count": 18, "token_count_estimate": 30}}, "https://cs.brown.edu/about/rooms/sunlab/": {"text_content": "The Sunlab CIT 143 The Sunlab is the primary facility for undergraduate computer science. It is the latest incarnation of a facility that first appeared in 1982. The machines in the Sunlab are equivalent to those used by graduate students, staff, and faculty, and are an integral part of the Computer Science Department network. For questions about usingaccessing the department computers, see the Sun Lab Consultant FAQ Schedule Work From Home Guides Windows Mac OS X Platform agnostic including Linux, nix, etc. Android Links for Working from Home FastX PuTTYgen and PuTTY XQuartz MobaXTerm WinSCP People Sunlab Consultants Head Consultants Other Information House Rules Computer System Policies", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "The Sunlab", "Schedule", "Work From Home Guides", "Links for Working from Home", "People", "Other Information"], "word_count": 107, "token_count_estimate": 138}}, "https://cs.brown.edu/about/system/accounts/email/": {"text_content": "Email Your Brown email is your CS email. The CS Department offers a mail forwarding service for addresses of the form shortID cs.brown.edu Where shortID is your Brown short ID aka logname or username. By default, this address forwards to your regular Brown email address. You can change that forwarding address to anything you like. Note that we do not provide alternate CS addresses to CS users - your address must be your University-issued short ID. Your CS address does not expire, ever. Change your email forwarding address At httpscs.brown.eduaccount you will have the opportunity to change your preferred email address as well as a few other personal items. You should login to that page using your ldap password. If you are already logged into the website, look for the profile icon in the lower right hand corner of the website upper right on the home page. Mailing Lists The Department runs its own email discussion lists . Beware of Phishing Phishing emails are bogus emails that try to trick you into giving away your personal info. Read the Phishing Primer provided by CIS IT service center.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "Email", "Change your email forwarding address", "", "Mailing Lists", "Beware of Phishing"], "word_count": 187, "token_count_estimate": 220}}, "https://cs.brown.edu/about/system/connecting/fastx/": {"text_content": "FastX FastX is a remote desktop service developed by StarNet Communications, which allows you to connect from your personal machine to our systems using a normal graphical interface as if you were sitting at a department machine. FastX also has far less network lag than using X forwarding over regular SSH. Detailed Instructions Follow the steps for setting up an ssh keypair. If you are running Windows, you will also need to install and run Pageant described under the Windows ssh instructions . Download and install the FastX 3 desktop client from httpswww.brown.eduinformation-technologysoftwarecatalogfastx-0 - CIS has a license for all of Brown, so the download links should appear after logging in. IMPORTANT We are now running FastX version 3 . Do not use the FastX version 2 client - the versions are incompatible. OSX users - Drag the FastX icon into your Applications directory to make it easier to find and run later. 32-bit Linux users - the Get FastX for Linux link will download a 64-bit binary. Contact problemcs.brown.edu for a copy of the 32-bit binary. Run FastX. Click the plus sign at the top right to add a new connection configuration. Youll be presented with two options, ssh and web. Select ssh. Fill out the form with the following information Name whatever you want Host fastx-cluster.cs.brown.edu Port 22 should be the default User your CS username Path fastx-protocol should be the default Forward Agent Connections check this if you are on Windows and running Pageant, otherwise leave unchecked Click Save after entering the above information. You might be presented with a warning that This host is not recognized by the system. Are you sure you want to continue Click Continue. This should create a new entry in the list. Double click on that - it should try to connect. Enter your key passphrase when prompted. If you have not previously logged into FastX, ssh, or any lab machine, or if you have recently changed your University password, you will also be prompted for your University password and Duo 2-factor auth. This should open a new window. You are now connected to FastX but have not created a session yet. The new window should present you with a few different session options GNOME, XFCE, or XTerm. If you dont know what these are, or dont have a preference between desktop environments, pick XFCE. Make sure Window mode is Single, then click OK. This should start a session on one of the virtual desktop machines in the FastX cluster, and open a window that looks like a normal desktop session. You might have to resize the window a bit. Other Issues If you have any issues not covered here, contact someone on the technical staff for help .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "FastX", "Detailed Instructions", "Other Issues"], "word_count": 458, "token_count_estimate": 558}}, "https://cs.brown.edu/about/system/accounts/passwords/": {"text_content": "Passwords With one exception, CS systems authenticate against the Universitys Active Directory, which means that your username and passsword are the same as for Banner, wifi, Workday, etc. If you need to reset your University password, go to httpsmyaccount.brown.edu . Here are three methods stolen from a Yale web page for creating passwords that are hard to guess yet easy to remember 1. Randomly pick alternating vowels and consonants. Throw in a digit or two or change a letter or two to a digit and punctuate. Mix up the case randomly capitalize for best effect. This will create passwords that have no meaning in the real world but which can still be sounded out e.g., Me1BopA. 2. Combine three and four character words with a punctuation character or digit between them, modify the case of some of the letter and change some of the others to digits or punctuation -- or add digitspunctuation to the beginning or end of the password e.g. 0YumfUn. 3. Randomly pick a book, poem or song. Select a phrase from the work and use the first character of each word in the phrase as your password. Capitalize some of the letters and add in at least one punctuation character and digit or change some of the existing letters to punctuation andor digits. For example, the phrase Four score and seven years ago our forefathers... might become 4s7YaOf.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "Passwords"], "word_count": 232, "token_count_estimate": 294}}, "https://cs.brown.edu/about/system/connecting/openvpn/": {"text_content": "OpenVPN A VPN Virtual Private Network provides a mechanism whereby a machine outside of the CS departments trusted network can securely access the departments resources. Typically, users connect to the VPN when they have access to a high speed internet connection, i.e. a cable modem or another university intranet, and require access to departmental resources which are not typically provided outside the firewall. Departmental VPN servers The department provides an OpenVPN server. This server has two configuration types available for download Browncs and Browncs-gateall. Browncs routes only traffic destined for a brown CS department IP through our VPN, leaving your computer to route other traffic as it sees fit. Browncs-gateall passes all traffic through the CS department. While browncs-gateall is not optimal for continual use, it does have some benefits over browncs - for example, if you wish to access Brown University Library services or other university-based web services. Setup Overview To use the Brown CS VPN, you will need to use your Brown account username and password this is the same account you use to log into CS Deparment Linux systems. After installing an appropriate OpenVPN client see OS specific instructions below download the Brown CS OpenVPN client certificate and config files . Configuration Files Use usernamebrowncs.ovpn when all you want to do is access Brown campus resources. Use usernamebrowncsgateall.ovpn when you want all network traffic to appear as though it originates from the CS department. This can be useful when accessing internet resources only available to Brown campus machines. The client certificates in these packages are specific to each user. Detailed Setup and Configuration Windows Instructions Mac OS X Instructions Linux Instructions Problems If youve followed the directions here and still cant connect to the departments VPN, then contact our technical staff for help.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "OpenVPN"], "word_count": 296, "token_count_estimate": 366}}, "https://cs.brown.edu/about/system/connecting/": {"text_content": "Connecting Remotely Internet access to the Brown Computer Science Department network is restricted by a firewall. The firewall protects our computers from outside attackers, but it also limits the ways legitimate users can access the department. This page describes how to get at department computing resources from outside the department. What does remote access let me do You can Work in a shell SSH or Mosh Connect through OpenVPN Read your email Display X client applications Run a remote desktop session using FastX Copy files to or from your CS account Mount department filesystems via Windows CIFS Access your home directory using VS Code requires an active VPN connection You cannot Mount department filesystems via NFS See the Remote Access page for information about connecting to the CS Department. See Connecting in the CIT page for information about access from within the CIT building. How to connect to the department and your home directory using VS Code Have an active VPN connection. Open VS Code and select the Remote Explorer icon in the left sidebar. Note that you need Microsofts Remote - SSH extension installed to see this Hover your cursor over SSH TARGETS or whatever text is below Remote and select the icon. Type yourbrownusernamefastx-cluster.cs.brown.edu Note that we expect you to have setup SSH through the department already as using VSCode requires you to have SSH key authentication. If this doesnt automatically start a SSH session, you need to then specify a remote window. If you click on the bottom left-hand corner, it should say start remote window and you can then choose if you want to create a new one or use the current window. If VSCode is saying Connection failed when it looks like you are connecting normall inside the terminal, you need to add ConnectTimeout 30 into your ssh config under the fastx host. Awesome, you should be connected now congrats Now, lets access your home folder as your default directory. Select the Explorer icon in the left sidebar. Select the blue button Open Folder. Select your home folder from the modal windo w VSCode for Windows Users If you are using Windows, you may need to do some extra steps to get this working. Please see the general VSCode extension guide for a further reference. You will need the OpenSSH client installed for Windows, which you can install using these instructions . Further, if youve used PuTTY you will need to convert your PuTTY key into an OpenSSH compatible key which you can do following these instructions .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "Connecting Remotely"], "word_count": 423, "token_count_estimate": 484}}, "https://cs.brown.edu/about/rooms/mslab/": {"text_content": "The MLab Schedule", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "The MLab", "Schedule"], "word_count": 3, "token_count_estimate": 4}}, "https://cs.brown.edu/about/system/connecting/ssh/": {"text_content": "SSH Ssh Secure Shell is a program used for logging onto a remote machine or for executing commands on a remote machine. It provides secure encrypted communications between two hosts over an unsecured network. X11 connections and arbitrary TCPIP ports can also be forwarded over the secure channel. Keypair Authentication You will need to upload public keys for each device you wish to use to connect to the CS department. You can upload keys to your CS website profile page . The first time you log in to ssh, after entering the passphrase associated with your ssh key, you will need to enter your University password and do Duo 2-factor authentication. On subsequent logins, you will only need to enter the key passphrase until you change your University password. Detailed Step-by-Step Guides Windows instructions Mac OS XLinux instructions Android instructions Problems If youve followed the directions here, looked at the detailed instructions, and still cant get in, contact someone on the technical staff for help .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:17+00:00", "headings": ["Information for:", "SSH", "Keypair Authentication", "Detailed Step-by-Step Guides", "Problems"], "word_count": 166, "token_count_estimate": 192}}, "https://cs.brown.edu/about/system/ergo/": {"text_content": "Ergonomics This page contains information on Repetitive Strain Injury RSI, ergonomic advice, and resources available in the Brown community. The advice here should not be used in lieu of contacting a medical professional. Additional resources are available in the Department of Computer Science through the ergo merc we have a pool of keyboards and mice that you can use to evaluate before buying and lots of practical advice on RSI prevention, treatment, insurance difficulties, etc. Please email the ergo merc currently Ben Abbatematteo if you have any questions or need assistance. Useful links What is RSI What you should do if you feel pain Prevention Treatment and recovery A special note on laptops List of ergonomic equipment in the pool Books, links, and other resources Brown Resources Brown University Safety Specialist, Stephanie Santucci 401 863-1522 Brown Health Services 401 863-3953 Student and Employee Accessibility Services 401 863-9588 Brown Psychological Services 401 863-3476 Office of Insurance and Purchasing Services 401 863-9481 Environmental Health and Safety EHS 401 863-3353 Brown University EHS staff are available upon request to assess workstation ergonomic needs for Brown faculty, staff and students. They are also available to meet with departments proactively to provide Office Ergonomics Training. EHS offers a guide to Sit Stand Adjustable Workstation Guidance. Quick Healthy Working Tips Modifying your behavior to practice healthy work habits along with regular work breaks, described here will vastly help you prevent and recover from typing injury. Take the time to look down at your hands occasionally to make sure your forearms are in neutral, prone positions straight lines, as depicted below and not twisted or bent. It can take weeks or months to re-train yourself, but this process is essential to preventing pain and injury.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Ergonomics"], "word_count": 288, "token_count_estimate": 369}}, "https://cs.brown.edu/about/system/services/printing/printers/": {"text_content": "Printers The department maintains several printers located in the CIT. Department etiquette dictates that large printouts be queued early in the morning or late at night, unless its an urgent need Please read the Printer Use Policy to ensure you are making appropriate use of the department printers. See the printing page for information how to print from Linux, Windows, and Mac NOTE Printing and printer installs over Wi-Fi must be done while connected to our . For instructions on setting up vpn access, please see our . The CS print server, printhost.cs.brown.edu, has the following printer queue names Printer Queue Name Printer Model Room Number Capability BW1 HP LaserJet 600 M603 143 - Sunlab Double-sided BW Paper BW2 HP LaserJet P3015 271 - TA room Double-sided BW Paper, Letterhead BW2-205 HP LaserJet M604 205 Double-sided BW Paper BW3 HP LaserJet M604 350 - hallway Double-sided BW Paper BW4 HP LaserJet Enterprise M608 480 - copy room Double-sided BW Paper BW5 HP LaserJet P4015 548 Double-sided BW Paper, Letterhead C3 HP Color LaserJet CP4025 350 - hallway Double-sided Color Paper C4 HP Color LaserJet CP4025 480 - copy room Double-sided Color Paper C4HQ HP Color LaserJet 4700 470 Double-sided Color Paper CLF4HQ HP Color DesignJet Z5200 480 Single-sided Color Coated Paper Roll C5 HP Color LaserJet CP4025 548 Double-sided Color Paper CCMB-C2-243 HP Color LaserJet MFP M476dn 243 Double-sided Color Paper CCMB-C2-247 HP Color LaserJet MFP M476dw 247 Double-sided Color Paper SciLi-BW HP LaserJet 600 - M601 SciLi 802 Double-sided BW Paper More details The BW Laserjets are 24 page-per-minute high quality printers. They are also duplex printers, providing two-sided printing. The names in the first column are valid names for use with the -P option to the printer commands lpr1, lpq1, and lprm1. Wi-Fi printing should be done over vpn . For instructions on setting up vpn check out this page. Restrictions The clf4hq print queue is a restricted print queue for faculty and graduate students only. The clf4hq printer is a large format printer capable of printing 42 width image.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Printers"], "word_count": 342, "token_count_estimate": 491}}, "https://cs.brown.edu/about/system/help/": {"text_content": "Help Problem Sometimes, things break. When they do, its nice to have someone to call. Tstaff maintains a problem resolution system. Each day, a member of the technical staff responds to all system problems. That person is responsible for resolving each problem, or forwarding it to someone who can. To contact the designated problem person, send email to problemcs.brown.edu . Submitting a Problem Ticket When sending an email to problem, please include the following information. This will greatly aid us in fixing your problem quickly and completely. If its an urgent situation, please call the tstaff cell phone which is available during University business hours - 401-316-2334 The name of the machine The OS of the machine which has the problem e.g. Windows 10,Linux The software packages being used e.g. Chrome, Office, OpenVPN Is the problem transient or repeatable If possible, specific steps to reproduce the problem Software Problems Some software is supported by tstaff, and some isnt. See software support page for details. Supported Software Users with software problems should first try to resolve their problems with the man pages provided with the operating system or specific software package, or with the hardcopy documentation. If the problem cannot be resolved by this approach, send mail to problem . Unsupported Software For help with unsupported software see section Unsupported Software ask the owner of the program. Hardware Problems Some hardware is supported by tstaff, and some isnt. The few remaining Suns, all tstaff-built PCs MaxBuilt running Windows or Linux, all networking see the self-managed network , and the printers see printers are supported by tstaff. Supported Hardware If the problem is a hardware problem ie. frozen workstation, jammed printer, etc. send mail to problemcs.brown.edu . Users are not to attempt hardware repairs themselves. Unsupported Hardware For help with unsupported hardware, contact the machines owneradministrator. forum.cs.brown.edu under service Tstaff is developing an instance of discourse that will be accessible to anyone with a brown login. Some features and resources available through forum FAQs run by tstaff and sunlab consultants for common issues faced. Announcements and updates from tstaff People can post about any questions they have or issues they encounter Members of the community can post and respond to each other to share information Forum exists as a space for the cs community to connect online. For more information on how to use the site and what the different categoriesterms mean, the discourse staff put together an extensive guide on getting used to the site. Additional questions can also be directed to tstaff via emailing problem or posting on discourse.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Help"], "word_count": 429, "token_count_estimate": 521}}, "https://cs.brown.edu/about/system/managed/latex/": {"text_content": "The LaTeX Page For the impatient Packages alphabetically Local FAQ General TeX FAQ Welcome to the LaTeX page Here you will find information about the TeX setup at the Computer Science Department at Brown University, available commands and how to use them, LaTeX primers and package documentation, and pointers to other useful TeX-related sites on the Web. Warning These pages contain no LaTeX source or distribution packages, only documentation. If you are running LaTeX on non-departmental machines note that some of the information may not be applicable to your installation. Our TeX Setup The currently installed version of TeX is 3.14159 as provided by the Web2C-7.4.5 distribution. The supported version of LaTeX is the 2001 version of LaTeX2e LaTeX2e is the recommended version of LaTeX, and the older version LaTeX 2.09 is obsolete. Public files are organized in a tree structure that obeys the TDS standard . Our TDS tree is rooted at usrsharetexmf . If you have LaTeX input files of your own, you should define the TEXINPUTS environment variable in your startups. This variable contains a colon-separated list of directories with inputs for latex2e . You do not need to include the system directories on this list, just your own directories the initial colon provides that the system directories are included. In csh you would need something like this setenv TEXINPUTS .your latex2e directory 1your latex2e directory 2... Collaborative LaTex Editing The department is working with the library to pilot a test of ShareLaTex httpswww.sharelatex.com , an online, collaborative LaTex editor. If you are interested in having access to the system, please email problemcs.brown.edu and provide your brown.edu email address. TeX-related Commands tex - plain TeX latex - Same as latex2e, see below xdvi - DVI previewer for X The online documentation for xdvi only available as a unix man page and is not provided in the teTEX documentation. Use man xdvi to read it. dvips - convert a DVI file to Postscript makeindex - a general purpose, formatter-independent index processor bibtex - make a bibliography for LaTeX see also bibtex texinfo - a macro package for TeX used by the GNU system for producing printed manuals tib -another way to create bibliographies for LaTeX available on our Solaris machines, please see the man page for documentation mf - the metafont program for generating fonts mp - the metapost program for generating Postscript figures latex2html - convert LaTeX files to HTML xfig - X11 drawing program can generate LaTeX figures in a variety of formats lgrind - produce nice program listings using LaTeX Local FAQ Questions that we find ourselves answering often are here . Primers The canonical documentation for LaTeX may be found in these books The TeXbook , by Donald Knuth The original book describing the guts of the system, written by the guy who wrote TeX in the first place. LaTeX A Document Preparation System , by Leslie Lamport , Addison-Wesley, 2nd ed, 1994. Leslie Lamport originally wrote LaTeX this book is the book to buy to learn LaTeX. The second edition documents LaTeX2e. The LaTeX Companion , by Goossens, Mittelbach and Samarin, Addison-Wesley, 1994. Written by members of the LaTeX3 project, it describes further how to use LaTeX2e and documents additional classespackages. A Guide to LaTeX , by Kopka and Daly, Addison-Wesley, 1999. This book is a more recent one and offers considerably more information than the earlier books. Useful on-line primers include The Not So Short Introduction to LaTeX2e A longer 87 pages more in-depth introduction to LaTeX2e. Also a good starting point. LaTeX Command Reference Manual Describes all LaTeX2e commands. Dont expect to learn LaTeX from this. Symbols in LaTeX A six page list of available mathematical symbols. A LaTeX Surivical Guide for Unix Systems This document describes how to run LaTeX and utilities on a Unix system. Including Graphics in LaTeX2e Documents Everything you ever wanted to know about using Postscript graphics in LaTeX documents. Packages in the graphics bundle This provides a documentation on the recommended LaTeX2e graphics package, which includes information on how to use colours in the output. HTML documentation of many LaTeX topics at NASA. Documentation LaTeX2e Users Guide , class and package authors guide and font guide . LaTeX2e packages AMSLaTeX and the AMS fonts Babel Packages in the graphics bundle The PSfrag system PSfrag system allows you to import PostScript figures from any other package, but use LaTeXs power for all of the mathematical and textual annotations. Note that xfig allows you to do this anyway. Creating graphics with MetaPost Creating graphics with PSTricks part1 , part2 , part3 , part4 XY-pic user guide and reference manual Using BibTeX and writing BibTeX styles Creating custom BibTeX styles with makebst Creating indices with makeindex Pretty-printing with lgrind Brown PhD thesis class file Brown Honors thesis class file Brown letterhead class file , logo , example letter Brown PhD and Honors thesis class files are available on the CS Dept intranet only Other TeX-related Resources on the Web LaTeX Navigator A Collection of Computer Science Bibliographies BibTeX TeX, LaTeX, etc. FAQ Credit where its due These pages were originally created and maintained by Dimitris Michailidis and Manos Renieris.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "The LaTeX Page", "Our TeX Setup", "Collaborative LaTex Editing", "TeX-related Commands", "Local FAQ", "Primers", "Documentation", "Other TeX-related Resources on the Web"], "word_count": 861, "token_count_estimate": 1123}}, "https://cs.brown.edu/about/system/services/printing/policy/": {"text_content": "Printing Policy bw1 All printing from undergraduate accounts as well as any course related listings should be directed to the Sunlabs HP laserjet printer bw1. Printing should be picked up immediately. Undergraduate Printing Policy You must be in the Sunlab or MSlab when printing. You must be standing in front of the printer when your job is printing. You may print only CS course-related work. You must keep the length of your printouts under 20 pages. Any printout that does not meet these requirements should be printed to a CIS printer. This policy will be enforced by the Sunlab consultants, and repeat violators will lose printing access. Other printers The departments other laserprinters both BW and color, may only be used by the following people Faculty, staff and graduate students in support of the departments research and administrative efforts. Course TAs producing course-related materials. You can find a list of printers here. See the wiki for instructions on printing.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Printing Policy"], "word_count": 159, "token_count_estimate": 192}}, "https://cs.brown.edu/about/system/services/printing/": {"text_content": "Printing Departmental printers can be accessed via our print server print.cs.brown.edu . You can access this print server from any departmental network, or wirelessly when connected through the CS VPN . It h osts a variety of print queues for all the department network printers . See the printing policy for usage limitations. BonjourDNS Available Printers Most Apple products will detect printers that are shared to the network using mDNS packets that adhere to the Bonjour standard. Those network packets provide details about the devices available on the network, for easy installation or access. In accordance with this feature we offer the following printers, which show up automatically when a host is wired to our network or connected to our VPN. BW1 C4 BW2 C4HQ BW2-205 C5 BW3 CCMB-C2-243 BW4 CCMB-C2-247 BW5 CLF4HQ C3 SciLi-BW For WIndows users, the names above should be used with windows add. i.e. c4windows When adding an auto-discovered printer it is important to note that capitalization and the name itself must be identical to the list above. If you do not see a printer that is listed above or the name is in any way different form that list, please visit the printer page on our cups server to get the official list of printers being offered by our server. httpsprint.cs.brown.edu631printers Printing in the Sunlab See the Printing in the Sunlab page for more information. Tstaff Managed Systems All managed department machines are configured to use the internal print server. No user configuration is required. Linux As with many things in Linux, there are quite a few printing commands . Some of the most important are lpstat -a show the list of printers available on the print server lpr send a file in text, postscript or pdf format to the printer Viewing the current jobs in a Linux print queue You can view the current jobs in a Linux print queue by running lpq -Pprint queue, where print queue is the name of the queue e.g. bw4. The command will return something similar to bw4 is ready and printing Rank Owner Job Files Total Size active esatoh 373926 smbprn.00001934 httpslibrary 76622848 bytes 1st esatoh 373927 smbprn.00001935 httpslibrary 21590016 bytes Windows In Windows, most programs let you print from the File-Print menu of that application. To see the list of printers, go to the Start Menu, select Control Panels, and then Devices Printers. All printers are available except for the clf4hq printer. Self Managed Systems Printer Mapping Instruction for Self Managed System or over Wireless network Windows Please only use printer names ending in windows. i.e. c4windows Mac OS X HP driver pack for Mac OS Mavericks and newer can be found here httpssupport.apple.comkbdl1888 Linux Other Printing Issues If you encounter a physical problem with a printer jammed, out of toner or ink, etc and have not been trained in how to fix the problem, please do not try to guess your way through. Use the problem facility to report the trouble, or ask a Tstaff member or one of those friendly veteran grad students. Theyll show you how to fix it for the next time. Be especially hesitant to mess with the color printers. If your printout is on the wrong type of paper Occasionally, if you specify a certain type of paper and that tray is empty, the printer will automatically default to a different paper tray. If your printout ends up printed on a different type of paper than you expected, you might want to check the paper trays and make sure none of them are empty. How to print an A4 sized PostScript file Our printers print only on US Letter sized paper. Most European countries print on A4 sized paper, which is taller and narrower. Electronic documents formatted for A4 often will not print properly, or at all, on our printers. When printing an A4 document from a browser or application on any platform, it will be helpful to preview it and, if necessary, to scale it down before sending the job to the printer. The easiest way around this is to transform the A4-size document into a Letter-size document before printing it. How you do this depends on the format the document is in. If, for example, the document is a Framemaker document, you may find it easiest to reformat the document in Framemaker. The same goes for Microsoft Word, or Acrobat or many other document formats. How to print an A4 sized PostScript file in Linux In Linux, you can reformat any A4 postscript document using the following simple command. Most desktop publishing applications let you save a document as PostScript, usually from the Print menu. If the document is already in PostScript format, or if you cannot reformat it in some other way, try this. Lets say our A4 document is called euro.ps mpage -1o euro.ps amer.ps lpr amer.ps The resulting file, amer.ps, is in US Letter format.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Printing", "Printing in the Sunlab", "Tstaff Managed Systems", "Self Managed Systems"], "word_count": 820, "token_count_estimate": 1043}}, "https://cs.brown.edu/about/system/services/hpc/": {"text_content": "Hydra Compute Cluster Hydra is a mythical multi-headed monster Hydra is the CS Department compute cluster for use by our faculty, staff, and students. Jobs are submitted to our cluster using the Slurm workload manager . We provide a slurm quick-start guide . Community There is an active group of researchers within the department working on computationally intensive research. The department continually tries to meet the needs of all researchers, by periodically adding new dedicated compute hardware. We encourage anyone involved in research requiring high performance computing to join the compute mailing list . Doing so will help you stay abreast of the latest compute-related changes within the department, and allow you to collaborate and exchange ideas with other cluster users. Policy and Appropriate Use The cluster is a general department resource and is available to all members of the CS community. Cluster users should only run jobs associated with legitimate research or educational activities. The cluster is a specialized tool, and should not be used to simply off-load normal desktop computing activities. If you are unsure if a proposed use of the cluster is appropriate, send mail to problemcs.brown.edu and tstaff will render an opinion. CCV Cluster Resources The Center for Computation Visualization has a large linux compute cluster which they make available to researchers across campus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "Hydra Compute Cluster"], "word_count": 218, "token_count_estimate": 250}}, "https://cs.brown.edu/about/system/services/cshe/": {"text_content": "CS Home Edition The CS Department runs on Linux . Brown CS has used a common platform for teaching and research almost as long as it has existed. Department desktops, servers, and hosted systems all share a standard operating system and configuration. CS Home Edition builds on this tradition by making it easy to recreate that platform on your own computer. How to Download and Install CS Home Edition Features What CS Home Edition adds to Linux Simplified installation with sensible defaults Perfect version match with CS Department OS and software Nightly updates to keep you in sync with the department Preconfigured access to department services Automated Brown user identity Requirements CS Home Edition can be run on any intel-based computer and as a virtual machine. A target system. This can be VirtualBox recommended for most Parallels recommended for M1 Mac VMWare Fusion Windows Hyper-V Your own hardware i.e., a bootable USB drive At least 32G of disk space Internet service Getting Help Send mail to problem CS Home Edition is a new idea to help support remote learning and research environments. It is under active development by the CS Technical Staff.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:18+00:00", "headings": ["Information for:", "CS Home Edition", "Features", "Requirements", "Getting Help"], "word_count": 192, "token_count_estimate": 217}}, "https://cs.brown.edu/about/system/services/printing/mac-os-x/": {"text_content": "Mac OS X Instruction Printing and printer installs over Wi-Fi must be done while connected to our vpn . For instructions on setting up vpn access, please see our vpn setup page . Mapping a Printer from the CS Print Server Mac OS users should install the HP Driver pack from Apple before attempting to use one or our shared printers. For Mac OS Mavericks and newer, the driver pack can be found here httpssupport.apple.comkbdl1888 For the advance Mac users, here is the basic the printer connection info you need Protocol IPP Address print.cs.brown.edu631 Queue printersqueue name where queue name is the queue on the print server i.e. bw4 Name printer name i.e. BW4 Detailed Instructions 1. Log on to Mac OS with an account with adminroot privilege try current login if unsure. 2. Click on the Apple icon on the upper left corner of the screen. 3. Select the System Preferences from the menu list. 4. Click on the Printers and Scanners icon. 5. If you have old CS printers mapped that are no longer working click the minus symbol to remove them before proceeding. On the Printers and Scanners dialog box, click on the plus sign near the bottom left hand corner of the dialog box to add a printer. 6. On the Add dialog box, click on the IP icon. 7. In the Address section, enter the print.cs.brown.edu631 without the quotes. 8. The Protocol section should be set to Internet Printing Protocol - IPP. 9. In the Queue section, enter printersqueue name where queue name is the print queue on the print server i.e. printersbw4 for the bw4 printer. 10. In the Name section, enter a name for the printer connection i.e. BW4 for the bw4 printer. 11. In the Use section, choose Select Software to pick the correct printer driver for the printer connection. See the printers page for the exact printer model. Pick the driver closest to the printer model i.e HP LaserJet P4010 for BW4 or BW5, going with the Series driver when the exact model is not available. 12. Click on the Add button to continue with the printer connection wizard. The printer setup will ask you to select some settings. The duplex unit or duplexing option should be selected to enable two sided print jobs. All CS printers, except CLF4HQ, have duplexing units. The other default options are sufficient. 13. Click OK to finish adding the printer. If you get a warning message stating something similar to Unable to verify the printer on your network click on the continue button to proceed.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Mac OS X Instruction"], "word_count": 430, "token_count_estimate": 542}}, "https://cs.brown.edu/about/system/services/printing/linux-tips/": {"text_content": "Linux Tips Self Managed Systems On a self managed linux system, the easiest to connect to the printhost server is to use cups client. Depending on your flavor of linux and architecture, you use either aptitude or yum to install the cups-client packages as follows Run as root aptitude install cups-client or Run as root yum install cup.x8664 Once the cup client is installed. Modify the etccupsprinters.conf file as follows ServerName printhost.cs.brown.edu You will need to authenticate with your LDAP credential every time you print if your local username and password is different than what the printhost server is expecting. Command Line Printing The command lpr1 sends a file to a printer. The CUPS version of lpr understands a variety of formats including, text, PostScript, and PDF. Many GUI programs, such as Mozilla and Acrobat, will print by passing arguments through LPR. Usually you can see the command the program will use after selecting Print from the File menu. Your default printer is specified by your shells PRINTER environment variable. For new users, this is set to bw1 in the .environment file in your home directory. To change your default printer, modify your PRINTER environment variable in the appropriate location. Setting Print Options on the Command Line For the common tasks of printing single-sided, on letterhead, and on transparency, we have modified the command-line lpr program to accept -s, -l, and -t, respectively. The full feature command set for CUPS are listed below and is available from man lpr. Some common printer options Printing non textpostscript documents from the command line lpr acrobatdoc.pdf Printing to a certain printer i.e. bw4 lpr -Pbw4 mydocument Setting the Custom paper size to 42.1 x 42.1 inches lpr -o mediaCustom.42.1x42.1in mydocument Setting Duplex Printing two-sided-long-edge is default lpr -o sidesone-sided mydocument lpr -o sidestwo-sided-long-edge mydocument lpr -o sidestwo-sided-short-edge mydocument Setting the media type duplex is on by default, so turn it off lpr -o mediaTransparency -o sidesone-sided mydocument lpr -o mediaLetterhead -o sidesone-sided mydocument Print on Letterhead for first page, Plain for remaining pages lpr -o sidesone-sided -o 1mediaLetterhead -o mediaPlain mydocument Print multiple document pages on a printed page N-Up lpr -o number-up2 mydocument lpr -o number-up4 mydocument Print only odd or even pages lpr -o page-setodd mydocument lpr -o page-seteven mydocument Print page ranges lpr -o page-ranges5 mydocument lpr -o page-ranges2-5 mydocument lpr -o page-ranges2-5,7-9 mydocument Rotate page lpr -o landscape mydocument Set the percentage brightness lpr -o brightness120 mydocument Set the Gamma correction 1000 is default lpr -o gamma1700 mydocument Print multiple copies lpr -n num copies -o collateTrue mydocument Text Printing Options lpr -o prettyprint mydocument.txt lpr -o cpi10 mydocument.txt lpr -o lpi8 mydocument.txt lpr -o columns2 mydocument.txt Setting Page Margins in 172s of an Inch lpr -o page-left72 -o page-right72 -o page-top72 -o page-bottom72 mydocument.txt Image Printing Options lpr -o positioncenter myimage center,top,left,right,top-left,top-right, bottom,bottom-left,bottom-right lpr -o scaling100 myimage 1-800 lpr -o ppi300 myimage dots per inch lpr -o hue-10 myimage -360 to 360 lpr -o saturation110 myimage 0-200 Setting Default Options The printing options above can also be used to set default options for future print jobs. Use the lpoptions command with the same arguments above. The options will be saved in the .lpoptions file in your home directory. The following example will set 12 margins and make text smaller lpoptions -o page-left36 -o page-right36 -o page-top36 -o page-bottom36 lpoptions -o cpi12 lpoptions -o lpi7 To get all available options for a specific printer lpoptions -p printer name Cancelling Jobs To cancel a job, use lprm and enter your LDAP password. Note that you have to cancel the job on the same printer you sent it to, specified with the -P option example lprm -P bw5. Each time you run lprm it deletes one job unless you give - as the last argument, in which case it deletes all your jobs. Graphically Setting Print Options To set printer options graphically, you may use the gtklp1 command instead of lpr in exactly the same manner. After you click Print in your application, a tabbed window will pop up where you can set options such as letterhead and single-sided printing in a point-and-click manner. Most of the useful options are on the General tab. By default, changes to the options presented in gtklp apply only to the current print job and not to subsequent print jobs. If you have a set of options that you wish to be able to reuse easily in the future, you can click on Templates at the bottom. To permanently change your default options for this printer, simply click Save. To save a set of options for this printer that you only want to use occasionally, type a name for this set in the box labeled Instance, and then click New. You can modify or remove these named sets of options later by clicking Templates later.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Linux Tips"], "word_count": 810, "token_count_estimate": 1188}}, "https://cs.brown.edu/about/system/services/printing/windows-instruction/": {"text_content": "Windows Instruction Mapping a printer on the Authenticated Printing Server IMPORTANT Windows users can only use the printers with names ending in windows. i.e. c4windows Follows these step to map a printer located on the authenticated print server. 1. Log on to the Windows system with local admin credential. 2. Click on the Start menu and choose Devices and Printers. 3. Click on the Add a printer button at the top menu item. 4. Click on the Add a network, wireless or Bluetooth printer menu item. 5. Click on The printer that I want isnt listed menu item. 6. Choose Select a shared printer by name and enter the printer mapping using IPP. Here is an example for bw5windows httpsprinthost.cs.brown.edu631printersbw5windows For Windows, only the printers with names ending in windows can be used for a list of printers browse to httpsprinthost.cs.brown.edu631printers 7. Click on the Next button. 8. Enter LDAP credential when prompted. Click on the Ok button to continue. 9. Choose the correct printer driver for the printer. 10. Click on the Next button to accept printer name. 11. Uncheck the Set as the default printer box. 12. Click on the Finish button.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Windows Instruction", "Mapping a printer on the Authenticated Printing Server"], "word_count": 194, "token_count_estimate": 268}}, "https://cs.brown.edu/courses/cs016/static/files/docs/cs0160.sty": {"text_content": "This is file fancyvrb.sty, generated with the docstrip utility. The original source files were fancyvrb.dtx with options fancyvrb IMPORTANT NOTICE For the copyright see the source file. Any modified versions of this file must be renamed with new filenames distinct from fancyvrb.sty. For distribution of the original source see the terms for copying and modification in the file fancyvrb.dtx. This generated file may be distributed as long as the original source files, as listed above, are part of the same distribution. The sources need not necessarily be in the same archive or directory. Package fancyvrb COPYING The files of this package fancyvrb are released under the Artistic License Version 2. A copy of that license is included in the file artistic2.txt. The package consists of the following files README artistic2.txt fancyvrb.cb fancyvrb.dtx fancyvrb.ins Timothy Van Zandt July 17, 1998 COPYRIGHT 1992-1999, by Timothy Van Zandt This package may be distributed under the terms of the LaTeX Project Public License, as described in lppl.txt in the base LaTeX distribution. Either version 1.0 or, at your option, any later version. DESCRIPTION fancyvrb.sty is a LaTeX style option, containing flexible verbatim environments and commands and extensive documentation. This is a companion to the fancybox package.NeedsTeXFormatLaTeX2edeffileversion2.7a, with DGSPQR fixes, and firstlinelastline fixdeffiledate20080207ProvidesPackagefancyvrbfiledatemessageStyle option fancyvrb vfileversion space filedate tvzcsname fancyvrbloadedendcsnameletfancyvrbloadedendinputdefFVError12 edeftempc2expandaftererrhelpexpandaftertempc errmessageFancyVerb ErrorJspacespace 1JdefFVehaYour command was ignored. Type to continue. DGSR modification begin - Jan. 21, 1998 Suggested by Bernard Gaulle to solve a compatibility problem with french it introduce the restriction to put VerbatimFootnotes AFTER the preambuledefVerbatimFootnotesletfootnotetextVfootnotetextletVfootnotefootnotedefVerbatimFootnotesletfootnotetextVfootnotetextletfootnoteVfootnote DGSR modification endlongdefVfootnotetext afterassignmentVfootnotetext lettempadefVfootnotetext insertfootinsbgroup csname resetfontendcsname footnotesize interlinepenaltyinterfootnotelinepenalty splittopskipfootnotesep splitmaxdepthdpstrutbox floatingpenalty MM hsizecolumnwidth parboxrestore edefcurrentlabelcsname pfootnoteendcsnamethefnmark makefntext rulezfootnotesep bgroup aftergroupVfootnotetext ignorespacesdefVfootnotetextstrutegroupRequirePackagekeyvaldefdefinebooleankey1234 namedefKV12default3 namedefKV12false4 namedefKV121KVbooleankey112defKVbooleankey123 edeftempa1expandafterKVbooleankeytemparelaxnil23defKVbooleankey12nil34 nameuseKV34if t1defaultelseif T1defaultelse falsefifidefFVNonenonedefFVAutoautodeffvset1setkeysFV1defFVCommand12 ifstar defFVKeyValues1,showspacesFVCommand2 defFVKeyValues1FVCommand2defFVCommand1 ifnextchar FVGetKeyValuesnameuseFVC1 nameuseFVC1defFVGetKeyValues12 expandafterdefexpandafterFVKeyValuesexpandafterFVKeyValues,21defCustomVerbatimCommand1234 begingroupfvset4endgroup If there are errors, it easier to locate. DGSR modification begin - Jan. 13, 1998 deftempa12nildeftempa2 expandaftertempastring3emptynil ifundefinedFVCtempa ifundefinedFVC3 DGSR modification end FVErrorCommand string3 is not a FancyVerb command.eha 12FVCommand43defCustomVerbatimCommandCustomVerbatimCommandnewcommanddefRecustomVerbatimCommandCustomVerbatimCommandrenewcommanddefFVEnvironment12 defFVKeyValues1 catcodeMactive ifnextchar catcodeM5 FVGetKeyValuesnameuseFVB2 catcodeM5 nameuseFVB2defCustomVerbatimEnvironmentCustomVerbatimEnvironmentnewenvironmentdefRecustomVerbatimEnvironmentCustomVerbatimEnvironmentrenewenvironmentdefCustomVerbatimEnvironment1234 begingroupfvset4endgroup If there are errors, it easier to locate. ifundefinedFVB3 FVError3 is not a FancyVerb environment.eha 12FVEnvironment43nameuseFVE3 12FVEnvironment4,showspaces3nameuseFVE3defDefineVerbatimEnvironment123 namedef1FVEnvironment32 namedefend1nameuseFVE2 namedef1FVEnvironment3,showspaces2 namedefend1nameuseFVE2defFVUseKeyValues ifxFVKeyValuesemptyelse defKVprefixKVFV expandafterKVdoFVKeyValues,relax, defFVKeyValues fidefFVCatCodes letdomakeotherdospecials The usual stuff. FVActiveWhiteSpace See below. FVFontScanPrep See below. FVCatCodesHook A style hook. FancyVerbCodes A user-defined hook.defFVActiveWhiteSpace catcodeMactive End of line catcode active Space catcodeIactive TabdefFVCatCodesHookdefFVAddToHook12 expandafterdefexpandafter1expandafter12relaxdefinekeyFVcodesdefFancyVerbCodes1relaxdefinekeyFVcodes expandafterdefexpandafterFancyVerbCodesexpandafter FancyVerbCodes1relaxfvsetcodesdefinekeyFVcommandchars deftempa1 ifxtempaFVNone letFVCommandCharsrelax else FVDefineCommandChars1relaxrelaxrelax fidefFVDefineCommandChars123 defFVCommandChars catcode10relaxcatcode21relaxcatcode32relaxFVAddToHookFVCatCodesHookFVCommandCharsdefinekeyFVcommentchar deftempa1 ifxtempaFVNone letFVCommentCharrelax else defFVCommentCharcatcode114 fiFVAddToHookFVCatCodesHookFVCommentCharfvsetcommandcharsnone,commentcharnonedefinekeyFVfirstline afterassignmentFVParseStarttempcnta01relaxnil1defFVParseStart1relaxnil2 ifxnil1nil edefFancyVerbStartNumthetempcnta letFancyVerbStartStringrelax else edefFancyVerbStartString2 fidefKVFVfirstlinedefault letFancyVerbStartNumz letFancyVerbStartStringrelaxdefinekeyFVlastline afterassignmentFVParseStoptempcnta01relaxnil1defFVParseStop1relaxnil2 ifxnil1nil edefFancyVerbStopNumthetempcnta letFancyVerbStopStringrelax else edefFancyVerbStopString2 fidefKVFVlastlinedefault letFancyVerbStopNumz letFancyVerbStopStringrelaxfvsetfirstline,lastlinenewcountFVCodeLineNodefFVPreProcessLine globaladvanceFVCodeLineNone FVFindStartStopdefFVPreProcessLine FVStepLineNo FVGobble expandafterFVProcessLineexpandafterFVLinedefFVFindStartStopFVDefineFindStartFVFindStartStop defFVDefinePreProcessLine setcounterFancyVerbLine0 FVDefineFindStartdefFVDefineFindStart ifxFancyVerbStartStringrelax ifnumFancyVerbStartNumtw FVDefineFindStop else letFVFindStartStopFVFindStartNum fi else letFVFindStartStopFVFindStartString fidefFVFindStartNum ifnumFancyVerbStartNumFVCodeLineNoelse FVDefineFindStop expandafterFVPreProcessLine fi SR modification begin - 1996defFVFindStartString expandafterFVFindStartStringmeaningFVLinemeaningFancyVerbStartStringdefFVFindStartString12edeffooA1edeffooB2 ifxfooAfooB FVDefineFindStop fi SR modification enddefFVDefineFindStop ifxFancyVerbStopStringrelax ifnumFancyVerbStopNumne letFVFindStartStopFVPreProcessLine else letFVFindStartStopFVFindStopNum fi else letFVFindStartStopFVFindStopString fidefFVFindStopNum ifnumFancyVerbStopNumFVCodeLineNo else letFVFindStartStoprelax ifeofFVInFileelse immediatecloseinFVInFile fi fi ifnumFancyVerbStopNumFVCodeLineNo else FVPreProcessLine fi SR modification begin - 1996defFVFindStopString expandafterFVFindStopStringmeaningFVLinemeaningFancyVerbStopStringdefFVFindStopString12edeffooA1edeffooB2 ifxfooAfooB letFVFindStartStoprelax ifeofFVInFileelse immediatecloseinFVInFile fi else expandafterFVPreProcessLine fi SR modification enddefFVGobble expandafterexpandafterexpandafterFVGobble expandafterFVGobbleFVLine nilnilnilnilnilnilnilnilnilnilnildefFVGobble1nil2nildefFVLine1definekeyFVgobble tempcnta1relax ifnumtempcntane letFVGobblerelax else ifnumtempcnta9 FVErrorgobble parameter must be less than 10FVeha else renewcommandFVGobbletempcnta letFVGobbleFVGobble fi fidefFVGobbledefKVFVgobbledefaultletFVGobblerelaxfvsetgobbledefFVScan FVCatCodes VerbatimEnvironment FVDefineCheckEnd FVBeginScanningdefVerbatimEnvironment ifxFVEnvironNamerelaxxdefFVEnvironNamecurrenvirfiletFVEnvironNamerelaxbegingroupcatcode0catcode1catcode2gdefFVCheckEndi1FVCheckEnd1endnilgdefFVCheckEndi1end23nildeftempa2deftempb3gdefFVCheckEndiendcatcode12gdefFVCheckEndii1FVCheckEnd1endnilgdefFVCheckEndii1end23nildeftempa2deftempb3gdefFVCheckEndiiendcatcode12catcode12gdefFVCheckEndiii1FVCheckEnd1endnilgdefFVCheckEndiii1end23nildeftempa2deftempb3gdefFVCheckEndiiiendcatcode0gdefFVCheckEndiv1FVCheckEnd1endnilgdefFVCheckEndiv1end23nildeftempa2deftempb3gdefFVCheckEndivendendgroupdefFVBadCodes1 FVError stringcatcodespace of expandaftergobblestring1 is wrong thecatcode1 Only the following catcode values are allowed Jspaces expandaftergobblestring spacespace -- 0 or 12. Jspaces string string -- 1 and 2, resp., or both 12. JTo get this error, either you are a hacker or you got bad advice. defFVCheckEnd1iftruedefFVDefineCheckEnd ifnumcatcodez ifnumcatcodene letFVCheckEndFVCheckEndi letFVCheckEndFVCheckEndi letFVCheckEndFVCheckEndi else ifnumcatcode12 letFVCheckEndFVCheckEndiv letFVCheckEndFVCheckEndiv letFVCheckEndFVCheckEndiv else FVBadCodes fi fi else ifnumcatcode12 ifnumcatcodene letFVCheckEndFVCheckEndii letFVCheckEndFVCheckEndii letFVCheckEndFVCheckEndii else ifnumcatcode12 letFVCheckEndFVCheckEndiii letFVCheckEndFVCheckEndiii letFVCheckEndFVCheckEndiii else FVBadCodes fi fi else FVBadCodes fi fibegingroupcatcodeMactive gdefFVBeginScanning1M deftempa1ifxtempaemptyelseFVBadBeginErrorfi FVGetLineendgroupdefFVBadBeginError1 expandaftertemptokenaexpandaftertempa FVError Extraneous input thetemptokena between stringbeginFVEnvironName and line end This input will be discarded. Hit to continue. DGSR modification begin - May. 18, 1998 added code to turn off ligatures defFVGetLineexpandafterFVCheckScanFancyVerbGetLinedefFVGetLinenoligsexpandafterFVCheckScanFancyVerbGetLine DGSR modification endbegingroupcatcodeMactivegdefFancyVerbGetLine1M nil FVCheckEnd1 ifxtempaFVEnvironName True if end is found ifxtempbFVCheckEndelseFVBadEndErrorfi letnextFVEndScanning else defFVLine1 defnextFVPreProcessLineFVGetLine fi nextendgroupdefFVBadEndError expandaftertemptokenaexpandaftertempb FVError Extraneous input thetemptokena between stringendFVEnvironName and line end This input will be discarded. Type to continue.defFVEndScanning edefnextnoexpandendFVEnvironName globalletFVEnvironNamerelax nextifundefinedcurrenvlineletcurrenvlineemptydefFVCheckScan1ifnextcharnilgobbleFVEOFdefFVCheckScan1ifxnil1emptyelseexpandafterFVEOFfidefFVEOF FVErrorCouldnt find stringendFVEnvironName to end a verbatim environmentcurrenvline. Probably you mistyped the environment name or included an extraneous Jspace, or are using an improperly defined verbatim environment. JHit return and I will try to terminate this job. FVEndScanning enddocument subsectionInputnewreadFVInFiledefFVInput1 immediateopeninFVInFile 1relax ifeofFVInFile FVErrorNo verbatim file 1FVeha immediatecloseinFVInFile else FVCatCodes expandafterFVInput fidefFVInput defFVLine FVReadLine ifeofFVInFile ifxFVLineemptyelse FVPreProcessLine fi immediatecloseinFVInFile else FVPreProcessLine expandafterFVInput fibegingroupcatcodeMactivegdefFVReadLine ifeofFVInFileelse immediatereadFVInFile totempa expandafterFVReadLinetempaMrelaxMnil figdefFVReadLine1M2M3nil expandafterdefexpandafterFVLineexpandafter FVLine1 ifxrelax2emptyexpandafterFVReadLinefiendgroupdefFVFormattingPrep globalFVCodeLineNoz frenchspacing Cancels special punctuation spacing. FVSetupFont See below. FVDefineWhiteSpace See below. FancyVerbDefineActive FancyVerbFormatCom A user-defined hook formatcom parameter.expandafterifxcsname selectfontendcsnamerelaxdefFVSetupFont FVBaseLineStretch ifxcurrsizesmallnormalsizeelsesmallficurrsize FVFontSize FVFontFamilyelsedefFVSetupFont FVBaseLineStretch FVFontSize FVFontFamily FVFontSeries FVFontShape selectfont DGSR modification begin - May. 18, 1998 added code to turn off ligatures noligs DGSR modification endfidefinekeyFVfontsize deftempa1 ifxtempaFVAuto letFVFontSizerelax else defFVFontSize1 fidefKVFVfontsizedefaultletFVFontSizerelaxdefinekeyFVbaselinestretchauto deftempa1 ifxtempaFVAuto letFVBaseLineStretchrelax else defFVBaseLineStretchdefbaselinestretch1 fidefKVFVbaselinestretchdefaultletFVBaseLineStretchrelaxdefinekeyFVfontfamily ifundefinedFVfontfamily1 defFVFontScanPrepdefFVFontFamilyfontfamily1 csname FVfontfamily1endcsnamedefinekeyFVfontseries deftempa1 ifxtempaFVAuto letFVFontSeriesrelax else defFVFontSeriesfontseries1 fidefinekeyFVfontshape deftempa1 ifxtempaFVAuto letFVFontShaperelax else defFVFontShapefontshape1 fidefFVMakeActive1 catcode1active defnext1expandafterdefexpandafterFVMakeUnActiveexpandafter FVMakeUnActivedef1string1 begingrouplccode1relaxexpandafternextexpandafterendgroupdefFVMakeUnActivebegingroupcatcodeactivegdefFVfontfamilytt defFVFontScanPrepFVMakeActive SR modification begin - 1995 defFVFontFamilyttstring defFVFontFamilyttfamilyedefstring SR modification endgdefFVfontfamilycmtt defFVFontScanPrepFVMakeActive defFVFontFamilyedefstringfontfamilycmttendgroupnamedefFVfontfamilycmtt-spanish defFVFontScanPrep defFVFontFamilyfontfamilycmttnamedefFVfontfamilycourier defFVFontScanPrep SR modification begin - 1995 defFVFontFamilyfontfamilyrpcr defFVFontFamilyfontfamilypcr SR modification endnamedefFVfontfamilyhelvetica defFVFontScanPrep SR modification begin - 1995 defFVFontFamilyfontfamilyrphv defFVFontFamilyfontfamilyphv SR modification endfvsetfontfamilytt,fontsizeauto,fontshapeauto,fontseriesauto, baselinestretchautobegingroupcatcode activecatcodeIactivegdefFVDefineWhiteSpacedef FVSpacedefIFVTabendgroupdefinekeyFVdefineactivedefFancyVerbDefineActive1relaxdefinekeyFVdefineactive expandafterdefexpandafterFancyVerbDefineActiveexpandafter FancyVerbDefineActive1relaxfvsetdefineactivedefinebooleankeyFVshowspaces defFVSpaceFancyVerbSpace defFVSpace catcode 12 gdefFancyVerbSpacett fvsetshowspacesfalsedefFVTabhbox toFancyVerbTabSizefontdimen2fonthssFVTabChardefinekeyFVtabsize tempcnta1relax ifnumtempcnta100 FVErrorTab size too large thetempcnta. Max size 100FVeha else edefFancyVerbTabSizethetempcnta fidefinebooleankeyFVshowtabs defFVTabCharFancyVerbTab letFVTabCharrelaxfvsettabsize8,showtabsfalsedefFancyVerbTab valign vfilvfilcr hboxscriptscriptstyle-cr hbox to 0pthssscriptscriptstyleranglemskip -.8mucr hboxscriptstylemskip -3mumidmskip -1.4mucrnewboxFVTabBoxdefFVObeyTabsInit tempdimbFancyVerbTabSizefontdimentwfont edefFVObeyTabSizenumbertempdimb advancetempdimbfontdimentwfont advancetempdimb-FancyVerbTabSize sp Allow for rounding errors. edefFVObeyTabSizenumbertempdimb letFVObeyTabsFVObeyTabs letFVTabFVTrueTabdefFVObeyTabs1setboxFVTabBoxhbox1boxFVTabBoxletFVObeyTabsrelaxdefFVTrueTab egroup tempdimaFVObeyTabSize sprelax tempcntawdFVTabBox advancetempcntaFVObeyTabSizerelax dividetempcntatempdima multiplytempdimatempcnta advancetempdima-wdFVTabBox setboxFVTabBoxhboxbgroup unhboxFVTabBoxkerntempdimahbox tozhssFVTabChardefinebooleankeyFVobeytabs letFVObeyTabsInitFVObeyTabsInit letFVObeyTabsInitrelaxfvsetobeytabsfalsedefinekeyFVformatcomdefFancyVerbFormatCom1relaxdefinekeyFVformatcom expandafterdefexpandafterFancyVerbFormatComexpandafter FancyVerbFormatCom1relaxfvsetformatcomdefFancyVerbFormatLine1FVObeyTabs1definekeyFVxleftmargindefFVXLeftMargin1letFVXLeftMarginzdefinekeyFVxrightmargindefFVXRightMargin1letFVXRightMarginzdefinebooleankeyFVresetmargins letifFVResetMarginsiftrue letifFVResetMarginsiffalsefvsetresetmarginsfalsedefinekeyFVlistparametersdefFVListParameterHook1defFVListParameterHookdefinekeyFVhfuzz tempdima1relax edefFancyVerbHFuzznumbertempdima spfvsethfuzz2ptdefinebooleankeyFVsamepage defFVInterLinePenaltyinterlinepenaltyM letFVInterLinePenaltyrelaxfvsetsamepagefalsedefFVList1 begingroup FVUseKeyValues FVLeaveVMode ifinlabelelsesetboxlabelsboxvoidbxfi FVListNesting1 FVListParameterHook FVListVSpace FVSetLineWidth FVInterLinePenalty letFVProcessLineFVListProcessLinei FVCatCodes FVFormattingPrep FVObeyTabsInit FVBeginListFramedefFVLeaveVMode ifnoskipsec leavevmode else ifFVResetMarginsifinlabelleavevmodefifi fi ifvmodenoparlisttrueelsenoparlistfalseunskipparfidefFVListNesting1 ifFVResetMargins listdepthz else ifnumlistdepth5relax toodeep else advancelistdepthne fi fi rightmarginz csname listromannumeralthelistdepthendcsname ifnum1z rightmarginz leftmarginz fidefFVListVSpace topsepaddtopsep ifnoparlistadvancetopsepaddpartopsepfi ifinlabel vskipparskip else ifnobreak vskipparskip clubpenaltyM else addpenaltybeginparpenalty topseptopsepadd advancetopsepparskip addvspacetopsep fi fi globalnobreakfalse globalinlabelfalse globalminipagefalse globalnewlistfalsedefFVSetLineWidth ifFVResetMarginselse advanceleftmargintotalleftmargin fi advanceleftmarginFVXLeftMarginrelax advancerightmarginFVXRightMarginrelax linewidthhsize advancelinewidth-leftmargin advancelinewidth-rightmargin hfuzzFancyVerbHFuzzrelaxdefFVListProcessLine1 hbox to hsize kernleftmargin hbox to linewidth FVLeftListNumber FVLeftListFrame FancyVerbFormatLine1hss DGSR modification begin - Jan. 28, 1998 for numbersright add-on FVRightListFrame FVRightListFrame FVRightListNumber DGSR modification end hssdefFVListProcessLinei1 hbox ifvoidlabelselse hbox to zkerntotalleftmarginboxlabelshss fi FVListProcessLine1 letFVProcessLineFVListProcessLineiidefFVListProcessLineii1 setboxtempboxaFVListProcessLine1 letFVProcessLineFVListProcessLineiiidefFVListProcessLineiii1 advanceinterlinepenaltyclubpenaltypenaltyinterlinepenalty boxtempboxa setboxtempboxaFVListProcessLine1 letFVProcessLineFVListProcessLineivdefFVListProcessLineiv1 penaltyinterlinepenalty boxtempboxa setboxtempboxaFVListProcessLine1defFVEndList FVListProcessLastLine FVEndListFrame endparenv endgroup endpetruedefFVListProcessLastLine ifxFVProcessLineFVListProcessLineiv advanceinterlinepenaltywidowpenaltypenaltyinterlinepenalty boxtempboxa else ifxFVProcessLineFVListProcessLineiii advanceinterlinepenaltywidowpenalty advanceinterlinepenaltyclubpenalty penaltyinterlinepenalty boxtempboxa else ifxFVProcessLineFVListProcessLinei FVErrorEmpty verbatim environment FVProcessLine fi fi fidefFVVerbatimBeginFVListzdefFVVerbatimEndFVEndListdefFVBVerbatimFVVerbatimBeginFVScandefFVEVerbatimFVVerbatimEndDefineVerbatimEnvironmentVerbatimVerbatimdefFVUseVerbatim1 FVVerbatimBegin1FVVerbatimEnd doendpeglobalignorefalseignorespacesdefVerbatimInputFVCommandVerbatimInputdefFVCVerbatimInput1FVUseVerbatimFVInput1defFVLVerbatimBeginFVListnedefFVLVerbatimEndFVEndListdefFVBLVerbatimFVLVerbatimBeginFVScandefFVELVerbatimFVLVerbatimEndDefineVerbatimEnvironmentLVerbatimLVerbatimdefFVLUseVerbatim1 FVLVerbatimBegin1FVLVerbatimEnd doendpeglobalignorefalseignorespacesdefLVerbatimInputFVCommandLVerbatimInputdefFVCLVerbatimInput1FVLUseVerbatimFVInput1defFVFramenone letFVBeginListFramerelax letFVLeftListFramerelax letFVRightListFramerelax letFVEndListFramerelaxdefFVFramesingle letFVBeginListFrameFVBeginListFrameSingle letFVLeftListFrameFVLeftListFrameSingle letFVRightListFrameFVRightListFrameSingle letFVEndListFrameFVEndListFrameSingledefFVFramelines letFVBeginListFrameFVBeginListFrameLines letFVLeftListFramerelax letFVRightListFramerelax letFVEndListFrameFVEndListFrameLinesdefFVFrametopline letFVBeginListFrameFVBeginListFrameLines letFVLeftListFramerelax letFVRightListFramerelax letFVEndListFramerelaxdefFVFramebottomline letFVBeginListFramerelax letFVLeftListFramerelax letFVRightListFramerelax letFVEndListFrameFVEndListFrameLines To define a frame with only a left linedefFVFrameleftline To define the FVFrameFillLine macro from FVBeginListFrame ifxFancyVerbFillColorrelax letFVFrameFillLinerelax else tempdimaFVFrameRulerelax multiplytempdima-tw edefFVFrameFillLine noexpandFancyVerbFillColorvrulewidthnumbertempdima sp kern-numbertempdima sp fi letFVBeginListFramerelax letFVLeftListFrameFVLeftListFrameSingle letFVRightListFramerelax letFVEndListFramerelaxdefFVBeginListFrameSingle lineskipz baselineskipz ifxFancyVerbFillColorrelax letFVFrameFillLinerelax else tempdimaFVFrameRulerelax multiplytempdima-tw edefFVFrameFillLine noexpandFancyVerbFillColorvrulewidthnumbertempdima sp kern-numbertempdima sp fi DGSR modification begin - May. 19, 1998 FVSingleFrameLine FVSingleFrameLinez DGSR modification end penaltyM FVSingleFrameSep penaltyM DGSR modification begin - May. 19, 1998definekeyFVlabel deftempa1 ifxtempaFVNone letFVLabelBeginrelax letFVLabelEndrelax else FVLabeli1nil fidefFVLabeliifnextcharFVLabeliiFVLabeliidefFVLabelii12nil deftempa1 ifxtempaempty defFVLabelBegin2 else defFVLabelBegin1 defFVLabelPositionBottomLinene fi defFVLabelEnd2fvsetlabelnonedefinekeyFVlabelpositionnone ifundefinedFVLabelPosition1 FVErrorLabel position 1 not defined.FVeha nameuseFVLabelPosition1defFVLabelPositionnone letFVLabelPositionTopLinerelax letFVLabelPositionBottomLinerelaxdefFVLabelPositiontopline defFVLabelPositionTopLinene letFVLabelPositionBottomLinerelaxdefFVLabelPositionbottomline letFVLabelPositionTopLinerelax defFVLabelPositionBottomLinenedefFVLabelPositionall defFVLabelPositionTopLinene defFVLabelPositionBottomLinenefvsetlabelpositiontopline DGSR modification end DGSR modification begin - May. 19, 1998 defFVSingleFrameLinedefFVSingleFrameLine1 DGSR modification end hbox toz kernleftmargin DGSR modification begin - Jun. 22, 1998 ifnum1z letFVLabelFVLabelBegin else letFVLabelFVLabelEnd fi ifxFVLabelrelax DGSR modification end FancyVerbRuleColorvrule widthlinewidth heightFVFrameRule DGSR modification begin - Jun. 22, 1998 else ifnum1z setboxzhboxstrutenspaceFVLabelBeginenspacestrut else setboxzhboxstrutenspaceFVLabelEndenspacestrut fi tempdimbdpz advancetempdimb -.5htz tempdimclinewidth advancetempdimc -wdz dividetempdimctw ifnum1z Top line ifxFVLabelPositionTopLinerelax FancyVerbRuleColorvrule widthlinewidth heightFVFrameRule else FVFrameLineWithLabel fi else Bottom line ifxFVLabelPositionBottomLinerelax FancyVerbRuleColorvrule widthlinewidth heightFVFrameRule else FVFrameLineWithLabel fi fi fi DGSR modification end hss DGSR modification begin - May. 19, 1998defFVFrameLineWithLabel htztempdimbdpztempdimb FancyVerbRuleColor vrule widthtempdimc heightFVFrameRule raisetempdimbboxz vrule widthtempdimc heightFVFrameRule DGSR modification enddefFVBeginListFrameLines begingroup lineskipzskip DG modification begin - June 18, 1997 effect of baselineskip too earlier baselineskipzskip FVSingleFrameLine DGSR modification begin - May. 19, 1998 FVSingleFrameLine FVSingleFrameLinez DGSR modification end kern-0.5baselineskiprelax baselineskipzskip DG modification end kernFVFrameSeprelax endgroupdefFVEndListFrameLines begingroup baselineskipzskip kernFVFrameSeprelax DGSR modification begin - May. 19, 1998 FVSingleFrameLine FVSingleFrameLinene DGSR modification end endgroupdefFVSingleFrameSep hbox to z kernleftmargin hbox tolinewidth FancyVerbRuleColor DG modification begin - June 18, 1997 FVFrameSep missing ifxFancyVerbFillColorrelax vrulewidth 0ptheightFVFrameSeprelax fi DG modification end vrulewidthFVFrameRulerelax ifxFancyVerbFillColorrelax hfil else FancyVerbFillColorleadershruleheightFVFrameSephfil fi DG modification begin - June 18, 1997 FVFrameSep missing ifxFancyVerbFillColorrelax vrulewidth 0ptheightFVFrameSeprelax fi DG modification end vrulewidthFVFrameRulerelax hssdefFVLeftListFrameSingle strut FancyVerbRuleColorvrule widthFVFrameRule FVFrameFillLine DG modification begin - June 18, 1997 to fill color on left side kernFVFrameSep ifxFancyVerbFillColorrelax kernFVFrameSep else noexpandleavevmodeFancyVerbFillColorvrulewidthFVFrameSep fi DG modification enddefFVRightListFrameSingle DG modification begin - June 18, 1997 to fill color on right side kernFVFrameSep ifxFancyVerbFillColorrelax kernFVFrameSep else noexpandleavevmodeFancyVerbFillColorvrulewidthFVFrameSep fi noexpandleavevmodeFancyVerbRuleColorvrulewidthFVFrameRule DG modification enddefFVEndListFrameSingle penaltyM FVSingleFrameSep penaltyM DGSR modification begin - May. 19, 1998 FVSingleFrameLine FVSingleFrameLinene DGSR modification enddefinekeyFVframerule tempdima1relax edefFVFrameRulenumbertempdima sprelaxdefKVFVframeruledefaultletFVFrameRulefboxruledefinekeyFVframesep tempdima1relax edefFVFrameSepnumbertempdima sprelaxdefKVFVframesepdefaultletFVFrameSepfboxsepfvsetframerule,framesepdefinekeyFVrulecolor deftempa1 ifxtempaFVNone letFancyVerbRuleColorrelax else letFancyVerbRuleColortempa fidefinekeyFVfillcolor deftempa1 ifxtempaFVNone letFancyVerbFillColorrelax else letFancyVerbFillColortempa fifvsetrulecolornone,fillcolornonedefFVFramedouble letFVFrameBeginFVFrameBegindouble letFVFrameLineFVFrameLinedouble letFVFrameEndFVFrameEnddoubledefinekeyFVframenone ifundefinedFVFrame1 FVErrorFrame style 1 not defined.FVeha nameuseFVFrame1fvsetframenonenewcounterFancyVerbLinedefinekeyFVfirstnumberauto deftempa1deftempbauto ifxtempatempb defFVSetLineNo cFancyVerbLineFVCodeLineNo advancecFancyVerbLinemne else deftempblast ifxtempatempb letFVSetLineNorelax else DGSR modification begin - Jan. 19, 1998 defFVSetLineNocFancyVerbLine1 defFVSetLineNo cFancyVerbLine1 advancecFancyVerbLinemne DGSR modification end fi fidefinebooleankeyFVnumberblanklines letifFVNumberBlankLinesiftrue letifFVNumberBlankLinesiffalsefvsetnumberblanklinestrue DGSR modification begin - May. 20, 1998defrefstepcounter1 Adapted from latex.ltxdefFVrefstepcounter1 DGSR modification end stepcounter1 protectededefcurrentlabel csname p1endcsnamearabicFancyVerbLinedefFVStepLineNo FVSetLineNo DGSR modification begin - Apr. 28, 1998 and May 20, 1998 defFVStepLineNorefstepcounterFancyVerbLine defFVStepLineNo ifFVNumberBlankLines FVrefstepcounterFancyVerbLine else ifxFVLineempty else FVrefstepcounterFancyVerbLine fi fi DGSR modification end FVStepLineNo DGSR modification begin - 1995deftheFancyVerbLinermtinyarabicFancyVerbLinedeftheFancyVerbLinermfamilytinyarabicFancyVerbLine DGSR modification enddefinekeyFVnumbersnone ifundefinedFVNumbers1 FVErrorNumbers style 1 not defined.FVeha nameuseFVNumbers1 DG modification begin - Dec. 20, 1995 and Jan. 28, 1998defFVNumbersnoneletFVLeftListNumberrelaxdefFVNumbersnoneletFVLeftListNumberrelaxletFVRightListNumberrelaxnewcountFVStepNumberdefinekeyFVstepnumberFVStepNumber1defKVFVstepnumberdefaultFVStepNumbernefvsetstepnumber DG modification begin - Dec. 20, 1995defFVNumbersleft defFVLeftListNumberhbox toz hsstheFancyVerbLinekernFVNumberSepdefFVNumbersleft DGSR modification begin - Apr. 28, 1998 letFVRightListNumberrelax DGSR modification end defFVLeftListNumber tempcntaFVCodeLineNo tempcntbFVCodeLineNo dividetempcntbFVStepNumber multiplytempcntbFVStepNumber ifnumtempcntatempcntb DGSR modification begin - Apr. 28, 1998 hbox tozhsstheFancyVerbLinekernFVNumberSep ifFVNumberBlankLines hbox tozhsstheFancyVerbLinekernFVNumberSep else ifxFVLineempty else hbox tozhsstheFancyVerbLinekernFVNumberSep fi fi DGSR modification end fidefFVNumbersright DGSR modification begin - Apr. 28, 1998 letFVLeftListNumberrelax DGSR modification end defFVRightListNumber tempcntaFVCodeLineNo tempcntbFVCodeLineNo dividetempcntbFVStepNumber multiplytempcntbFVStepNumber ifnumtempcntatempcntb DGSR modification begin - Apr. 28, 1998 hbox to zkernFVNumberSeptheFancyVerbLinehss ifFVNumberBlankLines hbox tozkernFVNumberSeptheFancyVerbLinehss else ifxFVLineempty else hbox tozkernFVNumberSeptheFancyVerbLinehss fi fi DGSR modification end fi DG modification enddefinekeyFVnumbersep tempdima1relax edefFVNumberSepnumbertempdima sprelaxfvsetnumbersnone,numbersep12pt,firstnumberautodefFVBVerbatimBegin begingroup FVUseKeyValues FVBeginVBox letFVProcessLineFVBProcessLine FVFormattingPrep FVObeyTabsInitdefFVBVerbatimEndFVEndVBoxendgroupdefFVBeginVBox leavevmode hboxifxFVboxwidthrelaxelse toFVboxwidthfibgroup ifcaseFVbaselinevboxorvtoporvcenterfibgroupdefFVEndVBoxegroupifmmodefihfilegroupdefinekeyFVboxwidth deftempa1deftempbauto ifxtempatempb letFVboxwidthrelax else tempdima1relax edefFVboxwidthnumbertempdima sp fidefKVFVboxwidthdefaultletFVboxwidthrelaxdefinekeyFVbaseline if t1emptyletFVbaselineneelse if c1emptyletFVbaselinetwelseletFVbaselinezfi fifvsetbaselineb,boxwidthdefFVBProcessLine1hboxFancyVerbFormatLine1defFVBBVerbatimFVBVerbatimBeginFVScandefFVEBVerbatimFVBVerbatimEndDefineVerbatimEnvironmentBVerbatimBVerbatimdefFVBUseVerbatim1FVBVerbatimBegin1FVBVerbatimEnddefBVerbatimInputFVCommandBVerbatimInputdefFVCBVerbatimInput1FVBUseVerbatimFVInput1defSaveVerbatimFVEnvironmentSaveVerbatimdefFVBSaveVerbatim1 bsphack begingroup FVUseKeyValues FVBeginVBox letFVProcessLineFVBProcessLine FVFormattingPrep FVObeyTabsInit defSaveVerbatimName1 gdefFVTheVerbatim defFVProcessLine1 expandaftergdefexpandafterFVTheVerbatimexpandafter FVTheVerbatimFVProcessLine1 gdefFVTheVerbatim FVScandefFVESaveVerbatim expandafterglobalexpandafterlet csname FVSVSaveVerbatimNameendcsnameFVTheVerbatim expandaftergdef csname FVSVSaveVerbatimNameendcsnameFVTheVerbatim FVEndVBox endgroup endgroupesphackDefineVerbatimEnvironmentSaveVerbatimSaveVerbatimdefFVCheckIfSaved12 ifundefinedFVSV1 FVErrorNo verbatim text has been saved under name 1FVeha 2csname FVSV1endcsnamedefUseVerbatimFVCommandUseVerbatimdefFVCUseVerbatim1FVCheckIfSaved1FVUseVerbatimdefLUseVerbatimFVCommandLUseVerbatimdefFVCLUseVerbatim1FVCheckIfSaved1FVLUseVerbatimdefBUseVerbatimFVCommandBUseVerbatimdefFVCBUseVerbatim1FVCheckIfSaved1FVBUseVerbatimnewwriteFVOutFiledefVerbatimOutFVEnvironmentVerbatimOutdefFVBVerbatimOut1 bsphack begingroup FVUseKeyValues FVDefineWhiteSpace defFVSpacespace FVDefineTabOut defFVProcessLineimmediatewriteFVOutFile immediateopenoutFVOutFile 1relax letFVFontScanPreprelax DGSR modification begin - May. 18, 1998 to avoid problems with ligatures letnoligsrelax DGSR modification end FVScandefFVEVerbatimOutimmediatecloseoutFVOutFileendgroupesphackDefineVerbatimEnvironmentVerbatimOutVerbatimOutdefFVDefineTabOut defFVTab tempcntaFancyVerbTabSizerelax loopifnumtempcntaz edefFVTabFVTabspace advancetempcntamne repeatdefSaveVerbFVCommandSaveVerbbegingroupcatcodeMactivegdefFVCSaveVerb12 namedefFVSV1 begingroup FVUseKeyValues FVCatCodes outerdefMFVEOL globallettempgFancyVerbAfterSave catcode212 deftempadefFancyVerbGetVerb12 expandaftertempastring2endgroupnamedefFVSV12tempg FancyVerbGetVerbFVEOLendgroupdefFVEOL endgroup FVError Could not find the end delimiter of a short verb command You probably just forget the end delimiter of a stringVerbspace or stringSaveVerbJ command, or you broke the literal text across input lines.J Hit to procede.definekeyFVaftersavedefFancyVerbAfterSave1fvsetaftersavedefFVUseVerb1mboxFVUseKeyValuesFVFormattingPrep1defUseVerbFVCommandUseVerbdefFVCUseVerb1 ifundefinedFVSV1 FVErrorShort verbatim text never saved to name 1FVeha FVUseVerbnameuseFVSV1defVerbFVCommandVerbbegingroupcatcodeMactivegdefFVCVerb1 begingroup FVUseKeyValues FVFormattingPrep FVCatCodes outerdefM catcode112 deftempadefFancyVerbGetVerb12 expandaftertempastring1mbox2endgroup FancyVerbGetVerbFVEOLendgroupdefDefineShortVerbFVCommandDefineShortVerbdefFVCDefineShortVerb1 ifundefinedFVCCstring1 FVCDefineShortVerb1 FVErrorexpandaftergobblestring1 is already a short verb character.FVehadefFVCDefineShortVerb1 begingroup lccode1 lowercasegdeftempgedefgloballettemph endgroup expandafterletcsname FVACstring1endcsnametemph expandafteredefcsname FVCCstring1endcsnamethecatcode1 expandafterletcsname FVKVstring1endcsnameFVKeyValues tempg letnoexpandFVKeyValuesexpandafternoexpand csname FVKVstring1endcsname noexpandFVCVerbexpandaftergobblestring1 expandafterdefexpandafterdospecialsexpandafterdospecialsdo1 expandafterdefexpandaftersanitizeexpandaftersanitizemakeother1 catcode1activedefUndefineShortVerb1 ifundefinedFVCCstring1 FVErrorexpandaftergobblestring1 is not a short verb characterFVeha FVUndefineShortVerb1defFVUndefineShortVerb1 catcode1csname FVCCstring1endcsname DGSR modification begin - Jun. 12, 1998 expandafterletcsname FVCCstring1endcsnamerelax DGSR modification end begingroup lccode1 lowercasegdeftempglet endgroup expandaftertempgcsname FVACstring1endcsname deftempa1do12nil3nil4nil3defdospecials12fi expandaftertempadospecialsniliftruenildo1niliffalsenilnil deftempa1makeother12nil3nil4nil 3defsanitize12fi expandaftertempasanitizeniliftruenildo1niliffalsenilnildefSaveMVerbFVCommandSaveMVerbbegingroupcatcodeMactivegdefFVCSaveMVerb12 ifundefinedFVSVM1 FVErrorMoving verbatim name 1 already used I will overwrite the old definition. Hit to continue. globalnamedefFVSVM1 begingroup letFVSavedKeyValuesFVKeyValues FVUseKeyValues FVCatCodes outerdefM globallettempgFancyVerbAfterSave catcode212 deftempadefFancyVerbGetVerb12 expandaftertempastring2 iffilesw FVDefineWhiteSpace letFVSpacespace letFVTabspace FVMakeUnActive letprotectstring immediatewriteauxout noexpandSaveGVerbFVSavedKeyValues1string22string2 fi endgroup namedefFVSV12 tempg FancyVerbGetVerbFVEOLendgroupdefSaveGVerbFVCommandSaveGVerbbegingroupcatcodeMactivegdefFVCSaveGVerb12 globalnamedefFVSVG1 begingroup FVUseKeyValues FVCatCodes outerdefM catcode212 deftempadefFancyVerbGetVerb12 expandaftertempastring2endgroupglobalnamedefFVSVG12 FancyVerbGetVerbFVEOLendgroupdefUseMVerbprotectpUseMVerbdefpUseMVerbFVCommandpUseMVerbdefFVCpUseMVerb1 expandafterifx csname FVSVM1endcsnamerelax expandafterifx csname FVSVG1endcsnamerelax warningMoving verbatim text not defined for name 1FVeha bf else FVUseVerbnameuseFVSVG1 fi else FVUseVerbnameuseFVSVM1 fiexpandafterifxcsname documentclassendcsnamerelax deflrbox1 edeftempa endgroup setbox1hbox begingroupaftergroup defnoexpandcurrenvircurrenvir defnoexpandcurrenvlineonline tempa endpefalse bgroup ignorespaces defendlrboxunskipegroupfi New for CS16newenvironmentpseudoVerbatimcommandchars,codescatcode3catcode7catcode8endVerbatimnewenvironmentverbatimcsVerbatimcommandchars,codescatcode3catcode7catcode8endVerbatimnewcommandnew1em 1 New term set in italics.newcommandset11 Set as in set1,2,3newcommandsetof2,1 mid2, Set as in setofxx 0newcommandNmathordBbb N Positive integers.newcommandcompl1overline1 Complement of ... newcommandbigandbigwedgenewcommandbigorbigveenewcommandORveenewcommandANDwedgenewcommandcode1texttt1newcommandtabhspace.3innewcommandnlognn log n DGSR modification begin - Mar 21 2000inputfancyvrb.rcInputIfFileExistsfancyvrb.cfg DGSR modification endendinput End of file fancyvrb.sty.", "metadata": {"last_modified": "2021-05-08T18:38:17+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 2004, "token_count_estimate": 10460}}, "https://cs.brown.edu/courses/cs015/javadocs/cs15/fnl/sketchySupport/FileIO.html": {"text_content": "JavaScript is disabled on your browser. Skip navigation links Overview Package Class Tree Index Help Prev Class Next Class Frames No Frames All Classes Summary Nested Field Constr Method Detail Field Constr Method cs15.fnl.sketchySupport Class FileIO java.lang.Object cs15.fnl.sketchySupport.FileIO public class FileIO extends java.lang.Object A SUPPORT class that provides easy file input and output operations. The read methods provide word by word and number by number access to any file. The write methods, however, should only be used to create new files and not to modify existing files. The FileIO class uses sequential file access. This means that it views the file as a sequence of entries or tokens. Each string, int, or double that is written using the write methods of this class makes up its own entry. Each time one of the write methods is called, a new entry is added to the end of the sequence of entries in the file which is currently open for writing. Each time one of the read methods is called, it returns the next entry in the sequence of entries in the file which is currently open for reading. Constructor Summary Constructors Constructor and Description FileIO Method Summary All Methods Static Methods Instance Methods Concrete Methods Modifier and Type Method and Description void closeRead A SUPPORT method that closes the current file which is open for READING. void closeWrite A SUPPORT method that closes the current file which is open for READING. static java.lang.String getFileName boolean save, javafx.stage.Window stage A SUPPORT method that opens a FileChooser pop-up window that allows you to navigate your computer to choose a file to load or save to. boolean hasMoreData A SUPPORT method that returns whether there is more data to be read from the file that is currently open for reading. void openRead java.lang.String filename A SUPPORT method that opens the file specified by filename for reading. void openWrite java.lang.String filename A SUPPORT method that opens the file specified by filename for writing. double readDouble A SUPPORT method that reads the next entry in the file and returns it as a double. int readInt A SUPPORT method that reads the next entry in the file and returns it as an integer. java.lang.String readString A SUPPORT method that reads the next entry in the file and returns it as a string. void writeDouble double num A SUPPORT method that adds an entry to the end of the current file open for writing. void writeInt int num A SUPPORT method that adds an entry to the end of the current file open for writing. void writeString java.lang.String message A SUPPORT method that adds an entry to the end of the current file open for writing. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FileIO public FileIO Method Detail closeRead public void closeRead A SUPPORT method that closes the current file which is open for READING. This method should be called as soon as a program is done reading from the current file. Calling this method when there is no file currently open for reading will result in an error message and termination of the program. closeWrite public void closeWrite A SUPPORT method that closes the current file which is open for READING. This method should be called as soon as a program is done reading from the current file. Calling this method when there is no file currently open for reading will result in an error message and termination of the program. getFileName public static java.lang.String getFileNameboolean save, javafx.stage.Window stage A SUPPORT method that opens a FileChooser pop-up window that allows you to navigate your computer to choose a file to load or save to. This method will return the absolute path of the file or null. Parameters save - a boolean value - pass TRUE if youre saving, FALSE if loading stage - your programs Stage Returns the name of the file to open, null if invalid file hasMoreData public boolean hasMoreData A SUPPORT method that returns whether there is more data to be read from the file that is currently open for reading. Returns A boolean that is TRUE if there is more data, FALSE otherwise openRead public void openReadjava.lang.String filename A SUPPORT method that opens the file specified by filename for reading. This method must be called before any of the read methods can be called. Calling one of the three read methods or closeRead before calling openRead will result in a Null Pointer Exception. Once a file has been opened for reading, every subsequent call to one of the three read methods will read from the file specified by filename. This method can be called multiple times, but once a file has been opened for reading, it must be closed for reading before another file can be opened for reading. Parameters filename - The pathname of the file to be opened for reading. openWrite public void openWritejava.lang.String filename A SUPPORT method that opens the file specified by filename for writing. This method must be called before any of the write methods can be called. Calling one of the three write methods or closeWrite before calling openWrite will result in a Null Pointer Exception. Once a file has been opened for writing, every subsequent call to one of the three write methods will write to the file specified by filename. This method can be called multiple times, but once a file has been opened for writing, it must be closed for writing before another file can be opened for writing. Calling this method an existing file will delete the contents of the original and replace them with whatever new information is written. For this reason, openWrite should only be used to create new files or to replace the information in an existing file. Parameters filename - The pathname of the file to be opened for writing. readDouble public double readDouble A SUPPORT method that reads the next entry in the file and returns it as a double. You must only use this method if you are certain that the entry being read will be a double. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns A double value that stores the value that was just read readInt public int readInt A SUPPORT method that reads the next entry in the file and returns it as an integer. You must only use this method if you are certain that the entry being read will be a integer. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns An integer value that stores the value that was just read readString public java.lang.String readString A SUPPORT method that reads the next entry in the file and returns it as a string. You must only use this method if you are certain that the entry being read will be a double. The program will terminate with an error message if this method is called but there are no more entries in the file to be read. There must be a file open for reading when this method is called or an error message will be produced and the program will terminate. Returns A string that stores the value that was just read writeDouble public void writeDoubledouble num A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as a double and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters num - The double to write to the file writeInt public void writeIntint num A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as an integer and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters num - The integer to write to the file writeString public void writeStringjava.lang.String message A SUPPORT method that adds an entry to the end of the current file open for writing. This entry is encoded as a string and will have the value of the passed in parameter. There must be a file open for writing when this method is called or An error message will be produced if this method is called and a file is not open for writing and the program will terminate. Parameters message - The string to write to the file Skip navigation links Overview Package Class Tree Index Help Prev Class Next Class Frames No Frames All Classes Summary Nested Field Constr Method Detail Field Constr Method", "metadata": {"last_modified": "2021-10-07T01:03:31+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Class FileIO"], "word_count": 1575, "token_count_estimate": 1781}}, "https://cs.brown.edu/archive/submit/": {"text_content": "Submit Asset Brown CS Digital Archive BCSDA Welcome to the submission form for the Brown CS Digital Archive BCSDA, an extension of the Brown Digital Repository. Put simply, it allows anyone on the planet to submit a piece of Brown CS history for permanent preservation online, accessible to all. The BCSDA accepts more than a dozen different formats Photos and other graphic files PDFs, audio, video, etc... Papers, abstracts, and posters Even code please submit a PDF containing descriptive text and a link to the source code All assets go through a virus check and are verified for accuracy. Authorscreators retain all copyright. We would like items with real historical interest, so please do not send us your lecture notes, but you can visit www.cs.brown.eduarchive to see the wide variety of things that we are looking for. After verification from an appropriate staff or faculty member, your asset will enter the BCSDA and be available in perpetuity to anyone with an Internet connection. Please be patient if were getting a lot of submissions all at once. Thanks for sharing your piece of Brown CS history Submit New Asset Required Name submitted by limit 250 chars Email submitted by limit 250 chars Asset Title limit 250 chars Year 4-digits Description limit 750 chars Asset file Faculty choose multiple Computer Science Faculty Adam Blumenthal Alan Usas Alessandro Epasto Alexander Galakatos Alexander Steinmaurer Alper Ahmetoglu Amy Greenwald Andrew Crotty Andries van Dam Ankit Shah Anna Lysyanskaya Barbara Meier Benedetto Buratti Benjamin Greenman Benjamin Lerner Benjamin Raphael Bernardo Palazzi Bertrand Cambou Bruce Campbell Caroline Klivans Caroline Ziemkiewicz Carsten Eickhoff Carsten Binnig Chad Jenkins Chen Avin Chen Sun Christopher Crick Claire Mathieu Cristina Menghini Cyrus Cousins Daniel Ritchie Daniel Keefe Daniel Potter David Paulius David Laidlaw David Beazley Deborah Hurley Dina Goldin Donald Stanford Dora Erdos Doug Woos Elaheh Raisi Eliezer Upfal Ellie Pavlick Ellis Hershkowitz Erik Sudderth Erika Sudderth Ernesto Zaldivar Eugene Charniak Evangelos Atlidakis Fabio Vandin Franco Preparata Frank Pfenning Fumei Lam Gabriel Taubin Gayathri Garimella George Konidaris Gianluca Brero Gopal Pandurangan Grigory Yaroslavtsev Gunnar Klau Harini Suresh Ian Gonsher Iman Hajirasouliha Jake Russin James Hays James MacGlashan James Tompkin Jeff Huang Jian Chen John Savage John Jannotti John Clements John Hughes Jose James Joseph Laviola Julia Netter Karianne Bergen Kathi Fisler Konstantinos Stylianou Lawson Wong Liang Zhang Linn Freedman Lionel Reveret Lorenzo De Stefani Malte Schwarzkopf Mark Johnson Mark Nadel Martha Lewis Matteo Riondato Matthew Reyna Maurice Herlihy Megumi Ando Meinolf Sellmann Michael Littman Michael Black Michael Turchin Milda Zizyte Mohammed El-Kebir Musik Kwon Nancy Pfenning Nicholas DeMarinis Nikos Vasilakis Nikos Triandopoulos Nora Ayanian Norm Meyrowitz Omer Gottesman Pascal Hentenryck Paul Valiant Pedro Felzenszwalb Peihan Miao Peter Wegner Peter Wegner Philip Klein R Bahar Ravindra Pendse Ritambhara Singh Robert Lewis Roberto Tamassia Rodrigo Fonseca Roger Blumberg Ronald Parr Sarah Chasins Sarah Osentoski Seny Kamara Serdar Kadioglu Shahrzad Haddadan Sherief Reda Shriram Krishnamurthi Sohini Ramachandran Sorin Istrail Srinath Sridhar Stanley Zdonik Stefanie Tellex Stephen Bach Steven Reiss Subarna Shakya Suresh Venkatasubramanian Tarik Moataz Tharpe Stephen Strickland Theophilus Benson Thomas Sgouros Thomas Dean Thomas Serre Thomas Hofmann Thomas Doeppner Tim Nelson Tim Kraska Timothy Edgar Trevor Jay Tristan Dyer Ugur Cetintemel Vanessa Cho Vasilis Kemerlis Vincent Cohen-Addad Waleed Khamies Will Crichton Yoonseon Oh Yu Cheng Research areas choose multiple Algorithms and Theory Artificial Intelligence Computational Biology Computer Systems Database Systems Distributed Systems Graphics and Visualization Human-Computer Interaction Machine Learning Networking Programming Languages Robotics Security and Cryptography Software Engineering Communities choose multiple Faculty Undergraduate Students Masters Students PhD Students Staff Alums Buildings choose multiple 180 George Street Barus and Holley 151 Thayer Street The CIT 182 George Street", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Brown CS Digital Archive (BCSDA)", "Submit New Asset"], "word_count": 603, "token_count_estimate": 972}}, "https://cs.brown.edu/courses/cs019/2012/assignments/filesystem": {"text_content": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Filesystem Read How to Design Programs Chapter 16 Complete exercises 16.3.2-16.3.4 and the Challenge question. Clarifications Though we would love to see your response for the follow-up question for 16.3.2, we arent requiring you to. There is a solution attached to 16.3.2. Though we know you may well read it, we highly suggest not to, at least until youve completed the problem. Before you start working, you should add dir.ss as a teachpack. LanguageAdd Teachpack In the second part of exercise 16.3.3, the size of a directory is the sum of the sizes of its contents, the length of its files list, and the length of its dirs list. For example, in HTDP Figure 44, the size of the TS directory is 218, and the size of the Code directory is 12. The Challenge question asks you to Generalize the function find to return a list of paths if the file name occurs more than once. Each path should lead to a different occurrence, and there should be a path for each occurrence.The find function you hand in should have type signature find directory symbol - listof path where a path is a list of symbols. Note it should return empty if the file name does not occur rather than false as stated under the challenge instructions, and a list containing a single path if the file name occurs only once. What to turn in A Racket file, filesystem.rkt , containing your implementations of the functions described in these exercises. Only turn in the final version of each function.", "metadata": {"last_modified": "2012-10-03T15:54:38+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["", "", "Filesystem", "What to turn in:"], "word_count": 272, "token_count_estimate": 345}}, "https://cs.brown.edu/courses/cs016/averages.html": {"text_content": "Toggle navigation SEA-S 16 Home Documents Lectures Assignments Section TA Hours Staff Assignment Averages Assignment Averages Assignment averages will be released after grade reports are sent. Assignment Mean Median Out Of HW1 52.12 53 60 HW2 - Written 31.26 33 36 HW2 - Code 60.73 63.17 68.5 HW3 - Written 18.41 20 22 HW3 - Code 39.46 42 44 HW4 - Written 27.15 28.5 33 HW4 - Code 25.19 27.47 31 HW5 - Written 23.69 25 28 HW5 - Code 18.82 20.48 23 Optional HW6 - Written 16.88 20 25 Optional HW6 - Code 33.52 41.13 46 HW8 - Written 12.71 13 16 HW8 - Code 55.94 60 62.5 HW9 - Written 17.97 19 20 HW9 - Code 36.94 39 44 Seamcarve 91.48 93 100 Heap 90.75 94 100 Decision Tree Graph Midterm 71.98 74 87", "metadata": {"last_modified": "2021-08-04T16:27:38+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 136, "token_count_estimate": 265}}, "https://cs.brown.edu/courses/cs019/2012/assignments/flags": {"text_content": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Flags Supplement The world is full of countries, each with its own unique identifier, in the form of a beautiful flag.Your job is to create the flags of the following countries by composing shapes onto a scene. Vietnam Chile Suriname Tunisia Saint Lucia Example Japan. place-image circle 35 solid red 100 50 rectangle 200 100 solid white Note You can use either place-image or overlay to position your images, it is up to you. The Image.ss Teachpack In order to use the functions place-image , rotate ,and other goodies that weve included, you will be wanting to add a specialimage-processing teachpack called image.ss . You can find it in the Add Teachpackmenu, LanguageAdd Teachpack in the HtDP2e section, in the center of the screen.You will find the documentation to be useful. The CS17 teachpack will conflict with image.ss , so uninstall 17.ss while working with the images. How to turn it in Please submit a Racket file, flags.rkt , which, when run, displays all the flags in order, along with the rest of your CS17 handin. Read the CS17 homework for details on how to submit all of your files.", "metadata": {"last_modified": "2014-09-10T13:06:36+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["", "", "Flags Supplement", "The Image.ss Teachpack", "How to turn it in:"], "word_count": 203, "token_count_estimate": 261}}, "https://cs.brown.edu/courses/cs019/2012/assignments/rocket": {"text_content": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits RacketRocket In this assignment you will use universe to create a simple game. In this game you must pilot a rocket around invading aliens to reach space the top of the screen. Here is an example of how the game should look Winning Reaching the End Losing Crashing into a UFO The Problem When you are finished, your game should contain the following A rocket that moves continuously towards the top of the screen from the bottom. The user can control the left-right motion of the rocket with the arrow keys. If the rocket gets to the side of the screen, it should hit a wall and not be able to fly off the side of the screen. Three UFOs moving left and right across the screen. All three should have different random starting X positions, different random starting Y positions, and different speeds. The position should be random but constrained so as to make sense. The UFOs should detect collisions with the edge of the screen and move the other way after colliding. If the rocket hits any of the UFOs the rocket should burst into flames turn into fire-small.png and the game should end. If the rocket reaches the top of the screen outer space the game should end and a victory message should be displayed. To make the assignment easier, you may want to break it up into simpler stages such as Draw a rocket on the screen and have it move from the bottom to the top. Add UFOs drawn standing still at different starting x and y positions. Make the Rocket horizontally controllable by keyboard Make the UFOs move from left to right across the screen. Add collisions between the UFOs and the walls. Add collision detection between the UFOs and the rocket and add the flame-burst final scene Testing Your test cases will be a major part of your grade on this assignment.Remember, many of your functions have graphical output, which makesthem difficult to test. This puts an even greater burden on how wellyou test your non-graphical functions. We expect to see you sustainthis burden. Hints You will want the following clipart images rocket-small-up.png ufo.png fire-small.png Remember, you can insert an image into your Racket code by selecting Insert Image... from the Insert menu, or by copying and pasting an image into your code. Your definition of an image to use for drawing would look like define MY-IMAGE You may also find the Racket documentation on big-bang to be useful. Youll want a big-bang that reacts to key-presses, knows when to stop, can draw itself and continually moves the rocket. Youll need to figure out which of the big-bang clauses will allow you to do this. Remember to think about what you want in your world - and how youll need tochange your world before starting to program, and use the design recipe. You will also find the Racket documentation on drawing your own images to be useful - especially on how to overlay one image above another in a givenposition. For generating random numbers, look at the documentation on random here . You shouldnt have to copy-paste any code. If you find yourself duplicating code, you make wish to rethink the structure of your world. Finally, you may want to look through the fully worked-out example ofa universe program Flight Lander in How to Design Worlds . Note thatthe text uses an older version of big-bang , so read itfor the ideas and most, but not all, of the code. What should my Racket code look like Your Racket should look like Racket, not Java. We expect you to follow the formatting conventions below This means,closing parentheses go on the same line, not the line below. You wantthe following define add-two num num 2 not define add-two num num 2 Name your variables using dashes to separate words. Dont camel case, dont useunderscores. You want my-function not MyFunction , myfunction or My-Function . Try to keep the total length of your lines around 80 characters. You can bringarguments down to a new line if you have too many. Breaking up different argumentsonto separate lines allows the reader to see what expressions are arguments to what other functions. This is much easier to read a-very-long-function-name a-long-input-argument an-even-longer-input-argument an-even-even-longer-input-argument than a-very-long-function-name a-long-input-argument an-even-longer-input-argument an-even-even-longer-input-argument If you bring arguments down to a new line, many coders will put all of thearguments on their own line, even if multiple arguments could be fit on the sameline. However, this depends on the coder. Comments - you should have them and they should say things that the functionname doesnt already say. Constants - should be named in all caps with hyphens. E.g define SOME-CONSTANT 2 The Image.ss Teachpack Again, youll want to include the image.ss teachpack to get accessto image processing function. You can find it in the Add Teachpack menu,LanguageAdd Teachpack in the HtDP2e section, in the center of the screen. Also, since youll be using world programming, please include Universe.ss , from the same middle column. And also remember to uninstall the 17.ss teachpack while working with image.ss . What to turn in A Racket file, rocket.rkt , with code implementing the finished game.", "metadata": {"last_modified": "2012-09-23T18:01:56+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["", "", "RacketRocket", "The Problem", "Testing", "Hints", "What should my Racket code look like?", "The Image.ss Teachpack", "What to turn in:"], "word_count": 880, "token_count_estimate": 1119}}, "https://cs.brown.edu/courses/cs019/2012/assignments/sortacle": {"text_content": "Programming with Data Structures and Algorithms Welcome README Assignments Readings Software Contact Credits Supp 5 Sortacle When you are testing complex functions, or perhaps even relations as in the case of this assignment, you will need to put time and effort into building testing oracles. In this assignment, you will develop oracles to test purported sorting algorithms. Countries by medal count, companies by income, students by GPA, the list goes on and on. The Assignment Being confident that your software is correct involves more than just writing code you think is right. However, almost no software complex enough to be useful can be proved correct by hand in a reasonable amount of time. Naturally, a computer scientists solution to this problem is to write automated testing. Your job, in this assignment, is to build an automated testing oracle for a solution to the sorting problem. Your oracles job is to generate and feed test inputs to this solution and test the correctness of the output. In the past, you did this by comparing the output to a precomputed correct answer. This assumes two things that there is only one right answer, and that it is easy for you to find it. In the real world, either or bothof these can be false. Using the following struct where name is a string and age is a number , you will build an oracle for a function sorting lists of people by non-decreasing age. define-struct person name age Use the sort function in the language to make a correct version called age-sort that takes in a list of people and returns the sorted list. Our sorting functions will use the same contract. age-sort listof person - listof person We will be feeding your oracle a multitude of interesting functions, some that are legitimate sorting algorithms, some that are not. Your oracle should only return true for functions that pass all tests. Input-Output Specification Each purported solution will return the list of people in a new order your oracle must determine the functions that consistently return the list sorted by age in a strictly non-decreasing order eg. 1, 13, 25, 25, 41. Your assignment has three tasks Write a function named generate-input that surprise, surprise generates input. This function should take an integer length, and return a list of randomly aged people of that length. You may assume an upper age limit of 150. generate-input number - listof person Write a function that determines whether the second input is a sorted version of the first. valid listof person listof person - boolean Using valid and generate-input along with any other edge cases you think to include, write a function named oracle that tests whether an algorithm is a valid sorter. oracle listof person - listof person - boolean Remember, an algorithm may sometimes produce a correct solution even if it is an incorrect algorithm. Therefore, your oracle should only return true if an algorithm always sorts correctly it is up to you to determine the magnitude of always. To do well on this assignment, you will want to spend time considering all the different ways that output could be either invalid or inconsistent with the original problem statement. Be thorough Thats the name of the game when testing. What to turn in A Racket file, sortacle.rkt , containing your implementation.", "metadata": {"last_modified": "2012-10-08T19:16:03+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["", "", "Supp 5: Sortacle", "The Assignment", "Input-Output Specification", "What to turn in:"], "word_count": 557, "token_count_estimate": 652}}, "https://cs.brown.edu/courses/cs016/static/files/docs/nds4/index.html": {"text_content": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "metadata": {"last_modified": "2021-05-08T18:38:13+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Frame Alert"], "word_count": 36, "token_count_estimate": 44}}, "https://cs.brown.edu/courses/cs004/": {"text_content": "Welcome to CS4 ABOUT Welcome to CS4, Introduction to Scientific Computing and Problem Solving . CS4 provides an introduction to using computers to solve STEM Science, Technology, Engineering, and Mathematics data analysis, visualization, simulation, and numerical analysis problems. The course begins with an introduction to the basics of programming, accompanied by several applications of fundamental coding elements and concepts. As we do this we will explore some of the breadth of Computer Science as a discipline. The first part of the course which runs until Spring Break will be taught in Python. Following this, we will explore more specialized topics related to scientific computing and mathematics that will allow students to access and analyze a number of real world problems. The later portion of the course will be taught in MATLAB. Requirements No prior programming experience is required to take this course Python and MATLAB are easy and fun to use. A calculus course perhaps in high school is highly recommended. SUPPORT If you have any feedback about assignments or the course in general, please fill out the Anonymous Feedback Form to let the course staff know. If you have any academicSEAS accommodations that we should be aware of, please fill out this form so that the course staff can best support you. We understand that being a student can be stressful and that certain circumstances can affect your performance in the course. Please refer to the syllabus for more information about receiving academic support for CS0040 or email the HTAs or Prof. Gaudette for more information regarding accommodations. You can also find some resources the CS department has compiled for students here and a helpful message from your TAs here . COURSE DOCUMENTS Syllabus Course Schedule TA Section Signups First Steps Collaboration Policy CS For All Textbook Python Tutor Python Installation Style Testing Terminal MATLAB Installation Quiz 2 Review QUICK LINKS OUR INSTAGRAM ACCOUNT Piazza Picobot Anonymous Feedback Form WORKING FROM HOME Working from Home Windows Working from Home Mac OSXLinux Hours Homework Projects Lectures Topics Date Section Notes Course Introduction and Computational Problem-Solving 123 Intro to Python Data Types, Expressions, Strings, List, Functions 128 Conditional Logic and Variable Scope 130 131 Test-Driven Design and Iterative Programming 24 Iterative Programming and Nested Loops 26 27 2D Lists and Mutability 211 211 Files, Dictionaries, and Markov Text 213 214 Long Weekend 218 Recursion I 220 221 Recursion II 225 Higher Order Functions and Anonymous Functions 227 228 Modeling and OOP I 34 OOP II 36 Inheritance 311 Connect 4 313 MATLAB I Programs and Functions 318 MATLAB II Conditional Statements and Arrays 320 325 Spring Break 327 MATLAB III More Arrays and Design Recipe 41 Linear Algebra I 43 Linear Algebra II 48 Image Processing I 410 Image Processing II 415 Medical Imaging 417 HTA Lecture 422 HTA Lecture 424 MATLAB Quiz 429 CS4 Staff Professor Jason Gaudette jegaudet Team Puppies Welcome to CS4 I am happy to be your instructor this semester. As a research engineer with loads of real-world experience in scientific computing, my goal is to teach you the art and joy of the field. Outside of my main job, I coach kids in FIRST LEGO robotics, volunteer for the IEEE, teach programming and electronics courses, sail a Hobie Cat, and run with my dog Luna. HTAs E-mail us at cs0040headtaslists.brown.edu if you have administrative or private questions. Griffin Kao gk16 Team Babies Hi there, Im a junior from Philadelphia studying computer science and engineering. A fun fact about me is that Kobe Bryant went to my high school Hersh Gupta hgupta1 Team Puppies Hey everybody My name is Hersh and Im a junior concentrating in chemistry and computational biology. Im a big sports fan and love going on Netflix binges but never actually finishing the show. Joy Bestourous jbestour Team Babies Hi hello Im a junior studying computer science while filling pre-med requirements and maybe pre-law Who knows. I like New York pizza, iced coffee, going to the gym, dancing, and singing Disney songs. Loudly. UTAs E-mail us at cs0040taslists.brown.edu or post a question privately on Piazza if you have any questions about the course. Annie He ahe6 Team Babies Hey yall Im a junior from Dallas, TX concentrating in computational biology. If you dont see me in the scili, Im either chilling in my pjs or exploring new restaurants I also love to rock climb, ski, bungee jump, basically anything adventurous Alex Liu aliu31 Team Babies I am a junior concentrating in Applied Mathematics and Computer Science. Im from Eugene, Oregon and outside of class I am involved with the Socially Responsible Investment Fund, I play golf whenever I get the chance, and I try my best to keep up on practicing the Piano. I also run Brown Data Science, a club that, much like this class, brings educational opportunities related to Data Science to undergraduates of all academic backgrounds. Aryan Srivastava asriva11 Team Puppies I am a freshman concentrating in CS probably. I love watching and playing basketball 1v1 me, reading and talking philosophy, and watching artisan videos on youtube My favorite thing to eat at Brown is a warm Blue Room Chocolate Chip Muffin. Ellen Ling eling Team Babies Hi, Im a junior from Shanghai studying physics and CS. I like good movies and dance and babies Irene Rhee irhee Team Puppies Sup dudes, my name is Irene and Im a junior from Corvallis, OR studying computer science I like to drink my coffee black, am part of a dance group called Daebak come to our spring show, and enjoy dim sum, boba, and tagging people in memes go like my post on subtle asian traits. My favorite word is lit. Joseph Chen jchen88 Team Babies Hey everyone Im a junior from California concentrating in Neuroscience and CS, and Im a big fan of all things related to swimming, playing basketball, Game of Thrones, and stand-up comedy. Jarrett Huddleston jhuddle1 Team Puppies Hey Im a sophomore from Eastern Massachusetts concentrating in computer science. Outside of classes I enjoy camping and music, and Im always looking for a good book Milla Shin mshin7 Team Puppies Im a junior from Tokyo studying computer science. I like going to the beach. I like food and cooking I like snowboarding and scuba diving I love sweet potatoes, avocado, and matcha Yummy. I like puppies but I like babies too. Pedro de Freitas pfreitas Team Babies Senior from Portland, Maine studying cognitive neuroscience. Im a lyra performerinstructor who also enjoys painting. Solomon Rueschemeyer-Bailey sruesche Team Puppies I am a junior trying not to let school get in the way of college. Come to my hours or my section if you want to learn about The Bucket Theorem, whether or not true Love exists, and the future of teleportation. Tiffany Ding tding5 Team Puppies Hi Im a sophomore from upstate NY studying applied math, economics, and computer science. When Im not in the CIT, you can find me going for a run or taking photos for the Brown Daily Herald. I also love puns, penguins, and podcasts", "metadata": {"last_modified": "2019-04-25T22:53:56+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["CSCI0040", "ABOUT", "SUPPORT", "COURSE DOCUMENTS", "QUICK LINKS", "WORKING FROM HOME", "How do TA hours work?", "Diversity and Inclusion Goals"], "word_count": 1178, "token_count_estimate": 1492}}, "https://cs.brown.edu/courses/cs0112/": {"text_content": "Under construction", "metadata": {"last_modified": "2021-08-18T13:21:46+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/courses/cs015/": {"text_content": "Assignments Lectures Sections Code-along Hours Resources SRC Staff WELCOME TO CSCI 0150 CS0150 is one of the introductory Computer Science courses offered at Brown University. This course introduces students to Computer Science through object-oriented design and programming, using Java and the JavaFX graphics library. You will use these tools for building interactive programs with graphical user interfaces. CS0150 reinforces concepts with practical exercises in weekly lab sessions and with challenging and engaging programming assignments, such as Doodle Jump and Tetris There are no prerequisites for CS0150 and the course expects no prior programming experience. This Week in CS15 Nov 26 - Dec 2 Assignment Othello Handout Help Slides Help Session AI Handout Assignment Pacman Handout Help Slides Help Session Assignment Sketchy Handout Help Slides Help Session Javadocs Assignment Indy Handout Mini-Assignment Assignments Assignment Released Early On Time Late Javadocs Help Slides Help Session Additional Handouts Rattytouille Sept 13 NA Sept 16 NA - - - - AndyBot Sept 17 NA Sept 20 NA JavaDocs - - - Pong Sept 21 NA Sept 25 NA JavaDocs - - - TicTacToe Sept 26 Sept 28 Sept 30 Oct 02 JavaDocs - - - Fruit Ninja Oct 03 Oct 08 Oct 10 Oct 12 JavaDocs Help Slides - - Cartoon Oct 12 Oct 19 Oct 21 Oct 23 - Help Slides - Mini-Assignment DoodleJump Oct 24 Oct 30 Nov 01 Nov 03 - Help Slides - - Tetris Nov 04 Nov 11 Nov 13 Nov 15 - Help Slides - - Pacman Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session - Sketchy Nov 17 Dec 10 Dec 12 Dec 14 Javadocs Help Slides Help Session - Othello Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session AI Handout Indy Nov 17 Dec 10 Dec 12 Dec 14 - - - Mini-Assignment Lectures Lectures are held in Salomon DECI on Tuesdays and Thursdays from 230-350pm. Date Lecture PDF Printable PDF PPT Recordings Skit Code 0907 Welcome to CS0150 What is Programming PDF Printable PDF PPT Recording Skit - 0912 Calling and Defining Methods PDF Printable PDF PPT Recording - - 0914 Introduction to Parameters and Math PDF Printable PDF PPT Recording - - 0919 Working with Objects I PDF Printable PDF PPT Recording - - 0921 Working with Objects II PDF Printable PDF PPT Recording - - 0926 Interfaces and Polymorphism PDF Printable PDF PPT Recording - - 0928 Inheritance and Polymorphism PDF Printable PDF PPT Recording - - 1003 Math and Making Decisions PDF Printable PDF PPT Recording Skit - 1005 Graphics I PDF Printable PDF PPT Recording - Code 1010 Graphics II PDF Printable PDF PPT Recording - Code 1012 Graphics III PDF Printable PDF PPT Recording - Code 1017 Loops PDF Printable PDF PPT Recording - - 1019 Arrays PDF Printable PDF PPT Recording - - 1024 Design Principles and Patterns I PDF Printable PDF PPT Recording - Code 1026 Design Principles and Patterns II PDF Printable PDF PPT Recording - - 1031 Recursion PDF Printable PDF PPT Recording Skit - 1102 Big O, Sorting and Searching PDF Printable PDF PPT Recording - - 1107 Data Structures I Linked Lists PDF Printable PDF PPT Recording - - 1109 Data Structures II Stacks, Queues, and Trees PDF Printable PDF PPT Recording - - 1114 Data Structures III PDF Printable PDF PPT Recording - - 1116 Final Project Intro PDF Printable PDF PPT Recording - - 1128 History PDF Printable PDF PPT Recording - - 1130 Computer Graphics PDF Printable PDF PPT Recording - - 1205 HTA Lectures PDF Printable PDF PPT Recording - - Labs Sections Labsection is a time to review course content in a smaller group setting and practice applying those concepts through partnered labs. Each section will meet once a week and will be led by two TAs with around SOME NUMBER of students, so it is also a time to work closely with and get to know some of your fellow CS15-ers. A typical labsection consists of short group check in, a fun SRC activity, and then either a presentation and some smaller group activities to review concepts or a lab. Date LabSection Handout Mini-Assignment Review Video SRC Slides 0912 Lab 0 Linux Terminal Handout Mini-Assignment - - Slides 0919 Lab 1 Intro to Java Handout - - SRC Activity - 0926 Section 2 Class Relationships - Mini-Assignment - SRC Activity Slides 1003 Section 3 Polymorphism - Mini-Assignment - SRC Activity Slides 1010 Lab 4 JavaFX Handout - Video - - 1017 Lab 5 Debugging Handout Mini-Assignment - - - 1024 Section 6 1D Array, ArrayLists, and Loops Handout Mini-Assignment - SRC Activity Slides 1031 Lab 7 2D Arrays Handout Mini-Assignment Video SRC Activity Slides 1107 Section 8 Algorithms - Mini-Assignment - - Slides 1114 Lab 9 Data Structures and Recursion Handout - - SRC Activity Slides Code-Along CS15 Code-Alongs are your one stop shop for getting hands-on experience with guided coding exercises in order to better understand the concepts of OOP We know that lectures can at times feel very abstract, and that we sometimes need examples in code in order to fully understand how these concepts work. Throughout the semester, we will host various code-alongs in order to assist you all with the skills necessary for succeeding in the course Code-Along Related To Date 1 Date 2 Date 3 Video Stencil Java Syntax Code-along Rattytouille 0913 at 700 PM MacMillan 117 0915 at 700 PM MacMillan 117 0917 at 700 PM MacMillan 117 Video Stencil Writing Classes Code-along Andybot, Pong, TicTacToe 0919 at 800 PM Metcalf Research Auditorium 0924 at 300 PM Metcalf Research Auditorium 0927 at 900 PM Metcalf Research Auditorium Video Stencil Java FX Design Code-along Cartoon 1015 at 300 PM MacMillan 115 1018 at 400 PM MacMillan 115 - Video Stencil GitHub and Debugging Code-along Doodle Jump 1025 at 700 PM MacMillan 117 1029 at 300 PM MacMillan 117 - Video Stencil Tetris Pieces Code-along Tetris 1105 at 300 PM Friedman 202 1108 at 700 PM Friedman 202 - Video Stencil Hours Have a Quick Question Try out CS15s own virtual TA Chatbot, GPTA Terms and Conditions GPTA User Guide Generative AI Usage Guide reminder that GPTA is experimental and is a supplement, not a replacement, for real TA help CONCEPTUAL TA HOURS Confused about an idea discussed in lecture or in a project handout If we dont have to look at your code to answer your question, conceptual hours are a great place to meet other students and talk to a TA. Your question will get answered much faster here than at the debugging hours line. DEBUGGING HOURS Debugging Hours are a great resource to discuss 1-on-1 with a TA about your code and learn how to solve your bugs however, please be sure to check our TA Hours policy and the Ed page before getting in line at the hours website . When waiting for hours, wait near CIT 210 and a TA will come to get you Resources Quick Links Syllabus Ed Course Calendar Course Missive Gradescope Feedback Form Hours Emails TA Email cs0150taslists.brown.edu general questions for all TAs HTA Email cs0150headtaslists.brown.edu HTA-Specific QuestionsConcerns Individual TA Emails ltcslogingtcs.brown.edu cslogins found under Staff General Resources Required Readings Course Syllabus Course Missive Collaboration Policy TA Hours Policy Retake Policy GPTA User Guide Generative AI Usage Guide Online Help IntelliJ Git Set-up Guide Mac IntelliJ Set-up Video Windows IntelliJ Set-up Video Github Guide Github Video Master the Terminal Guide Understanding CS0150 Support Code Java Documentation Javadocs All built-in Java classes JavaFX-docs All built-in JavaFx classes JavaFX Guide JavaFX Images Documentation Java Language Specification Guides Tutorials README Guide Style Guide Variables Constructors Runtime Errors Containment Inheritance Diagrams Guide CS15 Vocabulary Sheet Partner Projects Logistics Guide Department Docs Undergraduate Missive Ergonomics IT Services Email Organizations Student Support Services CAPS Title IX Women in Computer Science Mosaic Health Wellness Advocates Diversity Inclusion Advocates Computer Science DUG SRC What is SRC As awareness of technologys consequences increases, attention turns to how computer scientists are trained. In response, the CS department created the Socially Responsible Computing initiative in 2019 to integrate ethics and social impact topics broadly across its curriculum. At Brown, SRC is embedded into most major CS courses. Our goals in CS15 are to give a broad overview of todays technological landscape so that you are familiar with these concepts when you are eventually faced with ethical design decisions further down your CS journey. How does this fit into the CS15 curriculum Mini-lectures Lab activities about lecture content Two extra credit discussion sections with details TBA How can I get involved Groups Brown SRC Reading group ARGBrown AIRES AI Robotic Ethics SocietyBrown Human Centered Robotics Initiative Design for America Brown Alum-foudned groups others Better World by Design Impact Labs Coding it Forward TechCongress Classes Brown CSCI1870 Cybersecurity Ethics CSCI1951I CS for Social Change DATA0080 Data, Ethics and Privacy MCM0230 Digital Media PHIL401 Ethics of Digital Technology STS 1700T Race, Gender, and Technology in Everyday Life Classes under the Science, Technology, and Society STS department ...and more Topics in Socially Responsible Computing Artificial Intelligence Lecture 1 Lectures 2-4 Lecture 5 Blockchain and Crypto Lecture 1 Lecture 2 Cybersecurity Lecture 1 Data Privacy Lecture 1 Lecture 2 Ethics in Big Tech Lecture 1 Lecture 2 Misinformation Freedom of Expression Lecture 1 Labor Practices Lecture 1 Philosophy Lecture 1 Software Design Lecture 1 Lecture 2 AI Overview GPT-3 Creative Fiction Interactive Stable Diffusion free text-to-image generator How DALL-E could power a creative revolution One Hundred Year Study on Artificial Intelligence AI100 LLMs and Neural Nets Exclusive OpenAI Used Kenyan Workers on Less Than 2 Per Hour to Make ChatGPT Less Toxic A Very Gentle Introduction to Large Language Models Without the Hype Lawyer Used Chat-GPT in Court and Cited Fake Cases AI for radiographic COVID-19 detection selects shortcuts over signal AI Bias and Ethics Who Is Making Sure the A.I. Machines Arent Racist A.I. Brings the Robot Wingman to Aerial Combat Automation isnt the biggest threat to US factory jobs Robots were supposed to take our jobs. Instead theyre making it worse Economic possibilities for our grandchildren Privacy Violations and Regulation The New Rules of Data Privacy Data Protection and Privacy Laws China Social Credit System Explained CCTV Surveillance for Crime Prevention FTC Finalizes Order with Flo Health Examining the intersection of data privacy and civil rights Ring, Google and the Police What to Know About Emergency Requests for Video Footage H.R.8152 - American Data Privacy and Protection Act Section 230 Surveillance Capitalism High tech is watching you What Is Surveillance Capitalism Cambridge Analytica and Facebook The Scandal and the Fallout So Far You Are the Product Targeted by Cambridge Analytica on Facebook Corporate Surveillance in Everyday Life Antitrust Support for tech regulation has declined The Antitrust Laws House passes antitrust bill Regulating Big Tech To Regulate Network-Based Platforms, Look at Their Data Why Breaking Up Big Tech Probably Wont Work Who Will Teach Silicon Valley to Be Ethical Responsible AI tools and Practices Ethics Alone Cant Fix Big Tech Can Big Tech be Disrupted Big Tech Needs to Be Regulated. Here Are 4 Ways to Curb Disinformation and Protect Our Privacy The value and challenges of regulating big tech F.T.C.s Court Loss Raises Fresh Questions About Its Chairs Strategy Blockchain Overview Blockchain Facts What Is It, How It Works, and How It Can Be Used The Collapse of FTX What Went Wrong With the Crypto Exchange Blockchain Energy and Sustainability Cryptocurrencys energy consumption problem What is proof of work or proof of stake Ethereums Energy Revamp Is No Guarantee of Global Climate Gains Cybersecurity The Untold Story of Solarwinds Equifax Data Breach Settlement Chinese Malware Hits Systems on Guam. Is Taiwan the Real Target Hunting Russian Intelligence Snake Malware What You Need to Know About Autonomous Weapons Executive Order on Improving the Nations Cybersecurity A.I Brings the Robot Wingman to Aerial Combat Philosophy Microsoft Says New A.I Shows Signs of Human Intelligence Philo-GPTs Surprisingly Wise Answer to What is the Meaning of Life A.I Thinking vs. Human Thinking How Close Are We to A.I That Surpasses Human Intelligence Dark Addictive Design Deceptive Design How Facebook and other sites manipulate your privacy choices How financial apps get you to spend more and question less A survey of addictive software design Dopamine, smartphones and you Good User Design Practice Coming Soon Misinformation Freedom of Expression Coming Soon Labor Practices Coming Soon Staff Professor Head Teaching Assistants Andy avd hehim Im originally from the Netherlands. My CS specialty is Computer Graphics, especially pen- and touch-computing. Im a foodie and love the outdoors hiking and backpacking especially in the Grand Canyon, mountain- and road-biking, and kayaking. THE CAPITOL Allie amasthay sheher Hi guys I am a junior from Connecticut studying Computer Science, and I am super excited for this semester When I am not in the CIT, I love going to Bajas, drinking Diet Coke, singing karaoke, or trying to catch the Sci Li rats. Feel free to reach out to me anytime about anything CS15, CS at Brown, or general questions on life. Cant wait to meet you DISTRICT 10 - LIVESTOCK Anastasio aortiz18 hehim Hey My name is Anastasio, I am a Junior from Nicaragua studying APMA-CS. I like ice cream and long walks by the beach. DISTRICT 2 - MASONRY Cannon ccaspar hehim I am Cannon, Junior, CS and Classics Major, from Concord MA. Super excited to HTA CS15 I often do things that make me happy, which includes adventure, fun, hope, power, meditation, and sometimes even CS. Reach out if you ever wanna talk about anything DISTRICT 7 - LUMBER Lexi ehenrion sheher Hi everyone I switched to CS after taking CS15 as a student, and Im now a senior studying Visual Computing. I couldnt be happier, and Im so excited to share this AWESOME class with all of you Im also an artist and writer when Im not coding, wandering around Providence, or eating waffles and reading manga at Zinnekens DISTRICT 6 - TRANSPORTATION Sarah sonderdo sheher Hi I am a junior from New Jersey studying computer science and history. In my free time you can find me hanging out with my friends, pretending to read books, dreaming about pasta, and watching the same movies over and over again. In my not-free time you can find me in the CIT. I am so excited to meet you all, feel free to reach out and say hi DISTRICT 11 - AGRICULTURE Joint Socially Responsible ComputingUndergraduate Teaching Assistants Adam amroueh hehim Hi I am a senior from Rochester, NY studying CS-Econ. I enjoy food, reading and trying new coffee shops. I cant wait for CS15 and to meet everyone DISTRICT 8 - TEXTILES Faizah ffnaqvi sheher Hi everyone Im a sophomore from NJ studying CS and IAPA. In my free time I like reading, baking and then eating what I bake, and dousing my food with Tabasco sauce. Looking forward to meeting you all and having a great semester DISTRICT 13 - NUCLEAR Katie kli154 sheher Hi Im a sophomore from the Seattle area studying computer science and philosophy. I like reading, hiking, tap dancing, losing at chess, and eating Andrews yogurt bowls. DISTRICT 7 - LUMBER Undergraduate Teaching Assistants Alyssa asun59 sheher Hi I am a sophomore from Oregon studying CS-Econ. When I am not rotting in the CIT, Im fencing, watching Dance Moms, or getting food with friends. Welcome to CS15, super excited to have an awesome semester with you guys DISTRICT 5 - POWER Annabel aroth7 sheher Hi Im a senior studying APMA-Econ and CS. I was born in Boston, MA, then lived in Shanghai, China for 5 years before moving to Connecticut. When Im not working on psets in one of the CIT conference rooms, you can find me running, baking, or doing the NYT crossword or some variation of wordle. So excited for an awesome semester with everyone DISTRICT 9 - GRAIN Ashton agglover hehim Hi everyone Im a sophomore from Lake Wylie, South Carolina studying computer science. I like the outdoors, traveling, and watching sports especially soccer. Looking forward to meeting everyone DISTRICT 3 - TECHNOLOGY Asia atnguyen sheher Im a sophomore from Nashville, Tennessee Im planning on concentrating in CS and IAPA. Im a huge swiftie, and I love to read and hang out with my friends in my free time Im so excited to meet you all DISTRICT 1 - LUXURY Astrid armoreno sheher Hi Im a sophomore concentrating in Computer Science. Im from Detroit, Michigan and I enjoy things like reading, crocheting, sewing, and cooking. So excited to guide everyone through the semester DISTRICT 6 - TRANSPORTATION Ayman abenjell hehim Hi everyone Im Ayman, a junior from Casablanca, Morocco studying Computer Science here at Brown When Im not in the CIT, I like walking around campus while drinking boba, playing retro and current Nintendo games, and practicing piano started learning a year ago. I also love drinking anything with caffeine in it, so any teacoffee shop recommendations are welcome. Im super excited for this semester, cant wait to meet yall DISTRICT 12 - MINING Ben baizenbe hehim I am a sophomore from Highland Park, Illinois, probably studying either CS or APMA. Outside of school, I play tennis, do crosswords, and watch movies -- most recently Puss in Boots The Last Wish, one of the best movies ever made. I cant wait to be your TA DISTRICT 12 - MINING Brandon bdiaz2 hehim Hi Im a senior from Atlanta, GA studying CS and IAPA. I love spontaneous beach trips and listening to music. Cant wait to meet everyone DISTRICT 10 - LIVESTOCK Chloe cnevas sheher Hi Im a sophomore from Westport, CT and Im studying APMA-CS. In my free time I love to bake and cook, play the violin, and listen to music. Im SO excited to be a TA for CS15 and Im looking forward to a great semester DISTRICT 8 - TEXTILES Channing cpbryant hehim Hey everyone My name is Channing, and Im from Massachusetts. Im a sophomore studying Computer Science-Economics. I like listening to music, playing sports, eating, and watching movies. Im excited to work with all of you, and feel free to reach out. DISTRICT 3 - TECHNOLOGY Caden cschroe4 hehim Hi Im a sophomore from New Hampshire studying Applied Math and Computer Science. I love going to the beach, playing Spikeball, and climbing trees. Plus, Im a big Ratty and Jos fan so you can usually find me there. Im super excited to meet all of you DISTRICT 6 - TRANSPORTATION Cameron csikich sheher Hi everyone Im a junior from Toronto, Ontario concentrating in APMA-CS. Im also on the Womens Ice Hockey team and I love to bake. Feel free to talk to me about sports, food or anything else. I look forward to meeting you all DISTRICT 4 - FISHING Cindy czheng27 sheher Hi, Im a senior from Louisiana studying APMA-Biology. I love reading, gardening, and walking aimlessly. Looking forward to meeting everyone DISTRICT 6 - TRANSPORTATION Dan dliu58 hehim Hello there Im a junior concentrating in CS from Lockport, NY. My hobbies are sleeping in late, try-harding at Mario Kart and Smash, reading mangaweb serials, and spending money at the CIT vending machines. DISTRICT 12 - MINING Daniel Z.dzhu36 hehim Hey everyone Im a sophomore from San Ramon, California studying neuroscience and computer science. In my free time, I enjoy hiking, reading mangabooks, playing games, cooking, and voice calling friends on discord. So excited to meet you all in CS15 DISTRICT 3 - TECHNOLOGY Dawood dolaniyi hehim Hey everybody, Im Dawood Im a CS student from Americas most beloved state, Iowa real place, I swear. If Im not coding video games in my dorm Im probably saving my semester in the Sci-Li basement. If you ever see me hopping around campus, try to stop me for a conversation Id love to chat Thank yall for contributing to my sophmore-year excitement by taking CS15, Im beyond excited to work and learn with you all DISTRICT 11 - AGRICULTURE Emily H. ehinds3 sheher Im a senior from Seattle, WA concentrating in Computer Science and French and I am so excited to meet all of the students this year DISTRICT 7 - LUMBER Emily O. eiolson sheher Hi everyone Im a sophomore planning on studying a combination of computer science and physics. Im from the Bay Area, California, but I am so happy to call Providence a home now too. Im even more happy to get to work with you all, and I cant wait for a great semester in CS15 DISTRICT 11 - AGRICULTURE Emily W. emwang sheher Hi Im a sophomore from the Chicago suburbs, studying CS. I spend most of my time crocheting, watching anime, playing violin, and making silly drawings. Super excited to be your TA this semester D DISTRICT 9 - GRAIN Ethan eohayon1 hehim Hi I am a Junior from Maryland studying CS-Econ. In my free time I enjoy playing sports, hanging at the beach, and walking my dog. Im looking forward to working with everyone this fall DISTRICT 6 - TRANSPORTATION Francesca felia sheher Hi Im a sophomore double concentrating in APMA-Econ and CS. I love thrifting, iced caramel lattes, watching trashy reality TV, and beach days which is unfortunate considering Im from Minnesota. Im so incredibly excited to TA this year and cannot wait to meet you all, so feel free to reach out for anything DISTRICT 1 - LUXURY Gaby cgchoi sheher hi im a sophomore from irvine, california studying cs-econ and international business in my free time i love making coffee, drinking coffee, and spending way too much on coffee ceremony. im also always at trader joes. so excited to meet everyone DISTRICT 10 - LIVESTOCK Gavin gdhanda hehim Hi Im a sophomore majoring in CS and Econ from Denver, Colorado. I play the guitar and piano in my free time and take lots of naps, and Im so excited to TA CS15 this fall DISTRICT 3 - TECHNOLOGY Grace gcma sheher Hi, and welcome to CS15 Im Grace and Im a sophomore from Montgomery County, Maryland studying music and maybe cs idk. I enjoy playing random instruments, eating Chinese food, and watching animated kids shows. Super excited to meet you all DISTRICT 11 - AGRICULTURE Grace gmarshbu sheher Hi Im a junior from Houston studying CS and visual arts, both for animation. Im also interested in Russian language, musical performance, and fiction writing. When I can, I love to travel, watch animated movies, and listen to all sorts of music. Im also very fond of Blue Room, so Ill go there as often as my flex points allow. DISTRICT 3 - TECHNOLOGY Grant glandon hehim Hello everyone Im a Junior from the North Shore of Massachusetts studying Applied Math and Computer Science. In my free time, I enjoy playing Spikeball on the main green, climbing anything and everything that looks climbable including but not limited to rocks, walls, and trees, and playing tabletop games like Dungeons and Dragons. I cant wait to meet you all DISTRICT 13 - NUCLEAR Julie hchung33 sheher Hi everyone Im Julie from West Hartford, CT. In my free time, I love to write music, go for nature walks, play Nintendo Switch, and attempt to skateboard. You can probably spot me in Steinert center practice rooms. Im so excited to meet everyone, welcome to CS15 DISTRICT 6 - TRANSPORTATION Ilan ibrauns hehim Hi everyone, Im Ilan I am a sophomore from South Orange, New Jersey studying Applied Math - Computer Science and Mathematics. In my free time I like to play sports, work out, and hang with friends. I love my dog Ruby and you can find me constantly tracking my fantasy football team. Im so excited for the semester and feel free to reach out about CS15 or anything else DISTRICT 7 - LUMBER Imran ihussai3 hehim Hey Im a sophomore from Cambridge, MA, studying neuroscience and computer science. I love climbing, pottery, and I am a barista here at the underground cafe So excited to meet all of you DISTRICT 7 - LUMBER Isabelle iashapir sheher Hi Im Isabelle, and Im a sophomore from Los Angeles studying CS. In my free time, I love cooking, baking, and trying new food. Ive enjoyed eating pretty much every food Ive tried except for cashews. I also love anything outdoors hiking, rock climbing, kayaking, swimming, etc. I am so excited to be a CS15 TA this semester DISTRICT 9 - GRAIN Jackson jwschwar hehim I am a sophomore from southern Connecticut. I am thinking about concentrating in Computer Science and possibly Political Science. I love sports and am involved in club Frisbee on campus. I also love the outdoors and spend most of my summers in the Adirondacks in upstate New York. I am super excited to experience CS15 again and to meet you all throughout the semester DISTRICT 7 - LUMBER Jaclyn jcohen45 any pronouns Hi all Im a sophomore CS and Visa concentrator from South Florida. I love anything art and design, spooky full moon ceremonies, spending time in nature, ressurecting Blueno, and chasing birbs Im excited to meet all of you DISTRICT 10 - LIVESTOCK Jinho jlee812 hehim Hey Im a sophomore from Cambridge, Mass studying CS and literary arts When Im not on tiktok, Im in lecture watching tiktok. I love Taylor Swift, Succession, and am looking forward to meeting you all DISTRICT 11 - AGRICULTURE Jennifer jzliao sheher Hi, Im Jennifer Im a sophomore from Farmington, CT planning to concentrate in CS and History. I like reading, playing piano and guitar, and rotting in bed. so excited for CS15 DISTRICT 1 - LUXURY Juan jgarci71 hehim Hey everyone My name is Juan, and Im a junior from Compton, CA studying CS and Education. Outside of school, I tend to spend time playing random mobile games or watching a Gordon Ramsay show. Im so excited to meet you all this semester DISTRICT 6 - TRANSPORTATION Kamryn kwalke19 sheher Hi Im a sophomore from Maryland studying CS. When Im not camping at the CIT, Im dancing go Fusion Dance Company, reading, thrifting, or exploring cities. You can also find me in the Mosaic room pretty often. Im so excited for this semester and I cant wait to meet you all DISTRICT 12 - MINING Kanayo kduru1 hehim Hi Im a junior from Maryland. I like outdoor activities, cooking, and listening to music. If Im not sleeping, you can usually find me sitting on the green enjoying the sun, unless its winter in which case Ill disappear. I love exploring new places and food, so you might also just catch me wandering around Im so excited to meet all of you. Welcome to CS15 DISTRICT 1 - LUXURY Karim kmouline hehim Hi there My name is Karim, and I am a junior studying Math-CS and English. While Im not in the CIT working on projects or essays, you can find me in the pool with the club swim team, on the bike path with the running club, or spending an abnormal amount of flex points on Blue Room bagels and coffee. Let me know if you have questions about anything, whether it be Brown related or life in general DISTRICT 4 - FISHING Keanu kthuynh hehim Hi Im a sophomore from LA concentrating in Computer Science and Applied Math if everything goes my way. Outside of CS15, I enjoy video games, comics, photography, and blowing all my Bear Bucks on Blue Room muffins. If its something to brag about, I own the griddy emote in Fortnite. If its not, I dont own the griddy emote in Fortnite. Excited to see you all this year DISTRICT 9 - GRAIN Khalil kodesai hehim Hello My name is Khalil and I am a sophomore from San Diego, California planning to study Computational Biology. I love all things science and have some wet-lab experience if that is something any of yall want to ask me about Outside of academics, I love playing the flute, baking pies, and being generally a bit of a mess. I also listen to a ton of music Big Thief, Radiohead, Angel Olsen, Sufjan Stevens, etc., so come talk to me about that DISTRICT 11 - AGRICULTURE Logan ldhines hethey hey im a sophomore from portland, oregon studying CS and maybe linguistics. outside of school im really into thrifting, hiking, and listening to music while worrying about my spotify wrapped please feel free to recommend anything i also love trying out random baking recipes and failing miserably. im super super excited to meet all of you this semester DISTRICT 6 - TRANSPORTATION Lana lyangmac sheher Hi everyone Im a sophomore from Ann Arbor, Michigan and Im planning on concentrating in computer engineering. In my free time, I love to read, eat anything mango flavored, and spend time outside especially hiking or swimming. Cant wait to meet you all DISTRICT 7 - LUMBER Morgane mpizigo sheher Hi Im a sophomore from France concentrating in Computer Science and Psychology. CS15 is the class that convinced me to pursue CS, so I hope yall have a blast Outside of classes, I love crocheting, cooking badly, playing fishing mini games, and pursuing my love for hiking and martial arts. Debugging and testing are my favorite parts of CS, so dont feel bad if you bring a bug to me DISTRICT 4 - FISHING Marissa mshaffe3 shethey Hiya Im a sophomore from Philadelphia, PA, studying CS and either Science, Technology, and Society or Gender and Sexuality Studies. On campus, you can find me performing circus shows with Brown Aerial Acrobatics and a cappella music with the Higher Keys. I love contemporary fantasy fiction, racing my mom on the NYT crossword, and sipping boba on the main green. DISTRICT 6 - TRANSPORTATION Megan mtanuwid sheher Hi everyone Im a sophomore from Jakarta, Indonesia studying Computational Biology. I love solving crosswords, eating English muffins, and binge-watching Law Order SVU. Cant wait to meet everyone DISTRICT 3 - TECHNOLOGY Natalie nking12 sheher Im a sophomore from Houston, Texas. Im planning on concentrating in CS and Econ and Im so excited to TA the best class ever this year DISTRICT 3 - TECHNOLOGY Owen oanders6 hehim Im a junior studying Computer Science and Philosophy from Portland, Maine. When Im not coding, I like watching sports, the beach, and bagels. Looking forward to the semester with you all DISTRICT 13 - NUCLEAR Orlando ocedeno hehim Hey my name is Orlando Im currently a Senior studying computer science and Im originally from the Bronx, NY. Currently, Im binge watching One Piece, catching sunsets, going to the gym, or just chilling. DISTRICT 10 - LIVESTOCK Robyn rjecroi1 Hi Im a sophomore. I am 87.2 likely to double concentrate in IAPA and CS. I am an avid sunset picture taker, Music lover Spotify Apple Music, and an unhealthily committed binger of shows yes Ive watched up to 16 seasons of Greys Anatomy and will finish 20 seasons of One Piece. I am also excited to be your TA this semester. DISTRICT 4 - FISHING Sarah sberhan4 sheher Hi everyone Im Sarah, and I am a sophomore from Cambridge, MA. I am undecided in my concentration, but I am thinking about Education and CS. In my free time, I enjoy doing the wordle, playing connections, and reading I am super excited to get to know you all Feel free to ask me any questions DISTRICT 6 - TRANSPORTATION Sarah snrichma sheher Hi Im a sophomore from Danville, New Hampshire studying APMA-CS and physics. Outside of computer science, I love dancing and eating mint chocolate chip ice cream. Im super excited to be a C15 TA this semester DISTRICT 8 - TEXTILES Seehanah stang52 sheher hiii im a junior from central jersey studying apma- cs. im from central jersey and enjoy eating, hiking, and traveling. really excited for a great semester with everyone DISTRICT 9 - GRAIN Sherry szhan235 sheher Hey Im a junior from Bellevue, WA studying CS with a focus on animation. I love drawing a lot and also enjoy powerlifting, swimming, and being in nature. Please do not mention anything animeanimation-related in front of me because I will literally not be able to stop talking about it. Cant wait for you to take CS15 lt3 DISTRICT 4 - FISHING Sophia szlim sheher Hi everyone My name is Sophia and Im a sophomore from Auckland, New Zealand. I intend on concentrating in Computer Science and maybe Cognitive Science but I enjoy exploring different classes in Browns Open Curriculum. I love traveling, baking, and wasting my time watching tv shows and movies. Cant wait to get to know you all this semester DISTRICT 1 - LUXURY Will wvandewa hehim Junior from Cleveland, Ohio studying APMA-CS. Crochet enjoyer and casual runner. Its gonna be a crazy year. DISTRICT 7 - LUMBER Xiaoyue xhou8 sheher Im a junior concentrating in CS and Econ, and Im from Beijing, China. I love traveling, hiking, learning languages, and watching stage managing musicals. Really excited to meet you all DISTRICT 3 - TECHNOLOGY", "metadata": {"last_modified": "2023-12-07T01:33:54+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["WELCOME TO CSCI 0150", "Assignments", "Lectures", "Labs & Sections", "Code-Along", "Hours", "Resources", "SRC", "Staff"], "word_count": 5521, "token_count_estimate": 7386}}, "https://cs.brown.edu/login/?next=/account/": {"text_content": "Sign In Brown CS users , please use your Brown Account to sign in. Brown Login Friends and alumni , non-Brown logins are disabled for now.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Sign In"], "word_count": 26, "token_count_estimate": 31}}, "https://cs.brown.edu/courses/cs019/2016/professionalism.html": {"text_content": "Fall 2016 Accelerated Introduction to Computer Science 1 Anticipated Frequent Questions 2 README 3 Learning Goals, Assessments, and Time Allocation 4 Syllabus and Course Policies 5 Diversity and Professionalism 6 Assignments 7 Textbook 8 Software 9 Staff and Contact 10 Peer Review 11 How to Ask Questions and Report Bugs 12 Pyret Style Guide 13 Credits 5 Diversity and Professionalism 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure On this page 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure prev up next 5 Diversity and Professionalism 5.1 Be An Adult 5.2 About Course Staff 5.3 Disclosure The lack of sufficient diversity is an important problem in computerscience. In this course, we want to help improve the situation, notmake it worse. Some of the responsibility for that lies with us, thecourse staff, but a lot of it ultimately rests with you, the students. 5.1 Be An Adult College is a great time, and for many of you might offer a sense ofnew-found liberation. I sure remember how liberating college felt forme Its a space for exploration and experimentation of various kindslegal, no doubt. However, it also provides opportunities to crossvarious lines, and unfortunately some people do so in awful ways. Every now and then I hear disturbing statements from students abouthow they have been made to feel uncomfortable in class or in thedepartment. I dont mean intellectual discomfort e.g., the kind youmight get from having a heated debate about a technical subject with afellow student but the personal kind. These range from inappropriatecomments to invitations to even touching and other physicalcontact. The subjects are almost overwhelmingly but not exclusivelyfemale students or from races underrepresented in computer science. Theres a term for some of the behaviors I hear about. Its called harassment . And let there be absolutely no doubt about thisharassment is against the law and it is completely against thenorms by which we want to run this course and thisdepartment. See Browns Title IX Web site .We the university, the department, and this coursesstaff have absolutely zero tolerance for it. Your reaction might be to laugh it off, or to make or think snideremarks about political correctness or jokes about consent or whathave you. You might think people just need to grow a thicker skin orlearn to take a joke. However, the subject of your harassment and thats what your remarksand actions are, harassment , even if you decide you wouldclassify them as jokes is forced, by the nature of classes and campuslife, to be around you. That can make them uncomfortable to the pointof wanting to stay away, or focusing more on you than on what they arehere to learn. That hurts their education. That is not okay at allyou have no right to steal their hard-won education away fromthem. And often the harm goes much deeper it hurts thempsychologically in subtle and long-standing ways. And thats why theseare not laughing matters. In light of recent reports about such issues on campus, Brown istaking additional steps to reduce this form of harm. Therefore, if Icannot appeal to your decency, intelligence, and collegiality, let meat least appeal to your self-interest. Do not mess around on thismatter. It will not go well for you. However, I prefer that you think of this in positive terms. Yourclassmates are your colleagues. Someday you may be each othersstart-up partners or co-employees one of you may even be the othersinterviewer or boss. So start treating one another like professionals,and I mean that in the best possible interpretation of that phrase. In short Be safe, be happy, and have fun without taking away anyoneelses. 5.2 About Course Staff Professionalism and respect for diversity are not just matters betweenstudents they also apply to how the course staff treat the students.The staff of this course pledge to treat you in a way that respectsour differences. However, despite our best efforts, we might slip up,hopefully inadvertently. When we do, please feel free to talk to usabout it. Sometimes, you may not be comfortable bringing this up directly tous. If so, you are welcome to talk to Laura Dobler or to the department chair . As a department, we will take all complaints about unprofessional ordiscriminatory behavior seriously. 5.3 Disclosure In principle, I would like to say that you are always open to cometalk to me if you are facing any such issues. Unfortunately, I have towarn you that on account of being the director of our PhD program, Imwhat Title IX law calls a Responsible Employee . That means, ifyou report an incident to me, I am required to report it to theTitle IX coordinator at Brown. This will likely launch aninvestigation. Usually, an investigation is a good idea. However, I realize this mayput you in an uncomfortable position, and thats certainly not what Iwant. Therefore, I need to tell you that if you want to do thingsconfidentially, you should talk to one of the many resources listed here . If you would like to learn more about Browns policies and resources,please see the universitys Title IX site . prev up next", "metadata": {"last_modified": "2016-12-24T01:59:00+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 847, "token_count_estimate": 1091}}, "https://cs.brown.edu/courses/cs125/index.html": {"text_content": "CS125 Menu Home FAQs Course Missive Syllabus Lectures Assignments Resources Gallery CS125 Intro to 3D Computer Animation Brown University Learn More Welcome to CSCI 1250 In this course you will be introduced to the process of making a short computer animated film from beginning to end. Its super fun and usually a lot of work. To learn more about the course, click on Course Missive . Also check out the CS125 FAQs . First Class Meeting CSCI 1250 will not be offered Fall 2023. I will be teaching my advanced course CS1950T instead. The course is capped at 20 students and requires an application which is open here . You must also attend the first class in order to have your application considered. Make sure to put this course in your shopping cart to get email updates about the course. Selection criteria include class seniority, previous related experience, and enthusiasm. We aim to create a diverse class so there is no one thing that assures acceptance. Prerequisites There are no fixed prerequisites for the class, but we like to see demonstrated in-depth background in computer science, computer graphics, a related area like filmmaking, or in some aspect of visual art. Your background does not have to be from a formal course, but you will have to explain or demonstrate it. If you have an online portfolio or website, you can provide a link in your application. This is not necessary, but can give us a better picture of you. In the mean time, you can read about the course in the missive and syllabus. HTML5 UP", "metadata": {"last_modified": "2023-03-07T18:34:07+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["CS125"], "word_count": 266, "token_count_estimate": 320}}, "https://cs17-fall2022.github.io": {"text_content": "cs17-fall2022.github.io I think youre on the wrong page If you were looking for the current version of CS17, you can find the website at httpscs17-fall2023.github.iocs17fall2023.github.io", "metadata": {"last_modified": "2023-08-04T00:11:17+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 25, "token_count_estimate": 50}}, "https://cs.brown.edu/courses/cs051/": {"text_content": "CS051 Models of Computation The Next Generation rip 51 About Models of Computation This was a core undergraduateComputer Science course on the foundations of computing. Thequestions it aimed to answer were 1 What is computation 2 What iscomputable 3 What is computable given our limited resources The course has now been renamed CS1010, Theory of Computation. Come visit CS1010", "metadata": {"last_modified": "2016-09-02T06:18:15+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["CS051 Models of Computation", "The Next Generation"], "word_count": 59, "token_count_estimate": 79}}, "https://cs.brown.edu/courses/": {"text_content": "Computer Science Courses The following is a comprehensive list of Computer Science course offerings. Or view CS courses at CoursesBrown . Semester charts are available for Fall 23 119.3 KB and Spring 24 228.1 KB . The undergraduate TA program is a great way for students to get to know their professors, sharpen their knowledge of a subject, and get paid See the UTA-designed slides promoting next semesters courses . What CS Course Should I Take Showing all 2024-2025 courses Showing summer 2024-2025 courses Showing fall 2024-2025 courses Showing spring 2024-2025 courses Showing all current and past courses Hiding course details Showing course details CSCI0020 The Digital World Fall 2024 H-Tue Thu 0900am-1020am TBD Donald L Stanford CSCI0030 Introduction to Computation for the Humanities and Social Sciences CSCI0040 Introduction to Scientific Computing and Problem Solving CSCI0050 A Data-Centric Introduction to Programming CSCI0060 Practical Systems Skills CSCI0080 A First Byte of Computer Science CSCI0081 TA Apprenticeship Full Credit Fall 2024 TBD TBD Thomas W Doeppner Spring 2025 TBD TBD Thomas W Doeppner CSCI0082 TA Apprenticeship Half Credit Fall 2024 TBD TBD Thomas W Doeppner Spring 2025 TBD TBD Thomas W Doeppner CSCI0100 Data Fluency for All CSCI0111 Computing Foundations Data Fall 2024 C-Mon Wed Fri 1000am-1050am Metcalf Research Building AUD Milda Zizyte Spring 2025 TBD TBD Milda Zizyte CSCI0112 Computing Foundations Program Organization Fall 2024 TBD TBD Tim Nelson CSCI0130 User Interfaces and User Experience CSCI0150 Introduction to Object-Oriented Programming and Computer Science Fall 2024 TBD TBD Andries van Dam CSCI0160 Introduction to Algorithms and Data Structures CSCI0170 CS An Integrated Introduction Fall 2024 TBD TBD John F Hughes CSCI0180 CS An Integrated Introduction CSCI0190 Accelerated Introduction to Computer Science Fall 2024 TBD TBD Shriram Krishnamurthi CSCI0200 Program Design with Data Structures and Algorithms Fall 2024 TBD TBD Nicholas A DeMarinis Spring 2025 TBD TBD Kathi Fisler CSCI0220 Introduction to Discrete Structures and Probability Spring 2025 TBD TBD Robert Y. Lewis CSCI0300 Fundamentals of Computer Systems Spring 2025 TBD TBD Nicholas A DeMarinis , Malte Schwarzkopf CSCI0310 Introduction to Computer Systems CSCI0320 Introduction to Software Engineering Fall 2024 TBD TBD Tim Nelson Spring 2025 TBD TBD Tim Nelson CSCI0330 Introduction to Computer Systems Fall 2024 TBD TBD Thomas W Doeppner CSCI0360 Introduction to Systems Programming CSCI0450 Introduction to Probability and Computing CSCI0500 Data Structures, Algorithms, and Intractability An Introduction Spring 2025 TBD TBD Philip Klein CSCI0510 Models of Computation CSCI0530 Coding the Matrix an Introduction to Linear Algebra for Computer Science CSCI0920 Educational Software Seminar CSCI0931 Introduction to Computation for the Humanities and Social Sciences CSCI1010 Theory of Computation Fall 2024 TBD TBD Lorenzo De Stefani CSCI1040 The Basics of Cryptographic Systems Spring 2025 TBD TBD Anna A Lysyanskaya CSCI1230 Computer Graphics Fall 2024 TBD TBD Daniel C Ritchie CSCI1234 Computer Graphics Lab Fall 2024 TBD TBD Daniel C Ritchie CSCI1250 Introduction to Computer Animation Fall 2024 TBD TBD Barbara J. Meier CSCI1260 Compilers and Program Analysis Fall 2024 TBD TBD Robert Y. Lewis CSCI1270 Database Management Systems Fall 2024 TBD TBD Ugur Cetintemel CSCI1280 Intermediate 3D Computer Animation CSCI1290 Computational Photography Fall 2024 TBD TBD James H Tompkin CSCI1300 User Interfaces and User Experience Spring 2025 TBD TBD TBD CSCI1301 Livestreaming Reimagined CSCI1310 Fundamentals of Computer Systems Spring 2025 TBD TBD Nicholas A DeMarinis , Malte Schwarzkopf CSCI1320 Creating Modern Mobile Web Applications CSCI1330 Computer Systems Masters students only Fall 2024 TBD TBD Thomas W Doeppner CSCI1340 Introduction to Software Engineering Fall 2024 TBD TBD Tim Nelson Spring 2025 TBD TBD Tim Nelson CSCI1360 Human Factors in Cybersecurity Fall 2024 TBD TBD Ernesto Zaldivar CSCI1370 Virtual Reality Design for Science CSCI1380 Distributed Computer Systems Spring 2025 TBD TBD Nikos Vasilakis CSCI1410 Artificial Intelligence Fall 2024 TBD TBD TBD CSCI1420 Machine Learning Spring 2025 TBD TBD Stephen Bach CSCI1430 Computer Vision Fall 2024 TBD TBD Srinath Sridhar Spring 2025 TBD TBD Srinath Sridhar CSCI1440 Algorithmic Game Theory Spring 2025 TBD TBD Amy R Greenwald CSCI1450 Advanced Introduction to Probability for Computing and Data Science CSCI1460 Computational Linguistics Fall 2024 TBD TBD Ellie Pavlick CSCI1470 Deep Learning Spring 2025 TBD TBD Ritambhara Singh CSCI1480 Building Intelligent Robots CSCI1490 Introduction to Combinatorial Optimization CSCI1510 Introduction to Cryptography and Computer Security Fall 2024 TBD TBD Peihan Miao CSCI1515 Applied Cryptography Spring 2025 TBD TBD Peihan Miao CSCI1550 Probabilistic Methods in Computer Science Spring 2025 TBD TBD Eli Upfal CSCI1570 Design and Analysis of Algorithms Fall 2024 TBD TBD Lorenzo De Stefani CSCI1575 Algorithms In Depth CSCI1580 Information Retrieval and Web Search CSCI1590 Introduction to Computational Complexity CSCI1600 Real-time and Embedded Software Fall 2024 TBD TBD Milda Zizyte CSCI1610 Building High-Performance Servers CSCI1620 Computer Systems Security Lab Spring 2025 TBD TBD Nicholas A DeMarinis CSCI1650 Software Security and Exploitation Fall 2024 TBD TBD Vasileios Kemerlis CSCI1660 Computer Systems Security Spring 2025 TBD TBD Bernardo Palazzi , Nicholas A DeMarinis CSCI1670 Operating Systems Spring 2025 TBD TBD Thomas W Doeppner CSCI1680 Computer Networks Fall 2024 TBD TBD Nicholas A DeMarinis CSCI1690 Operating Systems Laboratory Spring 2025 TBD TBD Thomas W Doeppner CSCI1695 Operating System Design and Implementation CSCI1710 Logic for Systems Spring 2025 TBD TBD Tim Nelson CSCI1729 Programming Languages Lab CSCI1730 Design and Implementation of Programming Languages Fall 2024 TBD TBD Shriram Krishnamurthi CSCI1760 Multiprocessor Synchronization Fall 2024 TBD TBD Maurice P Herlihy CSCI1780 Parallel and Distributed Programming CSCI1800 Cybersecurity and International Relations Spring 2025 TBD TBD Ernesto Zaldivar CSCI1805 Computers, Freedom and Privacy Current Topics in Law and Policy Fall 2024 TBD TBD Timothy H Edgar CSCI1810 Computational Molecular Biology Fall 2024 TBD TBD Sorin Istrail CSCI1820 Algorithmic Foundations of Computational Biology Spring 2025 TBD TBD Sorin Istrail CSCI1850 Deep Learning in Genomics CSCI1860 Cybersecurity Law and Policy Fall 2024 TBD TBD Timothy H Edgar CSCI1870 Cybersecurity Ethics Fall 2024 TBD TBD Deborah Hurley CSCI1880 Introduction to Computer Security Spring 2025 TBD TBD Bernardo Palazzi CSCI1900 csciStartup CSCI1950-E Human-Robot Interaction Seminar CSCI1950-H Computational Topology CSCI1950-I Designing, Developing and Evaluating User Interfaces CSCI1950-N 2D Game Engines Fall 2024 TBD TBD James H Tompkin CSCI1950-Q Programming for the Humanities and Social Sciences CSCI1950-R Compiler Practice CSCI1950-S Fundamentals of Computer Systems CSCI1950-T Advanced Animation Production CSCI1950-U Topics in 3D Game Engine Development Spring 2025 TBD TBD Daniel C Ritchie CSCI1950-V Advanced GPU Programming CSCI1950-W Topics in Data Science CSCI1950-X Software Foundations CSCI1950-Y Logic for Systems CSCI1950-Z Computational Methods for Biology CSCI1951-A Data Science Spring 2025 TBD TBD Lorenzo De Stefani CSCI1951-B Virtual Citizens or Subjects The Global Battle Over Governing Your Internet CSCI1951-C Designing Humanity Centered Robots CSCI1951-D Projective Geometry via Interactive Proof Assistants CSCI1951-E Computer Systems Security Principles and Practice CSCI1951-G Optimization Methods in Finance CSCI1951-H Software Security and Exploitation CSCI1951-I CS for Social Change CSCI1951-J Interdisciplinary Scientific Visualization CSCI1951-L Blockchains Cryptocurrencies Spring 2025 TBD TBD Maurice P Herlihy CSCI1951-M Great Ideas in Computer Science CSCI1951-N VRX, the Potential of Virtual Reality to Transform Nearly Everything CSCI1951-O Design of Robotic Systems CSCI1951-R Introduction to Robotics CSCI1951-S Virtual Reality Software Review CSCI1951-T Surveying VR Data Visualization Software for Research CSCI1951-U Software Engineering of Large Systems CSCI1951-V HypertextHypermedia The Web Was Not the Beginning and the Web Is Not the End CSCI1951-W Sublinear Algorithms for Big Data CSCI1951-X Formal Proof and Verification CSCI1951-Y The Robots are Coming The Robots are Coming CSCI1951-Z Fairness in Automated Decision Making Spring 2025 TBD TBD Suresh Venkatasubramanian CSCI1952-B Responsible Computer Science in Practice Spring 2025 TBD TBD Julia Netter CSCI1952-C Frontiers of Graph Algorithms Seminar CSCI1952-I Language Processing in Humans and Machines CSCI1952-L Robotics and Choreography CSCI1952-Q Robust Algorithms for Machine Learning Spring 2025 TBD TBD Yu Cheng CSCI1952-V Algorithms for the People CSCI1952-X Contemporary Digital Policy and Politics Spring 2025 TBD TBD Timothy H Edgar CSCI1952-Y Computer Architecture Spring 2025 TBD TBD Milda Zizyte CSCI1952-Z Robots as a Medium Creating art with teams of robots Spring 2025 TBD TBD Nora Ayanian CSCI1970 Individual Independent Study CSCI1971 Independent Study in 2D Game Engines CSCI1972 Topics in 3D Game Engine Development CSCI2000 Computer Science Research Methods CSCI2002 Privacy and Personal Data Protection Spring 2025 TBD TBD Deborah Hurley CSCI2230 Computer Graphics Fall 2024 TBD TBD Daniel C Ritchie CSCI2240 Interactive Computer Graphics Spring 2025 TBD TBD Daniel C Ritchie CSCI2270 Topics in Database Management Spring 2025 TBD TBD Stanley B Zdonik , Ugur Cetintemel CSCI2300 Human-Computer Interaction Seminar CSCI2310 Human Factors and User Interface Design CSCI2330 Programming Environments CSCI2340 Software Engineering Fall 2024 TBD TBD Steven P Reiss Spring 2025 TBD TBD Steven P Reiss CSCI2370 Interdisciplinary Scientific Visualization Fall 2024 TBD TBD David H. Laidlaw CSCI2390 Privacy-Conscious Computer Systems CSCI2410 Statistical Models in Natural-Language Understanding CSCI2420 Probabilistic Graphical Models CSCI2440 Advanced Algorithmic Game Theory Spring 2025 TBD TBD Amy R Greenwald CSCI2470 Deep Learning Spring 2025 TBD TBD Ritambhara Singh CSCI2500-A Advanced Algorithms CSCI2500-B Optimization Algorithms for Planar Graphs Spring 2025 TBD TBD Philip Klein CSCI2500-C Graph Theory and Algorithms CSCI2510 Approximation Algorithms CSCI2520 Computational Geometry CSCI2531 Internet and Web Algorithms CSCI2540 Advanced Probabilistic Methods in Computer Science Spring 2025 TBD TBD TBD CSCI2550 Parallel Computation Models, Algorithms, Limits CSCI2560 Advanced Complexity CSCI2570 Introduction to Nanocomputing CSCI2580 Solving Hard Problems in Combinatorial Optimization Theory and Systems CSCI2590 Advanced Topics in Cryptography CSCI2660 Computer Systems Security Spring 2025 TBD TBD Bernardo Palazzi , Nicholas A DeMarinis CSCI2670 Operating Systems Spring 2025 TBD TBD Thomas W Doeppner CSCI2730 Programming Language Theory CSCI2750 Topics in Parallel Distributed Computing CSCI2810 Advanced Computational Molecular Biology Fall 2024 TBD TBD Sorin Istrail CSCI2820 Algorithmic Foundations in Computational Biology Spring 2025 TBD TBD Sorin Istrail CSCI2840 Advanced Algorithms in Computational Biology and Medical Bioinformatics CSCI2950-C Algorithms for Cancer Genomics CSCI2950-E Stochastic Optimization CSCI2950-G Large-Scale Networked Systems CSCI2950-J Cognition, Human-Computer Interaction and Visual Analysis CSCI2950-K Special Topics in Computational Linguistics CSCI2950-L Medical Bioinformatics Disease Associations, Protein Folding and Immunogenomics CSCI2950-O Topics in Brain-Computer Interfaces CSCI2950-P Special Topics in Machine Learning CSCI2950-Q Topics in Computer Vision CSCI2950-R Special Topics in Advanced Algorithms CSCI2950-T Topics in Distributed Databases Systems CSCI2950-U Special Topics on Networking and Distributed Systems CSCI2950-V Topics in Applied Cryptography CSCI2950-W Online Algorithms CSCI2950-X Topics in Programming Languages Systems CSCI2950-Z Robot Learning and Autonomy CSCI2951-A Robots for Education CSCI2951-B Data-Driven Vision and Graphics CSCI2951-C Autonomous Agents and Computational Market Design CSCI2951-D Topics in Information Retrieval and Web Search CSCI2951-E Topics in Computer System Security Fall 2024 TBD TBD Roberto Tamassia CSCI2951-F Learning and Sequential Decision Making Spring 2025 TBD TBD Ronald Parr CSCI2951-G Computational Protein Folding CSCI2951-H Algorithms for Big Data CSCI2951-I Computer Vision for Graphics and Interaction Fall 2024 TBD TBD James H Tompkin CSCI2951-J Topics in Advanced Algorithmics Algorithmic Game Theory, 3D Computational Geometry, Quantum Computing CSCI2951-K Topics in Collaborative Robotics CSCI2951-L Human-Computer Interaction Seminar CSCI2951-M Advanced Algorithms Seminar CSCI2951-N Advanced Algorithms in Computational Biology CSCI2951-O Foundations of Prescriptive Analytics Spring 2025 TBD TBD Serdar Kadioglu CSCI2951-P Human-Robot Interaction Seminar CSCI2951-Q Topics in Advanced Algorithms CSCI2951-R Personal Informatics Seminar CSCI2951-S Distributed Computing through Combinatorial Topology CSCI2951-T Data-Drive Computer Vision CSCI2951-U Topics in Software Security Spring 2025 TBD TBD Vasileios Kemerlis CSCI2951-V Systems for Interactive Data Exploration CSCI2951-W Creative Artificial Intelligence for Computer Graphics CSCI2951-X Reintegrating AI Spring 2025 TBD TBD George D Konidaris CSCI2951-Y Special Topics in Formal Semantics and Notional Machines CSCI2951-Z Advanced Algorithmic Game Theory CSCI2952-A Blockchains and Cryptocurrencies CSCI2952-B Topics in Computer Science Education Research CSCI2952-C Learning with Limited Labeled Data CSCI2952-D Computational Semantics CSCI2952-E Topics in Network Management Data-driven and Programmable Networks CSCI2952-F Distributed Systems at Scale Microservices Management CSCI2952-G Deep Learning in Genomics CSCI2952-H Recent Progress in Reinforcement Learning CSCI2952-I Language Processing in Humans and Machines CSCI2952-J Computing with Emerging Technology CSCI2952-K Topics in 3D Computer Vision and Deep Learning CSCI2952-L Special Topics in Secure Computation CSCI2952-M The Works that Made and Changed Machine Learning CSCI2952-N Advanced Topics in Deep Learning Spring 2025 TBD TBD Chen Sun CSCI2952-O A Practical Introduction to Advanced 3D Robot Perception Spring 2025 TBD TBD Srinath Sridhar CSCI2952-P Coordinated Mobile Robotics CSCI2952-Q Robust Algorithms for Machine Learning Fall 2024 TBD TBD Yu Cheng CSCI2952-R Systems Transforming Systems CSCI2952-S Topics in Cyber and Digital Policy Spring 2025 TBD TBD Timothy H Edgar CSCI2952-V Algorithms for the People CSCI2955 The Design and Analysis of Trading Agents CSCI2956-F Machine Learning Reading Group CSCI2980 Reading and Research DATA0080 Data, Ethics and Society DATA0200 Data Science Fluency DATA1030 Hands-on Data Science DATA1050 Data Engineering DATA2040 Deep Learning DATA2050 Data Science Practicum DATA2080 Data and Society ENGN2502 3D Photography ENGN2520 Pattern Recognition and Machine Learning XLISTBIOL1430 Computational Theory of Molecular Evolution XLISTENGN2911-I 3D Photography and Geometry Processing", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Information for:", "Computer Science Courses"], "word_count": 2073, "token_count_estimate": 3556}}, "https://cs.brown.edu/courses/cs137/2006/images.html": {"text_content": "VirtualReality Design for Science IMAGE GALLERIES 2002 ClassCreations July 2004Visit to Bat-Cave... sort of 2004 ClassDemo Day 2006 classfaces... home classdescription calendar images links previous years 2002 2004 Brown Brown CS RISD RISD Illustration BrownCS Visualization", "metadata": {"last_modified": "2006-09-13T13:25:54+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 36, "token_count_estimate": 68}}, "https://cs.brown.edu/courses/cs0931/": {"text_content": "This course has been renumbered and is using the URL cs.brown.educoursescsci0030 , so head there instead.", "metadata": {"last_modified": "2017-01-30T23:12:38+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 16, "token_count_estimate": 28}}, "https://cs.brown.edu/courses/cs0931/2012/": {"text_content": "Im Ruth Simmons and I endorse this interdisciplinary course. Home Assignments Staff Resources Projects Welcome to CS0931, Spring 2012 Before you continue , read About CS0931 for information about the waitlist, prerequisites, and work load. Whether you know a little bit about programming and are eager tolearn more or youve never programmed before, dont worry, were hereto help. CS0931 is an introductory computer science course specifically developed for concentrators in the humanities andsocial sciences. Because of this, well be focusing on real worldapplications rather than computer science theory. There are noprerequisites , though some experience with Excel will help.Students from all fields are welcome. The course will be very hands-on and cover a variety oftopics that will ultimately allow you to Practice solving real world problems by learning to use new tools and applying familiar ones - like Excel - in new ways Gather data from the web Learn about and create algorithms that analyze large amounts of data Create web-based interfaces Become proficient in a scripting language CS0931 meets Tuesdays and Thursdays from 230-350 PM in room 265 ofthe CIT map . Check out the staff page to meet theinstructor, faculty, and TAs. For more information, read the Course Missive . All studentsmust read and sign the Collaboration Policy . Past editions of the course can be found on the offerings page .", "metadata": {"last_modified": "2013-01-18T01:29:20+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [], "word_count": 224, "token_count_estimate": 277}}, "https://cs0320.github.io/": {"text_content": "You need to enable JavaScript to run this app.", "metadata": {"last_modified": "2024-03-11T22:16:24+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 9, "token_count_estimate": 10}}, "https://cs.brown.edu/courses/cs132/": {"text_content": "Skip to main content Home Description Tracks Lectures Assignments Final Project Labs Hours Docs Staff CSCI1320 Modern Web Mobile Applications CSCI1320 takes a holistic look at the process of developing web and mobile applications and aims to bring the students to a point of mastery of many of the most used technologies and development practices. Zoom link for the lecture link Course Description CSCI 1320, Creating Modern Web and Mobile Applications, is a spring semester course within the Brown CS department. The course has two tracks, one intended for CS concentrators, and one intended for non-concentrators with previous design experience. It takes a holistic look at the process of developing web and mobile applications and aims to bring the students to a point of mastery of many of the most used technologies and development practices. The course includes a semester long group final project in which the students will be working with external companies, non-profits, and other organizations. Tracks Concentrator The Concentrator track will teach students everything they need to know to program a practical and workable web or mobile application. It starts with HTML, covers JavaScript in the front end, various back end technologies, databases, as well as security, scaling and testing issues. Students in this track can expect to do a significant amount of programming mostly in JavaScript on their assignments and in their final project. CSCI 1320s Concentrator track is high encouraged for Computer Science concentrators or potential concentrators and is appropriate for any student who has completed an intro level CS course CS15, CS17, CS19 or has equivalent programming experience. Students should be comfortable with basic programming concepts. CS33 Introduction to Computer Systems and CS32 Introduction to Software Engineering are listed on CAB as recommended courses. Having taken either of these courses will certainly make the material easier, as students who have taken these courses will have had experience working on large-scale, open-ended projects similar to this courses final project. However, such experience is by no means necessary for students to succeed in CS132s concentrator track. Students should still bear in mind that the concentrator track of CS132 may be an intense experience, especially for students without previous web background. Expect assignments to take upwards of 5-10 hours to complete. Designer The Designer track is for students with a design background that would like to apply that background to creating web and mobile applications. Students in this track are expected to be familiar with various design tools and have some background in HTML or web design. Designers will be expected to take the lead role in the user interface design for their final project. The Designer track does involve some programming, but to a much smaller degree than the concentrator track. Assignments in this track will let students show off their design expertise rather than their programming skills. The Designer track is most appropriate for non-concentrators with design experience, as well as most RISD students. Capstone Students taking CS132 for capstone credit must take the concentrator track. In addition, they are expected either to propose and guide a final project or to act as the leader of their project team or both. Lectures Topic Date Slides Lecture Capture Course Introduction 12021 PDF PPTX Capture The Browser and HTML 12221 PDF PPTX Capture Accessibility 12521 PDF PPTX Capture Lab 2 HTML 12721 PDF PPTX JavaScript 12921 PDF PPTX Capture DOM 2121 PDF PPTX Capture DOM 2321 PDF PPTX Capture Requirements and Specifications 2521 PDF PPTX Capture Lab 3 DOM 2821 PDF PPTX Capture FrameworksVUE 21021 PDF PPTX Capture Lab 4 VUE 21221 PDF PPTX Capture NO CLASS 21521 --- Capture --- Capture Web Server 21721 PDF PPTX Capture Node.js 21921 PDF PPTX Capture Web Architectures 22221 PDF PPTX Capture Web Architectures II 22421 PDF PPTX Capture Lab 5 Node.js 22621 PDF PPTX Capture Project Elevator Pitches 3121 PDF PPTX Capture Databases Part I 3321 PDF PPTX Capture Databases Part II 3521 PDF PPTX Capture Lab 6 Databases 3821 PDF PPTX Capture Mobile Applications 31021 PDF PPTX Capture NativeScript 31221 PDF PPTX Capture Lab 7 Mobile Lab 31521 PDF PPTX Capture HCI I 31721 PDF PPTX Capture Lab 8 AWS 31921 PDF PPTX Capture HCI II 32221 PDF PPTX Capture HCI III 32421 PDF PPTX Capture Security I 32621 PDF PPTX Capture Security II 32921 PDF PPTX Capture Security III 33121 PDF PPTX Capture Privacy 4221 PDF PPTX Capture Testing Part I 4521 PDF PPTX Capture Testing Part II 4721 PDF PPTX Capture NO CLASS 4921 --- Capture --- Capture Project Presentations 41221 --- --- Project Presentations 41421 --- --- Project Presentations 41621 --- --- Assignments Concentrator Out Due 0 Logistics Setup 12021 12621 1 HTML CSS 12721 2721 2 Javascript 2821 21921 3 Vue 21721 22621 4 Backend 3121 31221 5 Mobile 31521 32621 6 Final Exam 41521 42021 Designer Out Due 0 Logistics Setup 12021 12621 1 HTML CSS 12721 2721 2 Javascript 2821 21921 3 Vue 21721 22621 4 Wireframes Mockups 3121 31221 5 Prototype 31521 32621 6 Final Exam 41521 42021 Labs Please complete pre-labs before each lab. Topic Pre-Lab Out Pre-Lab Due Lab Out Lab Due 1 Accessibility --- --- 12221 12721 2 HTML Pre-Lab 12221 12721 12721 During class 12721 During class 3 DOM Pre-Lab 2321 2821 2821 During class 2821 During class 4 Vue.js Pre-Lab 21021 21221 21221 During class 21221 During class 5 Node.js Pre-Lab 21921 22621 22621 During class 22621 During class 6 Databases Pre-Lab 3321 3821 3821 During class 3821 During class 7 Mobile Pre-Lab 31221 31521 31521 During class 31521 During class 8 AWS Pre-Lab 31521 31921 31921 During class 31921 During class Hours Please check the calendar for the latest times and the most updated schedule. Join the queue using SignMeUp when signing up for hours. Docs The syllabus can be found here . Note that the dates in the syllabus are tentative and that the actual deadlines will be on this website and on the course calendar for each LabPre-LabAssignmentFinal Project checkpoint. Professor Steve Reiss spr HTAs Jen Kaplan jckaplan Pragadeesh pchandir UTAs Colby Anderson cander23 Enmin Zhou ezhou24 Griffin Kupsaw gkupsaw Hans Bala hbala Kalli Feinberg kfeinbe1 Ragna Agerup ragerup Delmy Garcia dgarci14 CSCI1320 Spring 2021 Professor Steve Reiss cs1320taslists.brown.edu cs1320headtaslists.brown.edu", "metadata": {"last_modified": "2021-04-15T17:09:19+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["CSCI1320", "Modern Web & Mobile Applications", "Course Description", "Tracks", "Lectures", "Assignments", "Labs", "Hours", "Docs", "Professor", "HTAs", "UTAs"], "word_count": 1037, "token_count_estimate": 1548}}, "https://cs.brown.edu/courses/cs137/": {"text_content": "Virtual Reality Design for Science, Fall 2019 Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 2017 Brown CS Visualization RISD Illustration For those considering the Fall 2019 class, consider the following I suggest reviewing the course website from 2017, especially the calendar page, to see exactly what the class involves. That has all the assignments. The course description in CAB is short, so reviewing this info will make sure that know exactly what you would be doing in taking the course. We will provide overrides after the first assignment is handed in. In the past, we have almost always been able to accommodate everyone what was interested, who made it to the classes, and who completed the first assignment. I cant guarantee that will be the case this year, but it has been for the last 10 years. For registration, please request an override in CAB and also make sure that the class is in your primary cart. Those steps will keep you on the waiting list and also ensure that you get course emails. This course explores the visual and human-computer interaction design processfor scientific applications in immersive virtual reality. It is cross listedat Brown as CSCI1370 and RISD as ILLUS3340 and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, as well as Stephen Gatesy from Ecology and Evolutionary Biology. Brandon Li is the TA. Computer science students learn how to work effectively with each other aswell as with artists and designers in creating applications targeting BrownsCaves. A Cave is an immersive virtual reality space whose floor and walls arecovered with displays, which we will use to create interactive 3D virtualenvironments. There are currently two Caves on campus that are managed by the Brown Center for Computation and Visualization CCV the YURT, a curved display system with 360-degree field of view located at 180 George St., and its predecessor an 8x8x8 cube display system located at Studio4 of the Granoff Center. Artists and designers learn to interact with scientists in designing andrealizing applications in this new medium. We study the process of design fromseveral perspectives learn about some specific scientific problems studyexisting applications of scientific visualization and virtual reality explorethe medium of the YURT create designs for the scientific applicationscritique, evaluate, realize, and iterate the designs and culminate with ademonstration of final projects. The first class meets Thursday, September 5th at 10am in 180 George St. room 102B. 2019 shoppers, check out the calendar page for many details about what the course will involve.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Virtual Reality Design for Science, Fall 2019"], "word_count": 432, "token_count_estimate": 571}}, "https://cs.brown.edu/courses/cs137/2008/": {"text_content": "Virtual Reality Design for Science, Fall 2008 Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 Brown CS Visualization RISD Illustration This course explores the visual and human-computer interaction design process for scientific applications in immersive virtual reality. It is cross listed at Brown as CSCI1370 and RISD as ILLUS5303 and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, and Sharon Swartz from Ecology and Evolutionary Biology. Jadrian Miles is the TA. Computer science students learn how to work effectively with each other as well as with artists and designers in creating applications targeting Browns Cave. A Cave is an 8x8x8 cube whose floor and walls are covered with displays, which we will use to create interactive 3D virtual environments. Artists and designers learn to interact with scientists in designing and realizing applications in this new medium. We study the process of design from several perspectives learn about some specific scientific problems study existing applications of scientific visualization and virtual reality explore the medium of the Cave create designs for the scientific applications critique, evaluate, realize, and iterate the designs and culminate with a demonstration of final projects.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["Virtual Reality Design for Science, Fall 2008"], "word_count": 201, "token_count_estimate": 267}}, "https://cs.brown.edu/courses/cs137/2013/gallery/": {"text_content": "CS137 2013 Gallery This page shows student work from CS137 . Week 2 - 5 temporarily removed due to ongoing class assignments Tuesday, Week 6 Tuesday, Week 8 Tuesday, Week 10 Thursday, Week 10 Thursday, Week 11", "metadata": {"last_modified": "2017-09-10T01:42:08+00:00", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": ["CS137", "Gallery", "Week 2 - 5 temporarily removed due to ongoing class assignments", "Tuesday, Week 6", "Tuesday, Week 8", "Tuesday, Week 10", "Thursday, Week 10", "Thursday, Week 11"], "word_count": 37, "token_count_estimate": 53}}, "https://cs.brown.edu/courses/cs137/2015/gallery/": {"text_content": "VR Design for Science Gallery Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 Brown CS Visualization RISD Illustration Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 5B Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11A Week 11B Week 13A Week 13B Week 14A Week 14B Week 15A Week 15B", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:19+00:00", "headings": [": Gallery", "Week 2B", "Week 3A", "Week 3B", "Week 4A", "Week 4B", "Week 5A", "Week 5B", "Week 6A", "Week 6B", "Week 7A", "Week 7B", "Week 8A", "Week 8B", "Week 9A", "Week 9B", "Week 10A", "Week 10B", "Week 11A", "Week 11B", "Week 13A", "Week 13B", "Week 14A", "Week 14B", "Week 15A", "Week 15B"], "word_count": 78, "token_count_estimate": 151}}, "https://cs.brown.edu/courses/cs137/2017/gallery/": {"text_content": "VR Design for Science Gallery Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 Brown CS Visualization RISD Illustration Week 2A Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11A Week 11B Week 13A Week 13B Week 14A Week 14B Week 15A", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [": Gallery", "Week 2A", "Week 2B", "Week 3A", "Week 3B", "Week 4A", "Week 4B", "Week 5A", "Week 6A", "Week 6B", "Week 7A", "Week 7B", "Week 8A", "Week 8B", "Week 9A", "Week 9B", "Week 10A", "Week 10B", "Week 11A", "Week 11B", "Week 13A", "Week 13B", "Week 14A", "Week 14B", "Week 15A"], "word_count": 77, "token_count_estimate": 150}}, "https://cs.brown.edu/courses/cs137/gallery/": {"text_content": "VR Design for Science Gallery Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 Brown CS Visualization RISD Illustration Week 2A Week 2B Week 3A Week 3B Week 4A Week 4B Week 5A Week 5B Week 6A Week 6B Week 7A Week 7B Week 8A Week 8B Week 9A Week 9B Week 10A Week 10B Week 11 Week 12 Week 13 Week 14", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [": Gallery", "Week 2A", "Week 2B", "Week 3A", "Week 3B", "Week 4A", "Week 4B", "Week 5A", "Week 5B", "Week 6A", "Week 6B", "Week 7A", "Week 7B", "Week 8A", "Week 8B", "Week 9A", "Week 9B", "Week 10A", "Week 10B", "Week 11", "Week 12", "Week 13", "Week 14"], "word_count": 73, "token_count_estimate": 138}}, "https://cs.brown.edu/courses/cs138/s18/": {"text_content": "Latest Announcements 0412 Puddlestore released Due 0507, via handin script. 0405 Homework 3 released Due 0419, please submit on Gradescope. See all announcements Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms e.g., naming, replication, security, etc. and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time TuTh 1030-1150 Location Metcalf Research AUD If you are not registered for the class and would like to be put on the waitlist, thenplease fill out this form. Course Staff Well be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380taslists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtaslists.brown.edu . Instructor Name Email Office Hours Theo Benson tabcs.brown.edu CIT 327 Tuesdays 4-5 p.m., Wednesdays 11-12 p.m. Teaching Assistants Name Email Office Office Hours HTA Sidd Karamcheti skaramchcs.brown.edu CIT 205 Thursday 1-3 p.m. TA Amedeo Alberio aalberiocs.brown.edu CIT 205 Friday 4-6 p.m. TA Abdulla Aldilaijan aaldilaics.brown.edu CIT 205 Monday 6-8 p.m. TA Sandy Harvie charviecs.brown.edu CIT 205 Sunday 6-8 p.m. TA Ben Shteinfeld bshteinfcs.brown.edu CIT 205 Wednesday 10 a.m.-12 p.m. TA Jared Siskin jsiskin1cs.brown.edu CIT 205 Tuesday 6-8 p.m. Course Policies Collaboration Policy The collaboration policy document is available online. You must read it,and then sign the collaboration policy form so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances e.g. severe illness, death in the family, kidnapping, etc. too heavy of a course load is not sufficient reason for an incomplete. Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late.", "metadata": {"last_modified": "2023-11-08T16:09:51+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["", "", "Latest Announcements", "Overview", "Course Staff", "Course Policies"], "word_count": 398, "token_count_estimate": 626}}, "https://cs.brown.edu/courses/cs138/s17/": {"text_content": "Attention This is an old version of the CS 138 website. Please click here for the current offering. Latest Announcements 0316 Raft released Due 0411 via handin script. 0216 Tapestry released Due 0302 via handin script. 0212 Homework 1 released Due 0222, please submit on Gradescope. See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms e.g., naming, replication, security, etc. and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time TuTh 1030-1150 Location BioMed 202 If you are not registered for the class and would like to be put on the waitlist, thenplease fill out this form. Course Staff Well be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380taslists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtaslists.brown.edu . Instructor Name Email Office Hours Tom Doeppner twdcs.brown.edu CIT 405 Mondays and Wednesdays 3-4 p.m., Fridays 4-5 p.m. Rodrigo Fonseca rfonsecacs.brown.edu CIT 329 TBD Teaching Assistants Name Email Office Office Hours HTA Louisa Conwill lconwillcs.brown.edu CIT 205 Monday 7-9 p.m. HTA Atty Eleti aeletics.brown.edu CIT 271 Fishbowl Thursday 7-9 p.m. TA Carlos Rotger crotgercs.brown.edu CIT 205 Sunday 7-9 p.m. TA Scott Zellers szellerscs.brown.edu CIT 205 Thursday 4-6 p.m. TA Max Luzuriaga mluzuriacs.brown.edu CIT 205 Wednesday 7-9 p.m. TA Haris Choudhary hchoudhacs.brown.edu CIT 205 Friday 4-6 p.m. TA Ishan Bansal ibansalcs.brown.edu CIT 205 Tuesday 7-9 p.m. TA Rohil Bhansali rb32cs.brown.edu CIT 205 Tuesday 4-6 p.m. Course Policies Collaboration Policy The collaboration policy is available as a handout. You must print, read,and sign the collaboration policy before returning it to a TA so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances e.g. severe illness, death in the family, kidnapping, etc. too heavy of a course load is not sufficient reason for an incomplete. Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late.", "metadata": {"last_modified": "2023-11-08T16:10:08+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["", "", "Attention: This is an old version of the CS 138 website. Please click", "for the current offering.", "Latest Announcements", "Overview", "Course Staff", "Course Policies"], "word_count": 457, "token_count_estimate": 733}}, "https://cs.brown.edu/courses/cs173/2012/book/Desugaring_as_a_Language_Feature.html": {"text_content": "Programming Languages Application and Interpretation 1 Introduction 2 Everything We Will Say About Parsing 3 A First Look at Interpretation 4 A First Taste of Desugaring 5 Adding Functions to the Language 6 From Substitution to Environments 7 Functions Anywhere 8 Mutation Structures and Variables 9 Recursion and Cycles Procedures and Data 10 Objects 11 Memory Management 12 Representation Decisions 13 Desugaring as a Language Feature 14 Control Operations 15 Checking Program Invariants Statically Types 16 Checking Program Invariants Dynamically Contracts 17 Alternate Application Semantics 13 Desugaring as a Language Feature 13.1 A First Example 13.2 Syntax Transformers as Functions 13.3 Guards 13.4 Or A Simple Macro with Many Features 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages On this page 13.1 A First Example 13.2 Syntax Transformers as Functions sc-macro-eg sc-macro-eg-body sc-macro-eg-rule 13.3 Guards sc-macro-eg-guarded-rule 13.4 Or A Simple Macro with Many Features 13.4.1 A First Attempt 13.4.2 Guarding Evaluation 13.4.3 Hygiene 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages prev up next 13 Desugaring as a Language Feature We have thus far extensively discussed and relied upon desugaring, butour current desugaring mechanism have been weak. We have actuallyused desugaring in two different ways. One, we have used it to shrink the language to take a large language and distill itdown to its core REF. But we have also used it to grow thelanguage to take an existing language and add new features to itREF. This just shows that desugaring is a tremendously usefulfeature to have. Indeed, it is so useful that we might ask twoquestions Because we create languages to simplify the creation of commontasks, what would a language designed to support desugaring looklike Note that by look we dont mean only syntax but also itskey behavioral properties. Given that general-purpose languages are often used as atarget for desugaring, why dont they offer desugaring capabilities in the language itself For instance, this might meanextending a base language with the additional language that is theresponse to the previous question. We are going to explore the answer to both questions simultaneously,by studying the facilities provided for this by Racket. 13.1 A First Example DrRacket has a very useful toolcalled the Macro Stepper, which shows the step-by-step expansion ofprograms. You should try all the examples in this chapter using theMacro Stepper. For now, however, you should run them in lang plai rather than lang plai-typed . Remember that in REF we added let as syntactic sugar over lambda . The pattern we followed was this let var val body is transformed into lambda var body val Do Now If this doesnt sound familiar, now would be a good time to refreshyour memory of why this works. The simplest way of describing this transformation would be to stateit directly to write, somehow, let var val body - lambda var body val In fact, this is almost precisely what Racket enables you to do. Well use the name my-let instead of let Because the latter is already defined in Racket. define-syntax my-let-1 syntax-rules my-let-1 var val body lambda var body val syntax-rules tells Racket that whenever it sees an expressionwith my-let-1 immediately after the opening parenthesis, itshould check that it follows the pattern my-let-1 var valbody .The var , val and body are syntactic variables they are variables that stand for bodies ofcode. In particular, they match whatever s-expression is in thatposition. If the expression matches the pattern, then the syntacticvariables are bound to the corresponding parts of the expression, andbecome available for use in the right-hand side. You mayhave noticed some additional syntax, such as . Well explainthis later. The right-hand side in this case, lambda var body val is the output generated. Each ofthe syntactic variables are replaced with the corresponding parts ofthe input using our old friend, substitution. This substitution isutterly simplistic it makes no attempt to. Thus, if we were to tryusing it with my-let-1 3 4 5 Racket would not initially complain that 3 is provided in anidentifier position rather, it would let the identifier percolatethrough, desugaring this into lambda 3 5 4 which in turn produces an error lambda expected either id or id type for function argument in 3 This immediately tells us that the desugaring process isstraightforward in its function it doesnt attempt to guess or beclever, but instead simply rewrites while substituting. The output isan expression that is again subject to desugaring. As a matter of terminology, this simple form of expression-rewritingis often called a macro , as we mentioned earlier in REF.Traditionally this form of desugaring is called macro expansion ,though this term is misleading because the output of desugaring can besmaller than the input though it is usually larger. Of course, in Racket, a let can bind multiple identifiers, notjust one. If we were to write this informally, say on a board, wemight write something like let var val ... body-lambda var ... body val ... with the ... meaning zero or more, and the intent beingthat the var ... in the output should correspond to thesequence of var s in the input. Again, this is almost preciselyRacket syntax define-syntax my-let-2 syntax-rules my-let-2 var val ... body lambda var ... body val ... Observe the power of the ... notation the sequence ofpairs in the input is turned into a pair of sequences in theoutput put differently, Racket unzips the input sequence.Conversely, this same notation can be used to zip together sequences. 13.2 Syntax Transformers as Functions Earlier we saw that my-let-1 does not even attempt to ensurethat the syntax in the identifier position is truly i.e.,syntactically an identifier. We cannot remedy that with the syntax-rules mechanism, but we can with a much more powerfulmechanism called syntax-case . Because syntax-case exhibits many other useful features as well, well introduce it andthen grow it gradually. The first thing to understand is that a macro is actually a function . It is not, however, a function from regular run-timevalues to other run-time values, but rather a function from syntax to syntax . These functions execute in a worldwhose purpose is to create the program to execute .Observe that were talking about the program to execute theactual execution of the program may only occur much later or never atall. This point is actually extremely clear when we examinedesugaring, which is very explicitly a function from one kind ofsyntax to another kind of syntax. This is perhaps obscured above intwo ways The notation of syntax-rules , with no explicitparameter name or other function header, may not make clear thatit is a functional transformation though the rewriting rule formatdoes allude to this fact. In desugaring, we specify one atomic function for the entireprocess. Here, we are actually writing several little functions,one for each kind of new syntactic construct such as my-let-1 , and these pieces are woven together by aninvisible function that controls the overall rewriting process. Asa concrete example, it is not inherently clear that the output of amacro is expanded further though a simple example immediatelydemonstrates that this is indeed the case. Exercise Write one or more macros to confirm that the output of a macro isexpanded further. There is one more subtlety. Because the form of a macro looks ratherlike Racket code, it is not immediately clear that it lives inanother world. In the abstract, it may be helpful to imagine thatthe macro definitions are actually written in an entirely differentlanguage that processes only syntax. This simplicity is, however,misleading. In practice, program transformers also called compilers are full-blown programs, too, and need all the powerof ordinary programs. This would have necessitated the creation of aparallel language purely for processing programs. This would bewasteful and pointless therefore, Racket instead endowssyntax-transforming programs with the full power of Racket itself. With that prelude, lets now introduce syntax-case . Wellbegin by simply rewriting my-let-1 under the name my-let-3 using this new notation. First, we have to write aheader for the definition notice already the explicit parameter sc-macro-eg define-syntax my-let-3 x sc-macro-eg-body This binds x to the entire my-let-3 ... expression. As you might imagine, define-syntax simply tells Racket youreabout to define a new macro. It does not pick precisely how you wantto implement it, leaving you free to use any mechanism thatsconvenient. Earlier we used syntax-rules now were going touse syntax-case . In particular, syntax-case needs toexplicitly be given access to the expression to pattern-match sc-macro-eg-body syntax-case x sc-macro-eg-rule Now were ready to express the rewrite we wanted. Previously arewriting rule had two parts the structure of the input and thecorresponding output. The same holds here. The first matching theinput is the same as before, but the second the output is a littledifferent sc-macro-eg-rule my-let-3 var val body lambda var body val Observe the crucial extra characters . Lets examine whatthat means. In syntax-rules , the entire output part simply specifies thestructure of the output. In contrast, because syntax-case islaying bare the functional nature of transformation, the output partis in fact an arbitrary expression that may perform any computationsit wishes. It must simply evaluate to a piece of syntax. Syntax is actually a distinct datatype. As with any distinct dataype,it has its own rules for construction. Concretely, we constructsyntax values by writing the following s-expression istreated as a syntax value. In case you were wondering, the x bound in the macro definition above is also of this datatype. The syntax constructor, , enjoys a special property. Insidethe output part of the macro, all syntax variables in the input areautomatically bound, and replaced on occurrence. As a result, whenthe expander encounters var in the output, say, it replaces var with the corresponding part of the input expression. Do Now Remove the and try using the above macro definition. Whathappens So far, syntax-case merely appears to be a more complicatedform of syntax-rules perhaps slightly better in that it morecleanly delineates the functional nature of expansion, and the type ofoutput, but otherwise simply more unwieldy. As we will see, however,it also offers significant power. Exercise syntax-rules can actually be expressed as a macro over syntax-case . Define it. 13.3 Guards Now we can return to the problem that originally motivated theintroduction of syntax-case ensuring that the bindingposition of a my-let-3 is syntactically an identifier. Forthis, you need to know one new feature of syntax-case eachrewriting rule can have two parts as above, or three. If there arethree present, the middle one is treated as a guard apredicate that must evaluate to true for expansion to proceed ratherthan signal a syntax error. Especially useful in this context is thepredicate identifier , which determines whether a syntax objectis syntactically an identifier or variable. Do Now Write the guard and rewrite the rule to incorporate it. Hopefully you stumbled on a subtlety the argument to identifier is of type syntax . It needs to refer to theactual fragment of syntax bound to var . Recall that var is bound in the syntax space, and substitutes identifiersbound there. Therefore, the correct way to write the guard is identifier var With this information, we can now write the entire rule sc-macro-eg-guarded-rule my-let-3 var val body identifier var lambda var body val Do Now Now that you have a guarded rule definition, try to use the macro witha non-identifier in the binding position and see what happens. 13.4 Or A Simple Macro with Many Features Consider or , which implements disjunction. It is natural, withprefix syntax, to allow or to have an arbitrary number ofsub-terms. We expand or into nested conditionals thatdetermine the truth of the expression. 13.4.1 A First Attempt Lets try a first version of or define-syntax my-or-1 x syntax-case x my-or-1 e0 e1 ... if e0 e0 my-or-1 e1 ... It says that we can provide any number of sub-terms more on this in amoment. Expansion rewrites this into a conditional that tests thefirst sub-term if this is a true value it returns that value more on this in a moment, otherwise it is the disjunction of theremaining terms. Lets try this on a simple example. We would expect this to evaluateto true , but instead my-or-1 f t my-or-1 bad syntax in my-or-1 What happened This expression turned into if f f my-or-1 t which in turn expanded into if f f if t t my-or-1 for which there is no definition. Thats because the pattern e0 e1 ... means one or more sub-terms, but we ignored thecase when there are zero. What should happen when there are no sub-termsThe identity for disjunction is falsehood. Exercise Why is f the right default By filling it in below, we illustrate a macro that has more than onerule. Macro rules are matched sequentially, so we should be sure toput the most specific rules first, lest they get overridden by moregeneral ones though in this particular case, the two rules arenon-overlapping. This yields our improved macro define-syntax my-or-2 x syntax-case x my-or-2 f my-or-2 e0 e1 ... if e0 e0 my-or-2 e1 ... which now expands as we expect. Though it isnt necessary, we willadd a rule for the case when there is only a single sub-term define-syntax my-or-3 x syntax-case x my-or-3 f my-or-3 e e my-or-3 e0 e1 ... if e0 e0 my-or-3 e1 ... This keeps the output of expansion more concise, which we will finduseful below. Observe that in this version of the macro, thepatterns are not disjoint the third one-or-more sub-termssubsumes the second one sub-term. Therefore, it is essential thatthe second rule not swap with the third. 13.4.2 Guarding Evaluation We said above that this expands as we expect.Or does it Lets try the following example let init f my-or-3 begin set init not init init f Observe that or returns the actual value of the firsttruthy value, so the developer can use it in furthercomputations. Therefore, this returns the value of init . Whatdo we expect it to be Naturally, because weve negated the value of init once, we expect it to be t . But evaluating itproduces f This problem is not an artifact of set . Ifinstead of internal mutation we had, say, printed output, the printingwould have occurred twice. To understand why, we have to examine the expanded code. It is this let init f if begin set init not init init begin set init not init init f Aha Because weve written the output pattern as if e0 e0 ... This looked entirely benign when we first wrote it, but it illustratesa very important principle when writing macros or indeed any otherprogram transformation systems do not copy code In oursetting, a syntactic variable should never be repeated if you need torepeat it in a way that might cause multiple execution of that code,make sure you have considered the consequences of this.Alternatively, if you meant to work with the value of theexpression, bind it once and use the bound identifiers namesubsequently. This is easy to demonstrate define-syntax my-or-4 x syntax-case x my-or-4 f my-or-4 e e my-or-4 e0 e1 ... let v e0 if v v my-or-4 e1 ... This pattern of introducing a binding creates a new potential problemyou may end up evaluating expressions that werent necessary. Infact, it creates a second, even more subtle one even if it going tobe evaluated, you may evaluate it in the wrong contextTherefore, you have to reason carefully about whether anexpression will be evaluated, and if so, evaluate it once in just theright place, then store that value for subsequent use. When we repeat our previous example, that contained the set ,with my-or-4 , we see that the result is t , as we wouldhave hoped. 13.4.3 Hygiene Hopefully now youre nervous about something else. Do Now What Consider the macro let v t my-or-4 f v . What wouldwe expect this to compute Naturally, t the first branch is f but the second is v , which is bound to t .But lets look at the expansion let v t let v f if v v v This expression, when run directly, evaluates to f . However, let v t my-or-4 f v evaluates to t . In otherwords, the macro seems to magically produce the right value the namesof identifiers chosen in the macro seem to be independent of thoseintroduced by the macro This is unsurprising when it happens in a function the macro expander enjoys a property called hygiene that gives it the same property. One way to think about hygiene is that it effectively automaticallyrenames all bound identifiers. That is, its as if the programexpands as follows let v t or f v turns into let v1 t or f v1 notice the consistent renaming of v to v1 ,which turns into let v1 t let v f v v1 which, after renaming, becomes let v1 t let v2 f v2 v1 when expansion terminates. Observe that each of the programs above,if run directly, will produce the correct answer. 13.5 Identifier Capture Hygienic macros address a routine and important pain that creators ofsyntactic sugar confront. On rare instances, however, a developerwants to intentionally break hygiene. Returning to objects, considerthis input program define os-1 objectself-1 first x msg self second x 1 second x x 1 What does the macro look like Heres an obvious candidate define-syntax objectself-1 syntax-rules object mtd-name var val ... let self lambda msg-name lambda v error object nothing here begin set self lambda msg case msg mtd-name lambda var val ... self Unfortunately, this macro produces the following error self unbound identifier in module in self which is referring to the self in the body of the method boundto first . Exercise Work through the hygienic expansion process to understand why error isthe expected outcome. Before we solve this directly, lets consider a variant of theinput term that makes the binding explicit define os-2 objectself-2 self first x msg self second x 1 second x x 1 The corresponding macro is a small variation on what we had before define-syntax objectself-2 syntax-rules object self mtd-name var val ... let self lambda msg-name lambda v error object nothing here begin set self lambda msg case msg mtd-name lambda var val ... self This macro expands without difficulty. Exercise Work through the expansion of this version and see whats different. This offers a critical insight had the identifier that goes inthe binding position been writtenby the macro user , there would have been no problem. Therefore, wewant to be able to pretend that the introduced identifier waswritten by the user. The function datum-syntax convertsthe s-expression in its second argument its first argument is whichsyntax to pretend it was a part of in our case, the original macrouse, which is bound to x . To introduce the result into theenvironment used for expansion, we use with-syntax to bind itin that environment define-syntax objectself-3 x syntax-case x object mtd-name var val ... with-syntax self datum-syntax x self let self lambda msg-name lambda v error object nothing here begin set self lambda msg-name case msg-name mtd-name lambda var val ... self With this, we can go back to having self be implicit define os-3 objectself-3 first x msg self second x 1 second x x 1 13.6 Influence on Compiler Design The use of macros in a languages definition has an impact on alltools, especially compilers. As a working example, consider let . let has the virtue that it can be compiledefficiently, by just extending the current environment. In contrast,the expansion of let into function application results in amuch more expensive operation the creation of a closure and itsapplication to the argument, achieving effectively the same result butat the cost of more time and often space. This would seem to be an argument against using the macro. However, asmart compiler recognizes that this pattern occurs often, and insteadinternally effectively converts left-left-lambda REF back into theequivalent of let . This has two advantages. First, it meansthe language designer can freely use macros to obtain a smaller corelanguage, rather than having to trade that off against the executioncost. It has a second, much subtler, advantage. Because the compilerrecognizes this pattern, other macros can also exploit it andobtain the same optimization they dont need to contort their outputto insert let terms if the left-left-lambda pattern occursnaturally, as they would have to do otherwise. For instance, theleft-left-lambda pattern occurs naturally when writing certain kindsof pattern-matchers, but it would take an extra step to convert thisinto a let in the expansion which is no longer necessary. 13.7 Desugaring in Other Languages Many modern languages define operations via desugaring, not onlyRacket. In Python, for instance, iterating using for is simplya syntactic pattern. A developer who writes for x in o is introducing a new identifier call it i but be sureto not capture any other i the programmer has alreadydefined, i.e., bind i hygienically, binding it to an iterator obtained from o , and creating a potentially infinite while loop thatrepeatedly invokes the .next method of i until theiterator raises the StopIteration exception. There are many such patterns in modern programming languages. prev up next", "metadata": {"last_modified": "2017-04-15T02:13:57+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 3503, "token_count_estimate": 4706}}, "https://cs.brown.edu/courses/cs173/2018/AFQ.html": {"text_content": "Fall 2018 Programming Languages 1 Anticipated Frequent Questions 2 Learning Goals, Assessments, and Time Allocation 3 Syllabus and Course Policies 4 Late Policy 5 Laptop Policy 6 Diversity and Professionalism 7 Assignments 8 Early Testing for Programming 9 Textbook 10 Software 11 Staff and Contact 12 How to Ask Questions and Report Bugs 13 Pyret Style Guide 14 Credits prev up next 1 Anticipated Frequent Questions This AFQ Anticipated Frequent Questions should cover most of your questions. Q How do I keep on top of things, and where can I ask questionswhile the assignments are in progress Please use the Piazza board .You should use your Brown emailaddress to access the board. Be sure to not post hints or solutions publicly Be aware of the Honesty and Sharing policy before you sign up. Q Are there any exams in this course No. I dont believe exams are a useful way of measuring learningexcept inasmuch as they can be proctored to detect cheating for whichwe have other mechanisms. In return, they are too dependent ontest-taking ability, time preferences, not being ill on a particularday, personal constraints, etc. Therefore, this course has no exams,only Assignments . Q Why do you want anonymous submissions To the extent possible, we want to eliminate biases whengrading. These may include biases both in favor or against peoplebased on attributes such as race, gender, or even how they presentthemselves in person. To make clear we are serious, we will impose asmall penalty if you do include personal identifying informationunless asked to. I know this runs counter to what you have probably been told bycountless prior instructors, and maybe even those in your otherclasses. If youre turning in pieces of paper, it is important tolabel them clearly. Since your submissions here are electronic, thatsnot a problem. In case youre wondering yes, your identity is recorded when yousubmit. However, we run an anonymization script before distributingwork for grading. Therefore, the graders only see an anonymous tokene.g., 103 in place of your identity. You may then wonder what happens when you go in for help after you getgraded material back. Would that deanonymize you for the future, i.e.,will that TA henceforth know who person 103 is No, because the scriptrandomly assigns different tokens on each use. Therefore,theres no reason to believe person 103 from the previous assignmentis the same as 103 on this one in fact, theres a very highlikelihood its a different person. Q What is the course format In your day-to-day work, you are going to confront numerousprogramming languages new ones are created almost daily, and younever know which new language will become really important in yourwork. You therefore need the ability to rapidly dive into newlanguages and understand them. However, you havent really been exposed to a useful mental landscapethat lets you quickly understand a new language. This usually comesthrough practice and experience, combined with a knowledge of variouspoints in the space of language design. The original style of cs173 used 2000 through 2015 was webelieve good at helping you understand a few points in the designspace really well. But it didnt cover enough of the space, nor did itgive you practice with rapidly exploring a large space of designs. In2016 we came up with a radically new way of running the course that wefound addressed this problem. However, we also felt something was lostin the original style, and this was echoed in student evaluations. We had suspected this, but werent sure how much time the new style ofassignments would take, and didnt want to accidentally overburdenstudents. Fortunately, the evaluations confirmed that the assignmentstook less time than we expected. Therefore, we have the time to mergethe two styles making some time for it by dropping or changingassignments. Q What did you do before 2016 Until 2016, the emphasis was on implementing languages throughso-called definitional interpreters working implementations thatcreated the core of a language. We still do this, but far less of it. Q What did you change in 2016 The most important thing is to make you understand that approaching a new language requires a security mindset ,and thats what we want the course to inculcate. It wont be aboutcomputer security per se, but it will be the mindset that comeswith it of probing, asking questions, looking for ways in whichthings might not fit together, etc. We will achieve this through a series of what we call mysterylanguage ML assignments. In an ML assignment, you are given a newlanguage features syntax and a very loose description of it. Theassignment will contain say three different languages thatcontain that new feature, each presented in terms of a black-boximplementation of that language. Each language will contain this newfeature but will define it to behave in a somewhat different way. Youwill need to use the implementations to explore how the feature variesacross the languages and try to pin down the differences precisely. For instance, suppose the new feature is array dereference, and youregiven a notation for it such as ai where a evaluatesto an array and i is an expression computing the arrayindex. When i is within the bounds of the array, all threelanguages might behave identically. But when i isout-of-bounds, one language might signal an error like Java does,another might return a special undefined value like JavaScriptdoes, and the third might return the content of some other arraylike C sometimes does. These differences have all been chosen because they have significantconsequences, and the class after the homework comes due, we willdiscuss them. Note that in the above example, to find thesedifferences, you needed to think like an attacker ask what thearrays do not when you use them as intended but rather when you usethem erroneously. Of course, many ML assignments have nothing to dowith errors, but it is wise to remember that those are also worthchecking. In general, in ML assignments, your task is to Write a small suite of one or more programs, which we call a classifier , that tell the languages apart. That is, eachprogram in the suite produces different outputs on at least two of theimplementations, and across the suite, you can tell all three apart. Since these small programs are meant to be illustrative, it helps tomake them relatively small. At the same time, you will not be rewardedby trying to cleverly wire them all together into a single programthat can sometimes be really hard to understand. If you spot two orthree conceptual differences, try to express them in differentprograms. Imagine youre trying to explain your findings toanother human being, not just impress them with your cleverness. Write a small textual description, the theory , of what you think is thedifference between the languages, focusing on the new feature and itsinteraction with the existing features. This should not just be atextual rewriting of the classifier, but rather an attempt tosynthesize what youve learned and describe the difference inhigh-level terms. What were getting at is essentially the heart of the ScientificMethod. You perform some observations using these, you formulate aninitial theory you use the theory to suggest additional experiments.If an experiment fails, then you have to revise your theory and tryagain. As more experiments succeed, you gain greater and greaterfaith in your theory. At some point you conclude youre sufficientlysatisfied with your theory, you clean up your work, and you turn it in. Q Were there other issues you were trying to address in 2016 Yes, there are a few things that also needed fixing The course was a little too helpful to cs017 students and to alesser extent, cs019 students, and disadvantaged cs015students. Though weve tried various mitigations over the years, theyhave worked only somewhat. The use of mystery languages greatlyreduces that advantage. The course was a little too much focused on implementation,whereas thats really the domain of a course on compilers. We wantedto reduce the emphasis on implementation of languages and increase theemphasis on understanding them. Q So the new style is a merger of the two approaches Thats correct. There will be a whole bunch of mystery languages. Nowthat we have a good understanding of how much time they take, we havealso been able to put back in several implementation tasks. We willalso implement some other tools to help you understand some patternsin programming language tools as well as in language expressive power. Q How much time will things take For the mystery languages, specificallywe ask that if you spend more than five hours on a homework,stop talk to the course staff make sure youre on the righttrack. We may tell you youre on the right track and to continue wemay tell you youre on the wrong path and help set you right or wemay tell you youve gotten the point of the assignment and shouldstop. For the other implementation assignments, your usual internal cueson programming apply. Q What are Core, Advanced, and Prank In the mystery language assignments, you may see the differentlanguages labeled differently. Every assignment has usually threeCore languages. These reflect the most common or important variationsin these features. The array dereference example described abovepresents three such variations. Sometimes, there are variations that have made it into real languagesbut are less important or harder to find. We label these Advanced. Forinstance, in array dereferencing, a negative index, instead of beingan error, could mean that many indices from the end of thearray. We would consider this an Advanced but a somewhatstraightforward one for people familiar with certain languages thathave this behavior. Before you tackle any Advanceds, make sure youvenailed down the differences between the Cores Also, be aware that theAdvanceds may take a little or a lot more time than a core. On very rare instances, an assignment might also have Pranklanguages. This is usually us re-implementing for you especiallybizarre behaviors found in some language. You should only try toclassify these languages if youre really bored or really want to showoff your language hacking skills. Under no circumstances will weexpect you to get any of them to get an A in the course. As anexample, there was once a bug in a well-known browser wheredereferencing the index -6 would return the value of eval , adangerous primitive that many Web sandboxes do their best to hide. Ifwe were to provide an implementation of this, wed certainly classifyit as a Prank. Q I have a question not answered above Where do I send it A Address it to the professor . prev up next", "metadata": {"last_modified": "2018-11-19T18:20:44+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 1732, "token_count_estimate": 2197}}, "https://browncsci1430.github.io/index.html": {"text_content": "This website requires JavaScript to function.", "metadata": {"last_modified": "2024-02-29T16:33:04+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["This website requires JavaScript to function."], "word_count": 6, "token_count_estimate": 7}}, "https://cs.brown.edu/courses/cs145/": {"text_content": "Home Lectures Assignments Calendar Staff Resources CS1450, Fall 2023, taught by Professor Eli Upfal and Alessio Mazzetto Probability and statistics have become indispensable tools in computer science. Probabilistic methods and statistical reasoning play major roles in machine learning, cryptography, network security, communication protocols, web search engines, robotics, program verification, and more. This course introduces the basic concepts of probability and statistics, focusing on topics that are most useful in computer science applications. Topics include modeling and solution in sample space, random variables, simple random processes and their probability distributions, Markov processes, limit theorems, and basic elements of statistical inference. This course emphasizes both mathematical rigor and computing applications. For more details, please refer to the course syllabus . We use Ed Stem in this course. You can join it by clicking the Ed Discussion tab on the canvas page for this course. Please let us know if you cant access Ed Stem. Fall 2023 Lectures will be held in CIT 368.", "metadata": {"last_modified": "2023-09-08T23:31:34+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 161, "token_count_estimate": 206}}, "https://brown-csci1660.github.io": {"text_content": "CS1660 Computer Systems Security About Assignments Lectures CalendarHours Staff Resources FAQ About Assignments Lectures CalendarHours Staff Resources FAQ Quick links Zoom Join lectures here EdStem Used for announcements, online questions, etc Gradescope Submit work here, and receive grades for all assignments Panopto View lecture recordings here. Hours Used to manage queuing and links for all one-on-one and remote office hours Administrative Information Whats this course about CS1660 formerly called CS166 is a course on computer systems security through a balanced mixture of theory and practice. Well start out with building the foundations of security through an exploration of cryptography . From there, well move to more complex, multi-faceted systems such as web applications , operating systems , and networks . Along the way, well explore complementary topics such as authentication, physical security, social engineering, privacy, anonymity, usability, and the security of emergent systems such as blockchains and machine learning. By learning about security through these multiple domains, youll concretely learn how various classes of attacks appear in a vast variety of scenarios and how they work in practice. Youll also learn how to evaluate systems adversarially, from writing precise security analyses about subtle issues in protocols to discovering and exploiting vulnerabilities in concrete technical systems for yourself. Through all of these activities, youll ultimately work to develop a specific kind of intuitiona security mindset that will give you the knowledge, vocabulary, and confidence to critically analyze and effectively defend the software and systems you approach as a computer scientist even after the course. CS1620CS2660 The Lab We encourage you to take additional half-credit lab, called CS1620 for undergraduates or CS2660 for masters graduate students, or concurrent masters students. Senior undergraduates may use the lab portion to count for their capstone requirement. Students taking the lab have the opportunity to work on advanced challenges that will provide you with a greater appreciation of systems security and the security mindset as a whole CS1620CS2660 provides students with a deeper understanding of the material by doing advanced versions of the CS1660s projects and advanced questions on the written assignments. These advanced versions focus on real-world skills performing attacks that are more difficult and rely on less serious vulnerabilities, performing attacks against systems with more real-world constraints, and creating attacks that achieve a higher standard of quality than a mere proof of concept. CS1620 vs. CS2660 Due to credit-counting logistics, the lab portion of the course has two different course numbers CS1620 and CS2660. Undergraduate students wishing to do the half-credit lab should sign up for CS1620 in addition to CS1660. CS2660 combines both CS1660 and CS1620 in one, 2000-level course. If you are a graduate student or an ScB student who has applied for the concurrent CS masters program, and wish to earn 2000-level credit for this course, you should sign up for CS2660 only . Whats the difference Both CS1620 and CS2660 share the same extra course content, but only CS2660 counts for 2000-level credit. In course materials, we will refer to the lab portion simply as CS1620this includes both CS1620 and CS2660 students. How much work is the lab In previous years, students taking the lab report spending approximately 820 extra hours on each project throughout the semester, though they also note that the additional components are more front-loaded so the second half of the semester is much more flexible. We anticipate that this will be the same this year. You do not need any additional experience beyond the base prerequsites of the course to succeed with the lab-anyone who feels comfortable taking CS1660 should also feel comfortable taking CS1620CS2660, so long as you are comfortable with the extra time requirement. Note that students taking CS2660 are committed to completing the requirements for both the lab and main portion of the courseafter the adddrop period ends, it is not possible for a CS2660 student to drop the lab portion and still get credit for CS1660 in the same semester. How do I sign up If you are interested in the lab portion, undergraduates should register for CS1660 and CS1620 on CAB. Senior undergraduates are eligible to capstone with CS1620-email the HTA list if you intend to have the lab count for your capstone credit. If you intend to take CS2660, please fill out this form and request an override code on CAB. Registration and Waitlist Interested in taking the course Thats great Since our course has multiple sections , all students require an override so that we can make sure everyone is in the correct section. See the following steps for instructions on how to request an override and if the course is full join the waitlist. If you are interested in registering, please do the following Request to register by filling out this form . If the course is full, this will also add you to the waitlist. If you have any particular reasons you want to take the course, please let us know on the form. Please avoid sending us email about this it will take longerthe form is designed to help us process your requests efficiently. You MUST fill out the form to be considered we will not consider requests on CAB without an accompanying form response . Add the course to your shopping cart. This will grant you access to EdStem and Gradescope, when they become available at the start of the semester. If possible, attend in person or via Zoom the first lecture on Thursday, January 25 or watch the recording as soon as is feasible. How does the waitlist work Once the course fills up, we will give priority to students who are unable to take the course at another timeotherwise, we admit students on a first-come, first-serve basis. If you have any strict program requirements or other constraints that limit when you can take the course, please indicate this in your form response. If you already responded and need to edit your response, you can do so by clicking on the form link again. What are my chances We hope to admit around 90-100 students across all sections of CS1660 and CS2660. While we cannot officially guarantee that all students on the waitlist will be able to take the course, we have typically been able to accommodate all students by the end of shopping period. Prerequisites You should have an intro-sequences worth of programming experience 0160 , 0180 , or 0190 and have a good understanding of systems programming 0300 , 0330 , 1310 , or 1330 . This concretely means that You should be comfortable writing programs and scripts in a language of your choice such as Python, Ruby, Bash, Go, C, etc., be somewhat comfortable in a Unix command-line environment running binaries, filesystem navigation, etc. and have a basic understanding of systems programming concepts such as memory management and networking. You also should have heard of the terms race condition, packet, TCP, UDP, buffer overflows, and DNS. If you forget what these are, dont worrywell describe them again when they come up in the latter half of the course. You should also be willing to learn how to read code in languages that youve never used before. We will gain practice with this throughout the course as we learn about securing systems in many areas. If you dont meet the official prerequisites but still want to take the course, please consult the instructors during shopping period . We are happy to discuss your individual situation to determine if the course is right for you Your willingness to challenge yourself is perhaps the most important prerequsite for the course. Security can be frustrating at times, but the rewards are great. In exchange for engaging with some difficult intellectual challenges, youll have the opportunity to gain concrete insights about systems and security and become a better computer scientist along the way Lecture Policy We will have live lecture on Tuesdays and Thursdays 230pm - 350pm ET in person at CIT 368 and on Zoom via this link . All lectures will be recorded and will be posted on Panopto within 24 hours of the lecture. Attendance Students are encouraged to attend lecture in-person or synchronously via Zoom, though this is not required. Attendance does not impact your course grade. Lecture may use TopHat questions to poll students during classthese are optional and are only used to gauge your understanding during class. TopHat responses have no impact on your course grade. Asking Questions We encourage students to ask questions in class, either by raising your hand either in person, or as a reaction or chat message in Zoom. If you are participating remotely, we will ask you to unmute and ask your question. Recordings All lectures will be recorded. Recordings and any notesslides from lecture will be made available within 24 hours of the lecture date in Panopto . During shopping period , students who are interested in CS1660 must have the course in their primary cart in order to have access to Panopto. Office Hours We are happy to work with you in office hours to help with understanding any course concept or homeworkproject work. We are happy to help with planning how to approach problems, working with tools, figuring out how to debug your work, or reviewing concepts from lectureshomework assignments. In order to make office hours accessible to as many students as possible, we are holding hours in two formats Collaborative hours in-person or hybrid Most hours will be collaborative hours. In this format, simply come to the designated room and members of the course staff will circulate and take questions. Some collaborative sections can support remote students in a hybrid format, as indicated on the calendar . Remote students may join via Zoom using the available on the Hours platform a dedicated staff member will talk with everyone on Zoom in parallel with in-person discussion. In collaborative hours, you are welcome to stay and work and ask questions as they come upthis is meant to create a space where you can meet and collaborate with your peers, while course staff is available to help you get unstuck, or explain a concept to a group if you encounter a problem. We can provide all forms of help during this time, including debugging or help with concepts. Some projects notably Flag and Handin may have certain restrictions on what can be discussed during collaborative hoursmore information will be provided when these assignments are released. Individual, queue-managed remote This is the standard format at Brown. When the hour begins, a queue will appear on the Hours platform designated for our course. Whether you are in-person or remote, simply join the queue When your turn comes up, you will receive a Zoom link to talk with a member of the course staff. Course staff may limit the amount of time one person may spend with a TA i.e. 10-15 minutes, especially during peak times. As the semester progresses, we may make adjustments to the balance of remotein-personhybrid hours or the mechanics of the different formats based on student and TA feedback. If you have thoughts on your experience in hours, please fill out our Anonymous Feedback Form Collaboration The Collaboration Policy is available as a separate document. Please read this policy, as it may differ significantly from other courses you have taken. By submitting any assignment, you agree to abide by the collaboration policy. If you have any questions, please ask on Edstem . Late Policy Students are have five 5 late passes to use on homeworks and projects, though no more than two 2 late passes may be applied to any deadline. Each late pass extends the deadline by one day. Weekends and University holidays long weekend, spring break, etc. do not count towards lateness or use of late passesin other words, a late submission for an assignment due on Friday at 1159pm and submitted before Monday at 1159pm is considered one day late. Accordingly, the last day the assignment could be submitted would be Tuesday at 1159pm which would be days late. If you have no more late passes, each day a project or homework is submitted late will subtract 20 from that assignments grade. Project 4 is a partner project that contains multiple deadlines. Late passes may not be applied to the intermediate deadlines of Project 4. On the final deadline, your group will be allowed to use the minimum of you and your partners remaining late days up to a maximum of two, as for all assignments. Late passes and penalties are automatically applied at the end of the semester in an optimal fashion that is, we will apply late passes in such a way that gives you the highest grade. CS1620 and CS2660 students receive two additional late passes seven total. However, students who drop CS1620 lose the additional passes and receive late penalties under the default CS1660 policy. Extenuating circumstances If there are extenuating circumstances preventing you from completing an assignment on time e.g., illness, you may use to request an extension without using late days, most preferably before the assignment is due. In these situations, please contact the instructors as soon as it is feasible for you to do so using this form . This form is not meant to be impersonalwe simply want to make sure we can keep track of any requests Please note that only the instructors are authorized to grant extensions for the course. The Head TAs and UTAs cannot approve, or comment on the likelihood of, extension requests. All assignments have a due time of 1159 PM ET. See this section for information on the course late policy. Homeworks Out In Resources Homework 0 Jan 25 Jan 30 Homework 1 Feb 9 Feb 23 Burp suite lab Homework 2 Mar 4 Mar 14 Homework 3 TBA TBA Homework 4 TBA TBA Projects Out In Resources Project 0 Setup Jan 27 Feb 5 Project 1 Cryptography Feb 2 Feb 16 Gearup notes Gearup recording Project 2 Flag Feb 22 Mar 7 Setup guide Flag Wiki Lecture demos Gearup notes Gearup recording Project 3 Handin Mar 8 Mar 22 Setup guide Handin Wiki Autograder source code OS Lecture demos Gearup notes Gearup recording Project 4 Dropbox Apr 2 May 1 Logistics Lectures take place on Tuesdays and Thursdays at 230pm ET in person at CIT 368 and on Zoom . Lecture recordings are available on Panopto within a few hours of the lecture time. Please note that this schedule is subject to change. Jan 25 Lec 1. Course Intro Logistics, Security Principles Lecture notes Textbook chapters 1.1, 1.3.1, 1.3.3, 1.3.4, 1.4 w Nick Jan 30 Lec 2. Cryptography I Confidentiality Intro Lecture notes Textbook chapters 8.1.1, 8.1.2, 8.1.3, 8.1.4, 8.1.6, 8.1.7, 8.3 Birthday survey In-class demo OTP - Imperfect Randomness In-class demo OTP - Key Reuse Reading The two-time-pad Reading Why is 2256 secure w Bernardo Feb 1 Lec 3. Crypto II Confidentiality in practice Lecture notes Textbook chapters 1.3.2, 1.3.5, 8.2.1, 8.2.2, 8.4 except 8.4.2, 7.1.2 In-class demo ECB vs CBC Reading A GIF which displays its own MD5 hash Reading A Stick Figure Guide to AES Reading Sections 35 of Move Fast and Roll Your Own Crypto Zoom, which describes Zooms use of ECB mode for video and audio w Bernardo Feb 6 Lec 4. Crypto III Integrity, Authentication I Lecture notes Textbook chapters 1.4.2 Reading Sections 12 and 47 of Defective Sign Encrypt w Bernardo Feb 8 Lec 5. Crypto IV Human authentication, Passwords Lecture notes Textbook chapters 7.1, 7.2.3 w Bernardo Feb 13 Lec 6. Crypto V Password mechanics and password cracking w Bernardo Feb 15 Lec 7. Web Security I Intro to the web Resources and Origins Lecture notes Textbook chapters 7.1, 7.2.3-7 In-class demo Client-Side Checks on WebGoat w Bernardo Reading Same-origin policy w Bernardo Feb 22 Lec 8. Web II Securing requests Cross-Site Request Forgery, CORS, CSP Lecture notes Textbook chapters 7.2.6, 7.3.3 In-class demo CSRF example Reading Cross Site Request Forgery CSRF on OWASP Reading A new default Referrer-Policy for Chrome Reading CSRF from the CS166 Flag Wiki Reading Content Security Policy w Nick Feb 20 No class, Long weekend Feb 27 Lec 9. Web III Code as data SQLI, XSS Lecture notes Textbook chapter 3.3.2 In-class demo XSS example Reading Cross-Site Scripting XSS from the CS166 Flag Wiki w Nick Feb 29 Lec 10. Web IV More code injection and defenses Lecture notes In-class demo SQLI example Reading SQL Injection from the CS166 Flag Wiki Reading Password max length limits are dumb but we need them w Nick Mar 5 Lec 11. Web V Modern Web Frameworks, Disclosure w Nick Mar 7 Lec 12. Operating Systems Intro, Privileges Lecture notes Textbook chapter 3 Reading CS166 Handin Wiki w Nick Mar 12 Lec 13. OS II Scripting and Privilege Escalation Lecture notes w Nick Mar 14 Lec 14. OS III Isolation and Sandboxing w Nick Mar 19 Lec 15. OS IV Supply chain and boot security w Nick Mar 21 Lec 16. OS V Mobile OS Security Textbook chapter 6.1 w Nick Mar 26 No class Spring break Mar 28 No class Spring break Apr 2 Lec 17. Storage Encryption, Cloud platform security Cloud security notes Textbook chapters 7.1.2, 8.2.4 w Bernardo Nick Apr 4 Lec 18. Networks I Intro, Scanning w Bernardo Apr 9 Lec 19. Networks II Low-level attacks w Bernardo Apr 11 Lec 20. Networks III DNS, DDoS, Botnets w Bernardo Nick Apr 16 Lec 21. Networks IV TLS, Certificates w Bernardo Nick Apr 18 Lec 22. Networks V Tor, Firewalls, Intrusion detection Preview notes on Tor In-class demo Scanning, Tor w Bernardo Nick Apr 23 Lec 23. AI ML security w TBA Apr 25 Lec 24. Physical Security and Lockpicking In-class demo Lockpicking, USB Rubber Ducky w Bernardo For information about office hours formats and policies, see here . Calendar not loading Make sure that you are signed into your Brown University Google account in this browser, then do a hard refresh Otherwise, click here to view the calendar in another page. All emails below have a cs.brown.edu suffix, though please do not write to individual course staff unless they have asked you to do so. For sensitive matters, please contact the instructors cs1660-profslists.brown.edu . Requests for extensions should be directed to the instructors---HTAs or UTAs cannot grant extensions. Bernardo Palazzi bernardocs - Instructor - hehim If you look hard enough around the spaceship, you might just find a clue... Nick DeMarinis ndemarincs - Instructor - hehim Hello Im a lecturer in CS, and not so long ago I was a TA and PhD student at Brown. When Im not teaching, I like to think about how to make systems and networks more secure. Outside of work, I enjoy climbing, baking, and board games. Rhea rgoyal6cs - HTA - sheher Hi Im a senior studying CS, and I like baking, basketball, and video games. Siming Feng sfeng22cs - HTA - hehim Im into gaming, photography, and cooking P Chen Wei cwei24cs - UTA - sheher Hey Im a second-year masters student from Nanjing, China, studying CS. Outside of class, I love rock climbing, debating, trying different foods, and taking random city walks Theres a chance we might meet on the street or in the rock climbing gym . Min Kang mkang30cs - UTA - hehim Hi, I am a senior studying CS. Outside of class, I love spending time watching NBA or EPL. I am a huge Chelsea fan, so let me know if you are one of the Blues. Oren okohavics - UTA - hehim Hi, Im Oren Im a senior from California studying focusing on systems security. Im usually playing board games, watching shows, or stealing cookies Rosalie Li cli248cs - UTA - sheher Hi, I study CS in system track. I am a lover for movies, ice cream, and snow boarding. Excited to meet you all Sedong Hwang shwang31cs - UTA - hehim Hello Lets accomplish some cool things in this life. Yuntian Yang yyang324cs - UTA - hehim Hello Im a second-year master student in Computer Science, diving into systems. Outside of coding, I like video games and outdoor adventures. Lately, Ive been capturing these moments with my camera and drone. Resources Course Documents All students are responsible for the contents of the following documents and registering for the following external services used in the course Syllabus and Collaboration Policy All students are required to read the Syllabus and Collaboration Policy . By working on any assignment in this course, you agree to the contents of both documents. Textbook The textbook for the course is Introduction to Computer Security by Michael T. Goodrich and Roberto Tamassia, 1st Edition . The lecture schedule includes supplementary readings from the textbook, which is available in the Brown University Library . Students are not required to purchase this textbook to participate in the course. Gradescope We use Gradescope for collecting certain assignments and grade distribution. We add students to our Gradescope page manually based course registrationif youre trying to hand in but arent able to access the page, please email the HTA list. Edstem Join our Edstem board to ask questions about course content see the Collaboration Policy for question guidelines. The course staff will also post announcements and assignment clarifications to this board. All Edstem questions must be posted privately by default, though the course staff will make posts public when necessary. Forms Extension Requests If there are extenuating circumstances preventing you from completing an assignment on time e.g., illness, you may use this form to request an extension without using late days, most preferably before the assignment is due. Anonymous Feedback If you have feedback that youd wish to share anonymously, you can use this form . Emails are tracked on this form, but these email addresses cannot be viewed by the course staff including the professor and are only viewable by Thomas Doeppner Director of Undergraduate Studies. Technical resources Resources for Go Some of projects have stencils provided in Go, which is a systems programming language that students report is relatively easy to pick up in a class setting. Learning Go is not required for this class, but, if youre interested, this may be a good opportunity to pick it up Here are our favorite resources about Go A Tour of Go is an interactive, concise introduction to the Go programming language. We highly recommend it for new and inexperienced learners of Go it provides an overview of all of its major language features, including the unique concurrency model. Go By Example is a hands-on introduction to Go with annotated example programs, with nice snippets of idiomatic Go code implementing various different programming constructs, from file IO to channel synchronization. The Go blog provides more in-depth articles on specific features within Go. We recommend it if you want to learn certain aspects of Go more in-depth for example, we found the blogs on slices , errors , and project organization quite helpful. This repository provides some examples of a standard package layout note that many people, including the Go tech lead , object to this structure we provide it here simply for inspiration. Another package layout resource is this blog post . Department Resources Diversity and Inclusion In addition to the following resources, you can email the Student Advocates for Diversity Inclusion at diversity.advocateslists.cs.brown.edu Diversity and Inclusion at Brown CS Responsible CS Program Health and Wellness In addition to the following resources, you can email the Student Advocates for Health Wellness at wellness.advocateslists.cs.brown.edu Health and Wellness at Brown CS Ergonomic Equipment Rental Student Groups The department sponsors or is affiliated with several student groups CS for Social Change Focuses on the intersection of computer science and social impact. CS DUG Department Undergraduate Group Seeks to increase undergraduate participation in the department and continue the Brown legacy of involved undergraduates. Mosaic Student-led diversity initiative to create an inclusive space for racially and ethnically underrepresented minority URM students. oStemBrown Student group that aims to empower LGBTQ people studying or working in STEM fields to succeed personally, academically, and professionally. WiCS Women in Computer Science Student group that aims to support and increase the participation of women in the field of Computer Science. Full Stack Brown A Brown University club committed to promoting the education of full stack software engineering by working on applications for the Brown community and beyond. University Resources Writing Center The Writing Center offers free consultations for students who would like to improve the quality of their writing this is relevant in CS1660 since the written components of the course involve communicating complex technical ideas clearly, concisely, and precisely. Appointments can be scheduled on the Writing Center website or by emailing writingcenterbrown.edu . CAPS Counseling and Psychological Services If you feel yourself falling behind, needing to talk to someone about personal problems, or, in general, want a supportive ear, you may find CAPS helpfulthey provide a range of mental health services to the Brown community. The office can be reached at 401-863-3476 or counselinghealth.brown.edu . SAS Student Accessibility Services Brown University is committed to full inclusion of all students. Students who, by nature of a documented disability, require academic accommodations should contact the professor. The staff of the SAS office can be reached at 401-863-9588 or seasbrown.edu to discuss the process for requesting accomodations. Ombudsperson Office The Ombuds Office provides a safe, informal, and confidential service independent from the University administration for students involved in a University-related problem academic or administrative, acting as a neutral complaint resolver and not as an advocate for any of the parties involved in a dispute. The Ombudsperson can provide information on policies and procedures affecting students, facilitate students contact with services able to assist in resolving the problem, and assist students navitgate conflicts concerning improper application of University policies or procedures. All matters referred to this office are held in strict confidence with the exception of cases where there appears to be imminent threat of serious harm. Student Support Services Student Support Services assists students with a wide-range of issues and concerns that might arise during their time at Brown. The Student Support Services Deans provide 24-hour crisis services for undergraduate, graduate, and medical students with personal or family emergencies, and are available by appointment to consult with individual students about their personal questionsconcerns, thus allowing students to succeed and thrive in their academic pursuits. Administrator on Call The Student Support Services office manages Browns Administrator On Call AOC system which provides a mechanism for Brown students to seek assistance in emergency situations after business hours. An AOC is able to respond to students, connect them with resources and referrals, consult with colleagues as needed, and gather information for additional follow-up during business hours. To reach the AOC, call 401-863-3322 and ask to speak to the Administrator-On-Call. FAQs Whats the difference between 1660 and 1510, 1650, 1800, 2390 Each of these courses cover relatively disjoint material, and youll learn completely different things in all of them. If you havent taken any of themgreat CS1660 is a great introduction to the field, and youll learn a lot through this course. If you have taken a subset of these coursesalso great A lot of CS1660s material will still be new to you, and all of these courses are useful in terms of honing your security mindset for the long-term. 1510 focuses on cryptography from a theoretical and more formal perspective by building on the concepts learned in 1010 and involves proving that cryptosystems are secure under defined, precise notions of security. In comparison, 1660 looks at a small slice of applied cryptography, and we generally assume the cryptographic tools that were using are secure. We instead focus on the practical applications of conventional cryptography as it applies to computer systems. 1650 is a deep-dive into software security , which focuses on low-level memory vulnerabilities i.e. on the stack, and coursework primarily focuses on developing attacks. In comparison, 1660 looks at higher-level abstractions cryptography, browser and web applications, networks, etc. and principles of systems security. Our coursework also focuses on a mix of discovering attacks and designing defenses. We dont really look at software security stack-based code execution vulnerabilities at all. 1800 looks at cybersecurity from a more historical and policy-driven perspective. In comparison, 1660 motivates much of its content with historical examples but is primarily about technical details. 2390 is about privacy engineeringmaking sure that the data is either not collected in the first place or, if collected, not misused. In comparison, 1660 focuses on the whole of the CIA mnemonic of confidentiality, integrity, and availability some of the techniques used in privacy engineering overlap with 1660 content, but our usage and analysis of those techniques differs. Can I use this course as a ugrad capstone If youre a 7th semester or greater undergraduate, then you can use CS1660 as a capstone by completing the lab . To do this, you must register for CS1620 or CS2660, and you need to email the HTA list to indicate that you want to use this course for your capstone requirement. Can I use this course for 2000-level credit If youre a graduate student, or an ScB student who has applied for the concurrent masters program in CS, you can obtain 2000-level credit by completing the lab . To do this, you must register for CS2660 CS1620 does not count for 2000-level credit. One caveat note that if you are taking CS2660, you must complete both the lab and main portion of the course in order to receive a gradeafter the adddrop period ends, it is not possible for a CS2660 student to drop the lab portion and still get credit for CS1660. Do I have to attend lectures synchronously See Lectures . If you have a time conflict with the lectures, you may enroll by registering for the remote section S02. If you need to do this, please indicate it on your registration form . Can I audit the course Students wishing to officially audit the course ie, to receive a grade of Audit on their transcript must achieve an overall passing grade, which usually requires completing a minimum version of all projects. Due to the time required to complete the projects see the syllabus for a breakdown, students rarely choose to audit the course officially. If you simply want to follow along with the material, any student at Brown may do so without officially registering all lecture materials, notes, and recordings are always available to any student with a Brown University account, even after the course ends. If you are considering auditing, or if you have trouble accessing any course resources, please contact the instructors. Brown University Department of Computer Science Spring 2024 This website was designed by zespirit . Its built on top of Jekyll , a static site generator. The text scanning effect at the top of the page uses TypewriterJS . The elevator feature uses Elevator.js . Fonts used are Jost , Alegreya , Iosevka Term , and In your face, joffrey . Syntax highlighting provided by Rouge . When you stand on the shoulders of giants, you can see really far. Special thanks to the staff members from the fifteen previous offerings of the course Aaron Gokoslan agokosla , Aaron Myers atm , Abigail Siegel as130 , Adam Horowitz ahorowi2 , Ahmad Mahmoody ahmad , Alex Light allight , Alexander Heitzmann aheitzma , Ali Ozler aozler , Andrej Simeski asimeski , Andy Donzelli adonzell , Anne Rothen arothen , Aurojit Panda apanda , Babi Papamanthou bpapaman , Bernardo Palazzi bernardo , Chanel Johnson cjohns18 , Charles Somerville csomerv1 , Charlotte Whatley cwhatley , DJ Hoffman dj , Dan Haugh dhaugh , Dan Kuebrich dkuebric , Danfeng Yao dyao , David Kilian dkilian , Douglas McErlean dmcerlea , Erica Li eli32 , Evgenios Kornaropoulos evgenios , Foteini Baldimtsi foteini , Gal Peleg gpeleg , Giselle Lillie glillie , Gregory Thompson gnthomps , Hannah Baackmann-Friedlaender hbaackma , Hannah Chow hchow , Harjasleen Malvai hmalvai , Harrison Xu hxu6 , Isaac Semaya isemaya , Jacob Baskin jbaskin , Jake Ellis jte , James Kelley jakelley , Jason Fedor jfedor , Jearson Alfajardo ja43 , Jeffrey Pfau jpfau , Jennie Rogers jennie , Jeremy Tong jwtong , Jian Cong Loh jloh4 , Jimmy Kaplowitz jk , Jingyiping Zhang jzhang12 , Joel Weinberger jweinber , John Boreiko jboreiko , Jonah Stanley jms11 , Jonathan Natkins jnatkins , Jonathan Sailor jon , Josh Brown jwsbrown , Joshua Liebow-Feeser jliebowf , Julia Kim jjk8 , Justin Bisignano jtbisign , Justin Brower jbrower , Kento Nambara knambara , Kimberly Le kle2 , Leo Meyerovich lmeyerov , Lilika Markatou emarkato , Linda Park lpark , Marcus Mitchell mmitch15 , Mariya Gedrich mgedrich , Matthew Milano matthew , Memo Beltran gbeltran , Mike Shim ssh , Milla Shin mshin7 , Natalie Roe nroe , Nathan Partlan npartlan , Neal Poole neal , Nick Ratchev nratchev , Nina Polshakova npolshak , Nisha Khater nkhater , Olin Gay ogay , Olivia Langley olangley , Oussama ben Abdelbaki obenabde , Pablo Meier pmeier , Priya Lotun dlotun , Rathanak Chhay rchhay , Roberto Tamassia rt , Samuel Boger sboger , Saurya Velagapudi svelagap , Scott Kidd shkidd , Sean Murray sem1 , Shawna Huang shuang19 , Sierra Rowley srowley2 , Willem Speckmann wspeckma , William Schor wschor , Yaou Wei yawei , Zach Dixon zdixon , Zachary Espiritu zespirit , Zachary Kirschenbaum zkirsche , Zachary Zagorski zzagorsk , Zoe Stoll zstoll", "metadata": {"last_modified": "2024-03-12T20:18:58+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Quick links", "Administrative Information", "What's this course about?", "CS1620/CS2660: The Lab", "Registration and Waitlist", "Prerequisites", "Lecture Policy", "Office Hours", "Collaboration", "Late Policy", "Resources", "Course Documents", "Forms", "Technical resources", "Department Resources", "University Resources", "FAQs"], "word_count": 5586, "token_count_estimate": 7327}}, "https://cs.brown.edu/courses/cs173/2012/book/": {"text_content": "Programming Languages Application and Interpretation 1 Introduction 2 Everything We Will Say About Parsing 3 A First Look at Interpretation 4 A First Taste of Desugaring 5 Adding Functions to the Language 6 From Substitution to Environments 7 Functions Anywhere 8 Mutation Structures and Variables 9 Recursion and Cycles Procedures and Data 10 Objects 11 Memory Management 12 Representation Decisions 13 Desugaring as a Language Feature 14 Control Operations 15 Checking Program Invariants Statically Types 16 Checking Program Invariants Dynamically Contracts 17 Alternate Application Semantics On this page Programming Languages Application and Interpretation Second Edition prev up next Programming Languages Application and Interpretation Shriram Krishnamurthi 1 Introduction 1.1 Our Philosophy 1.2 The Structure of This Book 1.3 The Language of This Book 2 Everything We Will Say About Parsing 2.1 A Lightweight, Built-In First Half of a Parser 2.2 A Convenient Shortcut 2.3 Types for Parsing 2.4 Completing the Parser 2.5 Coda 3 A First Look at Interpretation 3.1 Representing Arithmetic 3.2 Writing an Interpreter 3.3 Did You Notice 3.4 Growing the Language 4 A First Taste of Desugaring 4.1 Extension Binary Subtraction 4.2 Extension Unary Negation 5 Adding Functions to the Language 5.1 Defining Data Representations 5.2 Growing the Interpreter 5.3 Substitution 5.4 The Interpreter, Resumed 5.5 Oh Wait, Theres More 6 From Substitution to Environments 6.1 Introducing the Environment 6.2 Interpreting with Environments 6.3 Deferring Correctly 6.4 Scope 6.4.1 How Bad Is It 6.4.2 The Top-Level Scope 6.5 Exposing the Environment 7 Functions Anywhere 7.1 Functions as Expressions and Values 7.2 Nested What 7.3 Implementing Closures 7.4 Substitution, Again 7.5 Sugaring Over Anonymity 8 Mutation Structures and Variables 8.1 Mutable Structures 8.1.1 A Simple Model of Mutable Structures 8.1.2 Scaffolding 8.1.3 Interaction with Closures 8.1.4 Understanding the Interpretation of Boxes 8.1.5 Can the Environment Help 8.1.6 Introducing the Store 8.1.7 Interpreting Boxes 8.1.8 The Bigger Picture 8.2 Variables 8.2.1 Terminology 8.2.2 Syntax 8.2.3 Interpreting Variables 8.3 The Design of Stateful Language Operations 8.4 Parameter Passing 9 Recursion and Cycles Procedures and Data 9.1 Recursive and Cyclic Data 9.2 Recursive Functions 9.3 Premature Observation 9.4 Without Explicit State 10 Objects 10.1 Objects Without Inheritance 10.1.1 Objects in the Core 10.1.2 Objects by Desugaring 10.1.3 Objects as Named Collections 10.1.4 Constructors 10.1.5 State 10.1.6 Private Members 10.1.7 Static Members 10.1.8 Objects with Self-Reference 10.1.8.1 Self-Reference Using Mutation 10.1.8.2 Self-Reference Without Mutation 10.1.9 Dynamic Dispatch 10.2 Member Access Design Space 10.3 What Goes In Else 10.3.1 Classes 10.3.2 Prototypes 10.3.3 Multiple Inheritance 10.3.4 Super-Duper 10.3.5 Mixins and Traits 11 Memory Management 11.1 Garbage 11.2 What is Correct Garbage Recovery 11.3 Manual Reclamation 11.3.1 The Cost of Fully-Manual Reclamation 11.3.2 Reference Counting 11.4 Automated Reclamation, or GarbageCollection 11.4.1 Overview 11.4.2 Truth and Provability 11.4.3 Central Assumptions 11.5 Convervative Garbage Collection 11.6 Precise Garbage Collection 12 Representation Decisions 12.1 Changing Representations 12.2 Errors 12.3 Changing Meaning 12.4 One More Example 13 Desugaring as a Language Feature 13.1 A First Example 13.2 Syntax Transformers as Functions 13.3 Guards 13.4 Or A Simple Macro with Many Features 13.4.1 A First Attempt 13.4.2 Guarding Evaluation 13.4.3 Hygiene 13.5 Identifier Capture 13.6 Influence on Compiler Design 13.7 Desugaring in Other Languages 14 Control Operations 14.1 Control on the Web 14.1.1 Program Decomposition into Now and Later 14.1.2 A Partial Solution 14.1.3 Achieving Statelessness 14.1.4 Interaction with State 14.2 Continuation-Passing Style 14.2.1 Implementation by Desugaring 14.2.2 Converting the Example 14.2.3 Implementation in the Core 14.3 Generators 14.3.1 Design Variations 14.3.2 Implementing Generators 14.4 Continuations and Stacks 14.5 Tail Calls 14.6 Continuations as a Language Feature 14.6.1 Presentation in the Language 14.6.2 Defining Generators 14.6.3 Defining Threads 14.6.4 Better Primitives for Web Programming 15 Checking Program Invariants Statically Types 15.1 Types as Static Disciplines 15.2 A Classical View of Types 15.2.1 A Simple Type Checker 15.2.2 Type-Checking Conditionals 15.2.3 Recursion in Code 15.2.3.1 A First Attempt at Typing Recursion 15.2.3.2 Program Termination 15.2.3.3 Typing Recursion 15.2.4 Recursion in Data 15.2.4.1 Recursive Datatype Definitions 15.2.4.2 Introduced Types 15.2.4.3 Pattern-Matching and Desugaring 15.2.5 Types, Time, and Space 15.2.6 Types and Mutation 15.2.7 The Central Theorem Type Soundness 15.3 Extensions to the Core 15.3.1 Explicit Parametric Polymorphism 15.3.1.1 Parameterized Types 15.3.1.2 Making Parameters Explicit 15.3.1.3 Rank-1 Polymorphism 15.3.1.4 Interpreting Rank-1 Polymorphism as Desugaring 15.3.1.5 Alternate Implementations 15.3.1.6 Relational Parametricity 15.3.2 Type Inference 15.3.2.1 Constraint Generation 15.3.2.2 Constraint Solving Using Unification 15.3.2.3 Let-Polymorphism 15.3.3 Union Types 15.3.3.1 Structures as Types 15.3.3.2 Untagged Unions 15.3.3.3 Discriminating Untagged Unions 15.3.3.4 Retrofitting Types 15.3.3.5 Design Choices 15.3.4 Nominal Versus Structural Systems 15.3.5 Intersection Types 15.3.6 Recursive Types 15.3.7 Subtyping 15.3.7.1 Unions 15.3.7.2 Intersections 15.3.7.3 Functions 15.3.7.4 Implementing Subtyping 15.3.8 Object Types 16 Checking Program Invariants Dynamically Contracts 16.1 Contracts as Predicates 16.2 Tags, Types, and Observations on Values 16.3 Higher-Order Contracts 16.4 Syntactic Convenience 16.5 Extending to Compound Data Structures 16.6 More on Contracts and Observations 16.7 Contracts and Mutation 16.8 Combining Contracts 16.9 Blame 17 Alternate Application Semantics 17.1 Lazy Application 17.1.1 A Lazy Application Example 17.1.2 What Are Values 17.1.3 What Causes Evaluation 17.1.4 An Interpreter 17.1.5 Laziness and Mutation 17.1.6 Caching Computation 17.2 Reactive Application 17.2.1 Motivating Example A Timer 17.2.2 Callback Types are Four-Letter Words 17.2.3 The Alternative Reactive Languages 17.2.4 Implementing Transparent Reactivity 17.2.4.1 Dataflow Graph Construction 17.2.4.2 Dataflow Graph Update 17.2.4.3 Evaluation Order 17.3 Backtracking Application 17.3.1 Searching for Satisfaction prev up next", "metadata": {"last_modified": "2017-04-15T02:14:01+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Programming Languages: Application and Interpretation"], "word_count": 883, "token_count_estimate": 1952}}, "https://cs1420.vercel.app/": {"text_content": "CS 1420 Home Lectures Assignments Calendar Staff Resources Welcome to CS1420 - Machine Learning How can artificial systems learn from examples, and discover information buried in massive datasets We explore the theory and practice of statistical machine learning, focusing on computational methods for supervised and unsupervised data analysis. Specific topics include empirical risk minimization, probably approximately correct learning, maximum likelihood parameter estimation, kernel methods, neural networks, the expectation maximization algorithm, and principal component analysis. Time 230 - 350pm, Tue Thu Location Metcalf Research Building AUD Announcement Due to a large number of requests, were asking anyone who is unable to register through CB to join the waitlist here , in order to allocate any available spots as fairly as we can. There is also a waitlist FAQ available here . Useful Links Waitlist Waitlist FAQ Canvas Page Missive Gradescope TopHat Edstem TA Hours Steves Hours Anonymous Feedback Steves Research Group Lectures Time and Location Tuesday Thursday, 230pm to 350pm ET Lecture Recordings Lecture recordings are available through Canvas Media Library. Schedule Date Topics Book Chapters Notes Thursday, Jan 25 Intro, ERM framework 1, 2.0, 2.1, 2.2 Tuesday, Jan 30 Halfspaces and Perceptron 9.0, 9.1.0, 9.1.2 Thursday, Feb 1 Linear and Polynomial Regression 9.2 Tuesday, Feb 6 Logistic Regression 9.3, 12.1.1, 14.0, 14.1.0 Thursday, Feb 8 SGD, Data Prep, and other Practicalities 14.3.0, 14.5.1 Tuesday, Feb 13 PAC Learning 2.3, 3 Thursday, Feb 15 The Bias-Complexity Tradeoff 5 Tuesday, Feb 20 LONG WEEKEND, NO CLASS Thursday, Feb 22 Model Selection, Validation, and Regularization 11.0, 11.2, 11.3, 13.1, 13.4 Tuesday, Feb 27 Boosting 10 Thursday, Feb 29 Decision Trees 18 Tuesday, Mar 5 Learning via Uniform Convergence 4 Thursday, Mar 7 VC Dimension 6, 9.1.3 Tuesday, Mar 12 Naive Bayes 24.0, 24.1, 24.2 Thursday, Mar 14 K-Nearest Neighbors Fairness in Machine Learning 19 Tuesday, Mar 19 Support Vector Machines 15 Thursday, Mar 21 Kernel Methods 16 Tuesday, Mar 26 NO CLASS SPRING BREAK Thursday, Mar 28 NO CLASS SPRING BREAK Tuesday, Apr 2 Neural Networks 20.0, 20.1, 20.2, 20.3 Thursday, Apr 4 Backpropagation 20.6 Tuesday, Apr 9 Deep Learning Thursday, Apr 11 K-Means 22.0, 22.2, 22.5 Tuesday, Apr 16 Expectation Maximization 24.4 Thursday, Apr 18 Principal Component Analysis 23.0, 23.1 Tuesday, Apr 23 Ethics in Machine Learning Thursday, Apr 25 Cutting Edge Machine Learning Homework Policy All assignments are due at 1200pm noon . Written and programming assignments are to be submitted to Gradescope. See the missive for more information on late days and extensions. Assignments Description Release Due Latex Code Solutions 1. Review, Python Jan 25 Feb 1 Latex Code Solutions 2. Halfspaces, Linear and Polynomial Regression Feb 1 Feb 8 Latex Code Solutions 3. Logistic Regression Feb 8 Feb 15 Latex Code Solutions 4. PAC Learning and the Bias-Complexity Tradeoff Feb 15 Feb 22 Latex Solutions 5. Model Selection, Validation, and Regularization Feb 22 Feb 29 Latex Code 6. Boosting and Decision Trees Feb 29 Mar 7 Latex Code 7. Uniform Convergence and VC Dimension Mar 7 Mar 14 Latex 8. Naive Bayes and Fairness Mar 14 Mar 21 9. SVM and Kernels Mar 21 Apr 4 10. Neural Networks Apr 4 Apr 11 11. Deep Learning Apr 11 Apr 18 12. Clustering Apr 18 Apr 25 13. Dimensionality Reduction Apr 25 May 2 Final Exam May 16, 12pm noon May 17, 1159pm Calendar Refer to the calendar below for the most up-to-date lecture and office hour schedule. Meet Our Staff Stephen Bach hehim Professor Providence, RI Providence, RI Assistant professor with an awesome team of students. Check out our research group link under Useful Links Emily Ye sheher HTA Nothern Virginia Shanghai Hi, Im a senior studying CS economics Ask me about Providence cafes, book recs, and the NYT mini Kevin Lu hehim HTA New Orleans, LA Singapore Matthew Meeker HTA Milton, GA Stockholm, Sweden Im a senior studying mostly APMA. My interests are in probability, numerics and analysis, and of course ML. I play a lot of guitar, own too many hhkbs, and almost studied art history. Aditya Agashe hehim UTA Edison, NJ Edison, NJ Hi, Im Aditya. Im a junior studying APMA-CS. Alex Liang UTA Shanghai, China Shanghai, China Hi, Im a junior studying APMA-CS. I enjoy playing and watching basketball, binging Criminal Minds, and eating any microwave foods. Alex Lin UTA Boston, MA Seoul, South Korea Hey all, Im a Junior studying CS. I spend my free time cooking, playing tennis, and learning different languages and eating food from around the world. Andrew Yang hehim UTA Cincinnati, OH Cincinnati, OH I am a junior studying applied math and computer science. I am originally from Cincinnati, OH. Jaideep Naik UTA South Windsor, CT NYC Hey Im a sophomore from Connecticut studying APMA CS. I love playing soccer, hiking, and working out. Johnny Elias hehim UTA Dallas, TX Seoul Hey guys My name is Johnny and Im a sophomore studying Math and CS. In my free time, I really enjoy photography and studying languageslinguistics Keitaro Nishijima hehim UTA Tokyo, Japan Barcelona, Spain frosted caramel nut espresso Krishi Saripalli hehim UTA San Jose, CA San Francisco, CA Im a senior studying CS and love tropical fruits Luke Choi hehim UTA Avon, CT Seoul, South Korea Hi Im a junior studying computer science and math. In my free time, I like to follow football and play Tetris Marco Ayala hehim UTA Manila, Philippines Manila, Philippines International student from the Philippines I love tennis and basketball Mason Lee hehim UTA San Diego, CA Provy, RI Hi, Im a junior studying APMA-CS. I like to play soccer and try new foods. Nitin Sreekumar hehim UTA Thiruvananthapuram, India Los Angeles, CA Hello I am a junior studying Biology and Computer Science. I enjoy hiking through the wild and people watching in cities. I hope yall enjoy the class Noah Foster hehim UTA San Leandro, CA Melbourne, Australia Im a senior double concentrating in MATH-CS and APMA. My research with Ellie Pavlick and Chen Sun focuses on interpretability in large vision and language models and the implications for multimodal models. Talk to me about 1420 or any vaguely statistical course at Brown Reggie Zheng heany UTA Greenville, Mississippi Fuzhou, China howdy D im a senior studying cs-apma and a lover of coffee, lowercase letters, and video essays on obscure topics. excited to meet yall Sarah Peters sheher UTA Chennai, India Rome Always happy to talk about dancing, dogs and all things ML Spencer Dellenbaugh hehim UTA Portsmouth, RI Auckland, NZ I am a senior studying computer science in the AIML and theory tracks. Outside of the classroom I enjoy sailing on Browns club team, playing games with friends, and building robots. Taishi Nishizawa hehim UTA Tokyo, Japan Tokyo, Japan Hi guys, Im a Senior studying APMA-CS. Outside of CS, Im into soccer, cars, aquatic animals, and traveling. Excited to meet everyone Thomas Chang hehim UTA Pittsburgh, PA Seoul Hi Im a junior studying applied math and computer science. When Im not in the Sci Li, I love reading or playing the viola. Looking forward to a great semester with everyone Youjung Koo UTA Seoul Gyeongju Hey everyone Im a data science student with a background in electronic engineering. I enjoy swimming, yoga, and trying out different cuisines. This year, I plan to attend more workshops at the Brown Design Workshop Zeeshan Bhalwani hehim UTA Canton, MI Mumbai Hey everyone Im a junior studying CS and also have a passion for finance. In my free time, I enjoy playing basketball, practicing archery, and watching cricket and F1. Emma Huang sheher STA Short Hills, NJ San Francisco, CA Hi Im Emma, and Im a junior studying CS and IAPA. I enjoy skiing, anything disco ball themed, olive oil on ice cream, and house music unironically Julie Qian sheher STA Bay Area, CA Marin Headlands, CA butter-toasted multigrain bread thick layer of goat cheese roughly chopped blackberries healthy drizzle of honey key to my daily happiness Resources Course Documents LaTeX 2024 CS1420 TA Staff Computer Science Department Brown University Original art by Cindy Zhu", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Welcome to CS1420 - Machine Learning!", "Announcement", "Useful Links", "Lectures", "Homework Policy", "Calendar", "Meet Our Staff", "Resources"], "word_count": 1337, "token_count_estimate": 1987}}, "https://cs.brown.edu/courses/cs173/2018/web/mysteries/mystery-setup.xml": {"text_content": "To install the mystery languages, open DrRacket Version 7 required, click on the File tab in the upper left hand corner, and scroll down to Install Package. In the Package Source text box, type httpsgithub.comsamwaxmanMysteryLanguages7.git . Below the package source box, click Show Details. Change the Dependencies Mode to Auto Update update dependencies whenever possible, and then click install. This will install the mystery languages for all of the assignments in this class, so you only need to do this once. Once these are installed, you can run them as language in DrRacket. To do so, create a new file and write lang LANG at the top of the file, where LANG is the language to run. For any given assignment, the name of the language will be the name of the assignment in UpperCamelCasePascalCase. So for assignment foo bar, you would type lang FooBar at the top of your program. In addition, if you only wish to work with one language in a language set instead of all of them, you can append an 1-indexed number to the end of the language name. So for Numbers, if you only would like to look at core 1, you can type lang Numbers1 at the top of your program.", "metadata": {"last_modified": "2018-09-05T19:39:50+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 208, "token_count_estimate": 263}}, "https://csci1710.github.io/2024/": {"text_content": "You need to enable JavaScript to run this app.", "metadata": {"last_modified": "2024-03-11T15:23:48+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 9, "token_count_estimate": 10}}, "https://cs.brown.edu/courses/cs173/2021/testing-guidelines-section.html": {"text_content": "Fall 2021 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits Assignments SMo L Mystery Languages Implementation Analysis Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines 14 Testing Guidelines 14.1 Testing Guidelines On this page 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error- Handling 14.1.3 Check Your Understanding prev up next 14 Testing Guidelines 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error-Handling 14.1.3 Check Your Understanding 14.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions called wheat and chaff respectively that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignmentsome assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a defineprovide-test-suite test-suite-name ... statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to and encouraged to write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so youll need to use either Rackets or Plaits built-in testing utilities. 14.1.1 Provided Library You will always have access to the following forms test-equal name actual expected test-not-equal name actual expected Tests that actual and expected evaluate to the same value in the case of test-not-equal , different values. test-true name expr test-false name expr Tests that expr evaluates to t in the case of test-false , f . test-pred name pred expr Tests that expr returns a value that satisfies the given pred predicate. test-raises-error-with-substring name expr substr Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms see the assignment specs for more information. 14.1.2 Error-Handling When we run your tests, they can result in an error either due to an intentionally raised error or a bug in a chaff. It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this test-equal Works with Num primitive eval 2 2 v-num 4 However, dont write this define result eval 2 2 this is not caught by test-equal test-equal result v-num 4 That said, if you need to define intermediary variables in a test case, you can use a begin or let statement test-equal Multi-statement test case let result eval 2 2 result v-num 4 14.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a Tests upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome and encouraged to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once its done running, it will immediately give you feedback on Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, were going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while youre implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. prev up next", "metadata": {"last_modified": "2021-12-02T13:25:08+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 850, "token_count_estimate": 1101}}, "https://cs.brown.edu/courses/cs173/2020/policy.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Syllabus and Course Policies 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings Accessibility Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In- Class Electronics Use 20 Diversity and Professionalism 21 Semi- Anonymous Feedback 22 Counseling On this page 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings Accessibility Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In- Class Electronics Use 20 Diversity and Professionalism 21 Semi- Anonymous Feedback 22 Counseling prev up next Syllabus and Course Policies 1 Basic Course Information 2 Course Goals and Learning Objectives 3 Keeping Current and Contacting Us 4 Class Meeting Times 5 Assignments and Exams 6 Anonymous Submissions 7 Time Allocation 8 Grades 9 Grading Personnel 10 Books and Materials 11 Technologies and Sites 12 Hybrid Meetings Accessibility Class Recording 13 Timeliness 14 Due Dates 15 Academic Integrity 16 Capstone 17 Unusual Assignments 18 Legal and Ethical Issues 19 In-Class Electronics Use 20 Diversity and Professionalism 21 Semi-Anonymous Feedback 22 Counseling 1 Basic Course Information Please follow these links for relevant information Course Instructor ClassTimetable note that the lecture schedule is highly tentative andsubject to change, especially as the class adopts to virtual and hybridformats however, we are committed to the assignment dates 2 Course Goals and Learning Objectives Artists, engineers, poets all create things. Creators often develop anintimate understanding of the materials and media they work with this helpsthem better understand the creations of others and better able to create newartifacts themselves. For us who write programs, our primary medium is the programming language. Somelanguages help us write certain kinds of good programs better otherlanguages prevent us from writing certain kinds of bad programs at all. Somelanguages focus on unfettered freedom others try to find strong compromisesbetween expression and constraint. Understanding these trade-offs helps usbetter understand computation itself, and makes us better programmers. This course provides you with a framework to gain this understanding. I hope itwill help you to learn about the basic building blocks of modern programminglanguages use these building blocks to compare and contrast the languages youencounter and also to prepare you for the languages you will build andreflect on the relationship between languages and programming and, in somecases, programmers. 3 Keeping Current and Contacting Us You must subscribe to and follow the courses Piazza board . You are welcome to post questions to the board. When you do, unless you have aparticularly good reason for doing so, please make your question privateto the course staff . If we feel the question is of general interest, we maychoose to make it public. Please contact us solely through Piazza unless you have a very good reason notto. You are, of course, welcome to write course staff directly if you want todiscuss a private matter. However, please do not write to staffindividually for help with coursework those requests should all go throughPiazza. 4 Class Meeting Times This class is listed as hybrid . That means we will try to havein-person meetings as much as possible. The class currently has seven sections listed on CAB. The seventh isvirtual. The other six will meet in rotation. In one week, A will come on Monday, B onWednesday, and C on Friday the next week, D on Monday, E on Wednesday, and Fon Friday then we cycle back to A. That way, you will get an in-person classat least every two weeks. This allocation is tentative. The courses in-person enrollment may bemuch lower than the amount of capacity this creates. If so, well merge thesections. For instance, if we only fill three sections, then each section cancome to class once a week. If we only fill one section, then you can come toclass every day Of course, virtual students will also be supported. Whether you are virtualbecause you are physically remote or dont wish to attend, thats your choice andyou dont owe us any explanation. 5 Assignments and Exams The Assignments are divided into four threads Quizius Mystery Languages Implementation Reflection Each thread has a different set of tools and techniques. To avoid making thisdocument overwhelmingly long, each of them will be explained along the way inthe assignments. The course has no exams. 6 Anonymous Submissions We expect you to submit all your work anonymously . This is to eliminatebiases both positive and negative when grading, based on attributes such asrace, gender, or even how you present yourselves in person. To make clear we are serious, we will impose a small penalty if you do includepersonal identifying information unless asked to. The penalty will escalateif you keep repeating this mistake. Turning in work without your name on it may run contrary to what youve beentold by countless prior instructors. However, because youre turning in workelectronically, not on paper, there is no danger we will lose track ofwhose work it is. 7 Time Allocation The work load in the course is quite uniformly distributed across thesemester. Students can expect to spend about 10 hours each week onassignments. Combined with the 2.5 hours spent per week in class, thistranslates to approximately 180 hours over the course of the semester. 8 Grades I hope you are, or will become, as passionate about programming languages as Iam. Still, I recognize that students have different goals and constraints, andnot everyone can afford to immerse themselves fully in this course. You stilldeserve a quality course in return for a reasonable amount of effort. Therefore, the assignments in this course are broken down into two categories,depending on what kind of grade you are aiming for. If you want a lettergrade , you must do all the assignments. If you are taking the class SNC , then you can skip those assignments that are explicitly taggedas being for letter grades. I really mean you can skip them entirely. If you aim for the SNC level, then you have to do very well on all theassignments at that level to pass the course. If you go for a letter grade,then you will be given a letter commensurate with the quality of yoursubmissions. Each assignment type Assignments explains what we arelooking for in that kind of assignment. That said, there are two kinds of leniency The early part of the semester can be rough as youre getting used to allthese different kinds of assignments. Therefore, assignments due beforeSep 30will essentially be ignored in your final grade. By that date you will haveexperienced each of the tracks and gotten over initial learning hurdles. Ofcourse, it would be unwise to not take these assignments seriously, as the restof the semester will still build on them I will excuse up to two poor performances after this date when computingfinal grades. However, for students trying to earn an A, the standards will behigher doing poorly on a small assignment will be excused much more than doingpoorly on one of the significant, later assignments. In short, you get a breathing period early on, and you can screw up a littlebit later, well, youre human. Your overall course grade is a certificate of how you did An A means you didExcellent work, B means you did Good work, and C means you did Fair work. Iview it as a one-letter recommendation letter a recommendation letter ha, ha. I envision a person trying to hire a student with theskills that this class teaches. An A effectively says, This person knows orcan figure out how to do well most or all the tasks that might come up Agrade of B effectively says, This person can do several things, but may needsome guidance or help. A grade of C means, This person has basic competencein the area. It should then be obvious that your performance cannot affect that of yourclassmates, or vice versa. I therefore do not grade on a curve, because Iconsider the notion meaningless. By the same token, there is also nodefault grade in this course. At least in principle, everyone can do well. For some assignments, you will get two or more grades usually one willrepresent the correctness of your solution, while others its codequality, efficiency, thoroughness of testing, and so on. We give highest priority tocorrectness for a simple reason its very easy to write a clean orefficient or other solution to a different problem. Once weconfirm youve actually solved the problem we asked you to, then wecare about all these other characteristics as well. In general,assuming you have correct solutions, consistently poor code qualitywill hurt your grade while, if youre at a grade boundary, especiallygood code can improve it. If youre given an algorithmic problem, thenefficiency will be almost as important as correctness, but you shouldstill make sure you get the solution correct first its betterto have a less-efficient correct solution than a very efficientincorrect one. There is only one way in which I look at the performance of the class. If alarge portion of the class did poorly on an assignment, I assume there may havebeen a problem in the assignment itself, and I will check for that. If I findthat we did indeed screw up in some way, I will lower my expectations for theassignment i.e., lower standards for Excellent, Good, and Fair. 9 Grading Personnel In this course, you will encounter undergraduate TAsUTAs. UTAs are an important part of the educational mission of thisdepartment. We believe that students learn best by approachingmaterial multiple times we also know from personal experience that welearn best by teaching others. Therefore, UTAs undertake valuablepersonal learning by revisiting material some time after they firstlearned it, and by trying to explain it to others. In the same way,you may also encounter graduate TAs GTAs. These TAs also help with grading materials in the course. Their work isregularly reviewed by me. Grading is ultimately a collaboration in terms ofsetting standards, checking rubrics, reviewing work, etc. However, TAs are not involved in any way in the creation of coursegrades. The course grade is entirely determined by me and nobody else,and is kept confidential from all TA staff. I have ultimateresponsibility for the course. 10 Books and Materials We will rely, wherever possible, on material that is available free-of-cost. Wewill use free software tools, and the textbook and other materials for thecourse are also provided for free. We will link to some third-party sites thatare also available at no cost. The primary course textbook is PLAI , both thefirst and second edition, and some new material that may be created as thesemester progresses. The primary course software is DrRacket .Make sure youve installed version 7.8 . If you have an olderversion, you must upgrade. 11 Technologies and Sites Please see thisdepartmental list . If you have difficulty accessing some of these, please get in touch with thecourse staff. We think most issues can be addressed so long as you can adownload Racket and b ssh into the departments computers. 12 Hybrid Meetings Accessibility Class Recording Since the text for these is common across courses, to keep this document frombecoming excessively long, I am linking to the theSheridan Center site .The text on those pages should be considered included here. Please do not assume that just because I have linked to that page instead ofcopying its text that I dont take this content seriously. I am committed toworking with students with accessibility needs. If you have such needs, pleaseget in touch with me as early as possible and we will do everything we can toaccommodate them. Please be sure to note the copyright policy listed on the Sheridansite. 13 Timeliness This course has deadlines for two reasons Many assignments in this course are accumulative they aredesigned so that the learning in one assignment improves your learning in thenext assignment, and so on. Therefore, turning in one late can force you toturn in the next one late, and so on, potentially leading to a difficultsituation as the semester ends. As a team, the course staff need predictability in their gradingschedules. There is also benefit to locality by grading all thesubmissions for an assignment at the same time, a the staff dont have topage in the assignments content, and b they can handle all thesubmissions uniformly and thus fairly. For these reasons, we really prefer that you turn things in on time. However,we recognize that many things can interfere with our calendars, and we have setout accommodations for each of them. You can submit an assignment late underthe following circumstances You have five late days that you can use at almost see belowany time during the semester. You do not have to give us any reasons you donteven tell us youre using them. Just use them in the approved ways. Note There are a few rules and exceptions You may not take more than two late days on any assignment. Wewill start grading your assignment two days after it comes due. This way, we donot have to re-grade any work, while still providing feedback in a timelymanner. You may take only one late day on a Mystery Languagesassignment. This is because we will be posting solutions after a day. You cannot take any late days on the Quizius assignments. This is because they require you to author and respond to otherstudents work, which has to happen roughly synchronously. You cannot take any late days on the last assignment of thesemester. This is so that course staff can finish grading on a reasonable datewhile attending to their own other needs. For HW0, you do not have to use any late days . We understand youmay have joined the course late since this is only a procedural assignment,you wont be penalized for being late on it. If you are taking a late day, you can submit after the deadline even if youhave submitted something before the deadline. You dont need to notify us ifyou do this. Just submit and well automatically count your late days. Excused absences are when you have a reason that is justifiable bya note from a Dean or Health Services. If you are home, you can submit aletter from a local doctor. Excused absences do not count against your late days. Note When this happens, its usually because you are facing someadverse situation, sometimes an emergency. Follow the principle offorgiveness, not permission. That is, if you are in a crisis, focuson your needs . If you have a moment to drop us a note telling us you will bedelayed, thats helpful, but in an emergency, dont worry. You can submit yournote later. But you do need to submit official documentation for this delay tonot count otherwise it will be counted against your late days. Per the universitys ReligiousObservance policy , if a religious event overlaps with half or more of theduration of an assignment being out, you can have as many days as you missedextra to complete the assignment. You are responsible for giving the staff afull list of the expected religious absences that require extensions beforeSep 23. 14 Due Dates These are in the course calendar, linked above and also from Assignments . 15 Academic Integrity Brown University has an AcademicCode that governs all our transactions. This Code includes asection on Respect for the Integrity of the Academic Process, which establishesits policy on cheating. We expect that you, as students and scholars, will abide by this faithfully and fully . You should be extremely careful when using Internet resources for assistanceother than those specifically linked from the course website or specified inthe assignment. You are welcome to use reference material, e.g., programminglanguage documentation or an encyclopaedia. Be aware that performing a genericWeb search may get you to much more, such as solutions. The one exception iswhen an assignment explicitly tells you to search for information on the Web.If you accidentally find a solution and choose to use it, document that you aredoing so. You will lose some credit for the assignment, but at least you wontbe in violation of the Code. You shouldnt post looking for solutions onmailing lists or Web sites, either. Unless stated otherwise, assignments must be done alone. You are welcome todiscuss any parts of the assignments with course staff. With yourfriends, you may talk about the assignment e.g., how far along you are,how long you anticipate needing, etc. You may not, however, discusssolutions. If in doubt about whether you can discuss something, ask us. You are responsible for keeping your files private by setting the appropriateprotections. If you fail and someone copies your work, you too will be heldresponsible. The same holds for other kinds of sharing, such as leavingyour work visible in public places whether computer screens orwhiteboards. Another important kind of file-sharing is posting solutions on apublicly-visible version control repository site. If you host your work on sucha site, make sure its in a private repository. Regret Clause Exceptions are possible only if you admityour violation to the professor not a TA within 24 hours of theassignment due time. This gives you an option if you cheated indesperation the night an assignment was due, or allowed someone tocheat from you, or something else and then felt guilty about it soonafter. Violations may still be sent through the normal Universityprocess even if you admit to them under this clause, under mydiscretion, though perhaps with mitigating recommendationsso the penalty may be less harsh than if you were caught by us. 16 Capstone The course will have a capstone option. It is designed for students who havehad a logic course such as Logic for Systems, or a formal logic course inphilosophy. In the capstone option, you will learn to and use a tool for formally modelingprogramming languages called PLT Redex and use it to create and model a handful of systems. Even if you do not have abackground in logic, if you can figure out Redex and complete this work, thatsfine Details will be published on October 1. If you are interested in pursuing thecapstone option and we havent yet published information on this, please pingus on Piazza. 17 Unusual Assignments Unlike most other courses you take, this one may have some unusualassignments. For instance, you may be asked to do something impossible, or youmay be given a task that sounds significant but is actually trivial. In thesecases, you should focus on providing a justification for your reasoning ratherthan a solution itself. The purpose in having such assignments is to more accurately mimic the realworld in which you will be asked to solve tasks there are no answers in theback some problems are trivial while others, which look similar, areimpossible, and a priori you cant tell which is which. How will you know which assignments these are You wont. After youve wrestledwith a problem for a while and built a hunch that this is one of them, ask thecourse staff to confirm your hunch. They will ask you to justify yourreasoning. If you do and are on the right track, theyll tell you that youveunderstood the real point of the problem and inform you about how to write upyour non-solution. 18 Legal and Ethical Issues This text is based, withthanks, on text from CSCI 1660. Some of the material covered in this course may be usable to create attacks oncomputer systems or on people. It may be unethical andor illegal to use orapply it in contexts beyond the course itself. Breaking into, misusing, orharming computer systems, networks, or people can be illegal and punishable bylaw. You may also run afoul of Browns computeruse policy , which can have disciplinary consequences. 19 In-Class Electronics Use Please see the separate page on it Electronics Policy . 20 Diversity and Professionalism Please see the separate page on it Diversity and Professionalism . 21 Semi-Anonymous Feedback If you run into any issues that you wish to report to the courses head course staff, you can report them usingthis form .We will be discreet in how we use this information. In particular, we willdiscuss our plans with you before we contact anyone named in the form. 22 Counseling If you feel yourself falling behind, needing to talk to someone aboutpersonal problems, or in general want a supportive ear, the universityhas extensive Counselingand Psychological Services . Please dont hesitate to usethese everyone finds them helpful at some time or the other, andtheyre part of what youre paying for to attend Brown. Make the mostof them. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:10+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 3486, "token_count_estimate": 4402}}, "https://cs.brown.edu/courses/cs190/2017/": {"text_content": "csciStartup More than a class In csciStartup, you will incorporate and run a startup. You must apply as a team to be a part of a class to remove the mystery from starting a company, and to focus entirely on a product youre passionate about. Apply as a team You should apply if you have a team in place and a product in mind. Teams of two to four are probably best, and a great team might not be all CS students. We will focus on products that a small team can implement in months web sites and mobile apps will be the norm. If you nearly have a team in place, and want to meet other students who are looking for a team or vice versa, you might check out this Facebook group . Applications are closed for 2017. Product Focused We will learn by doing. Each team will incorporate, build a product for real customers, advertise their product, and improve it week after week. Well spend at least half of our class meetings with individual attention to each groups progress and how to improve your offerings. Assignments will be designed to apply to any company, with enough flexibility to ensure youre always working on things that make sense for your business. Lectures Talks We meet twice a week, Tuesday and Thursday from 640pm-8pm. Usually one meeting is normal class, and the other is a guest lecture. Last, year guests included Evan Stites-Clayton, Teesprings start Ted Howell, Legal questions Nick Kishfy, Mojotech, Addressing risks first Jon Mellon, TripAdvisor, SEO Ben Simon, Down Dog, Mobile app engagement Melissa Withers, Betaspring Adam Leventhal, Delphix, After the MVP Chris Erway, Appneta, Hiring Funding Eliot Horowitz, MongoDB Louis Forward-Henry, moo.com, Sales Many will return, and well look for more speakers that fit with team needs this year. Syllabus John Jannotti", "metadata": {"last_modified": "2017-01-23T18:51:52+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["More than a class", "Apply as a team", "Product Focused", "Lectures / Talks"], "word_count": 307, "token_count_estimate": 395}}, "https://cs.brown.edu/courses/cs195-5/spring2012/calendar.html": {"text_content": "Introduction to Machine Learning News Calendar Assignments Resources Lectures Readings Most course readings are taken from Machine Learning A Probabilistic Perspective MLaPP , a draft textbook in preparation by Prof. Kevin Murphy . The first chapter is freely available online. Later chapters will be distributed via a pair of readers available from the Metcalf Copy Center . The specific schedule of topics and readings below is tentative, and will change as the course progresses. Date Topic Primary Readings Materials 126 Course Overview MLaPP 1.1-1.3 slides 131 Probability Discrete random variables Dimensionality model validation MLaPP 2.1-2.3 MLaPP 1.4.1-1.4.4, 8.3.8 slides 202 Maximum likelihood Bayesian learning Naive Bayes classifiers MLaPP 3.1-3.2 MLaPP 5.1-5.2 slides 207 Probability Continuous random variables Smoothing Beta Dirichlet priors MLaPP 2.4, 2.5.4 MLaPP 3.3-3.5 slides 209 Bayesian decision theory ROCs Gaussian ML estimation MLaPP 8.1-8.2, 8.3.4 MLaPP 1.4.5-1.4.6 slides 214 Decision theory continuous estimation Bayesian model selection Directed graphical models MLaPP 8.2, 10.2 MLaPP 1.4.7-1.4.9, 10.3 MLaPP 9.1-9.2 slides 216 Multivariate Gaussian Distributions Gaussian Classification MLaPP 2.5, 4.1-4.4.2 MLaPP 5.3-5.3.1 slides 221 Brown Holiday No Lecture 223 Linear Regression Least Squares Bayesian Linear Regression MLaPP 1.4.5-1.4.7 MLaPP 6.2-6.3 slides 228 Gaussian Discriminant Analysis Logistic Regression, Probit Regression MLaPP 5.3 MLaPP 6.4, 7.4 slides 301 Logistic Regression Gradient Descent, Newtons Method MLaPP 6.4 MLaPP 6.4 slides 306 Logistic Regression ML MAP Laplace Approximations MLaPP 6.4 MLaPP 6.5 slides 308 Exponential Families MLaPP 7.1-7.2 slides 313 Midterm Exam In Class 315 Generalized Linear Models Robust Linear Regression Binary Feature Selection Search MLaPP 7.3 MLaPP 6.2.3 MLaPP 13.2 slides 320 L1 Regularization Sparsity MLaPP 13.3-13.4 slides 322 Online Learning Perceptrons Kernel Methods MLaPP 6.6 MLaPP 14.2, 14.4 slides 327 Spring Break No Lecture 329 Spring Break No Lecture 403 Gaussian Process Regression Gaussian Process Classification, GLMs MLaPP 15.1, 15.2 MLaPP 15.3 slides 405 Margins Support Vector Machines MLaPP 14.5 slides 410 Clustering K-Means Algorithm Probabilistic Mixture Models MLaPP 1.3, 11.2 MLaPP 11.2, 11.3 slides 412 Graphical Models EM for Mixture Models MLaPP 9.1, 9.2, 9.4 MLaPP 11.2-11.4 slides 417 Expectation Maximization Algorithm MLaPP 11.4 slides 419 Principal Components Analysis Factor Analysis Probabilistic PCA MLaPP 12.1-12.3 slides 424 EM Algorithm for Factor Analysis PPCA MLaPP 12.1-12.3 slides 426 Hidden Markov Models Inference Learning for HMMs MLaPP 17.1-17.3 MLaPP 17.4-17.5 slides 501 Topic Models Monte Carlo Methods MLaPP 27.3 MLaPP 23.2, 23.4 slides 503 MCMC Gibbs Samplers Continuous State Space Models MLaPP 24.2 MLaPP 18.1-18.3, 23.5 slides 508 Final Exam Review Session slides 1 slides 2 510 Graduate Project Presentations Recitations Date Topic Readings Materials 202 Matlab Tutorial YAGTOM Matlab 209 Continuous Bayesian Estimation MLaPP 2.4, 3.3 demo notes 216 Linear Algebra Tutorial Stanford CS229 notes 223 Multivariate Gaussians, Linear Regression MLaPP 4, 6.2-6.3 demo notes 301 Continuous Optimization MLaPP 6.4 demo notes 308 Midterm Review Session MLaPP 1-6, 8, 10 slides 1 slides 2 315 No Recitation 322 Lagrange Multipliers Klein tutorial notes 329 No Recitation 405 Kernels MLaPP 14 notes 412 EM Algorithm MLaPP 11.4 notes 419 Markov Chains MLaPP 17.2 Matlab notes 426 Dynamic Programming, HMMs MLaPP 17.4 notes 503 No Recitation", "metadata": {"last_modified": "2013-01-22T02:16:50+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Lectures & Readings", "Recitations"], "word_count": 512, "token_count_estimate": 1104}}, "https://cs.brown.edu/courses/cs195-5/spring2012/": {"text_content": "Introduction to Machine Learning News Calendar Assignments Resources CSCI 1950-F Introduction to Machine Learning, Spring 2012 Brown University Department of Computer Science Course Information See the syllabus , and the calendar for details on readings, lectures, and recitations. Textbook The primary course textbook is Machine Learning A Probabilistic Perspective , in preparation by Prof. Kevin Murphy . Printed copies are available as a pair of readers from the Metcalf Copy Center . Lectures Tuesdays and Thursdays from 100-220pm, CIT room 227 . Recitations Thursdays from 500-600pm, CIT room 227 . Led by the graduate teaching assistants. Instructor Professor Erik Sudderth , office hours Mondays from 1100am-1200pm, Tuesdays from 230-330pm, CIT room 509 . Graduate Teaching Assistants Dae Il Kim , office hours Wednesdays from 1000am-1200pm, CIT room 409 . Ben Swanson , office hours Tuesdays from 1200-100pm and 300-400pm, CIT room 411 . Undergraduate Teaching Assistants William Allen, Head UTA, office hours Sundays from 700-900pm, CIT room 219 . Paul Kernfeld, office hours Mondays from 700-900pm, CIT room 219 . Zachary Kahn, office hours Tuesdays from 800-1000pm, CIT room 219 . Soravit Changpinyo, office hours Wednesdays from 700-900pm, CIT room 219 . Vazheh Moussavi, office hours Wednesdays from 900-1100pm, CIT room 219 . Mailing Lists The course staff can be reached at cs195fheadtas-at-cs. The primary mailing list for course announcements is cs195f.2011-12.slists.cs.brown.edu . Registered students have been automatically added. If desired, you can forward your CS e-mail to another account. Previous Courses Spring 2011 CSCI 1950-F Introduction to Machine Learning, Erik Sudderth. Fall 2009 CSCI 1950-F Introduction to Machine Learning, Mark Johnson and Erik Sudderth. Fall 2006 CS 195-5 Introduction to Machine Learning, Greg Shakhnarovich. Announcements May 8, 2012 Graduate projects will be presented on Thursday, May 10 at 100pm in Lubrano CIT fourth floor. Food will be served May 1, 2012 Homework 10 is an optional, extra credit assignment. If you submit it, you can replace a low score on a previous homework with the points earned on homework 10. April 11, 2012 The deadlines for homeworks 8-10 have been extended, to better fit the schedule of lecture material. March 5, 2012 The deadline for homework 5 has been extended until 1200 noon on Monday, March 12. Remember that the midterm exam will be given in class on Tuesday, March 13. February 16, 2012 Due to the holiday weekend, Prof. Sudderths normal office hours are canceled on Monday and Tuesday, Feb. 20-21. He will hold extra office hours on Wednesday, Feb. 22 from 4-5pm. February 10, 2012 The problems with the electronic handin script have now been fixed, and you should be able to successfully submit homework 1. If you sent your solutions via email, please resubmit them using the handin script. We will extend the deadline for homework 1 until noon on Monday, February 13. February 3, 2012 The course mailing list, cs195f.2011-12.slists.cs.brown.edu , is now in use. Please ensure that you are receiving course emails, including information about homework 1. January 25, 2012 The first lecture will be held on Thursday, January 26 in CIT 227. A reader containing the course textbook is available for purchase from the Metcalf Copy Center .", "metadata": {"last_modified": "2013-01-22T02:17:32+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Announcements"], "word_count": 525, "token_count_estimate": 834}}, "https://cs.brown.edu/courses/cs1951r/": {"text_content": "CS1951R Introduction to Robotics Fall 2023 Home Syllabus Schedule Hours FAQ Staff Safety EDStem Forum Welcome Were excited to build and fly drones with you. Each student willlearn to program a small quad-rotor helicopter. We will provide eachstudent with their own robot for the duration of the course. Thecourse will cover PID controllers for stable flight, localization witha camera, mapping, and autonomous planning. At the end of the course,the aim is for students to understand the basic concepts of a mobilerobot and aerial vehicle. The class is taught by ProfessorStefanie Tellex and the rest of the course staff . Enrollment is limited due to limited amounts of drone kits, lab space, and staff support for the class. You can apply for an override to join the class here . Lectures Our lectures online can be found on edX Edge. Use this link to make an account and access the lecture material. Notwithstanding online lectures, attendance is required in person on Tuesday and Thursday 1030am-1150am in the Science Library 8th floor lab space. Professor Tellex will be running extended office hours during this time. The first lecture was delivered live over Zoom and covered mostly class logistics. You can find the slides here . Textbook The class textbook can be found online at DuckieskyLearning Materials . Each assignment or project is a link to aspecific chapter in this textbook and has corresponding lectures inthe edX Edge course. Schedule The class schedule contains videolectures, assignments, and projects organized based on due dates.This is the main page for what happens when with the class. Hardware For those taking the class at Brown, as well as our high schoolcollaborators, we will provide a drone kit using funds donated byAmazon Robotics. Anyone can buy the drone kit online here . Anonymous Feedback Form Please use this anonymousfeedback form to tell us how were doing. Copyright CS1951R Course Staff Computer Science Department Brown University", "metadata": {"last_modified": "2023-10-03T16:40:36+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Welcome!", "Lectures", "Textbook", "Schedule", "Hardware", "Anonymous Feedback Form"], "word_count": 318, "token_count_estimate": 397}}, "https://cs.brown.edu/courses/cs237/2018/brown-cs237-fall18-website/ideas.html": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2018 Project Ideas Home Syllabus Calendar People Gallery Links Project Ideas Ideas Compiled for Students Note Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "metadata": {"last_modified": "2020-09-06T19:04:44+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 143, "token_count_estimate": 211}}, "https://cs.brown.edu/courses/cs195y/2018/": {"text_content": "Home Assignments StaffHours Resources Notes Policies Labs Piazza What is Logic for Systems Logic plays a central role in describing systems. In addition, logic offers the foundation for a rich set of tools for reasoning about systems, namely, determining whether they have been described correctly relative to our expectations. Unfortunately, this fascinating set of activities can come across to some as rather drab and pedantic. In turn, logic often fails to take hold of computer science imaginations because it seems to be a collection of statements about the state of Socrates and rain, not about the state of buffers and caches and the other difficulties that everyday practicing computer scientists wrestle with. This course attempts to address this problem by re-focusing logic on computer systems. We will use logic to describe systems and then analyze our descriptions of them. We will use modern tools that ease the description and automate the analysis. In the process we will try to re-imagine the way we think about not only describing but even designing complex modern computer systems. Class Time and Location Class will be held on Mondays, Wednesdays, and Fridays from 1000am to 1100am in 85 Waterman 130. Useful Links Syllabus Piazza Signup Do you have any feedback for us Course Calendar", "metadata": {"last_modified": "2018-01-31T03:17:23+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["What is Logic for Systems?", "Class Time and Location", "Useful Links", "Course Calendar"], "word_count": 210, "token_count_estimate": 253}}, "https://cs.brown.edu/courses/cs1951i/": {"text_content": "CS1951I Course Info Assignments Staff Course Information CS1951I is taught by Lachlan Kermode and the HTAs. Class is held on Tuesday and Thursday mornings from 900 to 1020 am. Lachlans office hours are on Thursday afternoons , or by appointment. To take this course, you should have taken CS 32, CS 33 or CS 132. The course is limited to a certain number of students, and so it is also required to submit an application by January 20th. In Spring 23 students will work with one of the following four organizations The Peace Lab Student Clinic For Immigrant Justice Center For Health and Justice Transformation iCareForYou Students will work in a studio environment to iteratively design, build, and test technical projects in partnership with different social change organizations. Students will be placed in small teams to collaboratively work on projects that will range from, for example, developing a chatbot to aid community engagement to conducting geospatial data analytics. Through the course, we will also reflect on our positionality and ethics in engaging in social impact work and what it practically means to leverage technology to create social change on an everyday basis. Course Announcement Guides Documents Check out the following useful documents for questions you have about course organization, tools we use, and other helpful resources. Syllabus Student Support and Resources Guide to Github PDF Guide to Github HTML Assignments Milestones Students are responsible for setting milestones with their partnering organizations. See the syllabus for more information. Readings All reading responses are due Wednesday night at 1159 pm. Links to the forms where you should submit your response are listed weekly in the table below. Week Unit Readings Response Form Due Week 0 125 - 128 Introduction Syllabus Week 0 Response 130, 1159pm EST Week 1 129 - 24 Structural thinking Demystifying Big Tech with Meredith Whittaker audio - Meredith Whittaker and Astra Taylor Week 1 Response 21, 1159pm EST Week 2 25 - 211 Structural thinking When Did the Fire Start in Your Computer is on Fire - Mar Hicks The Internet We Could Have Had - Chris Kelty Week 2 Response 28, 1159pm EST Week 3 212 - 218 Capital David Harvey on Capital audio - David Harvey and Daniel Denver Week 3 Response 215, 1159pm EST Week 4 219 - 225 Capital The Making of the Tech Worker Movement - Ben Tarnoff Internet for the People The Fight for our Digital Future only the Introduction is required - Ben Tarnoff Week 4 Response 222, 1159pm EST Week 5 226 - 34 Labor Coding is Not Empowerment in Your Computer is on Fire - Janet Abbate optional Breaking Things at Work audio - Gavin Mueller Week 5 Response 31, 1159pm EST Week 6 35 - 311 Neoliberalism The Big Picture Defending Society - Wendy Brown Platforms are Infrastructures on Fire in Your Computer is on Fire - Paul N. Edwards Week 6 Response 38, 1159pm EST Week 7 312 - 318 Neoliberalism Counterculture to Cyberculture with Fred Turner - Fred Turner and Daniel Denver Hegemony Now How Big Tech and Wall Street Won the World And How We Win It Back excerpt - Jeremy Gilbert and Alex Williams Week 7 Response 315, 1159pm EST Week 8 319 - 324 Gender Sexism is a Feature, Not a Bug in Your Computer is on Fire - Mar Hicks When Computers Were Women - Jennifer S. Light Week 8 Response 322, 1159pm EST Week 9 SPRING BREAK Week 10 43 - 48 Partner 1 The Peace Lab Hemmatian GS No amount of weapons can end the Ukraine war, but a peace mindset might Tech Workers versus the Pentagon 3 Years After the Project Maven Uproar, Google Cozies to the Pentagon Militarising Big Tech The Rise of Silicon Valleys Digital Defense Industry Week 11 49 - 415 Partner 2 Student Clinic for Immigrant Justice The Fetishization of Data The Cruel New Era of Data-Driven Deportation Marc Benioff defends Salesforces contract with Customs and Border Protection At US border, tech issues plague new migrant applications Bidens new CBP One app panned for trapping asylum seekers in daily lottery system Week 12 416 - 422 Partner 3 Center for Health and Justice Transformation My Turn Sarah Martino Post-COVID justice system should be smaller, smarter Giving Serious Offenders a Second Chance Podcast An Algorithm that Grants Freedom or Takes it Away Deloitte Criminal Justice Tech Report page 6 onwards Week 13 423 - 429 Partner 4 iCareForYou Ableism, Technoableism, and Future AI Disability Visibility Project Ep. 3 Assistive Technology podcast with transcript first 12 minutes Ten Principles of Disability Justice Week 14 430 - 56 Reading Period Week 15 57 - 513 Final Project Submissions Final Project Submission 513, 1159pm EST Inclusive Course Goals Actions CS1951I is committed to the full inclusion of students. Our course goals and actions for the semester are the following Goal Ensure that students of different religious backgrounds feel supported by the staff. Action A Google form for students to request extensions or excused absences for a religious holiday that Brown does not officially observe. Goal Allow students to voice their opinions about the course. Action An anonymous feedback form for students to submit any concerns or questions they have about the course. Diversity Accessibility Statements The CSCI1951i course staff is committed to increasing the retention of historically underrepresented groups in upper level computer science classes. We believe that an inclusive environment allows students to thrive academically while also creating a diverse social atmosphere that is welcoming to all. We value all feedback about the environment that we are creating, so here is a link to our feedback form. You also can reach out to the Diversity and Inclusion Advocates here. Accommodations If you feel you have physical, psychological, or learning disabilities that could affect your performance in the course, we urge you to contact SEAS . We will do whatever we can to support accommodations recommended by SEAS. Mental Health The CSCI1951i staff cares deeply about student mental health. If there are any mental health issues that keep you from performing well at Brown, we encourage you to contact CAPS . They provide confidential, free counseling. Project LETS at Brown University also can provide access to Peer Mental Health Advocates. You can find more info on Project LETS here . Staff Instructor Lachlan Kermode HeHim Ciao Im a PhD student in the department of Modern Culture and Media at Brown, and a Research Fellow at the research agency Forensic Architecture. My current work is concerned with the history of computer science and software. HTAs cs1951Iheadtaslists.brown.edu Ahmad Jamal Alkhatib HeHim Hello I am a senior studying computer science and I call Jordan and Palestine home. I am part of the best a cappella group on campus - Harmonic Motion - Valerie Aguilar Dellisanti SheHer Hi Im a senior from Peru majoring in CS-Econ IAPA. In my free time, I love dancing and playing polo. I love desserts and Im very excited about HTAing this class for my last semester at Brown. UTAs cs1951Itaslists.brown.edu Trevor Ing HeHim Hey Im a senior studying CS from Seattle, WA. Im a club baseball captain and love solving and creating crosswords, watching sports, and using Notion Blake Shao HeHim Hi I am a junior from Jinan, China studying CS and MCM. I like powerlifting, making videosanimations, and looking at cool artworks 2022 CS1951I TA Staff Computer Science Department Brown University", "metadata": {"last_modified": "2023-04-26T19:21:06+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Course Information", "Assignments", "Staff", "Lachlan Kermode", "He/Him", "Ahmad Jamal", "Alkhatib", "He/Him", "Valerie Aguilar Dellisanti", "She/Her", "Trevor", "Ing", "He/Him", "Blake", "Shao", "He/Him"], "word_count": 1235, "token_count_estimate": 1617}}, "https://cs.brown.edu/courses/cs2951x/2018.html": {"text_content": "CSCI 2951X Reintegrating AI Spring 2018 Overview Schedule Assignments Grading Resources Overview The primary goal of Artificial Intelligence has always been to build complete intelligent agents. However, the field has also always been fragmented into a collection of problem-specific areas of study. This seminar course will survey efforts made, over several decades, to produce big picture theories and architectures for reintegrating the various component technologies into complete, generally-capable, intelligent agents. The class will read and discuss two papers per week. Grading will be based on two written essays, and a substantial open-ended final project. Instructor George Konidaris Office CIT 447 Email gdk at cs dot brown dot edu Back to top Schedule The first class is on Thursday January 25th . The class meets on aTuesday-Thursday schedule, from 100pm to 220pm in CIT 506 . Note that the schedule below is tentative , and may be revisedas we go along. Date Assigned Reading January 25th Elephants Dont Play Chess, R.A. Brooks. January 30th Class cancelled February 1st Computer science as empirical inquiry symbols and search. A. Newell and H.A. Simon, CACM 1976. Also readReport on a general problem solver. A. Newell, J.C. Shaw, and H.A. Simon. Technical report, Carnegie Institute of Technology, 1959. February 6th CYC Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks. Lenat, Prakash, Shepherd. AI Magazine, 1985. February 8th Extending the Soar Cognitive Architecture. Laird, GAIC 2008. February 13th From Micro-Worlds to Knowledge Representation AI at an Impasse. H.L. Dreyfus. In Mind Design II , Haugeland. February 15th Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRI International, April 1985. February 20th Long weekend February 22nd The Architecture of Mind A Connectionist Approach,D.E. Rumelhart. In Mind Design II, chapter 8. February 27th Connectionism andcognitive architecture a critical analysis. J.A. Fodor and Z.W. Pylyshyn. In Mind Design II, chapter 12. March 1st The Presence of a Symbol, A. Clark. In Mind Design II, chapter 14. March 6th Quantifying Uncertainty , Chapter 13, Russell and Norvig. March 8th On Chomsky and the Two Cultures of Statistical Learning, by Peter Norvig. March 13th Snow day March 15th How to Grow a Mind Statistics, Structure, and Abstraction, Tenenbaum et al., Science, 2011. March 20th No class March 22nd Building Machines That Learn and Think Like People, Lake et al., 2017. March 27th Spring break March 29th Spring break April 3rd Behaviour perception, action and intelligence - the view from situated robotics, J.C.T. Hallam and C.A. Malcolm, Philosophical Transactionsof the Royal Society A. April 5th The Animat Path to AI, S.W. Wilson Autonomous Mental Development by Robots and Animals, Weng et al. April 10th Class discussion embodiment, the modern AI method, and MDPsPOMDPs April 12th No class April 17th Hierarchically organized behavior and its neural foundationsA reinforcement learning perspective, Botvinick, Niv, and Barto, Cognition 2008. April 19th Building Portable Options Skill Transfer in Reinforcement Learning, Konidaris and Barto 2007, and Autonomous Skill Acquisition on a Mobile Manipulator, Konidaris et al., 2011. April 24th From Skills to Symbols Learning Symbolic Representations for Abstract High-Level Planning, Konidaris, Kaelbling,and Lozano-Perez, JAIR 2018. April 26th Discussion Back to top Assignments Assignment 1 GOFAI and connectionism are generally conceived of as direct competitors. However, their relationship is not quite that simple, since they are usually not applicable to the same sorts of problems. Id like you to think about a specific type of problem - two player, zero-sum games, like chess and Go - where both approaches have been tried. Your aim is to discuss the relative merits, successes, and failures of both GOFAI-like which well take to include all search, knowledge-based, and explicit reasoning systems and connectionist which well take to include the direct prediction of best move or value using a neural net, of whatever type systems. Where both types of methods have been combined in a single system, Id like you to explain why, and to analyze what specific advantages the combination brings to the game. Your goal is to try and characterize what specific aspects of a two-player game GOFAI-style and connectionist approaches are best suited to, or to demonstrate that one approach has decisively won. I expect you to do substantial reading outside of the course materials, and to write a properly referenced report. You should cover as many individual games as you feel is necessary to cover the space of solutions. I would be surprised if that is less than three. The assignment is due in class, in hardcopy, on March 15th . It may not be more than 8 pages in 11 point font not including references. Please do NOT feel the need to necessarily use all of those pages I am grading on insight, analysis, and coverage, NOT length. Assignment 2 Your second assignment is to compare connectionist and Bayesian approaches to Natural Language Processing. Here Id like you to pick a component problem in NLP e.g., parsing, and find and summarize the state-of-the-art approaches that use deep nets and that use explicit probabilistic models. Id like you to discuss both the actual performance achieved, and the specific things that each approach makes possible in principle e.g., semantically meaningful uncertainty for the specific task youve chosen. If the leading approaches are hybrid, thats OK, and even interesting Explain what advantages are imported from each paradigm. I expect a properly referenced hardcopy report handed in during class on April 17th . It may not be more than 5 pages in 11 point font not including references. Please do NOT feel the need to necessarily use all of those pages as usual I am grading on insight, and analysis, NOT length. Final Project Your major project will be a substantial creative and original piece of work, in one of the following two categories 1 A computational research study, in which I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain that speaks to what we have discussed. For example, one might design a new method that combines connectionism and probabilistic reasoning, or one might find such a method and then evaluate it in a domain designed to test one of the critiques of such methods that we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed singly or in pairs. I expect the submitted document to be more substantial for a pair than a similar single-author assignment that earns a similar grade. 2 A philosophical study, in which you propose and defend a proposition about the nature of intelligence. Here I am looking for the sort of argument and analysis that we have been seeing in the papers weve read so far. I expect a well-referenced, thoughtful piece that advanced a coherent and interesting argument and interrogates its implications. For example, one might propose that following todays discussion a text corpus, no matter how large, does not contain the information necessary to discover the meaning of any sentence in natural language. A good essay will describe the proposition, argue for its truth, point to or argue the irrelevance of results in the CS literature, and perhaps consider and argue against possible objections. Again this does not have to be a particularly new idea, but Id like you you to argue it without relying on the arguments of others. You should cite computational research studies and foundational philosophical studies e.g., Chomsky, but do not find another essay on a similar topic and use its arguments. This type of study will be graded on the coherence of the idea, how well it is argued and analyzed, and on writing style. I expect it to be about as long as it needs to be to be complete 10-20 pages as a ballpark. The project accounts for 60 of your grade and is due at the end of the reading period May 8th. Back to top Grading Graded components will tentatively include two written homework assignments 20 each,and a substantial final project 60. Back to top Resources Our readings are in large part drawn from the following books,all of which are highly recommended for more in-depth reading intothis topic Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2020-01-23T17:42:10+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 1529, "token_count_estimate": 2075}}, "https://cs.brown.edu/courses/cs195y/2020/": {"text_content": "Course Info Assignments StaffHours Lectures Piazza What is Logic for Systems Mathematical logic provides the foundation for a rich set of tools for reasoning about systems and discovering whether their behavior meets our expectations. These tools allow us to model e.g. the state of buffers and caches, prove whether our protocols obey desirable properties, explore the consequences of memory-management strategies, and much more. As a Computer Science student, youve often been asked to write code with the intent of creating a system. This class is different. Here, well ask you to create models of systems and interact with them in numerous ways. You will learn to use modern, logic-based tools to describe and analyze program designs, algorithms, data-structures, and other artifactswell learn the logical frameworks we need as we go along. In the end, youll develop a better understanding of how to use logic-based tools to analyze whatever systems you encounter after Brown. Class Time and Location Class will be held on Mondays, Wednesdays, and Fridays from 1000am to 1050am in Barus Holley 168. Course Calendar Resources Emails HTA email cs1950yheadtaslists.brown.edu HTAs and Tim TA email cs1950ytaslists.brown.edu All TAs Course Documents Syllabus Collaboration Policy Inclusion and Professionalism Policy Anonymous Feedback Form SSH Guide Other resources We recognize that being a student is not easy, and hope to provide support in any way we can. Beyond our staff, here is a list of other resources available to you here at Brown Counseling and Psycological Services CAPS Student and Employee Accessibility Services SEAS Student Advocates for Diversity and Inclusion email CS Health and Wellness Resources email", "metadata": {"last_modified": "2020-02-11T15:35:47+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["What is Logic for Systems?", "Class Time and Location", "Course Calendar", "Resources"], "word_count": 264, "token_count_estimate": 343}}, "https://browncs1951x.github.io": {"text_content": "CS 1951x Formal Proof and Verification Fall 2023 Assignments Lectures Calendar Resources Staff Project CS 1951x Assignments Lectures Calendar Resources Staff Project Course Description Proof assistants are tools that are used to check the correctness of programs. Unlike tools like model checkers and SAT solvers, proof assistants are highly interactive. Machine-checked formal proofs lead to trustworthy programs and fully specified reliable mathematics. This course introduces students to the theory and use of proof assistants, using the system Lean. We will use Lean to verify properties of functional programs and theorems from pure mathematics. We will learn the theory of deductive reasoning and the logic that these tools are based on. Syllabus syllabus.pdf Lecture MW 300420 p.m., CIT 368 Lab Th 430600 p.m., CIT 210 Course Content We plan to cover most of the Hitchhikers Guide to Logical Verification . Well cover chapters roughly according to the schedule below, but topics may shift slightly as the semester progresses. Basics 1. Types and Terms 2. Programs and Theorems 3. Backward Proofs 4. Forward Proofs Functional-Logic Programming 5. Functional Programming 6. Inductive Predicates Program Semantics 9. Operational Semantics Mathematics 12. Logical Foundations 13. Basic Mathematical Structures 14. Rational and Real Numbers Meta-Reasoning 7. Monads 8. Metaprogramming Assignments Homework Homework will be submitted via Gradescope . Please ensure that you have familiarized yourself with the grading and collaboration policies in the syllabus . Homework Material Covered Released Due HW 1 Ch. 1, 2 91123 92023 HW 2 Ch. 3 91823 92723 HW 3 Ch. 4 92523 10423 HW 4 Ch. 5 10223 101123 101323 HW 5 Ch. 6 101623 102523 HW 6 Ch. 9 102323 11123 HW 7 Ch. 13 103023 11823 HW 8 Ch. 12 11623 111523 HW 9 Ch. 14 111523 112923 HW 10 optional Ch. 8 112823 12623 Final Project 121723 Labs Labs are optional, TA-guided sessions that provide an opportunity to practice and reinforce the content covered in lecture. Labs are held every Thursday, 430600 p.m. in CIT 210 . Lab Date Lab 1 Lean Basics 91423 Lab 2 Backward Proofs 92123 Lab 3 Forward Proofs 92823 Lab 4 Functional Programming 10523 Lab 5 Inductive Predicates 101223 Lab 6 Operational Semantics 101923 Lab 7 Algebraic Structures 11223 Lab 8 Logical Foundations 11923 Lab 9 Rationals and Reals 111623 Lab 10 Monads and Tactics 113023 Lectures You can download lecture demo files and view lecture recordings here. We will aim to update this table shortly after each lecture. All lecture recordings can also be found on Panopto . Date Topic Downloads Summary 96 Introduction Ch. 0 demo file Well talk about what Lean is and see what it can do, and also go over some organizational points about the course. Takeaways Verified programming is fun and powerful 911 The basics of Lean syntax Ch. 1-2 demo file In this lecture well learn the basics of the Lean programming and specification language types and terms, type inhabitation, and writing and evaluating very simple functional programs. No proving yet 913 Dependent type theory Ch. 1-2 demo file Well finish Chapter 2 of the HHG, and get a head start on some material from Chapter 4. Todays topics inductive types continued, function definition and evaluation, specifications, and dependent type theory. 918 Backward tactic proofs Ch. 3 demo file Well dive into the meat of the HHG Ch. 3 what are some of the moves available to us in the tactic proving minigame, beyond intro and apply How do we deal with logical connectives And , Or , Not , and so on 920 Backward tactic proofs, contd. Ch. 3 demo file Well continue talking about tactic proofs. How do we deal with equality What about the natural numbers Well also talk about classical vs constructive logic. 925 Forward proofs Ch. 4 demo file Well see another way to write proofs in Lean, incorporating forward reasoning . Structured proof-term proofs are a little closer to the underlying logic. Surprise proofs in Lean are, literally, just terms in the type theory. 927 Dependent types Ch. 4 demo file We talked about dependent types before now, more. The type theory that Lean is based on, the Calculus of Inductive Constructions, is an instance of dependent type theory. In DTT, we follow the PAT principle propositions as types, proofs as terms. Buzzword the Curry-Howard correspondence Well look deeper today into these foundations. Time permitting, well look at a few important algorithms, including unification . 102 Functional programming data structures Ch. 5 demo file Chapter 5 of the Hitchhikers Guide introduces some paradigms inductive types, structures, recursive definitions, type classes that might be familiar from other functional programming languages. The interesting thing for us is how these paradigms interact with writing proofs. For instance, how do we mix properties into data structures 104 Functional programming type classes, lists, trees Ch. 5 demo file Type classes are a language feature inspired by Haskell with equivalents in Scala, ML, and other languages. They allow us a kind of ad hoc polymorphism we can define functions on types that implement certain interfaces, and can declare that certain types implement these interfaces, without bundling the interfaces into the data type itself. well see how this interacts with some of the data structures we like to use, as we implement and specify functions on these types. 1011 Inductive predicates Ch. 6 demo file Well cover ch. 6 of the Hitchhikers Guide today, on inductive predicates. This will complete what we need to know about foundations for now inductive predicates give us a way to introduce new propositions and prove things about them. Inductive predicates are also the source of most of the propositional symbols weve used so far And , Or , Exists , Eq , . 1016 Big-step operational semantics Ch. 9 demo file Were jumping ahead to Chapter 9 today Time to start putting what weve learned into practice. Well define the syntax of a toy programming language inside of Lean, discussing the difference between shallow and deep embeddings. Using inductive predicates, well define a transition system and use this to prove things about the execution of programs in this toy language. 1018 Small-step operational semantics Ch. 9 demo file The big-step semantics we saw on Monday arent fine-grained. We cant reason about intermediate states. An alternative is using a small-step semantics, where our program execution path is broken down much further. This comes with upsides and downsides. 1023 A look under the hood Ch. XX demo file Well talk theory today, about the data structures and process flow that underlie a proof assistant. Basically, well think about Lean as a programming language in the sense of the last two lectures. Whats its syntax What are its semantics 1025 Logical foundations Ch. 12 demo file Russellian paradox demo As this course has progressed, weve gotten some insight into the foundations of Lean and its type theory. But some features have remained mysterious. In the next few lectures well poke some more at this foundational theory. Today well be focusing in particular on the type universe Prop , what were allowed and disallowed in this universe compared to the others. 1030 Algebraic structures Ch. 13 demo file Complex numbers playground Well jump ahead again to chapter 13, where well start talking about algebraic structures. But well also improvise a bit here. After we see some basic structures, well define some mathematical types of our own. 111 Numbers and sets Ch. 13 demo file Complex numbers playground Well continue the Ch 13 material we started last time, including a little more with the complex number playground. Well also talk about embeddings between different numerical structures, and some different kinds of set-like objects. 116 Logical foundations, contd. Ch. 12 demo file Ch. 13 demo file Complex numbers playground Well continue with chapter 12 today, talking about more foundational constructs. As we discussed last class, theres a grab bag of features that we can take or leave proof irrelevance, impredicative Prop, the axiom of choice, and others. Why should we be convinced that the collection we choose is consistent Well introduce the notion of a model of the type theory to answer questions like this. 118 Quotients, rationals, and reals Ch. 12 demo file Ch. 14 demo file The last bit of Ch. 12, on quotient types, is very relevant to what we want to do next Well wrap up that discussion including talking a bit about the computability properties of quotients and then immediately use quotient types to define some familiar things. Rational and real numbers are interesting mathematically, and for programming purposes, they can be a very convenient tool for writing specifications. Even if we dont compute with real numbers theyre useful to have around. 1113 Real numbers Ch. 14 demo file We finished last week with the rational numbers. Now we need to complete them to get the reals. This will take yet another quotient. The reals bring to light some computability issues that weve touched on briefly before what does it mean to compute with real numbers How do we do it in normal languages If time permits, well look at mathlibs implementation of the reals and see some generalizations. 1120 Monads and tactics Ch. 7 demo file Lean has a very powerful framework for writing custom tactics. These tactics are written in Lean itself, with a number of catches to make this possible. Today well see the fundamentals of this approach. Well learn the very basics about monads, a technique used in some functional languages to simulate programming with side effects. But this isnt an FP class and were not going to dwell on monads, beyond what we need to know. Chapter 7 of the HHG is a more detailed introduction to monads. 1127 Monads and tactics Ch. 8 demo file More from chapters 7 and 8 of the HHG. Well look at macros , a simple kind of metaprogram. Then well turn our attention to the TacticM monad, which provides an API for interacting with our context and goals. 1129 Monads and tactics Ch. 8 demo file Well continue our discussion of metaprogramming by implementing a few custom tactics. Along the way, well see some more metaprogramming techniques and a few imperative-like features of monads that make our lives easier when writing tactics. 124 Tactic design strategies Tactic strategies demo file The tactics weve seen so far manipulate the tactic state in stages. Today well consider some high level designs for automation proof by certificate and proof by reflection. Well also talk about the strategy and algorithm behind the tactic linarith , a great example of a large metaprogram that shows off a number of interesting design principles. 126 Guest lecture Mario Carneiro Mario will tell us about part of his paper on Leans type theory . In particular what does it mean to have a model of Lean in ZFC Calendar Resources Course Links Syllabus Course Textbook Setup Instructions Course GitHub Repository Final Project Information Hours Queue Ed Discussion Anonymous Feedback Form Extension Request Form Lean Documentation Resources Loogle , a search tool for Mathlib The Lean Language Manual An index of Lean tactics Functional Programmming in Lean , a text focusing on Lean as a programming language instead of a theorem prover Metaprogramming in Lean 4 , a reference to programming-for-proving Official Leanmathlib4 API documentation Theorem Proving in Lean 4 , a comprehensive introduction to the system The leanprover-community website Concrete Semantics With IsabelleHOL , a textbook that covers similar material in a different proof assistant The Lean Zulip Chat is a very active and very helpful discussion site. Search the history here, or post questions in the New Members stream. Note please dont ask course-specific questions here. When in doubt, talk to the course staff first. This is a great resource if you want to learn beyond our course Staff To email the course staff, click here . To email just the HTA and Rob, click here . To email Rob directly, click here . You are also encouraged to post and answer questions on Ed Discussion. Robert Y. Lewis Professor Call me Rob Im half computer scientist, half mathematician, and fully excited to go through some of my favorite material with you all this semester. Pronouns hehimhis Joseph Rotella HTA Im a senior concentrating in math-CS. When not extolling the virtues of functional programming, I can be found playing piano, cycling, or reading in the Rock stacks. Ryan Edmonds UTA Im an MSc student with interests in game theory, graph algorithms, and logic. Outside of the classroom, I enjoy strategy games, MMORPGs, and progressive metal, and will happily chat about all of the above Pronouns hehimhis Yizhong Hu UTA Im a senior concentrating in APMA-CS and Physics with an interest in Complex SystemsNonlinear Dynamics. I also enjoy talking about Anime, classical music, and Linguistics. Pronouns hehimhis Copyright 2023 CSCI 1951X at Brown University", "metadata": {"last_modified": "2023-12-16T01:04:03+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Course Description", "Course Content", "Assignments", "Homework", "Labs", "Lectures", "Calendar", "Resources", "Course Links", "Lean Documentation & Resources", "Staff", "Robert Y. Lewis", "Joseph Rotella", "Ryan Edmonds", "Yizhong Hu"], "word_count": 2147, "token_count_estimate": 2802}}, "https://cs.brown.edu/courses/cs242/": {"text_content": "Brown CS 242 Probabilistic Graphical Models, Fall 2016. News Lectures Assignments Projects Resources Syllabus Probabilistic graphical models provide a flexible framework for describing large, complex, heterogeneous collections of random variables. This course surveys state-of-the-art methods for statistical learning and inference in graphical models, as motivated by applications in image and video analysis, text and language processing, sensor networks, autonomous robotics, biological structure prediction, social networks, and more. We will study efficient inference algorithms based on optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data will be covered, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Motivating applications will be explored via homework assignments and a final project. See the Fall 2016 syllabus for further details. News Have Questions September 7, 2016 All students should sign up for the CS242 Piazza discussion site . Please watch Piazza for course announcements, and use it to post questions about homeworks and projects. Please Register September 7, 2016 All students need to complete the CS242 registration survey . Without this, you wont be able to handin assignments or have them graded Welcome September 6, 2016 The first lecture is on Thursday, September 8 at 230pm in CIT 368 . To learn more about course prerequisites, see the webpage for CS 142 Introduction to Machine Learning . Brown University Computer Science CSCI 2420 , Fall 2016 Lectures on Probabilistic Graphical Models Tuesdays and Thursdays from 230-350pm, CIT 368 . Professor Erik Sudderth E-mail lastnamecs.brown.edu Office Hours Wednesdays from 1100-1200pm, CIT 555 Graduate TA Zhile Ren E-mail lastnamecs.brown.edu Office Hours Tuesdays Wednesdays from 400-500pm, CIT 545 2016 Erik Sudderth , adapted from a design by styleshout . Go To Top", "metadata": {"last_modified": "2016-09-07T19:46:35+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["News"], "word_count": 284, "token_count_estimate": 410}}, "https://cs.brown.edu/courses/cs2951x/2020.html": {"text_content": "CSCI 2951X Reintegrating AI Spring 2020 Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. Graduate students welcome undergraduates need instructor permission to enroll. The previous incarnation of this course was a reading seminar the old website and reading lists are here . Instructor George Konidaris Office CIT 447 Email gdk at cs dot brown dot edu Back to top Schedule The first class is on Tuesday January 23rd . The class meets on aTuesday-Thursday schedule, from 100pm to 220pm in CIT 316 . Back to top Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Graduate students should work in groups of at most 2. Undergraduates taking the course should work in groups of at least 2. Mixed groups have more flexibility but should talk to me. The project accounts for 100 of your grade and is due at the end of the reading period May 5th. There is an intermediate deadline a 2-page project proposal due by approximately the end of February,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure theyre on an appropriate path. Back to top Reading General background for embodiment and general AI all quite dated Elephants Dont Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A 1994. Youll need to login via Brown. MDPs and RL Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning A survey. Journal of artificial intelligence research 4 1996 237-285. Object-Oriented MDPs Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 1999 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 2019 1-7. POMDPs Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2021-01-19T02:52:37+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 860, "token_count_estimate": 1254}}, "https://cs.brown.edu/courses/cs2951x/2021_fall.html": {"text_content": "CSCI 2951X Reintegrating AI Fall 2021 Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar the old website and reading lists are here . Instructor George Konidaris Office CIT 447 Email gdk at cs dot brown dot edu Back to top Schedule The first class is on Wednesday September 8th , meeting weekly on a Wednesday from 3-530pm in CIT 241 Swig. The first few sessions will be lectures which will be recorded and uploaded to Pantopo, and so can be watched asynchronously, after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. Back to top Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100 of your grade and is due at the end of the reading period December 12th. There is an intermediate deadline a 2-page project proposal due by approximately early October,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure theyre on an appropriate path. Back to top Reading General background for embodiment and general AI all quite dated Elephants Dont Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A 1994. Youll need to login via Brown. Structuralism Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 3696506, pages 915-916, August 2020. MDPs and RL Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning A survey. Journal of artificial intelligence research 4 1996 237-285. Object-Oriented MDPs Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 1999 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 2019 1-7. POMDPs Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain Artificial Intelligence Back at a Branchpoint . Daedalus 1171, pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2023-01-25T20:53:12+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 955, "token_count_estimate": 1409}}, "https://cs.brown.edu/courses/cs2951x/2021_spring.html": {"text_content": "CSCI 2951X Reintegrating AI Spring 2021 Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar the old website and reading lists are here . Instructor George Konidaris Office CIT 447 Email gdk at cs dot brown dot edu Back to top Schedule The first class is on Thursday January 21st ,and the class is on a Tuesday-Thursday schedule, from 100pm to 220pm. The class is asynchronous lectures will be deliveredvia Zoom at this link at the scheduled date and time, andyou are welcome to attend live, but recordings will be posted. After the first few lectures, you will break into project groups,and we will arrange asynchronous check-ins. Back to top Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100 of your grade and is due at the end of the reading period April 19th. There is an intermediate deadline a 2-page project proposal due by approximately mid-February,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure theyre on an appropriate path. Back to top Reading General background for embodiment and general AI all quite dated Elephants Dont Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A 1994. Youll need to login via Brown. Structuralism Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 3696506, pages 915-916, August 2020. MDPs and RL Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning A survey. Journal of artificial intelligence research 4 1996 237-285. Object-Oriented MDPs Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 1999 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 2019 1-7. POMDPs Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain Artificial Intelligence Back at a Branchpoint . Daedalus 1171, pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2021-09-01T19:52:16+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 922, "token_count_estimate": 1363}}, "https://cs.brown.edu/courses/cs250/": {"text_content": "CS 2500b Optimization Algorithms for Planar Graphs Monday, Wednesday, Friday, 1100-1200 Instructor Location CIT 477 Planargraphs arise in applications such as road map navigation and logistics, graph drawing, and image processing. In this course, we study algorithmic techniques that exploit planarity in addressing classical problems, e.g. Traveling Salesperson , Shortest Paths , and Maximum Flow . Prerequisite CS 157 or equivalent introductory algorithms Focus The focus is on algorithms for addressing logistics and planning problems in road maps. Textbook Draft textbook chapters available at httpplanarity.org to be updated as the class proceeds. Work Homeworks will be assigned once every week or two for the first three-fourths of the semester. During the last one-fourth of the semester, students will work on projects. In addition, there will likely be a midterm to ensure students have mastered the basics. Class participation will also affect students grades. Topics will be chosen from among the following Separators in trees Elementary graph theory Embedded graphs and duality Planar graphs and planar duality Maintaining a bounded-outdegree orientation Separators in planar graphs Primal-dual method for approximation Approximation algorithms for vertex-weighted Steiner trees and feedback vertex set Carvingwidth and branchwidth Optimization algorithms for graphs with bounded branchwidth Brenda Bakers method for approximation schemes Metric version of Bakers method, and approximation for em k-centerem r-domination Linear-time approximation scheme for traveling salesperson problem Brick decomposition and approximation scheme for Steiner traveling salesperson problem Approximation scheme for Steiner tree Prize-collecting clustering Approximation scheme for Steiner forest Bicriteria approximation scheme for bisection Maximum flow in directed st-planar graphs Shortest paths with nonnegative edge-lengths Dynamic-tree data structure Maximum flow in directed planar graphs Multiple-source shortest paths Maximum flow and multiple-source shortest paths in graphs with small weights Fast construction of brick decomposition Shortest paths in directed graphs with positive and negative edge-lengths Approximate distance oracle Fakcharoenphol-Rao priority queue Exact distance oracle Multiple-source multiple-sink maximum flow", "metadata": {"last_modified": "2024-01-24T15:31:35+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["CS 2500b: Optimization Algorithms for Planar Graphs", "", "Focus", "Textbook", "Work", "Topics will be chosen from among the following"], "word_count": 311, "token_count_estimate": 426}}, "https://cs.brown.edu/courses/cs242/fall2014/": {"text_content": "Brown CS 242 Probabilistic Graphical Models, Fall 2014. News Lectures Assignments Projects Resources Syllabus Probabilistic graphical models provide a flexible framework for describing large, complex, heterogeneous collections of random variables. This course surveys state-of-the-art methods for statistical learning and inference in graphical models, as motivated by applications in image and video analysis, text and language processing, sensor networks, autonomous robotics, biological structure prediction, social networks, and more. We will study efficient inference algorithms based on optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data will be covered, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Motivating applications will be explored via homework assignments and a final project. See the Fall 2014 syllabus for further details. News Office Hours December 5, 2014 Regular office hours end on Friday, December 5. Additional office hours during reading period will be announced to the course mailing list. Thanksgiving Week November 24-28, 2014 During Thanksgiving week, the instructor and TA will be available for questions from 400-500pm on Tuesday, November 25. All other office hours are cancelled. Project Proposals November 3, 2014 The deadline for project proposals has been extended until Tuesday, November 11, 2014. See the detailed instructions . Discussion Group October 14, 2014 The Google group brown.course.csci.2420.2014-fall.s01 may be used to discuss assignments and projects. All registered students are members. Fall Weekend October 13, 2014 Normal office hours on Monday, October 13 are cancelled due to the Fall Weekend Holiday. Prof. Sudderth will instead hold office hours on Wednesday, October 15 from 400-500pm. Mailing List September 15, 2014 All registered students have been added to the primary course mailing list . Please confirm that you received the welcome message sent this afternoon, and that you regularly check e-mail sent to your CS account . Welcome September 2, 2014 The first lecture is on Thursday, September 4 at 230pm in CIT 368 . After lecture, Prof. Sudderth will be available to answer questions about the course prerequisite, CS 142 Introduction to Machine Learning . Brown University Computer Science CSCI 2420 , Fall 2014 Lectures on Probabilistic Graphical Models Tuesdays and Thursdays from 230-350pm, CIT 368 . Final lecture on December 9, 2014. Professor Erik Sudderth E-mail lastnamecs.brown.edu Office Hours Mondays from 330-500pm, CIT 509 Graduate TA Jeroen Chua E-mail firstnamelastnamebrown.edu Office Hours Tuesdays and Thursdays from 400-500pm, CIT 423 2014 Erik Sudderth , adapted from a design by styleshout . Go To Top", "metadata": {"last_modified": "2014-12-05T15:29:22+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["News"], "word_count": 409, "token_count_estimate": 603}}, "https://cs.brown.edu/courses/csci0050/2019/Lectures/Code/weather.csv": {"text_content": "Date,Place,Type,Data1616,Houston,ozone,11716,Houston,ozone,0.071816,Houston,ozone,0.51916,Houston,ozone,0.2311016,Houston,ozone,0.611116,Houston,ozone,0.4211216,Houston,ozone,0.311516,Houston,ozone,0.3211616,Houston,ozone,0.3511716,Houston,ozone,0.211816,Houston,ozone,0.0811916,Houston,ozone,0.092116,Houston,ozone,0.42316,Houston,ozone,0.422416,Houston,ozone,0.432516,Houston,ozone,0.53", "metadata": {"last_modified": "2019-07-31T12:59:49+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 1, "token_count_estimate": 155}}, "https://cs.brown.edu/courses/cs2951x/": {"text_content": "CSCI 2951X Reintegrating AI Spring 2024 Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar the old website and reading lists are here . Instructor George Konidaris Office CIT 447 Email gdk at brown dot edu Back to top Schedule The first class is on Tuesday January 30th there will be no class on January 25th , meeting weekly on Tuesday and Thursday from 1-220pm in CIT 477 Lubrano .The first few sessions will be lectures, after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. Back to top b Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of 5 people. This year your project proposal will have to include a half-page statementexplaining which model of a general intelligence you are using, and how your project fits into realizing that model. The project accounts for 100 of your grade and is due at the end of the reading period May 8th. There is an intermediate deadline a 2-page project proposal due by approximately mid-March,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure theyre on an appropriate path. Back to top Reading General background for embodiment and general AI all quite dated Elephants Dont Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A 1994. Youll need to login via Brown. Structuralism Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 3696506, pages 915-916, August 2020. The data-driven approach Y. LeCun. A Path Towards Autonomous Machine Intelligence . 2022. Blaise Agera y Arcas and Peter Norvig. Artificial General Intelligence is Already Here . Noema Magazine, October 2023. More cognitive approaches A. Laird, A. Newell, and P.S. Rosenbloom. Soar An architecture for general intelligence , Artificial Intelligence 331, 1987. B.M. Lake, T.D. Ullman, J.B. Tenenbaum, and S.J. Gershman. Building machines that learn and think like people , Behavioral and Brain Sciences 40, 2017. MDPs and RL D. Silver, S. Singh, D. Precup, and R.S. Sutton. Reward is Enough . Artificial Intelligence 299, October 2021. Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning A survey. Journal of artificial intelligence research 4 1996 237-285. Object-Oriented MDPs Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 1999 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 2019 1-7. POMDPs Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain Artificial Intelligence Back at a Branchpoint . Daedalus 1171, pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2024-01-22T18:03:42+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 1057, "token_count_estimate": 1588}}, "https://cs.brown.edu/courses/cs2951x/2023_spring.html": {"text_content": "CSCI 2951X Reintegrating AI Spring 2023 b Overview Schedule Project Reading Further Reading Overview The goal of AI has been to build complete intelligent agents, yet the field has been fragmented into a collection of problem-specific areas of study. We will first spend a few weeks in lecture covering a new approach to integrating existing AI subfields into a single agent architecture, and remainder of the semester on self-directed, semester-long research projects. Grading will be based on a mid-semester project proposal, and a substantial open-ended final project. The projects will be multi-disciplinary in nature but students will have the opportunity to work in small groups, so they need not necessarily have expertise in the relevant areas. All students need special permission to enroll advanced undergraduate students welcome. The 2018 incarnation of this course was a reading seminar the old website and reading lists are here . Instructor George Konidaris Office CIT 447 Email gdk at cs dot brown dot edu Back to top Schedule The first class is on Thursday January 26th , meeting weekly on Tuesdays and Thursdays from 1-220pm in CIT 477 Lubrano. The first few sessions will be lectures which will be recorded and uploaded to Pantopo, and so can be watched asynchronously, after which we will break into project groups, and weekly meetings will be progress check-ins and discussions with each group. Back to top b Project Your project will be a substantial creative and original piece of work.I expect you to design and implement theory and experiments studying some algorithm or model that is aligned with the course content - i.e., a model that integrates at least two aspects of AI research in an interesting way. I expect it to have approximately the length, form, and content of a conference paper at a good AI conference though it need not be publishable. That means careful, clear, and precise writing, a well-formalized and thoughtfully evaluated point, and thorough referencing throughout. It does not necessarily have to be an original contribution, although that would be nice. If it is not, then I expect at least an original evaluation that is relevant to our topic e.g., an existing algorithm is tried in a new domain or addresses a setting that speaks to what we have discussed. The study will be graded on insight, completeness, and clarity. These studies can be completed in groups of between 1 and 4 people. Undergraduates taking the course should work in groups of at least 3. The project accounts for 100 of your grade and is due at the end of the reading period May 10th. There is an intermediate deadline a 2-page project proposal due by approximately mid-March,which identifies the topic, names the group, and sketches out what you hope to accomplish in the study. I will use these to discuss the project with each group to make sure theyre on an appropriate path. Back to top Reading General background for embodiment and general AI all quite dated Elephants Dont Play Chess , R.A. Brooks. Shakey the Robot. N. Nilsson, ed. Technical Note 323, SRIInternational , April 1985. Video The Animat Path to AI , S.W. Wilson 1991. Behaviour perception, action and intelligence - the view fromsituated robotics , J.C.T. Hallam and C.A. Malcolm, PhilosophicalTransactions of the Royal Society A 1994. Youll need to login via Brown. Structuralism Kaelbling, Leslie Pack. The Foundation of Efficient Robot Learning . Science 3696506, pages 915-916, August 2020. MDPs and RL Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. Reinforcement learning A survey. Journal of artificial intelligence research 4 1996 237-285. Object-Oriented MDPs Diuk, Carlos, Andre Cohen, and Michael L. Littman. An object-oriented representation for efficient reinforcement learning. Proceedings of the 25th international conference on Machine learning. 2008. Abstraction in RL Sutton, Richard S., Doina Precup, and Satinder Singh. Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112.1-2 1999 181-211. Li, Lihong, Thomas J. Walsh, and Michael L. Littman. Towards a Unified Theory of State Abstraction for MDPs. ISAIM. 2006. David Abel, D Ellis Hershkowitz, Michael L. Littman. Near Optimal Behavior via Approximate State Abstraction. , ICML 2016. Problem-Specific Abstractions Konidaris, George. On the necessity of abstraction. Current opinion in behavioral sciences 29 2019 1-7. POMDPs Spaan, Matthijs TJ. Partially observable Markov decision processes. In Reinforcement Learning The State of the Art. Springer, Berlin, Heidelberg, 2012. 387-414. Natural Language for MDPs Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rocktaschel. A Survey of Reinforcement Learning Informed by Natural Language , Proceedings of the Twenty-Eighth International Joint Conference on Artificial IntelligenceSurvey track. Pages 6309-6317. R. Rodriguez-Sanchez, R. Patel, and G.D. Konidaris. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes . In The First Workshop on Language in Reinforcement Learning at ICML 2020, July 2020. Further Reading Readings from the following booksare recommended for more in-depth engagement with the topic, thoughnote that all of these are now dated Mind Design II, J. Haugeland, ed. Computers Thought, E.A. Feigenbaum and J. Feldman, eds. Mindware, 2nd edition, Andy Clark, ed. Being There, Andy Clark. Cambrian Intelligence, R.A. Brooks. Dreyfus, Herbert and Dreyfus, Stuart, Making a Mind versus Modeling the Brain Artificial Intelligence Back at a Branchpoint . Daedalus 1171, pages 15-43, 1988. Also worth reading, but much more about philosophy than CS, is Mind and Cognition, 2nd ed, W.G. Lycan, ed. These books and readings will be of interest to students who want to understandthe probabilistic foundation of AI more deeply Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference, by Judea Pearl. Probability Theory The Logic of Science, by E.T. Jaynes. Probabilistic Logic, by Nils Nilsson. In Artificial Intelligence 28 1986, 71-85. Back to top", "metadata": {"last_modified": "2024-01-22T17:31:31+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": [], "word_count": 957, "token_count_estimate": 1416}}, "https://cs.brown.edu/courses/csci0050/2019/Lectures/envs-practice.html": {"text_content": "Class summary Practice with Known Names 1 Recap Whats in the Environment Class summary Practice with Known Names 1 Recap Whats in the Environment 1.1 Practice Exercises Class summary Practice with Known Names Copyright c 2017 Kathi Fisler We have talked about how Pyret maintains a collection of known namesunder the hood. Pyret uses the known names area to look up thevalues associated with names while running your program. Weve talkeda bit about this idea, but today we want to look at it in much moredetail, since managing known names is one of the essential tasks inany programming language. While weve been using the informal term known names, the actualtechnical term for this mapping from names to values is theenvironment . Well switch to using the actual term now that youhopefully have intuition about the concept. 1 Recap Whats in the Environment So far, weve had the following rules for populating the environment A bunch of standard functions, like and string-length are in the environment by default If you use include , you add several more functions e.g.,on tables or images to the environment If you associate a name with a value using name some-expression then name goes into the environment, associated with the value fromcomputing some-expression . If a name gets added to the environment while Pyret isevaluating the body of a function, Pyret creates a temporaryenvironment for definitions that arise within the function. Pyretdeletes the temporary environment once the function body bfinishesevaluating. Theres one more rule we havent talked about yet. Up until now, wehave said that when you call a function, Pyret substitutes the inputsthat you provided for the variables within the function. Actually,Pyret just makes entries in the temporary environment for thevariables and associates those names with the values youprovided. This behaves the same way as substitution, but it will provea bit easier for us to work with as our programs get more complicated. Lets Try It For the following program, what is in theenvironment at each of the marked points month July point 1 fun create-dateday Number - String point 3 month day , 2019 end point 2 today create-date7 point 4 Answer Well omit the Pyret defaults as we write these out. At point 1, the environment has month - July At point 2, the environment has month - July create-date - function... At point 3, the environment has month - July create-date - function... ------ well use lines to mark off the temporary environment day 7 ------ At point 4, the environment has month - July create-date - function... today July 7, 2019 Notice that day goes into the temporary environment for theuse call of the function, then disappears once the function has finished. Question Point 3 appears on an earlier line than Point 2 in the originalcode sample. Why did we use that numbering, instead of swapping points2 and 3 Hint what order does the code get evaluated in 1.1 Practice Exercises We worked through two handouts of sample programs to make sure you seehow the environment works in different situations handout 1 handout 2 . For each handout,you were asked to indicate what order the lines are executed in, andthe environment contents at each marked point. Hopefully these exercises have helped you strengthen yourunderstanding of how programs evaluate in Pyret. These rules arefairly standard across most programming languages. Takeaways from this segment Two functions can use the same variable name. The two nameswont clash due to the temporary environments. The same value can be referenced via multiple names during thecourse of a program. This allows programmers to use different names indifferent parts of the code without causing problems. If the same function is called multiple times, it gets a freshtemporary environment on each call.", "metadata": {"last_modified": "2019-07-05T23:32:01+00:00", "scraped_at": "2024-03-13T22:15:20+00:00", "headings": ["Class summary: Practice with Known Names"], "word_count": 623, "token_count_estimate": 778}}, "https://cs.brown.edu/courses/csci0030/": {"text_content": "CS 3 CLASS MATERIALS TA HOURS RESOURCES CALENDAR PIAZZA CS 3 Introduction to Computation for the Humanities and Social Sciences Learn More Class Time Classes start the week of 0910. They will be held during the 900-1020 AM ET block on Tuesdays and Thursdays. All meetings will be recorded, and the videos will be uploaded to the class materials page. The zoom link for all classes is httpsbrown.zoom.usmyaagarwal . Welcome Thanks for your interest in our course In the past fifty years, computing has irrevocably changed subjects like engineering, physics, and biology, and it is now starting to do the same for the social sciences and humanities. You stand at the cusp of a new computing revolution. We offer a supportive environment that, combined with your hard work, will put you at the front of this wave. With the skills you get in this course, you should be able to contribute much more effectively to your chosen field, whatever it is, as computation takes a larger role over time. The course will be held synchronously. Students are encouraged to attend live lectures. However, recorded sessions will also be available. Waitlist We only have so much room in the classroom, so if you would like to take the course, please add yourself here , and well do our best to admit as many people as possible If we cant admit you this semester, you will be considered for next semester. In any case, to be admitted to the course, you must attend every class, and do the homework assignments. Finally, if you have special circumstances e.g., you enrolled last semester but talked to us about taking it this semester instead, well take that into account. Remind us if it looks like weve forgotten. For now, dont sweat it. Background We require no prior computer science or mathematical background As long as you are interested in learning, you have all the background we need. If you have done any prior programming, this is probably not the class for you. See here for other CS classes you can take. Workload Youve probably heard legends about computer science workloads. Some of the legends are true, many are not. Either way, CS 3 is not your typical computer science course. We expect you to put in roughly 6-8 hours per week including class time. Depending on your perspective, this can seem like a little or a lot. All the course staff are available to help you, but learning the material in this course requires a time investment. We require people to use laptops for the course. Since the classroom doesnt have any computers, youll be required to bring a laptop to class to do the work. If you dont have a laptop, talk with the course staff we will direct you to resources that have laptops available. Design HTML5 UP", "metadata": {"last_modified": "2020-09-21T15:25:26+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["CS 3", "Class Time", "Welcome", "Waitlist", "Background", "Workload"], "word_count": 475, "token_count_estimate": 575}}, "https://cs.brown.edu/courses/csci0050/2019/Lectures/handling-table-errors.html": {"text_content": "Class summary Handling Tables Errors with Programs 1 Identifying Table Errors 2 Managing Table Errors 3 Setting Up a Data Analysis file Class summary Handling Tables Errors with Programs 1 Identifying Table Errors 2 Managing Table Errors 3 Setting Up a Data Analysis file Class summary Handling Tables Errors with Programs Copyright c 2017 Kathi Fisler 1 Identifying Table Errors Last class, we talked about the importance of sanity checking databefore you begin to work with it. Lets briefly review what that meanson a concrete example, then look at how to use programs to help usmanage the sanicty-checking process. Open up this table of partial salary information for a small business. Spend a couple ofminutes looking at the table. What do you notice that warrants beingchecked or fixed about this data. Potential issues include Names of departments arent spelled or capitalized consistently One salary level seems much higher than the others Someone at a lower salary level is making more than someone elseat another level, even within the same department 2 Managing Table Errors How many of these errors could we check or correct with small Pyretprograms Many, as it turns out, though some point to additionalprogramming constructs that would be nice to have. Here is the starter file that loads the salary table into Pyret. We wrote a series of functions to work on different issues from theoriginal table. You can see the resulting code in the final codehandout posted to the lectures page. 3 Setting Up a Data Analysis file Now that we have a slew of programs to help detect, and in some casesclean, a data file, how should we use all of this in setting up a datatable for doing some sort of deeper statistical or other analysis Partly, this is a question of how to balance naming intermediatetables and keeping the collection of table names manageable forpeople. As a general rule, it makes sense to name the raw data tablethat you import into your program, to name the cleaned-up table, andto name any portions of the table that you want to use in multipleanalyses. For example THE CLEANING CODE TEMPLATE raw-data load-table... check for issues repair issues via programs sanity check values clean-data result of all repairs ... then work only with the clean data", "metadata": {"last_modified": "2019-07-05T23:32:16+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Class summary: Handling Tables Errors with Programs"], "word_count": 380, "token_count_estimate": 455}}, "https://cs.brown.edu/courses/csci0050/2019/": {"text_content": "CSCI0050- Home CSCI0050- Home CSCI0050 A Data-Centric Introduction to Programming Summer 2019 Home Schedule Staff Learning Software Policies Canvas Piazza Time MonWedThurs 900-1140am Location CIT 368 though first two classes in CIT 477Lubrano CSCI-50 provides an introduction to computer programming with a focus on skills needed for data-intensive applications. Topics include core constructs for processing both tabular and structured data including lists and trees decomposing problems into programming tasks data structures algorithms and testing programs for correct behavior. The course does not assume any prior programming background many assignments will have optional advanced material for students who already have some programming background or who want to cover the topic in greater depth. This is a computer science and programming course, not a data science course. While we will cover concepts and programming constructs and software practices that are highly relevant for data science, we will not cover statistics or statistics-focused programming. The course has been designed to provide the computer science background needed for Browns Data Science masters program but the course is open to all who wish to enroll. CSCI-50 does not currently satisfy the introductory programming sequence requirement for CS undergraduate concentrators. If you are interested in options that lead into the CS concentration, talk to Professor Fisler. Class sessions will interleave lecture and hands-on exercises both programming and conceptual. Students are expected to participate and work with others during class sessions. Page maintained by Kathi Fisler", "metadata": {"last_modified": "2019-06-24T09:51:42+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 239, "token_count_estimate": 300}}, "https://cs.brown.edu/courses/csci0050/2018/": {"text_content": "CSCI0050- Home CSCI0050- Home CSCI0050 A Data-Centric Introduction to Programming Summer 2018 Home Schedule Staff Learning Software Policies Canvas Piazza Time MonWedThurs 900-1140am Location SciLi 618 CSCI-50 provides an introduction to computer programming with a focus on skills needed for data-intensive applications. Topics include core constructs for processing both tabular and structured data including lists and trees decomposing problems into programming tasks data structures algorithms and testing programs for correct behavior. The course does not assume any prior programming background many assignments will have optional advanced material for students who already have some programming background or who want to cover the topic in greater depth. This is a computer science and programming course, not a data science course. While we will cover concepts and programming constructs and software practices that are highly relevant for data science, we will not cover statistics or statistics-focused programming. The course has been designed to provide the computer science background needed for Browns Data Science masters program but the course is open to all who wish to enroll. CSCI-50 does not currently satisfy the introductory programming sequence requirement for CS undergraduate concentrators. If you are interested in options that lead into the CS concentration, talk to Professor Fisler. Class sessions will interleave lecture and hands-on exercises both programming and conceptual. Students are expected to participate and work with others during class sessions. Page maintained by Kathi Fisler", "metadata": {"last_modified": "2019-06-21T14:19:47+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 232, "token_count_estimate": 289}}, "https://cs.brown.edu/courses/csci0050/2017/": {"text_content": "CSCI0050- Home CSCI0050- Home CSCI0050 A Data-Centric Introduction to Programming Home Schedule Staff Learning Software Policies Canvas Piazza Time MonWedThurs 900-1140am Location CIT 227 CSCI-50 provides an introduction to computer programming with a focuson skills needed for data-intensive applications. Topics include coreconstructs for processing both tabular and structured data includinglists and trees decomposing problems into programming tasks datastructures algorithms and testing programs for correct behavior. Thecourse does not assume any prior programming background. This is a computer science and programming course, not adata science course. While we will cover concepts and programmingconstructs that are relevant for data science, we will not coverstatistics or statistics-focused programming. The course has beendesigned to provide the computer science background needed for BrownsData Science masters program but the course is open to all who wishto enroll. CSCI-50 does not satisfy the introductory programmingsequence requirement for CS undergraduate concentrators. Studentsinterested in concentrating in CS should take CSCI 0150, 0170, or 0190instead. Class sessions will interleave lecture and hands-on programmingpractice. Students are encouraged to work with others during classsessions, and outside of class on some assignments. Page maintained by Kathi Fisler", "metadata": {"last_modified": "2017-06-21T14:44:34+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 184, "token_count_estimate": 266}}, "https://cs.brown.edu/courses/csci0111/fall2020/going-to-18.html": {"text_content": "Skip to main content Going to CS 0180 aka CS18 CS 0111 and CS 0180 form a valid intro sequence for all CS and CS-joint concentrations. You might not yet see this listed in the Brown Bulletin we are working on those edits, but it has been approved in all appropriate departments. All CS intro sequences 01500160, 01700180, 011101120180, 01110180, and 0190 prepare you for subsequent courses in the CS department. The first courses are all rather different in style and somewhat different in content we bring them together across by the end of the sequence. In order to take CS 0180 directly after 0111, you need to be able to work on problems at the complexity level of those in CS 0170. Those problems draw on the same concepts and style of programming that we do in 0111. You just need to be able to scale your skills to more complex problems. We will therefore offer additional exercises to help you prepare for 0180, most of them attached to existing 0111 assignments. These additional exercises are NOT required for 0111, nor do they affect your grade in 0111. They are only for those who wish to take CS0180 without going through CS0112. If you finish the additional work, you can take 0180 anytime before you graduate it doesnt have to be this year. The Assignments Sorting lists Working with trees In lecture, we looked at using data to capture a form of real-world data with a branching structure family relationships. Sometimes, we organize data into a tree shape to enable a particular approach to a computation. These next two assignments explore these two uses of trees. You can do them in either order. Files and Directories this is in the spirit of the problem we discussed in lecture about trees that let us navigate from people to their offspring. Binary Search Trees this is a different use of trees, but you might find this one easier to start with. The last problem on the run-time performance can be done either as part of this assignment or as a question on the running times assignment below -- your choice. Running times this is the one topic that we havent gotten to discuss in 111. Theres a lecture-capture video with background in the handout. Kathi will also offer a session on this content at some point later this semester. Running Times We wrap up with two more examples of interesting uses of trees, this time for capturing documents and programs. Getting these conceptually will likely be more challenging than the small bit of corresponding code. Processing Documents and Languages Frequently-Asked Questions When do I have to decide about trying for CS0180 We will start 0180-related assignments about 5 weeks into the course. How do I sign up By turning in the work once it starts. Theres no need to formally tell us you want to do this. Where do I submit the extra work There will be a separate assignment area on Gradescope for each assignment. When will the extra work be due We strongly encourage you to try to complete the assignments as they are released, as this will help acclimate you to the workload of CS18. That said, we understand that remote learning is posing its own challenges for many students. You can therefore take up through December 21, 2020 to turn in all of the assignments. PLEASE do not leave all of the work to that point. If you only start it after finals, you are unlikely to finish in time. Will the extra work be doable for those new to programming Yes. The extra work will not assume any more material than what we are covering in regular 0111 lecture with the exception of one additional lecture that we will schedule in November. The extra work simply uses the 111 material in somewhat more complex ways. How much time will the extra work take Roughly an extra 3-4 hours per assignment beyond the normal 0111 workload. This is in line with the time requirements of assignments in CS0170, which is the course that normally feeds into CS0180. If I dont want to do 0180, can I still take CS 0112 Absolutely, but we wont be offering 0112 again until next year likely fall. We apologize for the inconvenience, but the 3-semester schedule for this year needed us to offer some courses twice, which cuts into our available teaching staff. Can I take 0180 without doing the extra work No. Since you wont have taken 0170, youll need an override code for CS 0180. Kathi will only give override codes this year or in future years to students who have done the bridge work or completed CS 0112. If I took 0111 in a previous semester, can I still take CS0180 this year Yes. Reach out to Kathi to make arrangements. Is there a grade cutoff for getting into CS18 Thats not the right way to think about it. The goal of these assignments is to make sure that you understand the concepts sufficiently well for what 18 will expect. Kathi will get a sense of that from a combination of your work on the assignments, the kinds of comments that come up in your reflections, interactions in office hours, etc. Kathi will look at the quality of your work and reflections, not at whether you were above some arbitrary cutoff. Will we get grades and feedback on the bridge work When You will get some feedback, but it wont necessarily be the kinds of rubric-based grades that you get on the regular 111 homeworks since Kathi is handling these herself, without the backup of the TAs. Kathi will work on providing feedback as work comes in, starting in mid-November. Where can I get help if Im stuck on these Kathi has two open-access office hours per week see the 111 calendar, and is available for appointments contact her by email. Some of the TAs can answer 18 questions, but as a general rule, questions on the bridge work should route through Kathi since our TA staff is primarily allocated to help with 111. Kathi will be monitoring Campuswire and can take questions there as well. Reach out to Kathi with other questions, as she will be handling this part of 0111.", "metadata": {"last_modified": "2020-11-25T17:18:04+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Going to CS 0180 (aka CS18)", "The Assignments", "Frequently-Asked Questions"], "word_count": 1054, "token_count_estimate": 1280}}, "https://cs.brown.edu/courses/csci0111/": {"text_content": "CSCI 0111 Computing Foundations Data Welcome to CS111, the intro CS course that blends data science and computer science for both concentrators and non-concentrators alike Weve had students from a wide range of concentrations and backgrounds mostly with no prior programming experience succeed in the course. We strive to provide a supportive environment for all who wish to try out computing while leaving open options for subsequent courses in CS or Data Science. The broad vision for CS111 is to put data and socially responsible computing at the heart of introductory computer science. We do this through a combination of writing small programs for data analysis, looking at core data structures that help us organize data towards different computations, and looking at case studies that reveal ways in which data-facing decisions can prevent or foster social harms. For a short article on the vision for CS111, see Data-Centricity A Challenge and Opportunity for Computing Education , by Brown CS professors Shriram Krishnamurthi and Kathi Fisler . For those exploring from outside Brown feel free to explore our current or past editions to see our course structure, notes, and assignments. The course textbook which also has a major section on introductory algorithms that is not used in 111 is freely available online. CSCI 0111 is planned to be offered every Fall and Spring semester, as of Fall 2021 Current Offering Spring 2024 Past editions Fall 2023 Spring 2023 Fall 2022 Spring 2022 Fall 2021 Fall 2020 Spring 2020 Fall 2019 Fall 2018", "metadata": {"last_modified": "2024-01-18T17:43:23+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["CSCI 0111", "Computing Foundations: Data"], "word_count": 251, "token_count_estimate": 315}}, "https://cs.brown.edu/courses/csci0111/fall2020/": {"text_content": "Skip to main content Welcome to CSCI 0111 - Computing Foundations Data Meeting time MWF 1000-1050 AM EST, on Zoom CS0111 is the beginning course of a new introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Course Syllabus Anonymous Feedback Form Going to CS 0180 Extension Request Form Blocklist Form Lab Switch Form Late Day Form Important dates Midterm exam Oct 28-30 Midterm Prep Guide Final exam Dec 9 plus a couple of days TBD Final Prep Guide Shopping period announcements Students who are shopping should keep up with assignments, which will start being due the second week of classes. Past experience shows that many students who first join the course at the end of shopping period and are new to programming struggle to catch up. We strongly urge you to be participating in the course by the start of the second week. All students must agree to the collaboration policy at the end of the course syllabus . Course Archives Materials from previous semesters are linked to the main CS 111 page .", "metadata": {"last_modified": "2021-09-07T14:02:27+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Welcome to CSCI 0111 - Computing Foundations: Data!"], "word_count": 262, "token_count_estimate": 312}}, "https://cs.brown.edu/courses/csci0111/fall2021/": {"text_content": "Skip to main content Welcome to CSCI 0111 - Computing Foundations Data MWF 1000-1050 AM EST, Metcalf Auditorium CSCI 0111 is an introductory course for both concentrators and non-concentrators who want to understand computing through the lens of data. It covers the fundamentals needed for additional CS courses, while also being designed as a useful stopping point forstudents who want to use a bit of computing, data analysis, or programming in other disciplines. The course starts with writing small programs to process and manage table-shaped data like CSV files. It then progresses to problems involving structured text-based data for which tables arent the best organization introducing common computer science data structures. Throughout the course, we examine practical questions about working with realistic data, as well as the often adverse social impacts that can arise when using data at scale. The course expects no prior programming experience. It is paced more gently than CSCI 0150 or CSCI 0170 which also assume no prior experience, while also focusing on styles of programming that are in common practice across many disciplines. The course uses two programming languages initially Pyret and later Python, with the first explicitly designed to transition into the second. Students from concentrations across campus have succeeded in and enjoyed CSCI 0111. Check out the Critical Review Brown access only Professor Fisler last led the course in Spring 2020 she and Professor Woos co-taught in Fall 2020, with Professor Woos running lectures. Quick Links Course Syllabus Anonymous Feedback Form Going to CSCI 0200 Lab Switch Form Blocklist Form Important dates Final exam Dec 16 as per CAB What Can I Take After CSCI 0111 Students who want to continue learning CS at the pace of 0111 can take CSCI0112 offered in the fall, followed by CSCI 0200 the new course replacing the former CSCI 0160 and CSCI 0180 Students who want to accelerate their learning of CS can do additional work in the last third of the semester to move directly to CSCI 0200 in the spring just as students would do after CSCI 0150 and CSCI 0170 Students who are more interested in data science than computer science can take DATA 200 in the spring which leads into the Data Fluency Certificate.", "metadata": {"last_modified": "2021-11-04T23:01:21+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Welcome to CSCI 0111 - Computing Foundations: Data!"], "word_count": 372, "token_count_estimate": 473}}, "https://cs.brown.edu/courses/csci0111/spring2020/index.html": {"text_content": "Welcome to CSCI 0111 Computing Foundations Data Meeting time and location MWF 1000-1050 AM can choose to be asynchronous CS0111 is the beginning course of an introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data, alongside other big ideas in computing. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Anonymous Feedback Form Course Missive Blocklist Form Shopping period announcements All students must agree to the collaboration policy at the end of the course missive . Archive The archive to the previous iterations of the course could be found here .", "metadata": {"last_modified": "2020-09-08T09:37:52+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Welcome to CSCI 0111: Computing Foundations: Data!"], "word_count": 169, "token_count_estimate": 204}}, "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab10-recs1.html": {"text_content": "Things to Do Google error messages Check Stack Overflow for similar questions. Try to find the most popular postsquestions with a lot of upvotes. Specify the language youre using Ask specific questions Things Not to Do Copy and paste lines of code directly into Google Use long or complicated code snippets directly without attribution Copy and paste lines of code directly into your editor. This is because there are often special characters like extra whitespace or open- and close- quotes that will cause errors when you try to run your code, but wont be visibly different when you look at it Things to Do Things Not to Do Expand all Back to top Go to bottom Things to Do Things Not to Do Expand all Back to top Go to bottom", "metadata": {"last_modified": "2020-04-14T18:31:40+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 131, "token_count_estimate": 139}}, "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab6-help.html": {"text_content": "Proposed task list for days-in-range For the days-in-range function, heres a possible task list, with annotations after on how to implement each task determine whether a temperature is with a range of two other numbers write a lam or a named function for this determine whether all temps in a list are within a range write a helper such as all-in-rangelst ListNumber, low Number, high Number - Boolean find the days for which all temps are within a range filter the data using all-in-range count the days from the previous step Use L.length You could also choose to combine tasks 3 and 4 into something like the following count the days for which all temps are within a range recur through the days-lists, counting those for which all-in-range returns true Proposed task list for days-in-range Expand all Back to top Go to bottom Proposed task list for days-in-range Expand all Back to top Go to bottom", "metadata": {"last_modified": "2020-03-05T16:09:54+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Proposed task list for days-in-range"], "word_count": 156, "token_count_estimate": 185}}, "https://cs.brown.edu/courses/csci0111/spring2020/labs/lab10-recs2.html": {"text_content": "Identifying Useful Links Stack Overflow is useful for answering specific coding questions but try to find posts with lots of upvotes Websites with tutorials such as GeeksForGeeks are more useful for explaining a particular concept or algorithm If an answer contains concepts that you havent seen before, keep searching there are often many ways to implement the same feature, and a different one might be more familiar If youre not sure why an answer isnt working, double check that it uses Python 3.7 or higher and not Python 2 Identifying Useful Links Expand all Back to top Go to bottom Identifying Useful Links Expand all Back to top Go to bottom", "metadata": {"last_modified": "2020-04-14T18:31:48+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 111, "token_count_estimate": 127}}, "https://cs.brown.edu/courses/csci0160/local.html": {"text_content": "Toggle navigation SEA-S 16 Home Documents Lectures Assignments Section TA Hours Staff Working Locally Guide Select your operating system and follow the guides or videos below to learn how to set yourself up to work locally If you run into any issues, post to Ed Discussion under the logistic tag Mac Windows 1 Local Python Setup These steps are to installensure the correct version of python and pytest are installed locally on your computer. In terminal, run python --version to get the python version you are running. If it says 3.7.3 you are good to go, if not Run python3 --version . If you dont get 3.7.3 install python 3.7.3 If you get 3.7.3 you must type python3 to run anything, or setup an alias as shown below. Setting up an alias What an alias is a usually short command that the shell terminal translates into another usually longer command. For example, if instead of typing cs0160install you wanted to type i you could set up an alias so i was interpreted as cs0160install in your terminal We are going to make an alias so python is interpreted as python3 by default. Note If your shell is zsh look at top of terminal and see if it says bash or zsh, you should be modifying the .zshrc file instead of the .bashprofile . In your local terminal not over ssh type open -e .bashprofile if a file does not exist type touch .bashprofile first and then open -e .bashprofile Then add the following line to the end of the document alias pythonpython3.7 Now run source .bashprofile essentially refreshing your terminal and then run python --version to confirm that youve correctly set the version to python 3. It should now say 3.7.3 Make sure pytest is installed by running python and then in the python shell run import pytest If you get no errors doing this, you are fine, If not Type exit to exit the python shell Run pip3.7 install -U pytest Now go back into the python shell by running python and then in the shell write import pytest once more to confirm it is installed by making sure you no longer have errors Important note if you have python 3.7.3 , then youre good to go. If not Follow this link to download python 3.7.3 To determine which download you want to do, go into system info and look at system type. If it is x64 you want the x86-64 executable installer If it is x86 you want the x86 installer Once that downloads open the executable. There will be a box in at the bottom that says add python 3.7 to path, make sure this box is checked. Press install now. Python 3.7.3 takes about 30 seconds to a minute to download Once the download is complete, open either powershell or cmd prompt and type python --version , you should see Python 3.7.3 Continue only if NOTHING or the WRONG version comes up If nothing comes up, or you receive a different version, python probably hasnt been added to the path. To add it to the path manually, press the windows key and type edit the system environment variables The bottom right hand corner will have an option environment variables that you should click on In user variables, click path then edit. You will be adding two new lines. Press new, then add CUsers AppDataLocalProgramsPythonPython37Scripts CUsers AppDataLocalProgramsPythonPython37 Make sure pytest is installed by running python and then in the python shell run import pytest If you get no errors doing this, you are fine, If not Type exit to exit the python shell Run pip3.7 install pytest Now go back into the python shell by running python and then in the shell write import pytest once more to confirm it is installed by making sure you no longer have errors 2 Local Java Setup These steps are to make sure the correct version of java is installed on your local computer. You must do this before doing your local Eclipse setup In terminal type, java -version and check that the number following java version starts with 1.8 or 8, if it does, youre done If not, read on. Visit this website, and download the program that corresponds with your computer ie Mac, Linux, or Windows, and download the 64-bit version. If you dont have an Oracle account and dont want to make one, you can also download jdk8 here. That said, we highly recommend making an Oracle account -- youll be able to download jdk8 directly from the source, and it may come in handy later on. In your terminal type java -version again to check if the version is now 1.8 or 8, and if it is not type the following into your terminal cd LibraryJavaJavaVirtualMachines ls you should see at least one file that starts with jdk, look for the file whose number starts with 1.8 or 8 and copy the file name. The full copied file name should look something like jdk.1.8.0181.jdk cd open -e .bashprofile if it says no bashprofile file exists, type touch .bashprofile then open -e.bashprofile Add the below code line to the end of your .bashprofile file. However, fill in the part fill me in with the copied file name from the second bullet point export JAVAHOMELibraryJavaJavaVirtualMachinesfill me inContentsHome Now type java -version to make sure the correct version of java is being used Type java -version to see your version of java, if it is 1.8, youre done Visit this website, and download the program that corresponds with your computer ie Mac, Linux, or Windows. If you dont have an Oracle account and dont want to make one, you can also download jdk8 here. That said, we highly recommend making an Oracle account -- youll be able to download jdk8 directly from the source, and it may come in handy later on. Follow the install setup provided from the download until it completes Check to make sure the path of java has been updated by running java -version in powershell or cmd prompt. If nothing or the wrong version comes up, continue following these instructions To add it to the path manually, press the windows key and type edit the system environment variables The bottom right hand corner will have an option environment variables that you should click on In system variables, click path then edit. You will be adding 1 line, press new, then add CProgram FilesJavajdk1.8.0231bin Note To make sure this runs properly, make sure this new line added to the path goes to the top, you can do so by clicking on the newly added line and pressing move up until it is at the top. 3 Local IntelliJ Setup Follow this guide . Follow this guide . 4 Local AtomSublimeVSCodePycharm Setup There are many different IDEs that work for writing in python IDEs are platforms in which you can write code. You can edit your python files in whatever program you like. Some recommended ones are Atom , VS Code , Sublime , and Pycharm . Atom, VS Code, and Sublime are free whereas Pycharm can be downloaded for free by first creating a GitHub account and then registering it as a GitHub student account here . The video tutorial shows these off more. There are many different IDEs that work for writing in python IDEs are platforms in which you can write code. You can edit your python files in whatever program you like. Some recommended ones are Atom , VS Code , Sublime , and Pycharm . Atom, VS Code, and Sublime are free whereas Pycharm can be downloaded for free by first creating a GitHub account and then registering it as a GitHub student account here . The video tutorial shows these off more. 5 Zoom Setup Zoom will be used for all interactions that used to be in person . This is the link to log in to your Zoom account. This is how Zoom will work for each of its implementations Code Hours At the beginning of an hours slot, TAs will release a link to join a Zoom video call. Sign up on signmeup as normal. You can join the call at any time. However, you will be placed in a waiting room before actually meeting with TAs until it comes to your spot in line. As a result, please constantly be monitoring the hours line andor your Zoom account when it comes close to being your turn in line. You will then be accepted to join the meeting. After being accepted into the meeting you will have 2 minutes to initiate conversation with the TA. If you fail to do so, the TA will release you back to the waiting room, where you will have 30 minutes to email the TAs who are currently on hours to unmark you missing. If it has been more than 30 minutes, we reserve the right to delete your sign up. Once in hours, in order to debug over Zoom, you will have to rely on Zooms screen-sharing feature. To screen share over Zoom in the panel on the bottom of the meeting, there is a Screen Share or Share option in which you can choose which screen youd like to share. You should select your Eclipse WorkspaceFastX SessionAtom Filewhatever, and then click share in the bottom right hand corner. Your TA should be able to see your screen. After youre done screen sharing, at the top of your screen, select the Stop Share option. Conceptual HoursClinic At the beginning of the Conceptual HoursClinic TAs will be posting a link for you to join them for Conceptual HoursClinic. TAs will answer questions by demand, and split you into supervised breakout sessions if necessary. Section Your section TAs will send out invitations to join a Zoom meeting 5 minutes before your section. Joining the meeting will earn you attendance points for that session. All mini assignments are to be emailed to your section TAs before your section. Zoom will be used for all interactions that used to be in person . This is the link to log in to your Zoom account. This is how Zoom will work for each of its implementations Code Hours At the beginning of an hours slot, TAs will release a link to join a Zoom video call. Sign up on signmeup as normal. You can join the call at any time. However, you will be placed in a waiting room before actually meeting with TAs until it comes to your spot in line. As a result, please constantly be monitoring the hours line andor your Zoom account when it comes close to being your turn in line. You will then be accepted to join the meeting. After being accepted into the meeting you will have 2 minutes to initiate conversation with the TA. If you fail to do so, the TA will release you back to the waiting room, where you will have 30 minutes to email the TAs who are currently on hours to unmark you missing. If it has been more than 30 minutes, we reserve the right to delete your sign up. Once in hours, in order to debug over Zoom, you will have to rely on Zooms screen-sharing feature. To screen share over Zoom in the panel on the bottom of the meeting, there is a Screen Share or Share option in which you can choose which screen youd like to share. You should select your Eclipse WorkspaceFastX SessionAtom Filewhatever, and then click share in the bottom right hand corner. Your TA should be able to see your screen. After youre done screen sharing, at the top of your screen, select the Stop Share option. Conceptual HoursClinic At the beginning of the Conceptual HoursClinic TAs will be posting a link for you to join them for Conceptual HoursClinic. TAs will answer questions by demand, and split you into supervised breakout sessions if necessary. Section Your section TAs will send out invitations to join a Zoom meeting 5 minutes before your section. Joining the meeting will earn you attendance points for that session. All mini assignments are to be emailed to your section TAs before your section.", "metadata": {"last_modified": "2021-06-14T18:59:07+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["", "", "", "", "", "", "", "", "", ""], "word_count": 2043, "token_count_estimate": 2491}}, "https://cs.brown.edu/courses/csci0160/static/files/docs/doc/decisiontree/index.html": {"text_content": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "metadata": {"last_modified": "2021-05-08T18:38:06+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Frame Alert"], "word_count": 36, "token_count_estimate": 44}}, "https://cs.brown.edu/courses/csci0160/static/files/docs/doc/graph/index.html": {"text_content": "JavaScript is disabled on your browser. Frame Alert This document is designed to be viewed using the frames feature. If you see this message, you are using a non-frame-capable web client. Link to Non-frame version .", "metadata": {"last_modified": "2021-05-08T18:38:12+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Frame Alert"], "word_count": 36, "token_count_estimate": 44}}, "https://cs.brown.edu/courses/csci0111/spring2020/data/hw10/": {"text_content": "Homework 10 Source Code Download The zip file below contains your data, and everything needed to run the Flask web appNote the absence of the stencil, which is instead on Canvas. hw10.zip", "metadata": {"last_modified": "2020-04-29T03:35:49+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Homework 10 Source Code Download"], "word_count": 32, "token_count_estimate": 40}}, "https://cs.brown.edu/courses/csci0300/2021/assign/labs/assets/Vagrantfile": {"text_content": "-- mode ruby -- vi set ftruby CS300 Development VM Feel free to modify this file to best work with your machine. For documentation, please see the comments here or go to httpsdocs.vagrantup.com for more information. All Vagrant configuration is done below. The 2 in Vagrant.configure configures the configuration version we support older styles for backwards compatibility. Please dont change it unless you know what youre doing.Vagrant.configure2 do config The most common configuration options are documented and commented below. For a complete reference, please see the online documentation at httpsdocs.vagrantup.com. Every Vagrant development environment requires a box. You can search for boxes at httpsvagrantcloud.comsearch. config.vm.box ubuntubionic64 Disable automatic box update checking. If you disable this, then boxes will only be checked for updates when the user runs vagrant box outdated. This is not recommended. config.vm.boxcheckupdate false Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine. In the example below, accessing localhost8080 will access port 80 on the guest machine. NOTE This will enable public access to the opened port config.vm.network forwardedport, guest 80, host 8080 Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine and only allow access via 127.0.0.1 to disable public access config.vm.network forwardedport, guest 80, host 8080, hostip 127.0.0.1 Create a private network, which allows host-only access to the machine using a specific IP. config.vm.network privatenetwork, ip 192.168.55.10 Create a public network, which generally matched to bridged network. Bridged networks make the machine appear as another physical device on your network. config.vm.network publicnetwork config.ssh.forwardagent true config.ssh.forwardx11 true Share an additional folder to the guest VM. The first argument is the path on the host to the actual folder. The second argument is the path on the guest to mount the folder. And the optional third argument is a set of non-required options. config.vm.syncedfolder .gosrc, homevagrantgosrc Manually edit synced folder mount options just in case, but this should not be an issue for most config.vm.syncedfolder ., vagrant, mountoptions dmode775,fmode777 Provider-specific configuration so you can fine-tune various backing providers for Vagrant. These expose provider-specific options. Example for VirtualBox config.vm.provider virtualbox do vb Display the VirtualBox GUI when booting the machine vb.gui true Customize the amount of memory on the VM vb.memory 1024 end View the documentation for the provider you are using for more information on available options. Enable provisioning with a shell script. Additional provisioners such as Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the documentation for more information about their specific syntax and use. config.vm.provision shell, inline -SHELL rm -fv etcsshsshhost dpkg-reconfigure openssh-server apt-get update SHELLend", "metadata": {"last_modified": "2021-01-21T03:07:47+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 449, "token_count_estimate": 648}}, "https://cs.brown.edu/courses/csci0190/2018/laptop-policy.html": {"text_content": "Fall 2018 Accelerated Introduction to Computer Science 1 Anticipated Frequent Questions 2 README 3 Learning Goals, Assessments, and Time Allocation 4 Syllabus and Course Policies 5 Late Policy 6 Laptop Policy 7 Diversity and Professionalism 8 Assignments 9 Early Testing for Programming 10 Textbook 11 Software 12 Staff and Contact 13 How to Ask Questions and Report Bugs 14 Credits 6 Laptop Policy 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature On this page 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature prev up next 6 Laptop Policy Thanks to Cassandra Jacobs and alum Jake Eakle forfeedback that improved this document. 6.1 Background 6.2 The Course Policy 6.3 Popular Press 6.4 Research Literature Note Laptop is used in this document as a proxy for abroad range of devices, including tablets, smartphones, etc. 6.1 Background Numerous research studies over the past several years have foundgenerally adverse learning impacts of having laptops in classrooms alist of papers on that and related topics is in Research Literature andsummarized in Popular Press . Some of this literature is mainly an argument about how using laptopscauses students to harm their own learning. However, not all studentsare alike, and some may feel theyre excellent multitaskers or thatusing a laptop actually helps them presumably almost everyone inthose studies felt that way.... Anyway, they may feel that theyshould be allowed to take responsibility for their own education. The research, however, also shows a much more perniciousproblem. Student learning is also negatively impacted by someone elses laptop use. This isnt surprising screens haveflashing content, keyboards make noise, and distractors are, ingeneral, distracting. This is where an individuals exercise of rightsbecome problematic you have the right to squander your educationalopportunities, but not to take away those of others. This phenomenon isnt confined to the research literature. Inend-of-semester surveys across multiple courses, I have foundnon-trivial percentages of students express frustration sometimes ina colorful manner at others laptop use. In fact, its seeing this onsurveys that prompted me to look up the research. At the same time, laptops are sometimes useful in coursework. Mostcommonly, you may be asked to try out a program, especially a conceptyou havent seen before and hence cant imagine in your head. 6.2 The Course Policy I am instituting a new policy on laptop use in class that reconcilesthese different pressures. By default, laptop use is prohibited. There are only threeexceptions Ive explicitly given permission to use laptops for sometask. If I havent but you think some task is laptop-suitable, ask. Imay want you to think about it instead of blindly typing it in. Whenthe task ends, you have to close Close means screenno longer visible and no more typing. More broadly, the deviceshould be inert, neither producing discernible output nor being giveninput. your laptop. You have some documentable reason that requires laptop use. Ifso please discuss it with me beforehand. Also, in light of the rest ofthis document, Id appreciate your positioning yourself in class in away that your laptops screen will not distract others. Note that thisdoes not mean you have to relegate yourself to the back perhaps thatisnt where you would like to sit But closer to the ends of rowswould help. Thanks. Emergencies. 6.3 Popular Press The following articles are not scientific literature but summarize theresearch in easily-accessible terms. To Remember a Lecture Better, Take Notes by Hand by Robinson Meyer, The Atlantic , 2014 Laptops Are Great. But Not During a Lecture or a Meeting. by Susan Dynarski, The New York Times , 2017 Note that Susan Dynarski is a distinguished professor of education, not just a random person with anopinion on the Web. 6.4 Research Literature The following are research papers you can read to learn more. The laptop and the lecture The effects of multitasking in learning environments byHelene Hembrooke and Geri Gay, Journal of Computing in Higher Education , 2003 In-class laptop use and its effects on student learning byCarrie B. Fried, Computers Education , 2007 Daydreaming and its correlates in an educational environment by Sophie Lindquist and John McLean, Learning and Individual Differences , 2011 Examining the impact of off-task multi-tasking with technology on real-timeclassroom learning byEileen Wood, Lucia Zivcakova, Petrice Gentile, Karin Archer, Domenica De Pasquale, Amanda Nosko, Computers Education , 2011 The impact of laptop-free zones on student performance and attitudes in large lectures byNancy Aguilar-Roca, Adrienne Williams, and Diane ODowd, Computers Education , 2012 Laptop multitasking hinders classroom learning for both users and nearby peers byFaria Sana, Tina Weston, Nicholas J. Cepeda, Computers Education , 2013 The pen is mightier than the keyboard Advantages of longhand over laptop note taking byPam A. Mueller and Daniel M. Oppenheimer, Psychological Science , 2014 The impact of computer usage on academic performance Evidence from a randomized trial at the United States Military Academy bySusan Payne Carter, Kyle Greenberg, Michael S. Walker, Economics of Education Review , 2017 Logged in and zoned out How laptop internet use relates to classroom learning bySusan Ravizza, Mitchell Uitvlugt, Kimberly Fenn, Psychological Science , 2017 prev up next", "metadata": {"last_modified": "2018-11-28T12:43:29+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 842, "token_count_estimate": 1180}}, "https://cs.brown.edu/courses/csci0190/2020/assignments.html": {"text_content": "Fall 2020 Accelerated Introduction to Computer Science Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Doc Diff Nile Sortacle Data Scripting Oracle Filesystem Updater Continued Fractions Twee Search Join Lists Tour Guide MST Map Reduce Fluid Images 24 prev up next Assignments Please make sure all submissions are anonymous . We will use Gradescope for assignment submission and grading. Follow theseinstructions to sign up for Gradescope. Please do not go to Gradescopedirectly you really do need to read these instructions All work will be due by 1159pm USEastern of the indicated day. Title Pair Published Due DocDiff no Wed, Sep 9 Fri, Sep 11 Nile no Sat, Sep 12 Tue, Sep 15 Sortacle no Wed, Sep 16 Mon, Sep 21 Data Scripting no Tue, Sep 22 Wed, Sep 23 Oracle no Fri, Sep 25 Tue, Sep 29 Filesystem no Wed, Sep 30 Thu, Oct 1 Updater yes Fri, Oct 2 Wed, Oct 7 Continued Fractions no Thu, Oct 8 Thu, Oct 15 TweeSearch no Sun, Oct 18 Wed, Oct 21 JoinLists yes Thu, Oct 22 Tue, Oct 27 Tour Guide no Wed, Oct 28 Thu, Nov 5 MST no Sun, Nov 8 Sat, Nov 14 MapReduce yes Sun, Nov 15 Thu, Nov 19 Fluid Images no Sun, Nov 22 Thu, Dec 3 24 no Fri, Dec 4 Sun, Dec 6 For assignments marked pair, you must work with at least onepartner. You cannotrepeat a partner across non-simultaneous pair assignments. The course homeworks will be programmed in Pyret , Please program according to the Pyret Style Guide . unless indicated otherwise.Pyret is a reasonably large language with many libraries, some ofwhich reproduce functionality like basic data structures that we areasking you to create in this course. This can lead to some confusionabout what you are and arent allowed to use from the language. Eachassignment provides information about this when necessary, but ingeneral, the following rules apply You can always use the computational core of the language basicconstants, functions, higher-order functions, and composition. You can always construct your own new data definitions, unlessexplicitly stated otherwise. You are allowed to use builtin functions for the followingdatatypes unless explicitly stated otherwise Numbers functions such as num-abs , num-max Strings functions such as string-to-number , string-length Booleans functions such as not You are allowed to use the following libraries unless explicitlystated otherwise lists sets pick tables option either You should not use any other built-in functions or librariesunless an assignment explicitly permits you to. When in doubt, ask. You may not use variables var or mutate objects unless explicitly permitted to by an assignment. prev up next", "metadata": {"last_modified": "2020-12-07T02:33:17+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 437, "token_count_estimate": 595}}, "https://cs.brown.edu/courses/csci0111/spring2020/": {"text_content": "Welcome to CSCI 0111 Computing Foundations Data Meeting time and location MWF 1000-1050 AM can choose to be asynchronous CS0111 is the beginning course of an introductory Computer Science sequence at Brown University for both concentrators and non-concentrators. We want to provide our students the chance to master the fundamentals needed for upper-level courses, in addition to reasonable stopping point after any course and real-life applications to other academic fields. In this course, you will learn foundational ideas about Computer Science through essential programming, data structures, data science applications, and social impacts of data, alongside other big ideas in computing. We use two different programming languages, Pyret and Python, to help students learn to approach concepts from different perspectives. The course expects no prior programming experience. Quick links Anonymous Feedback Form Course Missive Blocklist Form Shopping period announcements All students must agree to the collaboration policy at the end of the course missive . Archive The archive to the previous iterations of the course could be found here .", "metadata": {"last_modified": "2020-09-08T09:37:52+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Welcome to CSCI 0111: Computing Foundations: Data!"], "word_count": 169, "token_count_estimate": 204}}, "https://cs.brown.edu/courses/csci0150/": {"text_content": "Assignments Lectures Sections Code-along Hours Resources SRC Staff WELCOME TO CSCI 0150 CS0150 is one of the introductory Computer Science courses offered at Brown University. This course introduces students to Computer Science through object-oriented design and programming, using Java and the JavaFX graphics library. You will use these tools for building interactive programs with graphical user interfaces. CS0150 reinforces concepts with practical exercises in weekly lab sessions and with challenging and engaging programming assignments, such as Doodle Jump and Tetris There are no prerequisites for CS0150 and the course expects no prior programming experience. This Week in CS15 Nov 26 - Dec 2 Assignment Othello Handout Help Slides Help Session AI Handout Assignment Pacman Handout Help Slides Help Session Assignment Sketchy Handout Help Slides Help Session Javadocs Assignment Indy Handout Mini-Assignment Assignments Assignment Released Early On Time Late Javadocs Help Slides Help Session Additional Handouts Rattytouille Sept 13 NA Sept 16 NA - - - - AndyBot Sept 17 NA Sept 20 NA JavaDocs - - - Pong Sept 21 NA Sept 25 NA JavaDocs - - - TicTacToe Sept 26 Sept 28 Sept 30 Oct 02 JavaDocs - - - Fruit Ninja Oct 03 Oct 08 Oct 10 Oct 12 JavaDocs Help Slides - - Cartoon Oct 12 Oct 19 Oct 21 Oct 23 - Help Slides - Mini-Assignment DoodleJump Oct 24 Oct 30 Nov 01 Nov 03 - Help Slides - - Tetris Nov 04 Nov 11 Nov 13 Nov 15 - Help Slides - - Pacman Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session - Sketchy Nov 17 Dec 10 Dec 12 Dec 14 Javadocs Help Slides Help Session - Othello Nov 17 Dec 10 Dec 12 Dec 14 - Help Slides Help Session AI Handout Indy Nov 17 Dec 10 Dec 12 Dec 14 - - - Mini-Assignment Lectures Lectures are held in Salomon DECI on Tuesdays and Thursdays from 230-350pm. Date Lecture PDF Printable PDF PPT Recordings Skit Code 0907 Welcome to CS0150 What is Programming PDF Printable PDF PPT Recording Skit - 0912 Calling and Defining Methods PDF Printable PDF PPT Recording - - 0914 Introduction to Parameters and Math PDF Printable PDF PPT Recording - - 0919 Working with Objects I PDF Printable PDF PPT Recording - - 0921 Working with Objects II PDF Printable PDF PPT Recording - - 0926 Interfaces and Polymorphism PDF Printable PDF PPT Recording - - 0928 Inheritance and Polymorphism PDF Printable PDF PPT Recording - - 1003 Math and Making Decisions PDF Printable PDF PPT Recording Skit - 1005 Graphics I PDF Printable PDF PPT Recording - Code 1010 Graphics II PDF Printable PDF PPT Recording - Code 1012 Graphics III PDF Printable PDF PPT Recording - Code 1017 Loops PDF Printable PDF PPT Recording - - 1019 Arrays PDF Printable PDF PPT Recording - - 1024 Design Principles and Patterns I PDF Printable PDF PPT Recording - Code 1026 Design Principles and Patterns II PDF Printable PDF PPT Recording - - 1031 Recursion PDF Printable PDF PPT Recording Skit - 1102 Big O, Sorting and Searching PDF Printable PDF PPT Recording - - 1107 Data Structures I Linked Lists PDF Printable PDF PPT Recording - - 1109 Data Structures II Stacks, Queues, and Trees PDF Printable PDF PPT Recording - - 1114 Data Structures III PDF Printable PDF PPT Recording - - 1116 Final Project Intro PDF Printable PDF PPT Recording - - 1128 History PDF Printable PDF PPT Recording - - 1130 Computer Graphics PDF Printable PDF PPT Recording - - 1205 HTA Lectures PDF Printable PDF PPT Recording - - Labs Sections Labsection is a time to review course content in a smaller group setting and practice applying those concepts through partnered labs. Each section will meet once a week and will be led by two TAs with around SOME NUMBER of students, so it is also a time to work closely with and get to know some of your fellow CS15-ers. A typical labsection consists of short group check in, a fun SRC activity, and then either a presentation and some smaller group activities to review concepts or a lab. Date LabSection Handout Mini-Assignment Review Video SRC Slides 0912 Lab 0 Linux Terminal Handout Mini-Assignment - - Slides 0919 Lab 1 Intro to Java Handout - - SRC Activity - 0926 Section 2 Class Relationships - Mini-Assignment - SRC Activity Slides 1003 Section 3 Polymorphism - Mini-Assignment - SRC Activity Slides 1010 Lab 4 JavaFX Handout - Video - - 1017 Lab 5 Debugging Handout Mini-Assignment - - - 1024 Section 6 1D Array, ArrayLists, and Loops Handout Mini-Assignment - SRC Activity Slides 1031 Lab 7 2D Arrays Handout Mini-Assignment Video SRC Activity Slides 1107 Section 8 Algorithms - Mini-Assignment - - Slides 1114 Lab 9 Data Structures and Recursion Handout - - SRC Activity Slides Code-Along CS15 Code-Alongs are your one stop shop for getting hands-on experience with guided coding exercises in order to better understand the concepts of OOP We know that lectures can at times feel very abstract, and that we sometimes need examples in code in order to fully understand how these concepts work. Throughout the semester, we will host various code-alongs in order to assist you all with the skills necessary for succeeding in the course Code-Along Related To Date 1 Date 2 Date 3 Video Stencil Java Syntax Code-along Rattytouille 0913 at 700 PM MacMillan 117 0915 at 700 PM MacMillan 117 0917 at 700 PM MacMillan 117 Video Stencil Writing Classes Code-along Andybot, Pong, TicTacToe 0919 at 800 PM Metcalf Research Auditorium 0924 at 300 PM Metcalf Research Auditorium 0927 at 900 PM Metcalf Research Auditorium Video Stencil Java FX Design Code-along Cartoon 1015 at 300 PM MacMillan 115 1018 at 400 PM MacMillan 115 - Video Stencil GitHub and Debugging Code-along Doodle Jump 1025 at 700 PM MacMillan 117 1029 at 300 PM MacMillan 117 - Video Stencil Tetris Pieces Code-along Tetris 1105 at 300 PM Friedman 202 1108 at 700 PM Friedman 202 - Video Stencil Hours Have a Quick Question Try out CS15s own virtual TA Chatbot, GPTA Terms and Conditions GPTA User Guide Generative AI Usage Guide reminder that GPTA is experimental and is a supplement, not a replacement, for real TA help CONCEPTUAL TA HOURS Confused about an idea discussed in lecture or in a project handout If we dont have to look at your code to answer your question, conceptual hours are a great place to meet other students and talk to a TA. Your question will get answered much faster here than at the debugging hours line. DEBUGGING HOURS Debugging Hours are a great resource to discuss 1-on-1 with a TA about your code and learn how to solve your bugs however, please be sure to check our TA Hours policy and the Ed page before getting in line at the hours website . When waiting for hours, wait near CIT 210 and a TA will come to get you Resources Quick Links Syllabus Ed Course Calendar Course Missive Gradescope Feedback Form Hours Emails TA Email cs0150taslists.brown.edu general questions for all TAs HTA Email cs0150headtaslists.brown.edu HTA-Specific QuestionsConcerns Individual TA Emails ltcslogingtcs.brown.edu cslogins found under Staff General Resources Required Readings Course Syllabus Course Missive Collaboration Policy TA Hours Policy Retake Policy GPTA User Guide Generative AI Usage Guide Online Help IntelliJ Git Set-up Guide Mac IntelliJ Set-up Video Windows IntelliJ Set-up Video Github Guide Github Video Master the Terminal Guide Understanding CS0150 Support Code Java Documentation Javadocs All built-in Java classes JavaFX-docs All built-in JavaFx classes JavaFX Guide JavaFX Images Documentation Java Language Specification Guides Tutorials README Guide Style Guide Variables Constructors Runtime Errors Containment Inheritance Diagrams Guide CS15 Vocabulary Sheet Partner Projects Logistics Guide Department Docs Undergraduate Missive Ergonomics IT Services Email Organizations Student Support Services CAPS Title IX Women in Computer Science Mosaic Health Wellness Advocates Diversity Inclusion Advocates Computer Science DUG SRC What is SRC As awareness of technologys consequences increases, attention turns to how computer scientists are trained. In response, the CS department created the Socially Responsible Computing initiative in 2019 to integrate ethics and social impact topics broadly across its curriculum. At Brown, SRC is embedded into most major CS courses. Our goals in CS15 are to give a broad overview of todays technological landscape so that you are familiar with these concepts when you are eventually faced with ethical design decisions further down your CS journey. How does this fit into the CS15 curriculum Mini-lectures Lab activities about lecture content Two extra credit discussion sections with details TBA How can I get involved Groups Brown SRC Reading group ARGBrown AIRES AI Robotic Ethics SocietyBrown Human Centered Robotics Initiative Design for America Brown Alum-foudned groups others Better World by Design Impact Labs Coding it Forward TechCongress Classes Brown CSCI1870 Cybersecurity Ethics CSCI1951I CS for Social Change DATA0080 Data, Ethics and Privacy MCM0230 Digital Media PHIL401 Ethics of Digital Technology STS 1700T Race, Gender, and Technology in Everyday Life Classes under the Science, Technology, and Society STS department ...and more Topics in Socially Responsible Computing Artificial Intelligence Lecture 1 Lectures 2-4 Lecture 5 Blockchain and Crypto Lecture 1 Lecture 2 Cybersecurity Lecture 1 Data Privacy Lecture 1 Lecture 2 Ethics in Big Tech Lecture 1 Lecture 2 Misinformation Freedom of Expression Lecture 1 Labor Practices Lecture 1 Philosophy Lecture 1 Software Design Lecture 1 Lecture 2 AI Overview GPT-3 Creative Fiction Interactive Stable Diffusion free text-to-image generator How DALL-E could power a creative revolution One Hundred Year Study on Artificial Intelligence AI100 LLMs and Neural Nets Exclusive OpenAI Used Kenyan Workers on Less Than 2 Per Hour to Make ChatGPT Less Toxic A Very Gentle Introduction to Large Language Models Without the Hype Lawyer Used Chat-GPT in Court and Cited Fake Cases AI for radiographic COVID-19 detection selects shortcuts over signal AI Bias and Ethics Who Is Making Sure the A.I. Machines Arent Racist A.I. Brings the Robot Wingman to Aerial Combat Automation isnt the biggest threat to US factory jobs Robots were supposed to take our jobs. Instead theyre making it worse Economic possibilities for our grandchildren Privacy Violations and Regulation The New Rules of Data Privacy Data Protection and Privacy Laws China Social Credit System Explained CCTV Surveillance for Crime Prevention FTC Finalizes Order with Flo Health Examining the intersection of data privacy and civil rights Ring, Google and the Police What to Know About Emergency Requests for Video Footage H.R.8152 - American Data Privacy and Protection Act Section 230 Surveillance Capitalism High tech is watching you What Is Surveillance Capitalism Cambridge Analytica and Facebook The Scandal and the Fallout So Far You Are the Product Targeted by Cambridge Analytica on Facebook Corporate Surveillance in Everyday Life Antitrust Support for tech regulation has declined The Antitrust Laws House passes antitrust bill Regulating Big Tech To Regulate Network-Based Platforms, Look at Their Data Why Breaking Up Big Tech Probably Wont Work Who Will Teach Silicon Valley to Be Ethical Responsible AI tools and Practices Ethics Alone Cant Fix Big Tech Can Big Tech be Disrupted Big Tech Needs to Be Regulated. Here Are 4 Ways to Curb Disinformation and Protect Our Privacy The value and challenges of regulating big tech F.T.C.s Court Loss Raises Fresh Questions About Its Chairs Strategy Blockchain Overview Blockchain Facts What Is It, How It Works, and How It Can Be Used The Collapse of FTX What Went Wrong With the Crypto Exchange Blockchain Energy and Sustainability Cryptocurrencys energy consumption problem What is proof of work or proof of stake Ethereums Energy Revamp Is No Guarantee of Global Climate Gains Cybersecurity The Untold Story of Solarwinds Equifax Data Breach Settlement Chinese Malware Hits Systems on Guam. Is Taiwan the Real Target Hunting Russian Intelligence Snake Malware What You Need to Know About Autonomous Weapons Executive Order on Improving the Nations Cybersecurity A.I Brings the Robot Wingman to Aerial Combat Philosophy Microsoft Says New A.I Shows Signs of Human Intelligence Philo-GPTs Surprisingly Wise Answer to What is the Meaning of Life A.I Thinking vs. Human Thinking How Close Are We to A.I That Surpasses Human Intelligence Dark Addictive Design Deceptive Design How Facebook and other sites manipulate your privacy choices How financial apps get you to spend more and question less A survey of addictive software design Dopamine, smartphones and you Good User Design Practice Coming Soon Misinformation Freedom of Expression Coming Soon Labor Practices Coming Soon Staff Professor Head Teaching Assistants Andy avd hehim Im originally from the Netherlands. My CS specialty is Computer Graphics, especially pen- and touch-computing. Im a foodie and love the outdoors hiking and backpacking especially in the Grand Canyon, mountain- and road-biking, and kayaking. THE CAPITOL Allie amasthay sheher Hi guys I am a junior from Connecticut studying Computer Science, and I am super excited for this semester When I am not in the CIT, I love going to Bajas, drinking Diet Coke, singing karaoke, or trying to catch the Sci Li rats. Feel free to reach out to me anytime about anything CS15, CS at Brown, or general questions on life. Cant wait to meet you DISTRICT 10 - LIVESTOCK Anastasio aortiz18 hehim Hey My name is Anastasio, I am a Junior from Nicaragua studying APMA-CS. I like ice cream and long walks by the beach. DISTRICT 2 - MASONRY Cannon ccaspar hehim I am Cannon, Junior, CS and Classics Major, from Concord MA. Super excited to HTA CS15 I often do things that make me happy, which includes adventure, fun, hope, power, meditation, and sometimes even CS. Reach out if you ever wanna talk about anything DISTRICT 7 - LUMBER Lexi ehenrion sheher Hi everyone I switched to CS after taking CS15 as a student, and Im now a senior studying Visual Computing. I couldnt be happier, and Im so excited to share this AWESOME class with all of you Im also an artist and writer when Im not coding, wandering around Providence, or eating waffles and reading manga at Zinnekens DISTRICT 6 - TRANSPORTATION Sarah sonderdo sheher Hi I am a junior from New Jersey studying computer science and history. In my free time you can find me hanging out with my friends, pretending to read books, dreaming about pasta, and watching the same movies over and over again. In my not-free time you can find me in the CIT. I am so excited to meet you all, feel free to reach out and say hi DISTRICT 11 - AGRICULTURE Joint Socially Responsible ComputingUndergraduate Teaching Assistants Adam amroueh hehim Hi I am a senior from Rochester, NY studying CS-Econ. I enjoy food, reading and trying new coffee shops. I cant wait for CS15 and to meet everyone DISTRICT 8 - TEXTILES Faizah ffnaqvi sheher Hi everyone Im a sophomore from NJ studying CS and IAPA. In my free time I like reading, baking and then eating what I bake, and dousing my food with Tabasco sauce. Looking forward to meeting you all and having a great semester DISTRICT 13 - NUCLEAR Katie kli154 sheher Hi Im a sophomore from the Seattle area studying computer science and philosophy. I like reading, hiking, tap dancing, losing at chess, and eating Andrews yogurt bowls. DISTRICT 7 - LUMBER Undergraduate Teaching Assistants Alyssa asun59 sheher Hi I am a sophomore from Oregon studying CS-Econ. When I am not rotting in the CIT, Im fencing, watching Dance Moms, or getting food with friends. Welcome to CS15, super excited to have an awesome semester with you guys DISTRICT 5 - POWER Annabel aroth7 sheher Hi Im a senior studying APMA-Econ and CS. I was born in Boston, MA, then lived in Shanghai, China for 5 years before moving to Connecticut. When Im not working on psets in one of the CIT conference rooms, you can find me running, baking, or doing the NYT crossword or some variation of wordle. So excited for an awesome semester with everyone DISTRICT 9 - GRAIN Ashton agglover hehim Hi everyone Im a sophomore from Lake Wylie, South Carolina studying computer science. I like the outdoors, traveling, and watching sports especially soccer. Looking forward to meeting everyone DISTRICT 3 - TECHNOLOGY Asia atnguyen sheher Im a sophomore from Nashville, Tennessee Im planning on concentrating in CS and IAPA. Im a huge swiftie, and I love to read and hang out with my friends in my free time Im so excited to meet you all DISTRICT 1 - LUXURY Astrid armoreno sheher Hi Im a sophomore concentrating in Computer Science. Im from Detroit, Michigan and I enjoy things like reading, crocheting, sewing, and cooking. So excited to guide everyone through the semester DISTRICT 6 - TRANSPORTATION Ayman abenjell hehim Hi everyone Im Ayman, a junior from Casablanca, Morocco studying Computer Science here at Brown When Im not in the CIT, I like walking around campus while drinking boba, playing retro and current Nintendo games, and practicing piano started learning a year ago. I also love drinking anything with caffeine in it, so any teacoffee shop recommendations are welcome. Im super excited for this semester, cant wait to meet yall DISTRICT 12 - MINING Ben baizenbe hehim I am a sophomore from Highland Park, Illinois, probably studying either CS or APMA. Outside of school, I play tennis, do crosswords, and watch movies -- most recently Puss in Boots The Last Wish, one of the best movies ever made. I cant wait to be your TA DISTRICT 12 - MINING Brandon bdiaz2 hehim Hi Im a senior from Atlanta, GA studying CS and IAPA. I love spontaneous beach trips and listening to music. Cant wait to meet everyone DISTRICT 10 - LIVESTOCK Chloe cnevas sheher Hi Im a sophomore from Westport, CT and Im studying APMA-CS. In my free time I love to bake and cook, play the violin, and listen to music. Im SO excited to be a TA for CS15 and Im looking forward to a great semester DISTRICT 8 - TEXTILES Channing cpbryant hehim Hey everyone My name is Channing, and Im from Massachusetts. Im a sophomore studying Computer Science-Economics. I like listening to music, playing sports, eating, and watching movies. Im excited to work with all of you, and feel free to reach out. DISTRICT 3 - TECHNOLOGY Caden cschroe4 hehim Hi Im a sophomore from New Hampshire studying Applied Math and Computer Science. I love going to the beach, playing Spikeball, and climbing trees. Plus, Im a big Ratty and Jos fan so you can usually find me there. Im super excited to meet all of you DISTRICT 6 - TRANSPORTATION Cameron csikich sheher Hi everyone Im a junior from Toronto, Ontario concentrating in APMA-CS. Im also on the Womens Ice Hockey team and I love to bake. Feel free to talk to me about sports, food or anything else. I look forward to meeting you all DISTRICT 4 - FISHING Cindy czheng27 sheher Hi, Im a senior from Louisiana studying APMA-Biology. I love reading, gardening, and walking aimlessly. Looking forward to meeting everyone DISTRICT 6 - TRANSPORTATION Dan dliu58 hehim Hello there Im a junior concentrating in CS from Lockport, NY. My hobbies are sleeping in late, try-harding at Mario Kart and Smash, reading mangaweb serials, and spending money at the CIT vending machines. DISTRICT 12 - MINING Daniel Z.dzhu36 hehim Hey everyone Im a sophomore from San Ramon, California studying neuroscience and computer science. In my free time, I enjoy hiking, reading mangabooks, playing games, cooking, and voice calling friends on discord. So excited to meet you all in CS15 DISTRICT 3 - TECHNOLOGY Dawood dolaniyi hehim Hey everybody, Im Dawood Im a CS student from Americas most beloved state, Iowa real place, I swear. If Im not coding video games in my dorm Im probably saving my semester in the Sci-Li basement. If you ever see me hopping around campus, try to stop me for a conversation Id love to chat Thank yall for contributing to my sophmore-year excitement by taking CS15, Im beyond excited to work and learn with you all DISTRICT 11 - AGRICULTURE Emily H. ehinds3 sheher Im a senior from Seattle, WA concentrating in Computer Science and French and I am so excited to meet all of the students this year DISTRICT 7 - LUMBER Emily O. eiolson sheher Hi everyone Im a sophomore planning on studying a combination of computer science and physics. Im from the Bay Area, California, but I am so happy to call Providence a home now too. Im even more happy to get to work with you all, and I cant wait for a great semester in CS15 DISTRICT 11 - AGRICULTURE Emily W. emwang sheher Hi Im a sophomore from the Chicago suburbs, studying CS. I spend most of my time crocheting, watching anime, playing violin, and making silly drawings. Super excited to be your TA this semester D DISTRICT 9 - GRAIN Ethan eohayon1 hehim Hi I am a Junior from Maryland studying CS-Econ. In my free time I enjoy playing sports, hanging at the beach, and walking my dog. Im looking forward to working with everyone this fall DISTRICT 6 - TRANSPORTATION Francesca felia sheher Hi Im a sophomore double concentrating in APMA-Econ and CS. I love thrifting, iced caramel lattes, watching trashy reality TV, and beach days which is unfortunate considering Im from Minnesota. Im so incredibly excited to TA this year and cannot wait to meet you all, so feel free to reach out for anything DISTRICT 1 - LUXURY Gaby cgchoi sheher hi im a sophomore from irvine, california studying cs-econ and international business in my free time i love making coffee, drinking coffee, and spending way too much on coffee ceremony. im also always at trader joes. so excited to meet everyone DISTRICT 10 - LIVESTOCK Gavin gdhanda hehim Hi Im a sophomore majoring in CS and Econ from Denver, Colorado. I play the guitar and piano in my free time and take lots of naps, and Im so excited to TA CS15 this fall DISTRICT 3 - TECHNOLOGY Grace gcma sheher Hi, and welcome to CS15 Im Grace and Im a sophomore from Montgomery County, Maryland studying music and maybe cs idk. I enjoy playing random instruments, eating Chinese food, and watching animated kids shows. Super excited to meet you all DISTRICT 11 - AGRICULTURE Grace gmarshbu sheher Hi Im a junior from Houston studying CS and visual arts, both for animation. Im also interested in Russian language, musical performance, and fiction writing. When I can, I love to travel, watch animated movies, and listen to all sorts of music. Im also very fond of Blue Room, so Ill go there as often as my flex points allow. DISTRICT 3 - TECHNOLOGY Grant glandon hehim Hello everyone Im a Junior from the North Shore of Massachusetts studying Applied Math and Computer Science. In my free time, I enjoy playing Spikeball on the main green, climbing anything and everything that looks climbable including but not limited to rocks, walls, and trees, and playing tabletop games like Dungeons and Dragons. I cant wait to meet you all DISTRICT 13 - NUCLEAR Julie hchung33 sheher Hi everyone Im Julie from West Hartford, CT. In my free time, I love to write music, go for nature walks, play Nintendo Switch, and attempt to skateboard. You can probably spot me in Steinert center practice rooms. Im so excited to meet everyone, welcome to CS15 DISTRICT 6 - TRANSPORTATION Ilan ibrauns hehim Hi everyone, Im Ilan I am a sophomore from South Orange, New Jersey studying Applied Math - Computer Science and Mathematics. In my free time I like to play sports, work out, and hang with friends. I love my dog Ruby and you can find me constantly tracking my fantasy football team. Im so excited for the semester and feel free to reach out about CS15 or anything else DISTRICT 7 - LUMBER Imran ihussai3 hehim Hey Im a sophomore from Cambridge, MA, studying neuroscience and computer science. I love climbing, pottery, and I am a barista here at the underground cafe So excited to meet all of you DISTRICT 7 - LUMBER Isabelle iashapir sheher Hi Im Isabelle, and Im a sophomore from Los Angeles studying CS. In my free time, I love cooking, baking, and trying new food. Ive enjoyed eating pretty much every food Ive tried except for cashews. I also love anything outdoors hiking, rock climbing, kayaking, swimming, etc. I am so excited to be a CS15 TA this semester DISTRICT 9 - GRAIN Jackson jwschwar hehim I am a sophomore from southern Connecticut. I am thinking about concentrating in Computer Science and possibly Political Science. I love sports and am involved in club Frisbee on campus. I also love the outdoors and spend most of my summers in the Adirondacks in upstate New York. I am super excited to experience CS15 again and to meet you all throughout the semester DISTRICT 7 - LUMBER Jaclyn jcohen45 any pronouns Hi all Im a sophomore CS and Visa concentrator from South Florida. I love anything art and design, spooky full moon ceremonies, spending time in nature, ressurecting Blueno, and chasing birbs Im excited to meet all of you DISTRICT 10 - LIVESTOCK Jinho jlee812 hehim Hey Im a sophomore from Cambridge, Mass studying CS and literary arts When Im not on tiktok, Im in lecture watching tiktok. I love Taylor Swift, Succession, and am looking forward to meeting you all DISTRICT 11 - AGRICULTURE Jennifer jzliao sheher Hi, Im Jennifer Im a sophomore from Farmington, CT planning to concentrate in CS and History. I like reading, playing piano and guitar, and rotting in bed. so excited for CS15 DISTRICT 1 - LUXURY Juan jgarci71 hehim Hey everyone My name is Juan, and Im a junior from Compton, CA studying CS and Education. Outside of school, I tend to spend time playing random mobile games or watching a Gordon Ramsay show. Im so excited to meet you all this semester DISTRICT 6 - TRANSPORTATION Kamryn kwalke19 sheher Hi Im a sophomore from Maryland studying CS. When Im not camping at the CIT, Im dancing go Fusion Dance Company, reading, thrifting, or exploring cities. You can also find me in the Mosaic room pretty often. Im so excited for this semester and I cant wait to meet you all DISTRICT 12 - MINING Kanayo kduru1 hehim Hi Im a junior from Maryland. I like outdoor activities, cooking, and listening to music. If Im not sleeping, you can usually find me sitting on the green enjoying the sun, unless its winter in which case Ill disappear. I love exploring new places and food, so you might also just catch me wandering around Im so excited to meet all of you. Welcome to CS15 DISTRICT 1 - LUXURY Karim kmouline hehim Hi there My name is Karim, and I am a junior studying Math-CS and English. While Im not in the CIT working on projects or essays, you can find me in the pool with the club swim team, on the bike path with the running club, or spending an abnormal amount of flex points on Blue Room bagels and coffee. Let me know if you have questions about anything, whether it be Brown related or life in general DISTRICT 4 - FISHING Keanu kthuynh hehim Hi Im a sophomore from LA concentrating in Computer Science and Applied Math if everything goes my way. Outside of CS15, I enjoy video games, comics, photography, and blowing all my Bear Bucks on Blue Room muffins. If its something to brag about, I own the griddy emote in Fortnite. If its not, I dont own the griddy emote in Fortnite. Excited to see you all this year DISTRICT 9 - GRAIN Khalil kodesai hehim Hello My name is Khalil and I am a sophomore from San Diego, California planning to study Computational Biology. I love all things science and have some wet-lab experience if that is something any of yall want to ask me about Outside of academics, I love playing the flute, baking pies, and being generally a bit of a mess. I also listen to a ton of music Big Thief, Radiohead, Angel Olsen, Sufjan Stevens, etc., so come talk to me about that DISTRICT 11 - AGRICULTURE Logan ldhines hethey hey im a sophomore from portland, oregon studying CS and maybe linguistics. outside of school im really into thrifting, hiking, and listening to music while worrying about my spotify wrapped please feel free to recommend anything i also love trying out random baking recipes and failing miserably. im super super excited to meet all of you this semester DISTRICT 6 - TRANSPORTATION Lana lyangmac sheher Hi everyone Im a sophomore from Ann Arbor, Michigan and Im planning on concentrating in computer engineering. In my free time, I love to read, eat anything mango flavored, and spend time outside especially hiking or swimming. Cant wait to meet you all DISTRICT 7 - LUMBER Morgane mpizigo sheher Hi Im a sophomore from France concentrating in Computer Science and Psychology. CS15 is the class that convinced me to pursue CS, so I hope yall have a blast Outside of classes, I love crocheting, cooking badly, playing fishing mini games, and pursuing my love for hiking and martial arts. Debugging and testing are my favorite parts of CS, so dont feel bad if you bring a bug to me DISTRICT 4 - FISHING Marissa mshaffe3 shethey Hiya Im a sophomore from Philadelphia, PA, studying CS and either Science, Technology, and Society or Gender and Sexuality Studies. On campus, you can find me performing circus shows with Brown Aerial Acrobatics and a cappella music with the Higher Keys. I love contemporary fantasy fiction, racing my mom on the NYT crossword, and sipping boba on the main green. DISTRICT 6 - TRANSPORTATION Megan mtanuwid sheher Hi everyone Im a sophomore from Jakarta, Indonesia studying Computational Biology. I love solving crosswords, eating English muffins, and binge-watching Law Order SVU. Cant wait to meet everyone DISTRICT 3 - TECHNOLOGY Natalie nking12 sheher Im a sophomore from Houston, Texas. Im planning on concentrating in CS and Econ and Im so excited to TA the best class ever this year DISTRICT 3 - TECHNOLOGY Owen oanders6 hehim Im a junior studying Computer Science and Philosophy from Portland, Maine. When Im not coding, I like watching sports, the beach, and bagels. Looking forward to the semester with you all DISTRICT 13 - NUCLEAR Orlando ocedeno hehim Hey my name is Orlando Im currently a Senior studying computer science and Im originally from the Bronx, NY. Currently, Im binge watching One Piece, catching sunsets, going to the gym, or just chilling. DISTRICT 10 - LIVESTOCK Robyn rjecroi1 Hi Im a sophomore. I am 87.2 likely to double concentrate in IAPA and CS. I am an avid sunset picture taker, Music lover Spotify Apple Music, and an unhealthily committed binger of shows yes Ive watched up to 16 seasons of Greys Anatomy and will finish 20 seasons of One Piece. I am also excited to be your TA this semester. DISTRICT 4 - FISHING Sarah sberhan4 sheher Hi everyone Im Sarah, and I am a sophomore from Cambridge, MA. I am undecided in my concentration, but I am thinking about Education and CS. In my free time, I enjoy doing the wordle, playing connections, and reading I am super excited to get to know you all Feel free to ask me any questions DISTRICT 6 - TRANSPORTATION Sarah snrichma sheher Hi Im a sophomore from Danville, New Hampshire studying APMA-CS and physics. Outside of computer science, I love dancing and eating mint chocolate chip ice cream. Im super excited to be a C15 TA this semester DISTRICT 8 - TEXTILES Seehanah stang52 sheher hiii im a junior from central jersey studying apma- cs. im from central jersey and enjoy eating, hiking, and traveling. really excited for a great semester with everyone DISTRICT 9 - GRAIN Sherry szhan235 sheher Hey Im a junior from Bellevue, WA studying CS with a focus on animation. I love drawing a lot and also enjoy powerlifting, swimming, and being in nature. Please do not mention anything animeanimation-related in front of me because I will literally not be able to stop talking about it. Cant wait for you to take CS15 lt3 DISTRICT 4 - FISHING Sophia szlim sheher Hi everyone My name is Sophia and Im a sophomore from Auckland, New Zealand. I intend on concentrating in Computer Science and maybe Cognitive Science but I enjoy exploring different classes in Browns Open Curriculum. I love traveling, baking, and wasting my time watching tv shows and movies. Cant wait to get to know you all this semester DISTRICT 1 - LUXURY Will wvandewa hehim Junior from Cleveland, Ohio studying APMA-CS. Crochet enjoyer and casual runner. Its gonna be a crazy year. DISTRICT 7 - LUMBER Xiaoyue xhou8 sheher Im a junior concentrating in CS and Econ, and Im from Beijing, China. I love traveling, hiking, learning languages, and watching stage managing musicals. Really excited to meet you all DISTRICT 3 - TECHNOLOGY", "metadata": {"last_modified": "2023-12-07T01:33:54+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["WELCOME TO CSCI 0150", "Assignments", "Lectures", "Labs & Sections", "Code-Along", "Hours", "Resources", "SRC", "Staff"], "word_count": 5521, "token_count_estimate": 7386}}, "https://cs.brown.edu/courses/csci0300/2021/format.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Homework 1 Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 This is not the current iteration of the course Head here for the current offering. CS 300 format for 2021 Rather than conventional, synchronous lectures on Zoom, were trying out a different model that tries to accommocate different time zones and makes the Zoom experience as interactive as possible. Heres how this will work We will split each 80-minute lecture into several recording sessions 30 min each, which will take place at different times of the day, convenient for different time zones. Youll pick a time that works for you and join an active listener group of 12-15 students associated with this time. A signup form for this will be available on the first day of the course. When you are an active listener, your attendance is required . We expect you to attend the recording session, be prepared, ask questions and contribute to the discussion. This is your chance to experience CSCI 0300 as if it was a small seminar We will organize each lecture segment around a concept or demonstration program. Since we want you to participate actively in the lecture, there will often be some brief preparation work that we will assign to you. When it is not your rotations turn, you will watch the recorded video, which well post on the course website. You are welcome to attend anyway should you wish to, but well ask students who arent active listeners to turn off their video and give the active listeners priority for particiation. Over the course of the semester, each student will be required to attend about 10 lectures as an active listener exact number TBD. Recording times. See below for the recording times. Please ensure that you attend during your active listener rotations timeslot. Tuesday Thursday ALR1 9-10am ALR4 1030-1130am ALR2 1-2am ALR5 2-3pm ALR3 7-8pm ALR6 8-9pm Please submit your preferred times for youractive listener rotation via this form . Asynchronous lecture watching. Those students who arent part of a live lecture recording as active listeners are expected to watch that lecture asynchronously. Once the course enrollment has stabilized, we are hoping to form lecture watching teams of about four students each, based on a number of factors, including time zone. These teams will watch the lectures together and interact at times of their own choosing. Lecture length. Lecture length will be more driven by content than time block. We will record six lecture segments a week, each 30 minutes in duration sometimes a little more to allow for questions and discussion. Recording slots are 1 hour in duration, but will often take less time. Topics for the recordings will be announced in advance, and will roughly follow the course schedule . Optional sections. From time to time, we will offer optional sections, led by the instructor or TAs. These sections will review material and practice key skills, as well as offering a chance for you to ask questions. If the public health situation permits, we may offer in-person sections for those in Providence, subject to Browns rules for hybrid course meetings i.e., no more than 19 attendees, masks and social distancing required. Details will be announce on Piazza. In the shopping period , the initial lectures recordings will take place during the normal time slots 1-220pm Tuesday and Thursday. These recordings will be available shortly after for those who cannot make these times. Once course attendance has stabilized and youve submitted your active listener rotation time preferences, we will start the rotating recording schedule. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-01-31T01:11:15+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 696, "token_count_estimate": 876}}, "https://cs.brown.edu/courses/csci0300/2021/c-cpp-primer.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Homework 1 Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 This is not the current iteration of the course Head here for the current offering. CC Language Primers CS 131 teaches you the fundamentals of computer systems, using the C and C programming languages. C and C are the two most widely used systems programming languages in industry today millions of programs including your operating system and the web browser youre using to view this page are written in C and C. C and C are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language its been around since the 1970s But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources USNA Intro to C Programming . This is a brief, detailed guide to the C language syntax, as well as how you use utility functions like printf . You can ignore the bits about C. USNA Pointers, Arrays, and Structures . This explains in detail how the key data structure concepts of the C language work, and how you use them. C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library other parts of the site are a good C reference. The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie also known as KR Prentice Hall PTR, ISBN 0-13-110362-8 is the classic textbook for programming in C. Harvard CS 61s C Patterns explains some handy common tricky that will be useful for your assignments. LinuxOS XBSD man pages Theyre very detailed, but often tell you important details about library functions. Type man 3 libraryfunction to open the man page for libraryfunction e.g., strncpy . C C is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C, it is about systems programming , and we will not use or teach the complex object-oriented features in C and attempt to avoid its most confusing concepts. That said, getting familiar with Cs data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but dont despair It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C Harvard CS 161s C guide succinctly explains the key differences between C and C. It explains some of the C concepts you may encounter in documentation or compiler error messages e.g., constructors, destructors, etc.. C tutorials from LearnCpp.com C tutorial from cplusplus.com C tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C reference from cplusplus.com C reference from cppreference.com As of 2019, cplusplus.coms text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment We thank Eddie Kohler and Harvards CS 61 course for some of the above references, which weve reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-01-31T01:11:14+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 677, "token_count_estimate": 855}}, "https://cs.brown.edu/courses/csci0190/": {"text_content": "Next offering Fall 2023 . Shrirams first four 0190 HTAs, at the 2013 graduation ceremony Ethan Ceccetti 2009 Kshitij Lauria 2010 Jonah Kagan 2011 Aimee Lucido 2012 Thanks to Ethan for suggesting and arranging this Past editions. You can find newer reviews on the Critical Review site. Some old links may no longer work because they change their URLs. Offering Review Fall 2022 Fall 2021 Fall 2020 Fall 2019 Fall 2018 Fall 2017 review Fall 2016 review Fall 2015 Fall 2014 review Fall 2013 review Fall 2012 review Fall 2011 review Fall 2010 review Fall 2009 review", "metadata": {"last_modified": "2023-09-03T16:31:33+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 97, "token_count_estimate": 155}}, "https://cs.brown.edu/courses/csci0300/2021/notes/l03.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Homework 1 Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 This is not the current iteration of the course Head here for the current offering. Lecture 3 Pointers and Data Representation Lecture code Post-Lecture Quiz due 6pm on Monday, February 1st. Pointers and How To Use Them We previously discussed that memory boxes can store addresses of other memory boxes, and how an address occupies8 bytes. C provides the ampersand operator to get the address of any variable. In other words, if youhave a variable local , writing local gives you the address of the memory boxes thatstore local . Where are you going to store the address value returned from local Well, if you want to hold on to it,youll want to store it in a variable itself. Where does that variable live It better be in memory, too In otherwords, the 8 bytes corresponding to the address of local will have a memory location of their own.We refer to such memory locations that hold addresses as pointers , because you can think of them asarrows pointing to other memory boxes. In terms of C types, a type followed by an asterisk corresponds to a pointer. For example, int is apointer to an integer. An int itself occupies 8 bytes of memory since it stores an address, and itpoints to the first byte of a 4-byte sequence of memory boxes that store an int . To actually get to the value that a pointer points to, you use the asterisk operator on the pointersee data1ptr-intro.c in the lecture code void f int local 1 int ptr local prints 1 printfvalue of ptr dn, ptr here, we dereference the pointer to get to the value of local prints the address of local, twice printfaddress of local p pn, local, ptr p is a printf format for printing pointers For some people, it helps to think of the asterisk operator as cancelling out the asterisk on the typei.e., int int . Some C programmers like to put the asterisk next to the type int ptr for int -pointer ptr , others put it with the variable name int ptr , because that way its clear that the dereferenced version of ptr is an int . Use whatever notation makes sense for you To change the value behind a pointer, you must dereference it. For example, the following program changesthe value of integer local through the pointer ptr by assigning a value to the dereferencedpointer void f int local 1 int ptr local ptr 42 ------------- derefd pointer value we assign int also a int printfvalue of local is now dn, local prints 42 Pointers are how to use the are very important in this course and in CC programming in general. Well keepcoming back to these concepts. The key things to remember are takes the address of an object andmakes a pointer, dereferences a pointer and follows it to the value it refers to in memory. Types withan asterisk next to them are pointer types. Exploring Data Representation In Memory We already understand how programs are just bytes in memory, but now lets look in more detail at how data is represented in memory. Why are we covering this Were now building an understanding of where the different parts of a CC program and, in fact, programs in otherlanguages too are stored in memory. This will help you understand how a program obtains and manages memory,something that some programming languages e.g., Java, OCaml, Pyret do automatically behind your back, while others,and particularly systems programming languages like C and C, force you as the programmer do some of this memorymanagement. This gives you a great degree of control, and allows avoiding expensive hidden memory allocation andcopying costs. For this, we will use the program mexplore.c . This program declares and defines recall the differencethree variables, all of type char . char is the name for a byte type in the C language itrefers to the fact that a byte is exactly sufficient to store one character according to the ASCII standard, a wayof translating numbers into characters and vice versa. Computers can only store numbers, so all characters in acomputer are actually encoded as numbers. For example, the uppercase letter A in ASCII corresponds tothe number 65 see man ascii for the translation table. Whats ASCII, and do we still use it today In the early days of computers, every computer had its own way of encoding letters as numbers. ASCII, theAmerican Standard Code for Information Interchange, was defined in the 1960s to find a common way of representingtext. Original ASCII uses 7 bits, and can therefore represent 128 distinct characters enough for the alphabet,numbers, and some funky special characters e.g., newlines n , the NUL character 0 ,and bell character that made typewriter bells go off. But even 256 characters arent sufficient to support languages that use non-Latin alphabets, and certainly notfor advanced emoji. So, while all of todays computers still support ASCII, weve mostly moved on to a new standard, Unicode , which supports 1.1 million characters using one to four bytes per character. Fun fact to be backwardscompatible, Unicode is defined such that the original ASCII character encodings remain valid Unicode letters. Whats the difference between these three char variables Lets take a look. The first one, globalch is defined in what we call global scope its at the top level of the file, not insidea function or inside the curly braces that C and C use to delineate scopes in the program. Thisvariable can be referred to from anywhere in the entire program. The second variable, constglobalch is also a global variable, but the const keywordindicates that it is constant and the compiler and OS should not allow modifications to it. Finally, our third variable is inside function f . Its called localch and is a localvariable . Its valid only within the scope of f and other parts of the program such as main cannot refer to it. The hexdump function that f calls is defined in hexdump.c and imported via hexdump.h , a header file. In a future lecture, well talk about why header files exist. hexdumpADDR, N has the effect of printing the contents of N bytes of memory at address ADDR . Were passing our character variables to it, but prefix the variable with an ampersand character, . So hexdumpglobalch, 1 means print 1 byte from a box located at theaddress of globalch . This is an important concept of the C language you can always get the memory address at which an object islocated. The term object here means something different from what it means in an object-oriented languagelike Java rather than an instance of a class, an object according to the C standard is a set of bytes thatcontain a value. This can be code a function or data a variable. In other words, local and ptr in the snippet below refer to the same object, i.e., tothe same bytes of memory void f int local 1 int ptr local Reacll that local means the address of local , and the value stored in the memorylocation where ptr is located is the 8 bytes that make up the address of local . The type of ptr is int , which signifies that it is the address of an integer in memory a short would be the address of a short , a char the address of a char , etc.. You can invert the ampersand operator using the asterisk operator ptr dereferences the pointer and turns the address back into a value. In other words, local is the same as plain, old local . Thee concepts are very, very important youll use them all the time Back to our mexplore.c program though. Lets look at what it prints when we run it note that thespecific addresses will be different on your computer. .mexplore00601038 41 A004009a4 42 B7ffd4977e80f 43 C On the left, we see the addresses of our three variables, printed in hexadecimal notation. Next, just to the rightof that, we see the hexadecimal value of the data stored in the byte at each of these addresses. For example,hexadecimal 41 often written 0x41 for clarity is equal to ... 164 1 65 Not surprisingly, thisequals to the ASCII character A, which we see on the right. But let me draw your attention to the addresses on the left. They vary a fair amount The exact locations of variablesin memory are decided by the compiler and OS together, but the general region where an object lives is determined by its lifetime . Think about how long each of our variables needs to stick around before the memory can be reused The global variables, globalch and constglobalch , need to be around for the entire runtime of the program, as the program could reference them anywhere in the code. This is called a static lifetime . The local variable, localch , needs to stick around until it goes out of scope, which happens when the execution reaches the closing curly brace of f . After its out of scope, no code in the program can refer to the variable, so it is fine to reuse its memory. This is called an automatic lifetime . Local variables and function arguments have automatic lifetimes. But what if a function needs to create an object whose size is not known at the start of the program so it cant beglobal and which also needs to survive beyond the end of the function In this common situation, neither a staticlifetime nor an automatic lifetime are appropriate. Dynamically Allocated Objects What if you have a variable that you create inside a function, but you want to keep it around after the functionreturns For example, what if I want to define a character inside f in mexplore-with-dynamic.c and then print it from main I could make it a global variable, butwhen writing the program, I may not know exactly how many characters Im going to need. For this purpose, the C language allows for a third kind of object lifetime a dynamic lifetime . For anobject with a dynamic lifetime, you as the programmer have to explicitly create and destroy the object that is,you must set aside memory for the object and make sure it is released again when the object is no longer needed. To set aside memory, you use the malloc standard library function m emory alloc ate. malloc takes only one argument, which is the number of bytes youre asking for, and it returns theaddress of the newly allocated memory i.e., the address where the OS has set aside memory boxes for this object.For example, char allocatedch malloc1 reserves 1 byte of memory and stores the address of that bytes memory box in the variable allocatedch .The char in brackets is a cast of the pointer returned to the type we expect a pointer to a char this is needed because malloc itself does not have any idea what kind of objectyoure allocating, so we need to tell the compiler. To actually set the value inside a dynamic lifetime object, we have to dereference the pointer as usual.For example, in our character example in mexplore-with-dynamic.c , we dereference the pointer we got from malloc and put our character D into it by assigning a value to the dereferenced pointer void f ... char allocatedch malloc1 allocatedch D ------------- derefd pointer value we assign char also a char Similarities and differences with Java Calls to malloc may look clunky, but they effectively do the same thing as the new keyword in Java setting aside memory for a new object. Indeed, C actually provides a new keywordthat, under the hood, invokes malloc . One big difference compared to Java, however, is that youreresponsible for cleaning up and returning that memory. Java figures out automatically when an object with a dynamiclifetime is no longer needed, and frees the memory then a process called garbage collection. C andC dont do so, but leave it to the programmer to decide when the time is right to return the memory. The big upside of dynamic-lifetime objects is that we can decide at runtime how big they need to be, and that theycan outlive the function that creates them. Consider a string that takes the characters a user typed into the program a quantity thats hard to predict correctly, and data that we certainly want to outlive the function that readsthe input The big downside of dynamic-lifetime objects is that its the programmers responsibility to free the memoryallocated. You to this by calling the free function with the address of the allocated boxes as anargument. For example, freeallocatedch will free the memory we asked malloc toset aside for allocatedch . Incorrect use of dynamic lifetimes is an immensely common source of problems, bugs, and securityholes in CC programs serious problems like memory leaks, double free, use-after-free, etc. all arise from thislanguage feature. Memory Segments Objects with different lifetimes are grouped into different regions in memory. The program code, global variables, andconstant global variables are all stored in static segments, as these all have static lifetimes and known sizesat compile time. Other objects are come and go, and therefore the memory regions that contain them grow and shrink. For example, asfunctions call each other, they create more and more local variables with automatic lifetimes and as the program calls malloc to reserve memory for objects with dynamic lifetimes, more memory is needed for these objects. If we look at the addresses printed by mexplore , we see that the global variables stored in are atrelatively low memory addresses around 0x600000 hexadecimal and 0x400000 hexadecimal, whilethe local variable is stored at a high address, close to 0x7fffffffffff about 2 47 , andthe dynamically allocated character is stored in between albeit closer to the static segments. There is a reason for this placement it allows both types of segments to grow without risk of getting in each othersway. In particular, the automatic-lifetime segment grows downwards as more local variables come intoscope, while the dynamic-lifetime segment grows upwards . If they ever meet, your computer runs out of memory. The size of the dynamic segment changesas the program asks for memory and frees it up again. Moreover, the used memory in the dynamic segment is not necessarily contiguous . Consider a program that allocates four char s, c1 to c4 andthen frees the third one assuming the char s start at address 0x1a00050 , the memory would appearas below. 0x1a000.. ... 50 ... 51 ... 52 ... 53 - addresses ------------------------------ ... c1 c2 FREE c4 ... - values ------------------------------ The gap between c2 and c4 arises because the memory of c3 has been freed bythe program, but it has not been reused. In other words, the dynamic segment can have holes in it this iscalled fragmentation . Finally, these segments have names The part of the static-lifetime segment that holds program called is called the text segment because it holds program text though the text is in computer language the parts for read-only globals rodata and modifyable globals data and bss also have names. The automatic-lifetime segment is called the stack . Its named so because it grows and shrinks like a stack of paper when you call a function, its automatic-lifetime objects are added to the left of the existing automatic ones, and when the function returns, the program gives their memory up again. The dynamic-lifetime segment is called the heap , and it generally grows upwards in terms of memory addresses. But unlike the stack, it can have holes if the programmer destroyed an object that sits in between two others in memory, there is unused memory in between. You can think of this as air gaps in a heap of things, maybe. The stack and heap terms are important, and you will keep seeing them Java Similarities Note In Java, any object created with the new keyword is allocated with dynamic lifetime and lives on the heap.Java puts only primitive types int , double etc. on the stack.Indeed, Java under the hood uses malloc Yet, it seems likeJava has automatic lifetime for all objects, as you never need to destroy them explicitly This works because your programruns inside the Java virtual machine JVM, which magically injects code that tracks whether each object isstill reachable via an in-scope variable if this reference count goes to zero, the JVM automatically calls free to delete the object. But all this magic is not free in performance terms, as there is code to run tokeep track of objects reference counts. C and C instead opt to do nothing and give maximum control to the programmer,for better or worse. To summarize, the table below lists the memory segments weve learned about, what data they contain, and roughlywhere they are in terms of memory addresses. In the OS part of the course, it will turn out that these memoryaddresses are actually a lie and the OS playing clever tricks on us, but for now lets assume they are the actualmemory addresses. Object declaration C program text Lifetime Segment Example address range runtime location in x86-64 Linux, non-position-independent Constant global Static Code or Text 0x400000 1 2 22 Global Static Data 0x600000 1.5 2 22 Local Automatic Stack 0x7fff448d0000 2 47 2 25 2 22 Anonymous, returned by malloc C new C Dynamic Heap 0x1a00000 8 2 22 Summary Today, we looked at the notion of pointers values storing addresses in C. Then, we discussed more aboutwhere program data lives in memory. We learned about dynamically-allocated memory, which ishugely important for real-world programs that need to keep objects around after the end of a function or create objectswhose size is only known at runtime. We then built an understanding of how a programs memory is split into differentsegments that contain objects with different lifetimes. Youre now in a good place to work on Lab 1, butwell talk more about arrays and pointer arithmetic next time. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-01-31T01:11:17+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 3118, "token_count_estimate": 3834}}, "https://cs.brown.edu/courses/csci0300/2022/c-cpp-primer.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 Safer Systems Programming Lab 9 RPCs SRC Project Software Preservation Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2022 This is not the current iteration of the course Head here for the current offering. CC Language Primers CS 131 teaches you the fundamentals of computer systems, using the C and C programming languages. C and C are the two most widely used systems programming languages in industry today millions of programs including your operating system and the web browser youre using to view this page are written in C and C. C and C are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language its been around since the 1970s But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources USNA Intro to C Programming . This is a brief, detailed guide to the C language syntax, as well as how you use utility functions like printf . You can ignore the bits about C. USNA Pointers, Arrays, and Structures . This explains in detail how the key data structure concepts of the C language work, and how you use them. C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library other parts of the site are a good C reference. The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie also known as KR Prentice Hall PTR, ISBN 0-13-110362-8 is the classic textbook for programming in C. Harvard CS 61s C Patterns explains some handy common tricky that will be useful for your assignments. LinuxOS XBSD man pages Theyre very detailed, but often tell you important details about library functions. Type man 3 libraryfunction to open the man page for libraryfunction e.g., strncpy . C C is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C, it is about systems programming , and we will not use or teach the complex object-oriented features in C and attempt to avoid its most confusing concepts. That said, getting familiar with Cs data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but dont despair It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C Harvard CS 161s C guide succinctly explains the key differences between C and C. It explains some of the C concepts you may encounter in documentation or compiler error messages e.g., constructors, destructors, etc.. C tutorials from LearnCpp.com C tutorial from cplusplus.com C tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C reference from cplusplus.com C reference from cppreference.com As of 2019, cplusplus.coms text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment We thank Eddie Kohler and Harvards CS 61 course for some of the above references, which weve reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-03-16T12:52:15+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 683, "token_count_estimate": 861}}, "https://cs.brown.edu/courses/csci0300/2021/": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Homework 1 Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2021 This is not the current iteration of the course Head here for the current offering. Do you want to understand the magic that makes our computers work CSCI 0300 is your chance to master that magic. Lectures TuesdayThurday, 100-220pm initially various times Location Zoom . Missive Syllabus Schedule Staff Office Hours Infrastructure Piazza Grading server Lecture feedback Lecture code Announcements 20210419 Final Quiz released Due 6pm AoE on Wednesday, April 21. Best of luck Solutions 20210407 Project 6 released 20210402 Lab 8 released 20210326 Project 5 released 20210323 Lab 7 released 20210312 Lab 6 released 20210308 Midterm Quiz released Due 6pm AoE on Thursday, March 11. Best of luck Solutions 20210305 Project 4 released 20210302 Lab 5 released 20210226 Project 3 released 20210223 Lab 4 released 20210212 Project 2 released 20210209 Lab 3 released 20210202 Lab 2 released 20210126 Lab 1 released 20210121 Lab 0 and Project 1 released 20210121 Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 . 20210119 Please read the notes on the CSCI 0300 format for 2021 20210119 Sign up for Piazza Course Summary The goal of CSCI 0300CS 300 is to teach the fundamentals behind the magic of computer systems from the hardware level to the global internet. Well cover the ideas, principles and abstractions that unify computer systems design from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works well look into what happens when a program runs, from the basics to high-level concepts Use industry-strength tools CSCI 0300 teaches you modern CC programming with the tools that professional software engineers use Two programming languages for the price of one learn C and C, two widely-used systems programming languages for high-performance software Real-world inspired projects in CSCI 0300s projects, youll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day Testimonial and Reviews ...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. ... Overall, this interview was one I really wanted to ace and Im really glad it went well - all thanks to CS131. Spring 2020 CSCI 1310 CS131 student. See also the Critical Reviews CSCI 1310 review from Spring 2020 . Prior offerings. This course was previously offered as CSCI 1310 in Spring 2020. Enrollment. CSCI 0300CS 300 is open to anyone who has completed the introductory sequence i.e., CSCI 0160, 0180, or 0190. Course Email cs0300headtaslists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-01-31T01:11:15+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 692, "token_count_estimate": 979}}, "https://cs.brown.edu/courses/csci0300/2023/c-cpp-primer.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Concurrent Store Project 6 Privacy-Compliant KVStore Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Intro to WeensyOS Lab 5 Processes Lab 6 Threads SRC Project Time Machine Section 1 Memory Organization and Pointers Section 2 Debugging, Alignment, and Signed Integers Section 3 Assembly Is Fun Section 4 Virtual Memory and Pagetables Section 5 Pipes and Multithreading Midterm Quiz Final Quiz Resources CC Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2023 This is not the current iteration of the course Head here for the current offering. CC Language Primers CS 300 teaches you the fundamentals of computer systems, using the C and C programming languages. C and C are the two most widely used systems programming languages in industry today millions of programs including your operating system and the web browser youre using to view this page are written in C and C. C and C are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language its been around since the 1970s But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources The CS 300 TAs C Primer is a concise overview of C language syntax and features, as well as helpful debugging tips, and comes in three parts Part 1 , Part 2 , and Part 3 . Make sure to check this out first, since its tailored towards the course C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library other parts of the site are a good C reference. The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie also known as KR Prentice Hall PTR, ISBN 0-13-110362-8 is the classic textbook for programming in C. Harvard CS 61s C Patterns explains some handy common tricky that will be useful for your assignments. LinuxOS XBSD man pages Theyre very detailed, but often tell you important details about library functions. Type man 3 libraryfunction to open the man page for libraryfunction e.g., strncpy . C C is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C, it is about systems programming , and we will not use or teach the complex object-oriented features in C and attempt to avoid its most confusing concepts. That said, getting familiar with Cs data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but dont despair It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C Harvard CS 161s C guide succinctly explains the key differences between C and C. It explains some of the C concepts you may encounter in documentation or compiler error messages e.g., constructors, destructors, etc.. C tutorials from LearnCpp.com C tutorial from cplusplus.com C tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C reference from cplusplus.com C reference from cppreference.com As of 2019, cplusplus.coms text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment We thank Eddie Kohler and Harvards CS 61 course for some of the above references, which weve reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2024-01-05T00:02:26+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 693, "token_count_estimate": 879}}, "https://cs.brown.edu/courses/csci0300/2022/": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Vunmo Project 6 Distributed Store Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 Safer Systems Programming Lab 9 RPCs SRC Project Software Preservation Midterm Quiz Final Quiz Resources CC Primers Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2022 This is not the current iteration of the course Head here for the current offering. Do you want to understand the magic that makes our computers work CSCI 0300 is your chance to master that magic. Lectures MondayWednesday, 300-420pm Location Barus Holley 166 . Missive Syllabus Schedule Staff Office Hours Infrastructure EdStem Grading server Lecture feedback Lecture code Announcements 20220520 Final Quiz solutions released 20220427 Project 6 released 20220426 Lab 9 released 20220421 Lab 8 released 20220415 Project 5 released 20220412 Lab 7 released 20220405 Lab 6 released 20220329 Midterm Quiz solutions released 20220321 SRC Project released 20220320 Project 4 released 20220316 Lab 5 released 20220308 Lab 4 released 20220305 Project 3 released 20220218 Project 2 released 20220217 Lab 3 released 20220201 Lab 2 released 20220128 Lab 1 released 20220126 Lab 0 and Project 1 released 20220123 Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 . 20220123 22 Please read the notes on the CSCI 0300 format for 2022 20220123 Join the EdStem Course Summary The goal of CSCI 0300CS 300 is to teach the fundamentals behind the magic of computer systems from the hardware level to the global internet. Well cover the ideas, principles and abstractions that unify computer systems design from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works well look into what happens when a program runs, from the basics to high-level concepts Use industry-strength tools CSCI 0300 teaches you modern CC programming with the tools that professional software engineers use Two programming languages for the price of one learn C and C, two widely-used systems programming languages for high-performance software Real-world inspired projects in CSCI 0300s projects, youll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day Testimonial and Reviews ...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. ... Overall, this interview was one I really wanted to ace and Im really glad it went well - all thanks to CS131. Spring 2020 CSCI 1310 CS131 student. Critical Review Spring 2021 , Spring 2020 as CSCI 1310 . Prior offerings Spring 2021 , Spring 2020 as CSCI 1310 . Enrollment. CSCI 0300CS 300 is open to anyone who has completed the introductory sequence i.e., CSCI 0160, 0180, 0190, or 0200. Course Email cs0300headtaslists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2023-03-16T12:52:15+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 689, "token_count_estimate": 983}}, "https://cs.brown.edu/courses/csci0300/2024/c-cpp-primer.html": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Section 1 Pointers and Strings Section 2 Arrays and Structs Section 4 Assembly and the Stack Section 5 File Operations Resources CC Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Sections Office Hours Spring 2024 CC Language Primers CS 300 teaches you the fundamentals of computer systems, using the C and C programming languages. C and C are the two most widely used systems programming languages in industry today millions of programs including your operating system and the web browser youre using to view this page are written in C and C. C and C are valuable for every software engineer to know. They are powerful, but also dangerous, tools that give you more control over your computer, and more insight into its magic, than almost any other language. C C is an old programming language its been around since the 1970s But despite its simple syntax, it is very powerful and versatile. We will go over the language in lectures, but lectures will move quickly, so additional reference material can be useful. We recommend these resources The CS 300 TAs C Primer is a concise overview of C language syntax and features, as well as helpful debugging tips, and comes in three parts Part 1 , Part 2 , and Part 3 . Make sure to check this out first, since its tailored towards the course C Standard Library Refrence from cplusplus.com . Despite the domain name, this site has excellent documentation for the C standard library other parts of the site are a good C reference. The C Programming Language by Brian W. Kernighan and Dennis M. Ritchie also known as KR Prentice Hall PTR, ISBN 0-13-110362-8 is the classic textbook for programming in C. Harvard CS 61s C Patterns explains some handy common tricky that will be useful for your assignments. LinuxOS XBSD man pages Theyre very detailed, but often tell you important details about library functions. Type man 3 libraryfunction to open the man page for libraryfunction e.g., strncpy . C C is a popular language for low-level systems coding, and unlike C, its predecessor, it comes with an extensive data structure library and high-level abstraction facilities. Though the course uses C, it is about systems programming , and we will not use or teach the complex object-oriented features in C and attempt to avoid its most confusing concepts. That said, getting familiar with Cs data structures and libraries will be useful. You can get this information from free resources on the web. Some web resources are almost overwhelmingly detailed, but dont despair It often works to scroll through reference pages for example code, which can be more concise and clear than the English-language reference material. We recommend the following resources for C Harvard CS 161s C guide succinctly explains the key differences between C and C. It explains some of the C concepts you may encounter in documentation or compiler error messages e.g., constructors, destructors, etc.. C tutorials from LearnCpp.com C tutorial from cplusplus.com C tutorial from w3schools.com LearnCpp.com has an extensive set of tutorials. The cplusplus.com one is a good short tutorial. C reference from cplusplus.com C reference from cppreference.com As of 2019, cplusplus.coms text is more approachable, though its layout is uglier and its technical material slightly out of date. Acknowledgment We thank Eddie Kohler and Harvards CS 61 course for some of the above references, which weve reproduced with permission in modified form here. This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2024-03-07T16:30:36+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 640, "token_count_estimate": 800}}, "https://cs.brown.edu/courses/csci0300/2024/": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Section 1 Pointers and Strings Section 2 Arrays and Structs Section 4 Assembly and the Stack Section 5 File Operations Resources CC Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Sections Office Hours Spring 2024 Do you want to understand the magic that makes our computers work CSCI 0300 is your chance to master that magic. Lectures TuesdayThursday, 100-220pm Location MacMillan 117 . Missive Syllabus Staff Schedule Sections Office Hours EdStem Grading server Lecture feedback Lecture code Announcements 20240302 Project 3 Caching IO released 20240227 Lab 3 released 20240217 Project 2 DMalloc released 20240212 Due to the severe weather, lecture 6 Tuesday, February 13 will take place on Zoom 20240206 Lab 2 released 20240130 Lab 1 released 20240124 Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 . 20240124 Lab 0 and Project 1 Snake released 20240104 24 Please read the notes on the CSCI 0300 format for 2024 20240104 Join the EdStem Course Summary The goal of CSCI 0300CS 300 is to teach the fundamentals behind the magic of computer systems from the hardware level to the global internet. Well cover the ideas, principles and abstractions that unify computer systems design from how your laptop runs multiple programs at the same time, to how companies like Instagram, Airbnb, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works well look into what happens when a program runs, from the basics to high-level concepts Use industry-strength tools CSCI 0300 teaches you modern CC programming with the tools that professional software engineers use Two programming languages for the price of one learn C and C, two widely-used systems programming languages for high-performance software Real-world inspired projects in CSCI 0300s projects, youll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day Testimonial and Reviews ...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. ... Overall, this interview was one I really wanted to ace and Im really glad it went well - all thanks to CS131. Spring 2020 CSCI 1310 CS131 student. Critical Review missing reviews are due to CR Spring 2023 , Spring 2022 , Spring 2021 , Spring 2020 as CSCI 1310 . Prior offerings Spring 2023 , Spring 2022 , Spring 2021 , Spring 2020 as CSCI 1310 . Enrollment. CSCI 0300CS 300 is open to anyone who has completed the introductory sequence i.e., CSCI 0160, 0180, 0190, or 0200. Course Email cs0300headtaslists.cs.brown.edu . Instructors cs300-instructorsbrown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2024-03-07T20:42:08+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 619, "token_count_estimate": 857}}, "https://cs.brown.edu/courses/csci0300/2023/": {"text_content": "CSCI 0300 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Snake Project 2 DMalloc Project 3 Caching IO Project 4 WeensyOS Project 5 Concurrent Store Project 6 Privacy-Compliant KVStore Lab 0 Getting Set Up Lab 1 C Programming, Makefiles Lab 2 Debugging Lab 3 Assembly Lab 4 Intro to WeensyOS Lab 5 Processes Lab 6 Threads SRC Project Time Machine Section 1 Memory Organization and Pointers Section 2 Debugging, Alignment, and Signed Integers Section 3 Assembly Is Fun Section 4 Virtual Memory and Pagetables Section 5 Pipes and Multithreading Midterm Quiz Final Quiz Resources CC Primers Docker Issues Textbooks Syllabus Missive FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems GDB Debugger Guide GDB Debugger FAQ Anonymous feedback Staff Office Hours Spring 2023 This is not the current iteration of the course Head here for the current offering. Do you want to understand the magic that makes our computers work CSCI 0300 is your chance to master that magic. Lectures TuesdayThursday, 100-220pm Location MacMillan 117 . Missive Syllabus Schedule Staff Office Hours Infrastructure EdStem Grading server Lecture feedback Lecture code Announcements 20230530 Final Quiz solutions released Thanks for taking the course 20230415 Project 5B Privacy-Compliant KVStore released 20230420 Lab 6 released 20230418 Project 5A KVStore released 20230412 Midterm Quiz solutions released 20230409 Lab 5 released 20230321 SRC Project Time Machine released 20230321 Project 4 WeensyOS released 20230315 Lab 4 released 20230305 Project 3 Caching IO released 20230301 Lab 3 released 20230218 Project 2 DMalloc released 20230207 Lab 2 released 20230131 Lab 1 released 20230126 Lab 0 and Project 1 Snake released 20230124 Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 . 20230103 23 Please read the notes on the CSCI 0300 format for 2023 20230103 Join the EdStem Course Summary The goal of CSCI 0300CS 300 is to teach the fundamentals behind the magic of computer systems from the hardware level to the global internet. Well cover the ideas, principles and abstractions that unify computer systems design from how your laptop runs multiple programs at the same time, to how companies like Instagram, Airbnb, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. CSCI 0300 highlights Learn how a computer really works well look into what happens when a program runs, from the basics to high-level concepts Use industry-strength tools CSCI 0300 teaches you modern CC programming with the tools that professional software engineers use Two programming languages for the price of one learn C and C, two widely-used systems programming languages for high-performance software Real-world inspired projects in CSCI 0300s projects, youll implement the core of your own operating system, and learn to build scalable infrastructure such as a distributed data store and a multi-threaded server similar to those companies use to run web services you use every day Testimonial and Reviews ...the resources section, the final quiz, the lectures, labs and lecture notes, all have been immensely helpful in my preparation for interviews. Just today in an interview I got asked to explain how virtual memory works and was able to explain it correctly. I was also able to give intuition on why it is necessary. ... Overall, this interview was one I really wanted to ace and Im really glad it went well - all thanks to CS131. Spring 2020 CSCI 1310 CS131 student. Critical Review Spring 2022 , Spring 2021 , Spring 2020 as CSCI 1310 . Prior offerings Spring 2022 , Spring 2021 , Spring 2020 as CSCI 1310 . Enrollment. CSCI 0300CS 300 is open to anyone who has completed the introductory sequence i.e., CSCI 0160, 0180, 0190, or 0200. Course Email cs0300headtaslists.cs.brown.edu . This work is licensed under a Creative Commons Attribution 4.0 International License .", "metadata": {"last_modified": "2024-01-05T00:02:26+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 714, "token_count_estimate": 1017}}, "https://cs.brown.edu/courses/csci0330/": {"text_content": "this link", "metadata": {"last_modified": "2022-09-06T13:06:43+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/courses/csci0931/2015-fall/": {"text_content": "Home Class Materials About CS0931 MissiveSyllabus Staff Resources Calendar Student Projects CSCI 0931, Fall 2015 Daily News Permanent Office Hours Woot Sunday 8-10pm Pran Fishbowl Monday 630-830pm Stewart CIT 267 Wednesday 6-8pm Anna CIT 201 Wednesday 8-10pm Raymond CIT 201 Welcome For prospective students interested in this course, you can read About CSCI0931 for information about prerequisites, workload, and the waitlist. For more information about the syllabus, staff and grading of the course, you can read the Course Missive . CSCI0931 meets Tuesdays and Thursdays 9001020 in Lubrano Room 477 of the CIT map . Youll need a laptop to take this course. If you dont have one, talk with the instructor and well see if we can work out some solution for you. Past editions of the course can be found on the offerings page .", "metadata": {"last_modified": "2015-11-23T23:39:25+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 137, "token_count_estimate": 199}}, "https://cs.brown.edu/courses/csci1010/": {"text_content": "Home Assignments Hours Lectures Documents Staff Welcome to CSCI 1010 This is a core undergraduate computer science course on the foundations of computing. The questions it aims to answer are 1 What is computation 2 What is computable 3 What is computable given our limited resources Well answer these questions and, in the process, explore important concepts such as Turing machines, languages, reductions, and NP-completeness. Welcome to the delicious world of theoretical computer science, and we hope youll join us in exploring it Sincerely, the entre course chefs Announcements Logistics All information related to the class e.g., assignments, grading, collaboration policy, late policy is available in the official class syllabus . Time and Location CSCI 1010 will hold in-person lectures on Tuesdays and Thursdays from 1030AM to 1150AM in room 368 of the CIT. The recorded lectures will be available to everyone via Panopto. EdStem Access the course EdStem page here. Students are responsible for all clarifications and toppings posted on EdStem. Exams Both midterms will be in class exams, with details to be announced. Despite popular demand, there will be no culinary practical. Wellness Resources Check out the advice, resources, and friendly words Brown CS students have put together. Please reach out to the TAs, HTA, or professor at any time with concerns or questions about the course. Were rooting for you from the kitchen", "metadata": {"last_modified": "2023-08-29T19:48:28+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": [], "word_count": 226, "token_count_estimate": 297}}, "https://brown-cs500.github.io": {"text_content": "CS500 Home Lectures Assignments Labs Calendar Staff Welcome to CS500 This is the first-ever offering of CS500 and we are glad you can join us This course will cover the basics of how to design and analyze data structures and algorithms. This course aims to Develop your ability to think algorithmically. What does this even mean The answer will emerge gradually during the course. Ensure that you understand some well-established techniques, algorithms, and methods of analysis. Give you some technical tools to predict for a given computational problem what kind of performance is possible. Hone your ability to reason rigorously about computational problems and algorithms and quantities such as running time. Tweets The largest known prime number . Want to do better The randomized algorithm for testing primality, the Miller-Rabin algorithm mentioned in class on Jan. 29 uses exponentiation modulo the number being tested. We saw an algorithm for exponentiation in class on Jan. 24 exponentiation modulo an integer can be reduced to a integer multiplication and b truncated division. We have discussed a multiplication algorithm that is faster than the grade-school algorithm though there is a faster algorithm so take CS 1570. We are in the process of working out a reduction from truncated division to multiplication. Something to think about how fast would these algorithms have to be for you to be able to beat the record And what is the current computational bottleneck Course Info Useful Links Syllabus EdStem Gradescope Anonymous Feedback HTA Email Pseudocode Guide Github Guide Gradescope Guide Lectures Topic Date Notes AlgebraicArithmetic Operations I 0124 Sorting and Selection I 0126 Sorting and Selection II 0129 Sorting and Selection III AlgebraicArithmetic Operations II 0131 AlgebraicArithmetic Operations III 0202 BigFloat Modulo 0205 Hashing I 0207 Hashing II 0209 Hashing III 0212 Priority QueuesHeaps I 0214 Heaps 0216 Binary Search Trees I 0221 Binary Search Trees II 0223 Binary Search Trees III 0226 Graph Search I Components, Topological Sort 0228 Graph Search II Components, Topological Sort 0301 Topological Sorting and Satisfiability 0304 Satisfiability 0306 Single Source Shortest Paths I 0308 Single Source Shortest Paths II 0311 Dynamic Programming I 0313 Dynamic Programming II 0315 Dynamic Programming III 0318 Dynamic Programming IV 0320 Midterm I 0322 Finite Automata I 0401 Finite Automata II 0403 Finite Automata III 0405 Turing Machines I 0408 Turing Machines II 0410 Turing Machines III 0412 Cook-Levin Theorem I 0415 Cook-Levin Theorem II 0417 Cook-Levin Theorem III 0419 NP Reductions I 0422 NP Reductions II 0424 NP Reductions III 0426 Coping with NP-Hardness I 0429 Coping with NP-Hardness II 0501 Assignments Assignment Out In Handout Solution Getting Started 126 129 AlgebraicArithmetic Algorithms and Selection 22 210 Sorting, Division, and Primality Testing 214 221 Hashing and Heaps 228 36 Data Structure Design, Reductions, and Shortest Paths 311 318 Labs Lab Out Due Handout Sorting 130 21 BigPrime 26 29 Hashing 213 215 Heaps 220 222 BST 227 229 Treaps 35 37 Single Source Shortest Path 312 314 Calendar Staff Philip Klein Professor pklein Hammad Izhar HTA hizhar Robert Scheidegger UTA rscheide Ethan Williams UTA ewilli51 Derek Yang UTA dvyang", "metadata": {"last_modified": "2024-03-12T17:35:31+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Welcome to CS500!", "Tweets", "Course Info", "Useful Links", "Lectures", "Assignments", "Labs", "Calendar", "Staff"], "word_count": 514, "token_count_estimate": 752}}, "https://cs.brown.edu/courses/csci1270/": {"text_content": "Check out the previous iteration of the course here Fall 2023In Progress Fall 2021 Fall 2020", "metadata": {"last_modified": "2023-07-03T21:11:16+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["Check out the previous iteration of the course here"], "word_count": 16, "token_count_estimate": 23}}, "https://cs.brown.edu/courses/csci1270/website_2020/": {"text_content": "Toggle navigation CS127 Home Assignments TA Hours Lectures Documents Staff CS127 Database Management Systems Welcome to CSCI1270 The concepts you will learn in this class include aspects of database design, database languages, and database-system implementation. The course textbook is Database Systems Concepts, Sixth Edition by Silberschatz, Korth, and Sudarshan. ISBN 0073523321. The course is every Tuesday and Thursday, 230-350 Online . The first class is on Thursday, September 10th . Please stop on by Lectures will be held at this zoom link Announcements Waitlist If you were unable to register on Banner due to the enrollment cap but are still interested in taking the course, please fill out this form . Collaboration Policy This year we will be collecting collaboration policies electronically. Please use this link to carefully read the policy and sign to indicate your agreement to abide by the policy. You will not receive any credit for any assignments until we have your signature on file. A copy will be made available on our course page for future reference. Anonymous Feedback Find the form here . Quizzes The quizzes locations, times and dates will be announced. Piazza Access the course Piazza page here . Querying the Textbook Use a small app we built to query the textbook databases here . CSCI1270 Fall 2020 Prof. Stan Zdonik cs1270tascs.brown.edu", "metadata": {"last_modified": "2020-09-22T18:19:20+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["CS127", "Database Management Systems"], "word_count": 219, "token_count_estimate": 282}}, "https://browncs1260.github.io/": {"text_content": "CSCI 1260 Assignments Lectures Calendar Resources Staff CSCI 1260 Assignments Lectures Calendar Resources Staff CSCI 1260 Compilers and Program Analysis Fall 2023 Introduction Welcome to CSCI 1260 at Brown University Have you ever wondered why C programs seem to run faster than Python programs Have you ever been confused by an error message and wondered why Java couldnt understand your program In CSCI 1260, well learn how compilers read in code in one language and produce code in another in particular, well learn how to translate high-level languages to code that your computers processor can understand. We will get hands-on practice developing compilers for a series of increasingly complex languages. Along the way, well learn some general best practices for developing and testing complex software systems. Lectures take place every Monday and Wednesday from 930 - 1050 AM in CIT 241 . All course lectures will be recorded and livestreamed on Panopto . Assignments Homework Out In 0. OCaml Warmup Sep. 6 Sep. 13 1. S-expressions Sep. 13 Sep. 20 2. Characters Sep. 20 Sep. 27 3. DMAOC div, mul, and, or, case Sep. 27 Oct. 11 4. Error handling and the heap Oct. 11 Oct. 18 5. Fun with files Oct. 18 Nov. 1 2 6. Apply, variadic functions Nov. 1 Nov. 15 7. MiniML Nov. 15 Nov. 29 8. Optimizations Nov. 28 Dec. 17 benchmarks Dec 9 Lab Handout Github Classroom Compiler Infrastructure Handout Github Classroom Debugging Assembly Handout Github Classroom Parser Generators Handout Github Classroom Drill Out In Drill 1 Solutions Sep. 6 Sep. 10 Drill 2 Solutions Sep. 13 Sep. 17 Drill 3 Solutions Sep. 20 Sep. 24 Drill 4 Solutions Sep. 28 Oct. 1 Drill 5 Solutions Oct. 11 Oct. 15 Drill 6 Solutions Nov. 1 Nov. 5 Drill 7 Solutions Nov. 8 Nov. 12 Drill 9 Solutions Dec. 4 Dec 11 Exam Date Midterm Oct. 25 Final Dec. 13 Lectures Lectures take place every Monday and Wednesday from 930 - 1050 AM in CIT 241 . The lecture notes will be updated after every class. Streams and recordings will show up in our Panopto folder and are linked here. Lecture topics for future dates are very tentative. Date Topic Recording September 06 What is a compiler Recording Last years recording with audio September 11 OCaml intro S-Expressions Recording September 13 Unary operations Recording September 18 Booleans Recording September 20 More booleans, conditionals Recording September 25 Binary operations Recording September 27 Abstract syntax trees Recording October 02 Naming expression with let Recording October 04 Pairs and the heap Recording October 09 NO CLASS October 11 Handling errrors Recording October 16 Debugging assembly Recording October 18 Interacting with the environment Recording October 23 Output and functions Recording October 25 MIDTERM EXAM in class October 30 More on functions Recording November 01 Tail calls Recording November 06 Function pointers first-class and anonymous functions Recording November 08 Lambda lifting and closures Recording November 13 More on parsing Recording November 15 Guest lecture Keith Adams on HHVM Recording November 20 Optimization intro -- constant folding Recording November 22 NO CLASS November 27 Inlining, CSE Recording November 29 IRs and register allocation Recording December 04 Trust and verification Recording December 06 NO CLASS December 13 FINAL EXAM in person Calendar Zoom links are included in the Google Calendar event, as well as in the Hours Queue. Resources Quick Links Syllabus Software Guide Environment Setup Guide x86-64 reference Compiler from lectures EdStem Panopto Anonymous Feedback Form Extension Request Form Reference Labs Contact robertlewisbrown.edu cs1260headtaslists.brown.edu cs1260taslists.brown.edu Staff Robert Lewis Professor rlewis13 Call me Rob Im half computer scientist, half mathematician, and fully excited to learn about compilers with you all this semester. Pronouns hehimhis Jiahua Chen HTA jchen345 Hi Im a senior from HK and Shanghai studying Math CS Talk to me about art, photography, or board games Pronouns hehimhis Yutong Li UTA yli195 Just call me Yuu Im a masters student studying CS, and I used to be a ling major. I love strolling around while listening to J-popVocaloidPost-rock. Parker Simon UTA psimon2 Hi everyone Im a senior from Massachusetts studying Geology and Computer Science. I love climbing, hiking and skiing, and a good bowl of mac and cheese. Linus Sun UTA lsun23 Hi Im from Vancouver and I enjoy climbing, mixology, and keyboards Pronouns hehimhis Nora Tang UTA jtang82 Hello My name is Nora. Tizzy Ks is my favorite spot in Providence. Pronouns sheherhers Conrad Zimmerman UTA czimmer Hi I study math, play Pokemon Go, and sometimes run. In no particular order, I love coffee, programming languages, cute little dogs, and first order logic. Pronouns sheherhers Etha Hua UTA thua5 Hi I am a first-year masters student. Before coming to Brown, I studied CS and philosophy at Tufts. I enjoy street photography, 20th-century films, and the mechanical interpretability of language models. Pronouns hehimhis Xinrui Zhou UTA xzhou81 Hi Im a masters student studying CS. Im from Chengdu, China, the home to adorable pandas and some of the best hot pot youll ever taste. I love reading, cooking, listening to RB and kpop. Pronouns sheherhers Vipul Sharma UTA vsharm44 Hello Im a first-year masters student from India. I love trying out new recipes, modern classical music and phonk. Pronouns hehimhis Copyright 2023 CSCI 1260 Brown", "metadata": {"last_modified": "2023-12-13T01:11:59+00:00", "scraped_at": "2024-03-13T22:15:21+00:00", "headings": ["CSCI 1260", "Compilers and Program Analysis", "Fall 2023", "Introduction", "Welcome to CSCI 1260 at Brown University!", "Assignments", "Lectures", "Calendar", "Resources", "Quick Links", "Reference Labs", "Contact", "Staff", "Robert Lewis \ud83e\udd99", "Jiahua Chen \ud83c\udf35", "Yutong Li \ud83c\udf66", "Parker Simon \ud83e\udd96", "Linus Sun \ud83e\udd20", "Nora Tang \ud83d\udc28", "Conrad Zimmerman \ud83c\udfc3\u200d\u2640\ufe0f", "Etha Hua \ud83d\udc18", "Xinrui Zhou \ud83d\udc30", "Vipul Sharma \ud83d\udef6"], "word_count": 874, "token_count_estimate": 1260}}, "https://cs.brown.edu/courses/csci1290/asgn/final/": {"text_content": "Final Project Final Project Due Date 1159pm on Thursday, Dec 20th, 2011 Brief Handin final cs129handin final Required files README, code, html, htmlindex.html Proposal Requirements This year there is no formal requirement for you to propose a final project topic. If you are uncertain about the topic and scope of your project, you are encouraged to speak with or email the TAs and professor. Final Project Requirements You are required to choose a topic and implement a project based on it. A good way to start is by looking at published graphics and vision papers. You can also look at final projects from previous years in this course and similar courses linked from the course webpage e.g. 2011 , 2010 . If your topic is based on a particularly complex paper, you may only want to implement portions of it or a simpler version of the algorithm. On the flipside, if you want to expand upon an assignment you already did, youll need to make extensive improvements. Final Project Presentation You are required to make a web page for your project, as you have for the previous projects, but your write-up needs to be more extensive. You will use your web page to present your final project to the entire class during the final exam period on December 21st. Your presentation can be from 2 to 4 minutes . You will lose points if you present more than 4 minutes. Practice your talk . During this brief presentation, you should explain to the class what your project goal is, explain the algorithm in as much detail as time permits, and show a few results. Your web page should have the visualizations, diagrams, and results you need for this brief overview. Extra Credit Theres no real extra credit since you are defining the specifications of your project. So basically, do more work and youll definitely get an A. Graduate Credit Just like extra credit, except you are expected to do more work than other students. We realize this is very open-ended, so if youre not sure if youre doing enough work for graduate credit, ask us. Handing in This is very important as you will lose points if you do not follow instructions. Every time after the first that you do not follow instructions, you will lose 5 points. The folder you hand in must contain the following README - text file containing anything about the project that you want to tell the TAs code - directory containing all your code for this assignment html - directory containing all your html report for this assignment including images htmlindex.html - home page for your results Then run cs129handin final If it is not in your path, you can run it directly coursecs129bincs129handin final Rubric 70 pts Final Project 20 pts Write-up 10 pts Presentation -5n pts Lose 5 points for every time after the first you do not follow the instructions for the hand in format Good Luck", "metadata": {"last_modified": "2012-11-30T15:45:23+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Final Project", "Brief", "Proposal Requirements", "Final Project Requirements", "Final Project Presentation", "Extra Credit", "Graduate Credit", "Handing in", "Rubric", "Good Luck!"], "word_count": 496, "token_count_estimate": 591}}, "https://cs1230.graphics": {"text_content": "Home Docs Lectures Labs Projects Welcome to CS 1230 Calendar Staff Welcome to CS 1230 Welcome to CS 1230, the longest-running computer graphics course in the known universe This course offers an in-depth exploration of fundamental concepts in 2D and 3D computer graphics. It introduces 2D raster graphics techniques image creationmanipulationfiltering, as well as 3D modeling, viewing, and rendering using both raytracing and real-time rendering on the GPU. Along the way, youll learn to program in C and the shading language GLSL, and learn to use the OpenGL library. The course culminates in an open-ended group final project in which you and your teammates use the skills youve learned throughout the semester to make some cool visual effects. Check out the course missive for more information on prerequisites, assignments, workload, etc. Calendar Tip Use the dropdown at the top right of the Google Calendar embed to filter by event type Google Calendar and iCalendar subscription links For Google Calendar While logged in to your Google account, click on the links below to add them to your Google Calendar. For iCalendar Secondary-click on the links below and select Copy Link Address to copy the link to your clipboard. Then, follow the instructions for your calendar app to add a calendar subscription using the link. Do not download and import the .ics files directly, as they will not update if the calendar changes. Name Google Calendar iCalendar Description Assignments Link Link Contains project and lab timelines. Ed Hours Link Link Contains Ed hours. Hours Link Link Contains TA hours and Daniels office hours. Lectures Link Link Contains lectures and other events held during lecture. Mentor Meetings Link Link Contains Mentor Meeting slots. Staff CS 1230 was built by the following lovely people Daniel Ritchie Professor dritchi1 hehim Has an Erds number of 4, a Bacon number of 3, and debatably an Erds-Bacon number of 7. Dylan Hu HTA dhu24 hehim Is a senior from Massachusetts. Between perms. Wants to dye his hair orange. Enjoys grapefruit. William Sun HTA wsun28 hehim Is a concurrent masters student in Computer Science. Enjoys anime, memes, the Japanese language, memes, the violin, and memes. Orion Bloomfield TA obloomfi hehim Enjoys Norwalk, Connecticut but has never been. Sings in acapella. Afraid of cryptic crosswords. Jared Cambier TA jcambier hehim Im a senior from Kansas City. In my free time, I like playing bullet chess and video games Stardew Valley recently. I also enjoy listening to jazz. Jamie Chen TA achen309 hehim Is a second-yr master student in CS from Shenzhen. Loves everything glowy and volumetric . Tomas Dougan TA tdougan1 hehim Hello Im a junior from Athens, GA. Im interested in compilers, graphics, math, and hardware. I also like rock climbing, drawing, and TV My favorite programming language is C. Austin Funk TA afunk3 hehim Is a junior from Charlottesville, VA shoutout to my fellow TA, Stewart. Enjoys playing saxophone, feeding goats grass from the ground, and reading fantasy books Kazen Gallman TA kgallman hehim Hello Im a senior from RI studying CS and Cog Neuro, in my free time im probably playing video games, reading manga, playing volleyball, or sleeping, but I also like to make really bad websites D Helen Huang TA hhuang65 sheher Is a senior from Massachusetts. Favorite uses of graphics art and video games. Mehek Jethani TA mjethani sheher Is a senior from NJ studying CS. Favorite use of graphics movie VFX. Stewart Morris TA smorri21 hehim Is a junior from Charlottesville, VA shoutout to my fellow TA, Austin. Enjoys playing guitar, watching movies, and going for the occasional hike Sebastian Park TA spark265 hehim Hi. Im a junior from Massachusetts who likes talking and jazz and making sound with his mouth. Favorite use of graphics The Lego Movie. Anh Truong TA dtruong7 hehim Really enjoys playing the piano and seeing real, unharmed bunnies. Nick Vadasz TA nvadasz hehim is a senior from Texas studying CS. Ruminates to shoegaze. Enjoyer of brutalist web design. Loves cold pasta. Fan of the color blue. Smriti Vaidyanathan TA svaidya4 sheher Senior from the San Francisco Bay Area. Enjoys singing, cooking, molecular biology, and gymming. Krishi Saripalli Dev TA ksaripal hehim Im a senior from the San Francisco Bay Area and a fake TA for this course. I like interactive graphics software, like Spline, and making things with bloom .", "metadata": {"last_modified": "2023-12-15T04:23:53+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 723, "token_count_estimate": 991}}, "https://cs.brown.edu/courses/csci1310/2020/assign/labs/assets/Vagrantfile": {"text_content": "-- mode ruby -- vi set ftruby CS131 Development VM Feel free to modify this file to best work with your machine. For documentation, please see the comments here or go to httpsdocs.vagrantup.com for more information. All Vagrant configuration is done below. The 2 in Vagrant.configure configures the configuration version we support older styles for backwards compatibility. Please dont change it unless you know what youre doing.Vagrant.configure2 do config The most common configuration options are documented and commented below. For a complete reference, please see the online documentation at httpsdocs.vagrantup.com. Every Vagrant development environment requires a box. You can search for boxes at httpsvagrantcloud.comsearch. config.vm.box ubuntubionic64 Disable automatic box update checking. If you disable this, then boxes will only be checked for updates when the user runs vagrant box outdated. This is not recommended. config.vm.boxcheckupdate false Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine. In the example below, accessing localhost8080 will access port 80 on the guest machine. NOTE This will enable public access to the opened port config.vm.network forwardedport, guest 80, host 8080 Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine and only allow access via 127.0.0.1 to disable public access config.vm.network forwardedport, guest 80, host 8080, hostip 127.0.0.1 Create a private network, which allows host-only access to the machine using a specific IP. config.vm.network privatenetwork, ip 192.168.55.10 Create a public network, which generally matched to bridged network. Bridged networks make the machine appear as another physical device on your network. config.vm.network publicnetwork config.ssh.forwardagent true config.ssh.forwardx11 true Share an additional folder to the guest VM. The first argument is the path on the host to the actual folder. The second argument is the path on the guest to mount the folder. And the optional third argument is a set of non-required options. config.vm.syncedfolder .gosrc, homevagrantgosrc Provider-specific configuration so you can fine-tune various backing providers for Vagrant. These expose provider-specific options. Example for VirtualBox config.vm.provider virtualbox do vb Display the VirtualBox GUI when booting the machine vb.gui true Customize the amount of memory on the VM vb.memory 1024 end View the documentation for the provider you are using for more information on available options. Enable provisioning with a shell script. Additional provisioners such as Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the documentation for more information about their specific syntax and use. config.vm.provision shell, inline -SHELL rm -fv etcsshsshhost dpkg-reconfigure openssh-server apt-get update SHELLend", "metadata": {"last_modified": "2020-01-22T22:20:04+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 426, "token_count_estimate": 610}}, "https://browncsci1290.github.io/webpage/": {"text_content": "This website requires JavaScript to function.", "metadata": {"last_modified": "2024-01-11T01:02:19+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["This website requires JavaScript to function."], "word_count": 6, "token_count_estimate": 7}}, "https://cs.brown.edu/courses/csci1310/2020/notes/l02.html": {"text_content": "CS 131 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 WeensyOS Project 4 Vunmo Project 5 Distributed Store Lab 0 Getting Set Up Lab 1 C Programs Lab 2 Building Programs Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Final Quiz Resources COVID-19 virtualizing CS131 CC Primers Textbooks Course outline Why take CS131 FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 Lecture 2 Systems Programming Lecture video Brown ID required Lecture code Post-Lecture Quiz due 6pm Wednesday, January 29. Context The CS131 Journey After the first lecture, you may have wondered why understanding the details of how your computer works is so crucial.How does this understanding affect your goals, such as becoming a software engineer in industry or an academic computerscience researcher The answer is, beyond a natural thirst for knowledge, that this kind of understanding will make you amuch better, more versatile, and more valuable computer scientist and engineer. Some reasons why systems programming and understanding the machine matters There are billions of lines of C and C code in the world. If you work as a software engineer, you will sooner or later have to deal with these languages. For example, operating systems, web browsers, machine learning toolkits like TensorFlow and PyTorch, and high-performance infrastructure used by companies like Facebook and Google are written in C. Many companies yearn to hire engineers who know these languages The concepts were learning here are fundamental and ultimately impact how other languages work. Even if youre programming in Go or Java, you will understand these languages a lot better if you know the underlying infrastructure. When you work with concurrent and distributed systems which most moderately complex applications we use today, including nearly all applications on your phone, are, mysterious bugs and seemingly impossible behavior will make a lot more sense and be easier to debug if you know how the computer actually executes these programs. So, what will you learn throughout this course Heres an overview. You will learn the C and C programming languages , and youll be able to use standard debugging tools gdb, address sanitizers, build systems, and performance profilers that are widely-used in industry . You will write a crucial part of your own operating system , and youll see it safely run multiple programs side by side. You will implement the server-side backend of a high-throughput micropayment application , learning how to handle many user requests in parallel without accidentally corrupting someones balance. The concepts you learn are the core of every database and web application we use today. Finally, you will implement a scalable distributed storage system, similar to systems used at Google and make it react to changes in incoming request load by adapting itself Interpreting Bytes In Memory Why are we covering this The only place where a computer can store information is memory. Its up to the systems software and the programs that thecomputer runs to decide what these bytes actually mean . They could be program code, data integers, strings,images, etc., or meta-data used to build more complex data structures from simple memory boxes. Understandinghow complex programs boil down to bytes will help you debug your program, and will make you appreciate why they behave theway they do. Lets recap the final example from last lecture. We used bytes from the course logo image file to add numbers, and otherbytes to print messages to the terminal. How is that possible At the end of this section, youll understand how. We will build this up from first principles. Start with add.c , which is a C program that serves a simplepurpose it reads numbers from the command line and adds them. Lets disect the code, and youll get immersed in the basicstructure of a C program, as well as seeing the crucial add function that well use to explore how programsare just bytes in memory. A Simple C Program C Programming Resources Well go through the basics of C and later C in lectures, but in an immersive way well come acrosslanguage features are we are trying to understand fundamental concepts of systems. Check out our CC Primers if youre looking for step-by-step language tutorials or links todetailed language references. include stdio.h import standard IO fprintf, printfinclude stdlib.h import standard libraryint mainint argc, char argv starting point of our program if argc 2 fprintfstderr, Usage add A Bn Prints A B.n print error message if arguments are missing. n is a newline character exit1 int a strtolargv1, 0, 0 covert first argument string to integer int b strtolargv2, 0, 0 same for second argument printfd d dn, a, b, adda, b invoke add function, print result to console Whats going on here Every C programs execution starts with the main function. This is one of thethings that the C language standard, a long, technical document, prescribes. Our program checks if the user providedenough arguments and prints an error if not otherwise it converts the first two arguments from strings to integersusing strtol a standard library function, calls add on them and returns the results. How do the argc and argv arguments to main get set, and how is main called Your computers operating system OS is responsible for starting up the program, and does some prep. The command lineprogram youre using this is called a shell makes sure to put the argument count argc andargument values in boxes at well-known memory addresses before the OS starts your program. Lets try to compile this program. gcc -o add add.c Theres an error, because we havent actually provided an add function. Lets write one. The program now works, and it adds numbers. Yay But we can also define our add function in another file something that often happens in larger programs. Lets use the add function in addf.c instead.Since the compiler looks at each source file in isolation, we now need to tell it that there is an add functionin some other file, and what arguments it takes. Lets add a line to add.c that specifies the nameand arguments of add , but does not provide an implementation. This is called a declaration were telling the compiler there will be a function called add , and youll find out about itsimplementation later. All functions and variables in C have to be declared when you first use them, but theydo not have to be defined . Well understand the exact difference shortly. Lets try compiling this version of add.c . A different error Why Because we havent told thecompiler to also look at the addf.c file, which actually has our implementation of add .To do that, lets pass two files to the compiler. gcc -o add add.c addf.c It works Great. The compiler first compiles add.c into a file called add.o , and thencompiles addf.c into a file called addf.o . These files dont contain human-readable text,but binary bytes that the computers CPU central processing unit understands to execute. Programs are just bytes We can look at the contents of addf.o using a tool called objdump . objdump -daddf.o prints two things below the add line on the left, the bytes in the file inhexadecimal notation 8d 04 37 c3 , and on the right, a human-readable version of what these bytesmean in computer machine language specifically, in a language called x86-64 assembly, which is thelanguage my laptops Intel processor understands. addf.o file format elf64-x86-64Disassembly of section .text0000000000000000 08d 04 37 lea rdi,rsi,1,eax 3c3 retq bytes in file their human-readable meaning in x86-64 machine language in hexadecimal not stored in the file objdump generated this notation What does the machine language mean We dont know machine language yet, and though we will touch on it briefly later in the course, youll neverneed to memorize it. But to give you an intution, lea means to add integers, and retq tells the processor to return to the calling function. Lets focus on the bytes. When the program runs, these bytes are stored somewhere in memory. The processor,which on its own is just a dumb piece of silicon, then reads these bytes and interprets them as instructions as to what to do next. Now lets change our implementation in addf.c and just store the same bytes directly const unsigned char add 0x8d, 0x04, 0x37, 0xc3 Were no longer writing a function in the C programming language, were just defining an array of bytescalled add . Do you think our add program will still work It turns out it does work Why Because we are manually storing the exact same bytes in memory thatthe compiler generates when compiling our add function into machine instructions. The processor doesntcare that we were storing an array of data there if we tell it to go an execute these bytes, the dumb silicongoes and does as its told Now we can figure out how we could add numbers using the course logo our crucial bytes, 8d 04 37 c3 occur inside the JPEG file of the course logo. If we just tell the processor to look in the rightplace, it can execute these bytes. To do that, I use the addin.c program, which asks the operatingsystem to load the file specified in its first argument into memory, and then tells the processor to look forbytes to execute at the offset specified as the second argument. If we put the right offset 10302 decimal, the processor executes 8d 04 37 c3 and adds numbers The image decoder, meanwhile, justinterprets these bytes which I changed manually as data and turns them into slightly discolouredpixels. What about the party emoji code That secret was revealed in the lecture - Exploring Data Representation In Memory Now that we understand how programs are just bytes in memory, lets look in more detail at how data isrepresented in memory. Why are we covering this Were now building an understanding of where the different parts of a CC program and, in fact, programs in otherlanguages too are stored in memory. This will help you understand how a program obtains and manages memory,something that some programming languages e.g., Java, OCaml, Pyret do automatically behind your back, while others,and particularly systems programming languages like C and C, force you as the programmer do some of this memorymanagement. This gives you a great degree of control, and allows avoiding expensive hidden memory allocation andcopying costs. For, we will use the program mexplore.c . This program declares and defines recall the differencethree variables, all of type char . char is the name for a byte type in the C language itrefers to the fact that a byte is exactly sufficient to store one character according to the ASCII standard, a wayof translating numbers into characters and vice versa. Computers can only store numbers, so all characters in acomputer are actually encoded as numbers. For example, the uppercase letter A in ASCII corresponds tothe number 65 see man ascii for the translation table. Whats ASCII, and do we still use it today In the early days of computers, every computer had its own way of encoding letters as numbers. ASCII, theAmerican Standard Code for Information Interchange, was defined in the 1960s to find a common way of representingtext. Original ASCII uses 7 bits, and can therefore represent 128 distinct characters enough for the alphabet,numbers, and some funky special characters e.g., newlines n , the NUL character 0 ,and bell character that made typewriter bells go off. But even 256 characters arent sufficient to support languages that use non-Latin alphabets, and certainly notfor advanced emoji. So, while all of todays computers still support ASCII, weve mostly moved on to a new standard, Unicode , which supports 1.1 million characters using one to four bytes per character. Fun fact to be backwardscompatible, Unicode is defined such that the original ASCII character encodings remain valid Unicode letters. Whats the difference between these three char variables Lets take a look. The first one, globalch is defined in what we call global scope its at the top level of the file, not insidea function or inside the curly braces that C and C use to delineate scopes in the program. Thisvariable can be referred to from anywhere in the entire program. The second variable, constglobalch is also a global variable, but the const keywordindicates that it is constant and the compiler and OS should not allow modifications to it. Finally, our third variable is inside function f . Its called localch and is a localvariable . Its valid only within the scope of f and other parts of the program such as main cannot refer to it. The hexdump function that f calls is defined in hexdump.c and imported via hexdump.h , a header file. In a future lecture, well talk about why header files exist. hexdumpADDR, N has the effect of printing the contents of N bytes of memory at address ADDR . Were passing our character variables to it, but prefix the variable with an ampersand character, . So hexdumpglobalch, 1 means print 1 byte from a box located at theaddress of globalch . This is an important concept of the C language you can always get the memory address at which an object islocated. The term object here means something different from what it means in an object-oriented languagelike Java rather than an instance of a class, an object according to the C standard is a set of bytes thatcontain a value. This can be code a function or data a variable. In other words, local and ptr in the snippet below refer to the same object, i.e., tothe same bytes of memory void f int local 1 int ptr local local means the address of local , and the value stored in the memory locationwhere ptr is located is the 8 bytes that make up the address of local . The type of ptr is int , which signifies that it is the address of an integer in memory a short wouldbe the address of a short , a char the address of a char , etc.. You can invert the ampersand operator using the asterisk operator ptr dereferences the pointer and turns the address back into a value. In other words, local is the same as plain, old local . Thee concepts are very, very important youll use them all the time Back to our mexplore.c program though. Lets look at what it prints when we run it note that thespecific addresses will be different on your computer. .mexplore00601038 41 A004009a4 42 B7ffd4977e80f 43 C On the left, we see the addresses of our three variables, printed in hexadecimal notation. Next, just to the rightof that, we see the hexadecimal value of the data stored in the byte at each of these addresses. For example,hexadecimal 41 often written 0x41 for clarity is equal to ... 164 1 65 Not surprisingly, thisequals to the ASCII character A, which we see on the right. But let me draw your attention to the addresses on the left. They vary a fair amount The exact locations of variablesin memory are decided by the compiler and OS together, but the general region where an object lives is determined by its lifetime . Think about how long each of our variables needs to stick around before the memory can be reused The global variables, globalch and constglobalch , need to be around for the entire runtime of the program, as the program could reference them anywhere in the code. This is called a static lifetime . The local variable, localch , needs to stick around until it goes out of scope, which happens when the execution reaches the closing curly brace of f . After its out of scope, no code in the program can refer to the variable, so it is fine to reuse its memory. This is called an automatic lifetime . Local variables and function arguments have automatic lifetimes. But what if a function needs to create an object whose size is not known at the start of the program so it cant beglobal and which also needs to survive beyond the end of the function In this common situation, neither a staticlifetime nor an automatic lifetime are appropriate. Dynamically Allocated Objects We did not have much time to cover dynamic lifetimes and memory allocation in todays lecture well go over itagain on Thursday. The material below is for reference, in case you want to read ahead. The C language allows for a third kind of object lifetime a dynamic lifetime . For an object with a dynamiclifetime, you as the programmer have to explicitly create and destroy the object that is, you must set asidememory for the object and make sure it is released again when the object is no longer needed. To set aside memory, you use the malloc standard library function m emory alloc ate. malloc takes only one argument, which is the number of bytes youre asking for, and it returns a pointerto the newly allocated memory i.e., the address where the OS has set aside memory boxes for this object. For example, char allocatedch charmalloc1 reserves 1 byte of memory and stores the address of that memory in the variable allocatedch . The char in brackets is a cast of the pointer returned to the type we expect a pointer to a char this is needed because malloc itself does not have any idea what kind of objectyoure allocating, so we need to tell the compiler. Similarities and differences with Java Calls to malloc may look clunky, but they effectively do the same thing as the new keyword in Java setting aside memory for a new object. Indeed, C actually provides a new keywordthat, under the hood, invokes malloc . One big difference compared to Java, however, is that youreresponsible for cleaning up and returning that memory. Java figures out automatically when an object with a dynamiclifetime is no longer needed, and frees the memory then a process called garbage collection. C andC dont do so, but leave it to the programmer to decide when the time is right to return the memory. The big upside of dynamic-lifetime objects is that we can decide at runtime how big they need to be, and that theycan outlive the function that creates them. Consider a string that takes the characters a user typed into the program a quantity thats hard to predict correctly, and data that we certainly want to outlive the function that readsthe input The big downside of dynamic-lifetime objects is that its the programmers responsibility to free the memoryallocated. You to this by calling the free function with the address of the allocated boxes as anargument. For example, freeallocatedch will free the memory we asked malloc toset aside for allocatedch . Incorrect use of dynamic lifetimes is an immensely common source of problems, bugs, and securityholes in CC programs serious problems like memory leaks, double free, use-after-free, etc. all arise from thislanguage feature. Memory Segments Objects with different lifetimes are grouped into different regions in memory. The program code, global variables, andconstant global variables are all stored in static segments, as these all have static lifetimes and known sizesat compile time. Other objects are come and go, and therefore the memory regions that contain them grow and shrink. For example, asfunctions call each other, they create more and more local variables with automatic lifetimes and as the program calls malloc to reserve memory for objects with dynamic lifetimes, more memory is needed for these objects. If we look at the addresses printed by mexplore , we see that the global variables stored in are atrelatively low memory addresses around 0x600000 hexadecimal and 0x400000 hexadecimal, whilethe local variable is stored at a high address, close to 0x7fffffffffff about 2 47 , andthe dynamically allocated character is stored in between albeit closer to the static segments. There is a reason for this placement it allows both types of segments to grow without risk of getting in each othersway. In particular, the automatic-lifetime segment grows downwards as more local variables come intoscope, while the dynamic-lifetime segment grows upwards . If they ever meet, your computer runs out of memory. Finally, these segments have names The part of the static-lifetime segment that holds program called is called the text segment because it holds program text though the text is in computer language the parts for read-only globals rodata and modifyable globals data and bss also have names. The automatic-lifetime segment is called the stack . Its named so because it grows and shrinks like a stack of paper when you call a function, its automatic-lifetime objects are added to the left of the existing automatic ones, and when the function returns, the program gives their memory up again. The dynamic-lifetime segment is called the heap , and it generally grows upwards in terms of memory addresses. But unlike the stack, it can have holes if the programmer destroyed an object that sits in between two others in memory, there is unused memory in between. You can think of this as air gaps in a heap of things, maybe. The stack and heap terms are important, and you will keep seeing them Java Similarities Note In Java, any object created with the new keyword is allocated with dynamic lifetime and lives on the heap.Java puts only primitive types int , double etc. on the stack.Indeed, Java under the hood uses malloc Yet, it seems likeJava has automatic lifetime for all objects, as you never need to destroy them explicitly This works because your programruns inside the Java virtual machine JVM, which magically injects code that tracks whether each object isstill reachable via an in-scope variable if this reference count goes to zero, the JVM automatically calls free to delete the object. But all this magic is not free in performance terms, as there is code to run tokeep track of objects reference counts. C and C instead opt to do nothing and give maximum control to the programmer,for better or worse. Summary Today, weve seen more of a computers memory bytes can be interpreted to represent many different kinds of data. For example,the same bytes can be interpreted as program code or as an images pixels, and a sequence of bytes can represent characters of astring or a large number. Weve also seen why addresses are incredibly important C and C locate data and functions in memoryby their address. We learned some basic C syntax, and built an understanding of how a programs memory is split into differentsegments that contain objects with different lifetimes.We will talk more about dynamic lifetimes, strings, and sequences of objects in memory next time", "metadata": {"last_modified": "2020-05-09T16:00:22+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 3815, "token_count_estimate": 4654}}, "https://cs.brown.edu/courses/csci1310/2020/notes/l07.html": {"text_content": "CS 131 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 WeensyOS Project 4 Vunmo Project 5 Distributed Store Lab 0 Getting Set Up Lab 1 C Programs Lab 2 Building Programs Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Final Quiz Resources COVID-19 virtualizing CS131 CC Primers Textbooks Course outline Why take CS131 FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 Lecture 7 Assembly Language Lecture video Brown ID required Lecture code Post-Lecture Quiz due 6pm Wednesday, February 19. Assembly Language Weve now arrived at the end of our introduction to C programming. The rest of the course will mostly look athigher-level concepts built atop the understanding we have developed. But before the look at higher levels, we willbriefly pull back the covers and see what happens at the level below C to make your programs run. Web sites, Google, Facebook, AirBnB, etc.--- ------------------------------------------- Distributed systems -- block 4 C ------------------------- S Parallel programming -- block 3 ------------------------- 1 C Operating systems -- block 2 3 ------------------------- 1 C programming language -- we discussed this so far ------------------------- Assembly language -- we will briefly cover this--- ------------------------------------------- Hardware chips Now that you understand the C language and memory representations of data, you may wonder about the magichexadecimal bytes that the compiler outputs to make your computers processor do things like adding numbers. How does thecompiler choose these bytes, and what bytes are valid Each computer architecture such as x86-64, which most modern computers use and were considering in this course hasan instruction set specified by the manufacturer. The instruction set, first and foremost, defines what sequencesof bytes trigger specific behavior in the processor e.g., adding numbers, comparing them for equality, or loading datafrom memory. But hexadecimal bytes are hard for humans to read, so the instruction set also comes with a human-readable assembly language that consists of short, mnemonic instructions that correspond directly to a byte encoding i.e.,each of these instructions corresponds to a specific, unique set of hexadecimal bytes. Why are we covering this You will almost certainly never need to write code in assembly language yourself, but it is helpful to haveat least some intuition of how to read it. Being able to read assembly helps you debug weird problems with yourprogram, and can help you understand compiler optimizations betters. Some of the examples we look at will also illustrateto you the tricks used to make computers run our code efficiently. If youre curious to learn more details about assembly, consider taking CSCI 0330, which explains it in more detail andwith more hands-on exercises than well have time for From C code to instructions Lets take a look at how your C program get turned into hexadecimal bytes that can run on your processor. The compiler , which weve discussed a lot already, turns your C program into assembly language. Lots ofcleverness and optimizations. The assembler turns assembly language into a set of bytes in an executable. This a very direct translation. Registers Assembly instructions operate on registers , small pieces of very fast memory inside the processor. To processdata stored in memory, the processor first needs to load it into registers and once it has completed working on thedata in a register, it needs to store it back to memory. Registers are the fastest kind of memory available in the machine. x86-64 has 14 general-purpose registers and severalspecial-purpose registers. The table below lists all basic registers, with special-purpose registers highlighted inyellow. You wont understand all columns yet, but you will soon and can then use this table as a reference we wont askyou to memorize it in detail. Youll notice different naming conventions for subsets of the same register, a side effectof the long history of the x86 architecture the first x86 processor, the 8086 was first released in 1978. Full register name 32-bit bits 031 16-bit bits 015 8-bit low bits 07 8-bit high bits 815 Use in calling convention Callee-saved General-purpose registers rax eax ax al ah Return value accumulator No rbx ebx bx bl bh Yes rcx ecx cx cl ch 4th function argument No rdx edx dx dl dh 3rd function argument No rsi esi si sil 2nd function argument No rdi edi di dil 1st function argument No r8 r8d r8w r8b 5th function argument No r9 r9d r9w r9b 6th function argument No r10 r10d r10w r10b No r11 r11d r11w r11b No r12 r12d r12w r12b Yes r13 r13d r13w r13b Yes r14 r14d r14w r14b Yes r15 r15d r15w r15b Yes Special-purpose registers rsp esp sp spl Stack pointer Yes rbp ebp bp bpl Base pointer general-purpose in some compiler modes Yes rip eip ip Instruction pointer Program counter called pc in GDB rflags eflags flags Flags and condition codes No Note that unlike primary memory RAM which is what we think of when we discuss memory in a CC program registers have no addresses There is no address value that, if cast to a pointer and dereferenced, wouldreturn the contents of the rax register. Registers live in a separate world from the memory, and we needspecial instructions to move data to and from registers and memory. Whenever you see ZZZ in assembly code, this refers to a register named ZZZ . The x86-64registers have confusing names because they evolved over time each register also has multiple names thatrefer to different subsets of its bits. For example rax , one of the general-purpose registers that is,by convention, used to pass return values from functions, is split into the following five names 63 31 15 7 0 -------------------------------------------------------------- --------------------------------------------------------------- ---------------------rax 64 bits8 bytes-------------------- -----eax 32 bits4 bytes---- -ax 16b2B-- --ah----al-- -- 8 bits1 byte each Assembly instructions often have a suffix that indicates what input data size and register width theyreoperating on. For instance, a set of move instructions help load signed and unsigned 8-, 16-, and 32-bitquantities from memory into registers. movzbl , for example, moves an 8-bit quantity a b yte into32-bit register a l ongword e.g., eax with zero extension movslq moves a 32-bitquantity l ongword into a 64-bit register q uadword e.g., rax with sign extension. Whats up with long suddenly meaning 32-bits 4 bytes Because of wonderful history of the x86 architecture, and to confuse you, a long in x86-64 hardwareterms does not refer to the same things as a long integer type in C. Specifically, a x86-64assembly long is 4 bytes, so it corresponds to a C int . The 8-byte long or indeed any pointer typein C uses quad instructions in x86-64 assembly, denoted by a q suffix. Note that what looks like types such as long , short , etc. here merely refers to theregister width used in the instruction. All actual types are removed from the program during compilation thereare no types in assembly for examples, see asm06.s and asm07.s and their correspondingC source files in the lecture code. Instructions There are three basic kinds of assembly instructions Computation These instructions computate on values, typically values stored in registers. Most have zero or one source operands and one sourcedestination operand, with the source operand coming first. For example, the instruction addq rax, rbx performs the computation rbx rbx rax . Data movement These instructions move data between registers and memory so they can move values from one register to another, from memory into a register, and from a register back to memory. Almost all move instructions have one source operand and one destination operand the source operand comes first. For example, movq rax, rbx copies the contents of rax into rbx , so it performs the assignment rbx rax . Control flow Normally the CPU executes instructions in sequence and in the order they appear in the assembly code and, once translated into bytes, the order in memory. Control flow instructions change the next instruction the processor executes something called the instruction pointer, and stored in special register rip . There are unconditional branches the instruction pointer is set to a new value, conditional branches the instruction pointer is set to a new value if a condition is true, and function call and return instructions. Some instructions appear to combine computation and data movement. For example, given the C code int pi ...pi the compiler might generate incl rax rather than movl rax, ebx incl ebxmovl ebx, rax . However, the processor actually divides these complex instructions into tiny, simpler,invisible instructions called microcode , because the simpler instructions can be made to execute faster.The complex incl instruction actually runs in three phases data movement, then computation, then datamovement. This matters when we introduce parallelism. Different assembly syntaxes There are actually multiple ways of writing x86-64 assembly. We use the ATT syntax, which isdistinguished from the Intel syntax by several features, but especially by the use of percent signs forregisters. Sadly, and just to make things more confusing, the Intel syntax puts destination registers before sourceregisters. How to read an assembly file Assembly files and assembly layout in GDB, layout asm can be confusing at first. The importanttricks to reading them are the following Focus only on the instructions that you care about, and initially ignore anything else. Work backwards from the return statement. Heres an example assembly file output from gcc -S testasm.c to consider .file testasm.c .text .globl Z1fiii .type Z1fiii, functionZ1fiii.LFB0 cmpl edx, esi je .L3 movl esi, eax ret.L3 movl edi, eax ret.LFE0 .size Z1fiii, .-Z1fiii .ident GCC Ubuntu 7.4.0-1ubuntu118.04.1 7.4.0 .section .note.GNU-stack,,progbits There are many lines here that are effectively comments. All lines starting with a dot e.g., .file or .ident are of this kind they constitute directives, rather thaninstructions. Some directives tell the assembler what to do, but theyre often unimportant to your understanding.All directive lines that end in a colon, however, are important they constitute labels , which matter forcontrol flow instructions e.g., .L3 . The actual instructions are on the indented lines between the labels. The processor will execute these top tobottom unless its told to continue somewhere other than the next instruction by a control flow instruction e.g., je . A good way to figure out the important parts of the instructions is often to work backwards fromthe ret instructions, which is the functions return point. Why do we work backwards Going forwardis more difficult because it requires understanding what the state of the processors register is when we call thefunction something not explicitly described in the file here. By working backwards from the return, we can oftenfigure out what the function does without knowing its inputs. Sometimes, we are also interested in looking at the assembly in an already-compiled object file i.e.,binary code after the translation from human-readable assembly language to bytes. This is calleddisassembling from executable instructions, and happens when we look at assembly using GDB, objdump -d , or objdump -S . This output looks different from compiler-generated assemblyin disassembled instructions, there are no intermediate labels or directives. This is because the labels anddirectives disappear during the process of generating executable instructions. Heres the disassembly of our function above, coming from an object file e.g. testasm.o And a disassembly of the same function, from an object file0000000000000000 Z1fiii 0 39 d6 cmp edx,esi 2 74 03 je 7 Z1fiii0x7 4 89 f0 mov esi,eax 6 c3 retq 7 89 f8 mov edi,eax 9 c3 retq Everything but the instructions is removed, and the helpful .L3 label has been replaced with anactual address. The function appears to be located at address 0. This is just a placeholder the final address isassigned by the linking process, when a final executable is created. Finally, here is some disassembly from that actual executable 0000000000400517 Z1fiii 400517 39 d6 cmp edx,esi 400519 74 03 je 40051e Z1fiii0x7 40051b 89 f0 mov esi,eax 40051d c3 retq 40051e 89 f8 mov edi,eax 400520 c3 retq The instructions are the same, but the addresses are different. Other compiler flags would generate differentaddresses. Summary Today, we looked at how the computer operates at the level just below C code it executes a sequence of assemblyinstructions, which are small operations that translate into operations of the processors circuits. Assembly is hard towrite, but it is useful to be able to read it somewhat intuitively. We saw that in assembly, there are computation, data movement, and control flow instructions, and that the compileroften produces somewhat unexpected instruction sequences to make things faster. This is part of why we use compilersthey are incredibly smart at distilling our programs down into the fastest possible sequence of instructions. Next time, we will look at how function calls work and how the assembly instructions actually manage the automaticlifetime memory in the stack segment. After that, we will leave the low-level world of assembly and start moving upthe systems stack no pun in intended", "metadata": {"last_modified": "2020-05-09T16:00:23+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 2160, "token_count_estimate": 2924}}, "https://cs.brown.edu/courses/csci1380/s19/board.html": {"text_content": "The LiteMiner Competition CSCI1380 Discussion Refresh LiteMiner How Fast Can You Mine Be a lite miner and a polite miner. Rank Nickname Latest Score seconds Best Score seconds of Submissions Update Time I was born one mornin when the sun didnt shine. I picked up my shovel and I walked to the mine. Johnny Cash in Sixteen Tons CSCI1380 Distributed System Spring 2019 Brown University 2019-02-17 011246", "metadata": {"last_modified": "2023-11-08T16:09:44+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["LiteMiner | How Fast Can You Mine"], "word_count": 67, "token_count_estimate": 96}}, "https://cs.brown.edu/courses/csci1380/s20/board.html": {"text_content": "The LiteMiner Competition CSCI1380 Discussion History Refresh LiteMiner How Fast Can You Mine Be a lite miner and a polite miner. Rank Nickname Latest Score seconds Best Score seconds of Submissions Update Time I was born one mornin when the sun didnt shine. I picked up my shovel and I walked to the mine. Johnny Cash in Sixteen Tons CSCI1380 Distributed System Spring 2019 Brown University 2020-02-25 073706", "metadata": {"last_modified": "2023-11-08T16:07:11+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["LiteMiner | How Fast Can You Mine"], "word_count": 68, "token_count_estimate": 97}}, "https://cs.brown.edu/courses/info/csci1380/": {"text_content": "CSCI1380 Formerly CS138 Distributed Computer Systems Offered this year and most years Spring 2025 Explores the fundamental principles and practice underlying networked information systems, first we cover basic distributed computing mechanisms e.g., naming, replication, security, etc. and enabling middleware technologies. We then discuss how these mechanisms and technologies fit together to realize distributed databases and file systems, web-based and mobile information systems. Instructors Nikos Vasilakis Location TBD Meeting Time TBD Exam Group TBD CRN None", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Information for:", "CSCI1380", "Distributed Computer Systems"], "word_count": 75, "token_count_estimate": 102}}, "https://talie.town/cs1300_spring24/": {"text_content": "You need to enable JavaScript to run this app.", "metadata": {"last_modified": "2024-02-20T02:59:48+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 9, "token_count_estimate": 10}}, "https://cs.brown.edu/courses/csci1370/": {"text_content": "Virtual Reality Design for Science, Fall 2019 Home Calendar Class Description Images Links Previous years 1999 2000 2002 2003 2004 2005 2006 2007 2008 2013 2015 2017 Brown CS Visualization RISD Illustration For those considering the Fall 2019 class, consider the following I suggest reviewing the course website from 2017, especially the calendar page, to see exactly what the class involves. That has all the assignments. The course description in CAB is short, so reviewing this info will make sure that know exactly what you would be doing in taking the course. We will provide overrides after the first assignment is handed in. In the past, we have almost always been able to accommodate everyone what was interested, who made it to the classes, and who completed the first assignment. I cant guarantee that will be the case this year, but it has been for the last 10 years. For registration, please request an override in CAB and also make sure that the class is in your primary cart. Those steps will keep you on the waiting list and also ensure that you get course emails. This course explores the visual and human-computer interaction design processfor scientific applications in immersive virtual reality. It is cross listedat Brown as CSCI1370 and RISD as ILLUS3340 and is co-taught by David Laidlaw from Brown Computer Science, Fritz Drury from RISD Illustration, as well as Stephen Gatesy from Ecology and Evolutionary Biology. Brandon Li is the TA. Computer science students learn how to work effectively with each other aswell as with artists and designers in creating applications targeting BrownsCaves. A Cave is an immersive virtual reality space whose floor and walls arecovered with displays, which we will use to create interactive 3D virtualenvironments. There are currently two Caves on campus that are managed by the Brown Center for Computation and Visualization CCV the YURT, a curved display system with 360-degree field of view located at 180 George St., and its predecessor an 8x8x8 cube display system located at Studio4 of the Granoff Center. Artists and designers learn to interact with scientists in designing andrealizing applications in this new medium. We study the process of design fromseveral perspectives learn about some specific scientific problems studyexisting applications of scientific visualization and virtual reality explorethe medium of the YURT create designs for the scientific applicationscritique, evaluate, realize, and iterate the designs and culminate with ademonstration of final projects. The first class meets Thursday, September 5th at 10am in 180 George St. room 102B. 2019 shoppers, check out the calendar page for many details about what the course will involve.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Virtual Reality Design for Science, Fall 2019"], "word_count": 432, "token_count_estimate": 571}}, "https://cs.brown.edu/courses/csci1380/": {"text_content": "Skip to main content CS1380 Distributed Systems CS1380 Distributed Systems Resources Schedule Semester Schedule Calendar Staff Milestones Milestone 0 Milestone 1 Milestone 2 Milestone 3 Milestone 4 Past Years Spring 2023 Spring 2022 Spring 2021 Spring 2020 Spring 2019 Spring 2018 Spring 2017 Spring 2016 Spring 2015 Spring 2012 Resources Schedule Semester Schedule Calendar Staff Milestones Milestone 0 Milestone 1 Milestone 2 Milestone 3 Milestone 4 Past Years Spring 2023 Spring 2022 Spring 2021 Spring 2020 Spring 2019 Spring 2018 Spring 2017 Spring 2016 Spring 2015 Spring 2012 How are services like Google, Facebook, and Amazon built This hands-on, project-oriented course focuses on the issues encountered in building software systems for data at massive scale. We will study how these services handle massive datasets and billions of requests per day. We will build infrastructure for big-data collection and analysis, at-scale processing and storage, and information extraction in the cloud and at the edge including massive, heavily distributed infrastructure like the one used to run these services in production today. By the end of this course, students will be able to build their own distributed search engine and to deploy and execute it on cloud resources. Time 1030 1150am, Tue Thu gCal Location CIT 368 and Zoom 2024 CS1380 Brown Systems Group Brown University", "metadata": {"last_modified": "2024-02-27T04:03:40+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 213, "token_count_estimate": 306}}, "https://cs.brown.edu/courses/csci1380/s15/": {"text_content": "Attention This is an old version of the CS 138 website. Please click here for the current offering. Latest Announcements 418 PuddleStore is out 321 Raft is out 36 Midterm review Monday, March 16th, 530PM in 368 See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms e.g., naming, replication, security, etc. and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time TuTh 1030-1150 Location CIT 368 Course Staff Well be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs138tascs.brown.edu to e-mail thecourse staff regarding administrative issues. Instructor Name Email Office Hours Tom Doeppner twdcs.brown.edu CIT 405 Mon. 4-5PM, Wed. 3-4PM, Fri. 3-4PM Rodrigo Fonseca rfonsecacs.brown.edu CIT 329 By Appointment Teaching Assistants Name Email Office Office Hours HTA Cody Mello codycs.brown.edu Fishbowl CIT 271 Monday, 7-9 PM Grad TA Jeff Rasley jeffracs.brown.edu Fishbowl CIT 271 Tuesday, 5-7 PM Grad TA Jonathan Mace jcmacecs.brown.edu Fishbowl CIT 271 Wednesday, 10 AM-12 PM Course Policies Collaboration Policy The collaboration policy is available as a handout. You must print, read,and sign the collaboration policy before returning it to a TA so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances e.g. severe illness, death in the family, kidnapping, etc. too heavy of a course load is not sufficient reason for an incomplete. Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of three 3 late days to be used on homework and project assignments free of charge. Students will be penalized by a letter grade on the assignment for each day it is late.", "metadata": {"last_modified": "2023-11-08T16:21:16+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "", "Attention: This is an old version of the CS 138 website. Please click", "for the current offering.", "Latest Announcements", "Overview", "Course Staff", "Course Policies"], "word_count": 348, "token_count_estimate": 530}}, "https://cs.brown.edu/courses/csci1380/s19/": {"text_content": "Latest Announcements 0511 Final Exam at 2pm, May 11 Location 85 Waterman St, 130 0130 Welcome to ICE CREAM SOCIAL Jan 31 Thur, 1930-2100 at Lubrano CIT 477 0129 LiterMiner released See all announcements RSS 2.0 feed Overview CSCI 1380 is an undergraduate course in distributed computer systems. Wewill explore the fundamental principles and practice underlying networkedinformation systems. First we will cover basic distributed computingmechanisms e.g., naming, replication, security, etc. and enabling middlewaretechnologies. We then discuss how these mechanisms and technologies fittogether to realize distributed databases and file systems, web-based andmobile information systems. Prerequisites CSCI 0320, CSCI 0330, or consent of the instructor. Lecture time TuTh 1030-1150 Location 85 Waterman Street 130 Course Staff Well be using Piazza for almost all course-related communication. You can mark questions as privateor public. Private messages are seen by all course staff, see the collaboration policy for guidelinesof how to choose. You can also use cs1380taslists.brown.edu to e-mail thecourse staff regarding administrative issues. For sensitive issues that you wouldnot like to discuss with the entire course staff, you may email the instructorsand head TAs at cs1380headtaslists.brown.edu . Instructor Name Email Office Hours Office Theophilus Benson tabcs.brown.edu CIT 327 Tue 400-500 PM, Wed11-12 PM Teaching Assistants Name Email Office Hours Office HTA Joshua Pattiz jpattizcs.brown.edu Sat 2-4 PM Moonlab CIT 227 HTA Martin Ziyin Ma zma17cs.brown.edu Thur 8-10 PM Moonlab CIT 227 TA Ali Mir am209cs.brown.edu Mon 10 PM -12 AM CIT 201 TA Brian Oppenheim boppenhecs.brown.edu Wed 6-8 PM CIT 269 TA Galadriel Brady gbrady1cs.brown.edu Wed 10 AM - 12 PM CIT 205 TA Kerem Gurbey keremgurbeybrown.edu Fri 11 AM - 1 PM CIT 205 TA Kristen McLean kmclean1cs.brown.edu Wed 4-6 PM CIT 201 TA Tina Lu yuyanglubrown.edu Sun 4-6 PM CIT 201 TA William Riley wriley1cs.brown.edu Sat 1-3 PM Moonlab CIT 227 TA Zhedi Zhang zzhang57cs.brown.edu Tue 8-10 PM Moonlab CIT 227 See calendar for latest updates Course Policies Collaboration Policy The collaboration policy is available as a handout. You must sign the collaboration policy so that youcan receive credit for the assignments. Incomplete Policy Incompletes are granted only under exceptional circumstances e.g. severe illness, death in the family, kidnapping, etc. too heavy of a course load is not sufficient reason for an incomplete. Getting a dean to certify your reason for requesting an incomplete helps, but is not sufficient. Late Policy Students will be allowed a total of four late days to be used on homework and project assignments free of charge, but no more than three late days may be applied to any one assignment. Students will be penalized by a letter grade on the assignment for each day it is late. If you must miss an assignment deadline because of a religious holiday, you may also get an extension without using late days please contact one of the instructors within the first three weeks of the course and fill out the form to declare such conflicts and we will plan accordingly.", "metadata": {"last_modified": "2023-11-08T16:09:39+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "", "Latest Announcements", "Overview", "Course Staff", "Course Policies"], "word_count": 491, "token_count_estimate": 752}}, "https://cs.brown.edu/courses/csci1310/2020/": {"text_content": "CS 131 Fundamentals of Computer Systems Home Schedule Assignments Project 1 Strings Vectors Project 2 DMalloc Project 3 WeensyOS Project 4 Vunmo Project 5 Distributed Store Lab 0 Getting Set Up Lab 1 C Programs Lab 2 Building Programs Lab 3 Assembly Lab 4 Caching Lab 5 Intro to WeensyOS Lab 6 Processes Lab 7 Threads Lab 8 RPCs Final Quiz Resources COVID-19 virtualizing CS131 CC Primers Textbooks Course outline Why take CS131 FAQs Exercises Computer Systems Basics Exercises Operating Systems Exercises Concurrency Exercises Distributed Systems Anonymous feedback Staff Office Hours Spring 2020 Do you want to understand the magic that makes our computers work This is your chance to master that magic. Lectures TuesdayThurday, 100-220pm. Location BARHOL 168 Zoom . Missive Syllabus Schedule Staff Office Hours Infrastructure Piazza Grading server Lecture feedback Lecture code Announcements Due to the university going virtual for the rest of the semester, some CS 131 deadlines and policies have changed . See here for details . Stay safe and healthy everyone 20200409 Final Quiz released. Best of luck Due May 12, noon. 20200425 Project 5 Distributed Store released 20200421 Lab 8 released Now due May 5. 20200414 Lab 7 released 20200410 Project 4 Vunmo released 20200401 Lab 6 released 20200303 Lab 5 released 20200227 Project 3 WeensyOS released 20200225 Lab 4 released 20200219 Lab 3 released 20200214 Project 2 DMalloc released 20200211 Lab 2 released 20200123 Lecture notes, code, and videos will be available from the schedule page . Here are lecture notes for lectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 . 20200123 Lab 0 and Lab 1 , and Project 1 Strings Vectors released 20200122 Sign up for Piazza Logistics Course Summary. The goal of CS 131CSCI 1310 is to teach the fundamentals behind the magic of computer systems from the hardware level to the global internet. Well cover the ideas, principles and abstractions that unify computer systems design from how your laptop runs multiple programs at the same time, to how companies like Instagram, AirBnB, and Google operate large websites, to how easy it is to exploit security vulnerabilities on badly designed systems. This is a great class for students who are interested in learning what systems programming is, how systems work, and why these systems are so critical to modern technology. Enrollment. CS 131CSCI 1310 is open to anyone who has completed the introductory sequence i.e., CS 16, 18, or 19. For students who dont satisfy the registration restrictions on CAB, please request an override code on CAB and include an explanation of your course experience, and well review your request. What does CS 131 count for CS 131CSCI 1310 is a 1000-level course that can count as a related course in the systems pathway of the CS concentration and masters. In addition, CS 131 will satisfy the prerequisites for CSCI 1380 Distributed Systems, CSCI 1270 Databases, CSCI 1650 Software Security and Exploitation, CSCI 1660 Computer Systems Security, CSCI 1730 Programming Languages, CSCI 1951-A Data Science, CSCI 1680 Computer Networks, and CSCI 2390 Privacy-Conscious Computer Systems. Course Email cs1310headtaslists.brown.edu .", "metadata": {"last_modified": "2020-05-09T16:00:19+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 552, "token_count_estimate": 808}}, "https://cs.brown.edu/courses/csci1440/leaderboard/leaderboard.html?game=LemonadeArena": {"text_content": "CS1440 Agent Leaderboard Game Agent Average Score Games", "metadata": {"last_modified": "2021-02-03T16:43:48+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["CS1440 Agent Leaderboard", "Game:"], "word_count": 8, "token_count_estimate": 11}}, "https://csci1410-2023.vercel.app/": {"text_content": "You need to enable JavaScript to run this app.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 9, "token_count_estimate": 10}}, "https://cs.brown.edu/courses/csci1440/": {"text_content": "Toggle navigation Home Lectures Homeworks Labs Staff Calendar Welcome to Algorithmic Game Theory Course Description and Goals This course examines topics in game theory and mechanism design through the lens of computation. Like such a course in an economics department, the focus is the design and analysis of systems utilized by self-interested agents. Students investigate how the potential for strategic agent behavior canshould influence system design, and the ramifications of conflicts of interest between system designers and participating agents. Unlike a traditional economics course, however, emphasis on computational tractability is paramount, so that simplicity may trump other design desiderata. Students will learn to analyze competing designs using the tools of theoretical computer science. They will also use artificial intelligence to build autonomous agents for computational advertising markets, wireless spectrum auctions, automated negotiation, andor prediction markets. There are two primary learning outcomes intended for students taking this course. Students should be able to Reason about the design of multiagent systems taking into account agents incentives, a perspective borrowed from economists, as well as computational performance, the bread and butter of computer scientists. Design and build effective autonomous agents for market domains that again incorporate both strategic and computational considerations. Prerequisites Mathematical maturity and programming experience are necessary for success in this course. The following are specific areas in which basic expertise is assumed, along with suggested courses for acquiring said expertise. Comfort with continuous mathematics e.g., Math 0180, Math 0350, APMA 0350, or APMA 0360. Comfort with probability and statistics e.g., CS 1450, APMA 1650, APMA 1655, or Math 1620. Comfort writing proofs e.g., CS 22, CS 1010, CS 1550, or any 1000-level Math class. Comfort with programming e.g., CS 4, CS 111, CS 15, CS 17, CS 19, or equivalent. Some knowledge of Java and Python is assumed neither language is taught. For students wishing to enroll in the graduate section of this course, CSCI 2440, knowledge of Markov decision processes and linear programming is also assumed. Topics What is game theory What is mechanism design What is auction theory Simple, awesome, and EPIC auctions Bidding strategies for combinatorial auctions Empirical game-theoretic analysis and mechanism design Application domains Computational advertising markets Wireless spectrum markets Automated negotiation Prediction markets Course Format CSCI 14402440 lectures are held on Wednesdays from 3 PM to 530 in CIT 368. Lecture notes are posted on the course web page, as are weekly readings that reinforce the lecture materials. In addition to weekly lectures, there are weekly two-hour lab sessions, which offer students hands-on environments in which to practice the techniques they are taught in lecture. Labs are pair-programmed for their own benefit, students should make a concerted effort to work with multiple partners over the course of the semester. Students are required to register for and attend one lab per week. Penalties are incurred for failure to attend. Multiple lab sections will be offered, with accommodations offered only for students who are impacted by COVID-19. Students will be assigned weekly, written homework exercises, due on Tuesday nights at 1159 PM. To enhance the learning process, we recommend that students collaborate on homeworks, respecting the limits of the collaboration policy. During each class, the TAs will run something akin to section. During these sections, they will lead an interactive discussion of the ongoing and recently-submitted homework exercises. Participating in these discussions is a great way to gain insights into how to complete the weekly homework exercises. The TAs will also lead weekly tutorials at the start of the semester to bring students up to speed on some topics that are not strictly prerequisites, but would be helpful for students to know and love e.g., linear programming, Markov decision processes. The course will culminate in a final project that involves writing as well as programming, and students are assessed along both of these dimensions and others, like creativity. Consistent with all the other assignments in this course, students are invited to work in pairs. Groups will present their final projects to the class during class time during reading week Wednesday, May 1, 3-530 pm. All students are required both to present and be present for their fellow students presentations. The penalty for failing to appear is severe e.g., failing the class. There are no exams in CSCI 14402440. Students are evaluated based on their participation during lecture and in labs, and their performance on weekly written homework exercises, programming assignments, and the final project. This course offers a capstone option. In past years, students who elected this option did twice as much work on the final project as students who did not choose this route. Specifically, they did both final projects instead of choosing one. All students should expect to spend 2.5 hours per week in lecture and 2 hours per week in lab. In addition to these instruction hours, there will be weekly homework exercises 4-8 hours in the undergraduate section, and 6-10 hours in the graduate section, and supplementary readings available online, free-of-charge 1-2 hours. The final project is open-ended, but 40 hours, over the course of 4 weeks, should suffice to produce acceptable work. In sum, students enrolled in the undergraduate graduate section should plan to dedicate approximately 12 14 hours per week to this course, for a total of 180 210 hours over the course of a 15 week semester. Grading Grading rubrics in CSCI 1440 are developed by the professor in conjunction with undergraduate TAs. TAs then grade all assignments. Grade complaints on individual assignments should be addressed to the relevant TA within ten days of grade releases. The professor assigns all final grades and reviews individual assignment grades as necessary e.g., in borderline cases. Course grade complaints can be addressed to the professor. The tentative grading breakdown is as follows Assignment Percentage Participation 10 Labs 20 Homeworks 40 Final Project 30 Late Policy For all assignments unless stated otherwise, students will be granted three free late days, which can be applied, as needed, over the course of the semester to homework assignments, Footnote For homeworks due Tuesday night, late days only apply until 259 PM the next day Wednesday. Homeworks turned in after 259 PM on Wednesday will not be accepted, so that we can freely discuss the solutions in class. and any take-home labs, but not to the final project the final project deadline is a hard deadline late final projects will not be accepted. In the unfortunate circumstance that the three free late days are all used up, late day penalties will apply -10 within 24 hours, and -25 within 48. No assignments will be accepted electronically more than 48 hours beyond their due date. Note, however, that any assignments due the day before, but turned in the day after, a long weekend Presidents Day or spring break are only charged one late day. For assignments that are to be graded interactively meaning students have a set time at which they will be meeting a TA, the following late penalties always apply if the student is late by 10 minutes or less, -10 10 to 20 minutes, -20 more than 20 minutes counts as a no show, for which the penalty is -50. This same penalty schedule applies recursively to rescheduled interactive gradings following a no show. Last-minute email requests to reschedule interactive gradings must be sent to the relevant graders and to the head TAs at least 2 hours prior to the scheduled meeting time to avoid any penalties. For group projects that are graded interactively, if some members show up for the grading session while others do not, the grading will proceed, and those who do not appear will receive a grade of 0 for that portion of the project, while those who appear late will be penalized according to the aforementioned penalty schedule. Extensions may be granted by the professor in extreme circumstances. If you are ill, please visit health services so you can provide a doctors notes when requesting an extension. If you are under any other sort of duress, please seek advice from a dean. Collaboration Policy Students are encouraged to collaborate with their peers in CSCI 14402440. Indeed, all labs are pair programmed, and students may submit homeworks and the final project with a partner as well. When working on homeworks, students may also consult students other than their partner, for example during office hours, but each student or pair of students is always required to 1. write up their solutions to the homework on their own and 2. list the names of all students with whom they discussed the assignment on their submitted work. Unnatural similarities among students submissions will be forwarded to the Dean of the Colleges office for review, to assess whether or not there has been a violation of Browns Academic Code . As for language models like ChatGPT, students can ask them to further explain concepts which they may or may not do correctly, but as expected, students cannot ask language models to solve their homework problems for them. If a student chooses to engage a language model in a homework discussion, a TA-accessible link to the conversation history must be included with the handin. If you have any questions about this policy, please ask the course staff for clarification. Not understanding our policy is not grounds for not abiding by it. Diversity and Inclusion The computer science department is committed to diversity and inclusion, and strives to create a climate conducive to the success of women, students of color, students of any sexual orientation, and any other students who feel marginalized for any reason. If you feel you have been been mistreated by another student, or by a member of the course staff, consider reaching out to one of student advocates on the CS departments Diversity and Inclusion Committee, or to Professor Greenwald or Professor Tamassia the CS department chair. We, the CS department, take all complaints seriously. Accommodations If you feel you have any disabilities that could affect your performance in the course, please contact SEAS , and ask them to contact the course staff. We will support accommodations recommended by SEAS. Harassment Please review Browns Title IX and Gender Equity Policy . If you feel you might be the victim of harassment in this course or any other, you may seek help from any of the resources listed here .", "metadata": {"last_modified": "2024-01-25T18:57:43+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "", "Algorithmic Game Theory"], "word_count": 1725, "token_count_estimate": 2112}}, "https://cs.brown.edu/courses/csci1470/dlday.html": {"text_content": "Home Resources Lectures Assignments Labs Calendar Hours Staff Deep Learning Day When Thursday, December 12 Where Sayles Hall Come see the fantastical final projects produced by the hardworking students of CSCI 14702470 Deep Learning Day is a celebration of their efforts. It is also, by structure, a mini research conference. The day is divided into four Sessions, each of which features multiple projects organized around a small set of themes. Students in CSCI 1470 will present posters during these sessions, and students in CSCI 2470 the graduate-level version of the course will give brief oral presentations. Come to one session, to multiple, or to all---just come Wed love to have you stop by, give feedback, and show your support for the Fall 2019 cohort of Brown deep learners. Schedule oral presentation 900 AM Opening Remarks 915 AM Session 1 Natural Language Processing Identification of duplicate Quora question pairs Stella Xiao, Yaxi Lei, Qiran Gong, Wenhao Yang sarc2seq Translation of Sarcastic Sentences for Improved Sentiment Analysis Accuracy Kathryn Scholl, Yanyan Ren, Michael Coppoli Second Language Acquisition Modeling with Attention Rafael Alberto Sanchez Rodriguez, Nihal Vivekanand Nayak, Juho Choi, Seungchan Kim Five Pages in Five Lines Descriptive Text Summarization with GPT-2 Rashi Dhar, Soma Arunkanti Hota, Matthew McAvoy Quora Insincere Questions Classification Vipul Vinayak Gupta, Esen Erdemgil, Maulik Dang Generating Sarcastic Comments with LSTMs Kat Chai, Natalie Reed, Summer Gerry, Marshall Lerner RNN-based Classical Chinese Poetry Generation with Planning technique Qingyi Lu, Da Huo, Yue Sun Integrating Grammar Tree Structure into the BERT Language Model Shiyi Han, Shunjia Zhu, Yiming Zhang Conversation Generation with Transformer and ConceptNet Jiayang Wu, Haili Chen, Ke Ding, Houyu Zhang OMG Analyzing Sentiments of Tweets Ao Wang, Emily Reed, Yunyun Yao, Pedro Freitas Presidential Tweet Frequency Prediction Harman Suri, Jake Chanan, Anatoly Brevnov, Nikolai Illarionov Predicting Political Party Affiliation of Climate Change Tweets Hannah Haas, Claudia Meyer, Madeline Griswold, Cintia Araujo Fake Identifying fake news in tweets William Patterson, Rinad Salkham, Jaja Sothanaphan HOROSCRAPE - HOROSCOPE GENERATOR...THE DIFFERENCES BEHIND THE SIGNS Alexander Ogilvy, Emma Kofman, Andrew Rickert Online Post Fake News Detector Ariel Rotter-Aboyoun, Daniel Kostovetsky, Julius Sun, Raymond Cao Sentiment Analysis on Amazon Customer Reviews David Promisel, Kristen Mashikian, Daniel Adkins, Kuba Tarlowski Style Transfer of Natural Language Tiger Dingsun, Nadia Lahlaf Deep Loving Hating on Hate Speech Alina Kim, Diana Lee, Daniela Wiepert, Niharika Jhingan Genre is a Spectrum Synoptic Multiple Label Classification Solomon Zitter, Daniel Smits Long Short Term Memory Loss Pun Generation using Neural Networks Shawna Huang, Evan Velasquez Generating Natural Language in the style of The Office via a Neural Machine Translation Context Ruixi Seet, Lisa Yang Comment Classification Venkata Shubhang Kandiraju, Melissa Wang, Sally Zhi, Michael Lincoln Re-implementing Teaching Machines to Read and Comprehend Young Jie Cho, Ragna Agerup, Kento Nambara, Zhengyi Peng Rhyme Time Learning to Generate Rhythmic Verse Ivan Zhao, Sorin Cho, Timothy Wang, Morgann Thain Learning Emotional Intelligence Emotion-Cause Pair Extraction from Text Sophie Yang, Nazem Aldroubi, Daphne Li-Chen, Ang Li Aint Nobody Got Time for That Text Summarization Jason Fischman, Kei Nawa, Seth Wernick Sentiment Analysis of Movie Reviews Yue You, Zhen Zheng T3 Train, Transform, Translate Homer Walke, Sebastien Jean-Pierre, Gabriel Marks, David Cabatingan Constructing Kinship Graphs with RNNs Benjamin Spiegel 1040 AM Break 1050 AM Session 2 Vision and Data Science Weakly Supervised Image Classifier Ahmed Agiza, Marina Hesham Wasfy Neseem Pneumonia Detection from Medical Images Amber Ogata, Huayu Ouyang, Jennifer Nino Tapia Medical Image Segmentation through Pruned Deep Neural Networks Georgios Zerveas, Reza Esfandiarpoor Segmentation of Tumors in Medical Images Angel Suet Yan Cheung, Kyle Cui, Elliot Kang Pneumonia Prediction from Chest X-Ray Images Qian Xiang, Queena Zhang, Tiancan Yu Big Time Rush Predicting Rush Distance for Football Plays Gokul Ajith, Harrison Boyer, Benjamin Decky, Akhil Trehan CNN Based Predictive Maintenance Cong Huang, Hanyan Liu, Xiaodong Zhang Detecting fractures on ankles and predicting the location of fracture. Yuchen Hua, Chengzhao Tu Street Sign Classification Kaiqi Jiang, Christopher Wong, Dominic Ferri Ship Detection In Satellite Images with U-Net Dong Xian Zou, Peng Chen, Zhoutao Lu, Wensi You Bone Abnormality X-ray Classification Nicholas Merchant, Bowen Chen, Adam Pikelny NBA Predictions Using Feature Analysis William Schor, Jacob Begemann, Eric Dellavalle, Greyson Gerhard-Young Phishing in the Deep Detecting Phishing URLs with Deep Learning Elizabeth Wang, Koyena Pal, Cat Nguyen Dinh, Tiffany Ding Deep Climate Nickolas Eisele, Mert Tavukcuoglu, Zhen Zhang An Exploration Into the Classification of Dog Breeds feat. What Dog Breed Are YOU TAs Nicole Cheng, Zachary Mor, Gisele Garcia Night Sight for All Learing to Adjust Exposure in DarkUnderexposed Images Oscar Newman, Isaac Hilton-VanOsdall, Benjamin Gershuny, John Bitar Learning the Dress Code Fashion Style Compatibility Tomi Madarikan, Angel Rodriguez, Delmy Garcia, Hannah Chow You Only Look Once with TensorFlow 2.0 Ziwei Chen, Shixin Liu, Zeyu Ruan, Geng Yang Detecting Lung Cancer fron PET Scans Gerald Wu, Jonathan Lee Real-Time Logo Detection Geo Lee, Suhye Park A CNN to detect malignant skin lesions Jung Ho Gong, Jia-Shu Chen, Isaiah Liu, Elizabeth Dimen Automating food diary entries through images Jessy Ma, Rebecca Zuo, Karlly Feng Why so serious Facial Expression Classification Neil Sehgal, John Paul Champa, Andrew Wei, Zhe Chang Forecasting hotel reservations with LSTM based RNNs Diane Mutako, Litian Yang, Dinithi Silva Sassaman Deep State Can We Trust You Predicting First Impressions with Deep Learning John Diorio, Sophie Starck, Jonathan Douglas, Noah Duncan Bounding box object detection Alex Meyerowitz, Alexander Yu, Shrishti Lulla, Jesus Contreras Solving Captchas Sebastien Lamy, Ayse Sena Demir, Andrew Peterson Microorganism Classification Kayla Scharfstein, Ajay Balaji, David Lu WTF What The Font Font Detection Maggie Wu, Katherine Sang, Minna Kimura-Thollander Using regularization methods to tackle adversarial images classification problems ldeng8, yzhan236, yzhao101 Stock Prediction Using Reactionary Recurrent Neural Network Rahul Dey, Mustafa Ghani 1215 PM Lunch Break 115 PM Session 3 Graphics and Reinforcement Learning Filling in Incomplete Images Min Jeong Kang, Daniel Nam, Jingxiao Ma Wetnet Style Transfer for Water Simulation Natalie Lindsay, Purvi Goel, James Guesman, Michael Cosgrove Using Generative Adversarial Networks GANs to Synthesize Images Depicting Traditional Mexican Crafts Xiaotong Fu, Huakai Liu A de-weathering extension for self-driving cars Dhananjay Bhaskar, Loudon Cohen, Mert Alaydin, Saman Sang Practical lighting and reflectance decomposition for relighting face images Xianghao Xu, Qian Zhang Mastering BBTAN with Deep Reinforcement Learning Brandon Tan, Irvin Lim, Xiangyu Li, Chong Wang Deep Contra Lu Shao, Yanzhi Xin Project Pickaxe Playing Minecraft with Deep RL Nikhil Pant, Spencer Greene, Deniz Bayzit Self-Driving Mario Kart Using Deep Learning Tyler Jiang, Wenhuang Zeng, Lawrence Huang, George Lee Software Breaks Hearts Playing the Game of Hearts with Deep RL Tucker Berkmann, Gulam Murtaza, Peter Shewmaker Comparison of Deep Q Learning and Policy Learning on Trading Jeremy Chen, Stephen Cheung Deep Reinforcement Learning on Simplified Overcooked Gene Siriviboon, Top Piriyakulkij, Panthon Imemkamon Breakout of Being Bad Zak Wegweiser, Ethan Sattler, Ravi Kandula, Louis Kilfoyle Deep Recurrent Q Networks to Solve Avalon Alexander Ivanov, Jason Crowley Coloring in the Deep Using Deep Learning for Image Colorization Husam Salhab, Martin Chu, Rohit Jawle, Robert Maloney Zero Shades of Gray Real-Time User-Guided Image Colorization with Learned Deep Priors Shenandoah Duraideivamani, Thomas Del Vecchio, Geoffrey Glass, Mia Santomauro Image to Image Mapping using Conditional Adversarial Networks Jason Senthil, Coleman Dowdle, Nishant Kumar, Yuan Gao A Couple of If-Statements with Path-Tracing Denoising Monte Carlo Renderings Gabriel Rizk, Brandon Li, Dylan Tian, Andrew Canino JET Net Generating Running Routes Trevor Houchens, Elliot Laidlaw, Julia McClellan DeepLice Deep Learning Liars Dice Zhaoyong Zheng, Ilan Bigio, Jacob Leiken Towards Intelligent Upsampling of Natural Images TIUNI Zsozsho Biegl, Isa Milefchik, Rachel Wang, Tiffany Nguyen Colorizer Kshitij Sachan, Ben Silverman, Anoop Singh Classifying Hand-Drawn Sketch Images Nisha Khater, Lucia Reyes, Madelyn Adams, Laurie Finkelsztein Face Aging with Conditional Generative Adversarial Networks Joy Zheng, Joshua Kim, James Li, Melis Gokalp Reimplementing Image Style Transfer Kotone Tsuji, Ken Kawamura Album Cover Generation by Genre. Dybe Fredy Mwaisyange, William Kuenne, Griffin Kupsaw, Mateo Encarnacion Probabilistic Neural Networks Isaac Benghiat 240 PM Break 250 PM Session 4 Music, Audio, and Much More Multi-scale Deep Tensor Factorization for Financial Data Troy Moo Penn, Zachary Laporta Pulse Classification from LUX RQ Data Using Supervised Learning Austin Vaitkus, Nathaniel Swanson, Casey Rhyne Pulse discrimination of cosmic muon in simple scintillators Jeanne Bang, Taeun Kwon Understanding the Topology of Neural Networks Yang Xiao, He Yun Physics-Informed Neural Networks for Partial Differential Equations in Mechanics Enrui Zhang, Minglang Yin, Zongren Zou, Wei Cheng Transcription Binding Site Identification with Attention Model Suchen Zheng, Xiling Zhang Transformer Modeling on Autoencoded Neuronal Signals to Predict Relative Joint Angle Displacement Matthew Alexander, Tyler DeFroscia Using AIQNs and Imitation learning to Construct an Optimal Stochastic Policy for Primate Arm Motion Olivia Langley, Sean Nathan, Gregory Cho Gene Expression Prediction using Graph Convolutional Networks Jeremy Bigness, Qing Wu, Omer Dai New Ears Resolution Audio Super-Resolution using Neural Nets Jackson Markey, Victoria Lin, Kevin Ouyang, Sung Hyun Mo Reducing Dimension in Single-Cell Data with Generative Networks Daniel Ben-Isvy, Jaison Jain, Benjamin Foulon ShallowVariant - Training a Child Model from DeepVariant August Guang, Mary McGrath Predicting Depression Levels Shbham Makharia, Srinjoy Srimani, Jake Sokol Predicting Primate Upper Limb Movements Via Neuron Firing Rates is No Monkey Business Jason Manuel, Cindy Li, Put Dam Predicting Monkey Hand Pose from Neural Activity Conrad Zborowski, Xavier Loinaz, Naomi Lee BrainGELU Monkeying Around Zoe Beckman, Alexander Homer, Soryan Kumar, Viknesh Kasthuri Music Generation Katie Friis, William Jurayj Accenter Mark Lavrentyev, Arvind Yalavarti, Jeffrey Zhu BachLSTM John Lhota, Nicholas Wee Efficient Music Auto-Tagging with Convolutional Neural Networks Ekaterina Lezine, Shash Sinha, Yilmaz Sayin LSTM-Type Beat Kyle Qian, Christie Gahm, Dylan Ngo Low Transverse Momentum Tau Reconstruction Using LHC Data Jason Whang, Ye Won Byun, Eleanor Eng, Young Park Bach to the Future Learning To Generate Bach Compositions Gabby Asuncion, Sophia Chen, Kelvin Yang, Stanley Yip Pop Predictor v1.0 Predicting Music Popularity Andrew Kopplin, Marshall Vyletel, Lynn Hlaing Arabic Spoken Digit Classification Lauren Anderson, James White Music Genre Classification Prithu Dasgupta, Daniel Park, Bill Ma Piano Genie Music Generation Based on User Input Oh Joon Kwon, Jaehyun Jeon, Junewoo Park, Min Jean Cho From Franck to Fitzgerald Jazz in the Style of Classical Music Anessa Petteruti, Katherine Kwan, Alexander Rothberg, Luke Cadigan Implementation of a physics-informed deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations Hanxun Jin, Zhi Li 415 PM Closing Remarks 2019 CS14702470 TA Staff Computer Science Department Brown University", "metadata": {"last_modified": "2019-12-11T05:37:56+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Deep Learning Day"], "word_count": 1722, "token_count_estimate": 2866}}, "https://cs.brown.edu/courses/csci1450/": {"text_content": "Home Lectures Assignments Calendar Staff Resources CS1450, Fall 2023, taught by Professor Eli Upfal and Alessio Mazzetto Probability and statistics have become indispensable tools in computer science. Probabilistic methods and statistical reasoning play major roles in machine learning, cryptography, network security, communication protocols, web search engines, robotics, program verification, and more. This course introduces the basic concepts of probability and statistics, focusing on topics that are most useful in computer science applications. Topics include modeling and solution in sample space, random variables, simple random processes and their probability distributions, Markov processes, limit theorems, and basic elements of statistical inference. This course emphasizes both mathematical rigor and computing applications. For more details, please refer to the course syllabus . We use Ed Stem in this course. You can join it by clicking the Ed Discussion tab on the canvas page for this course. Please let us know if you cant access Ed Stem. Fall 2023 Lectures will be held in CIT 368.", "metadata": {"last_modified": "2023-09-08T23:31:34+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 161, "token_count_estimate": 206}}, "https://cs.brown.edu/courses/csci1510/": {"text_content": "CSCI 1510 Resources Homeworks Lectures Calendar Staff CSCI 1510 Homeworks Lectures Calendar Resources Staff CSCI 1510 Introduction to Cryptography and Computer Security Introduction Welcome to Cryptography and Computer Security CSCI 1510 at Brown Cryptography is about communication and computation in the presence of an adversary. In this course, we will address questions such as Can a secret message be sent over an unsecured channel How can Alice send a message to Bob such that Bob will understand it but no eavesdropper will Can we guarantee authenticity of data How can Bob be sure that the message he received is indeed from Alice How can he convince someone else of this fact Can we guarantee that it is impossible to cheat in an online game Can Alice and Bob play cards over the Internet To answer these questions, we will first decide what security properties are desirable for the situation at hand. We will then formally define the objects that we wish to derive encryption schemes, signature schemes, and hash functions. Finally, we will give suitable constructions and prove that they satisfy the definitions we have given. Besides these foundational cryptographic notions, we will also cover more advanced topics including identity-based encryption, post-quantum cryptography, fully homomorphic encryption, zero-knowledge proofs, secure multi-party computation, and program obfuscation. We will see what security guarantees are desirable, how to properly define these security guarantees, and how to design cryptographic algorithms and protocols that satisfy them. Lectures take place every Tuesday and Thursday from 1030 - 1150 AM , in CIT 101 and on Zoom . Resources Quick Links Syllabus EdStem Gradescope Class Participation Template Textbooks KL Introduction to Modern Cryptography by Jonathan Katz and Yehuda Lindell BS A Graduate Course in Applied Cryptography by Dan Boneh and Victor Shoup R The Joy of Cryptography by Mike Rosulek G Foundations of Cryptography by Goldreich Vol. 1 and Vol. 2 Lecture notes by Pass-Shelat , Bellare-Goldwasser , Bellare-Rogway , and Ostrovsky Contact peihanmiaobrown.edu leahrosenbloombrown.edu simoncamposgreenblattbrown.edu Homeworks Homework Release Due Homework 0 Sep 8 Sep 15 Homework 1 Sep 15 Sep 22 Homework 2 Sep 22 Sep 29 Homework 3 Sep 29 Oct 6 Homework 4 Oct 6 Oct 13 Homework 5 Oct 13 Oct 20 Homework 6 Oct 27 Nov 3 Homework 7 Nov 3 Nov 10 Homework 8 Nov 10 Nov 17 Homework 9 Nov 17 Dec 1 Homework 10 Dec 1 Dec 8 Lectures This schedule is tentative and subject to updates throughout the semester. indicates optional reading material. Date Topics and Readings Pre-Lec Notes Post-Lec Notes Zoom Rec Sep 7 Topics Introduction and overview. Readings Syllabus KL 1.1 Cryptography and modern cryptography. KL 1.3 Historical ciphers and cryptanalysis. Pre01.pdf Post01.pdf Rec01 Sep 12 Topics Syntax of symmetric-key encryption scheme. Kerckhoffs principle. Definitions of perfect security. One-time pad. Limitations of perfect security. Readings KL 1.2, R 1.1 Encryption syntax and Kerckhoffs principle. KL 1.4.1 Formal definitions. KL 2.1-2.3 Perfectly secure encryption. KL 2.4 Shannons theorem. Pre02.pdf Post02.pdf Rec02 Sep 14 Topics Computational security. Concrete vs asymptotic security. Definition of semantically secure encryption. Readings KL 3.1 Computational security concrete vs asymptotic. KL 3.2, BS 2.2.2 Semantic security. Pre03.pdf Post03.pdf Rec03 Sep 19 Topics Definition of semantically secure encryption continued. Definition of pseudorandom generators PRGs. Semantically secure encryption scheme from PRG. Proof by reduction. Readings KL 3.2, BS 2.2.2 Semantic security. KL 3.3.1, BS 3.1.1 Definition of PRG. KL 3.3.2-3.3.3, BS 3.2 Encryption scheme from PRG and proof. Pre04.pdf Post04.pdf Rec04 Sep 21 Topics Fixed-length encryption from PRG continued. Security against chosen-plaintext attacks. Pseudorandom functions PRFs. Readings KL 3.3.2-3.3.3, BS 3.2 Encryption scheme from PRG and proof. KL 3.4.2, BS 5.3 Definition of CPA security. KL 3.5.1, BS 4.4.1 Definition of PRF. Pre05.pdf Post05.pdf Rec05 Sep 26 Topics Construction of PRF from PRG GGM tree. CPA-secure encrytpion scheme from PRF. Hybrid argument. Readings BS 4.6 Construction of PRF from PRG. KL 3.5.1, BS 5.4.1 CPA-secure encryption from PRF and proof. Pre06.pdf Post06.pdf Rec06 Sep 28 Topics Message authentication codes MACs. Fixed-length MAC. CBC-MAC. Readings KL 4.1-4.2, BS 6.1 Definition of MACs. KL 4.3.1, BS 6.3 Fixed-length MAC. KL 4.4 CBC-MAC. Pre07.pdf Post07.pdf Rec07 Oct 3 Topics CBC-MAC continued. Security against chosen-ciphertext attacks. Definition of authenticated encryption. Readings KL 5.1.2, BS 9.2.2 Definition of CCA security. KL 5.2, BS 9.1 Definition of authenticated encryption. Pre08.pdf Post08.pdf Rec08 Oct 5 Topics Constructions and proofs of authenticated encryption. Readings KL 5.3.1, BS 9.4 Generic constructions of authenticated encryption. KL 5.4 Secure communication sessions. Pre09.pdf Post09.pdf Rec09 Oct 10 Topics Proof of authenticated encryption continued. Collision resistant hash function CRHF. Birthday attacks on CRHF. MerkleDamgrd transform. Readings KL 6.1.1, BS 8.1 Definition of CRHF. KL 6.4.1, BS 8.3 Birthday attacks on CRHF. KL 6.2, BS 8.4 MerkleDamgrd transform. Pre10.pdf Post10.pdf Rec10 Oct 12 Topics Hash-and-MAC. Applications of CRHF. Practical constructions of block ciphers. Readings KL 6.3.1, BS 8.2 Hash-and-MAC. KL 6.6 Applications of CRHF. BS 8.7, 8.9, 8.10, 8.12 Additional applications of CRHF. KL 7.2.1 Substitution-Permutation Network SPN. Pre11.pdf Post11.pdf Rec11 Oct 17 Topics Substitution-permutation networks continued. Feistel networks. Data encryption standard DES. Block cipher modes of operation. Readings KL 7.2.1-7.2.5 Practical constructions of block ciphers. KL 3.6.3, R 8.1 Block cipher modes of operation. R 5.1, 6.2 PRG from block cipher. Pre12.pdf Post12.pdf Rec12 Oct 19 Topics Block cipher modes of operation continued. Practical constructions of hash functions. Midterm review. Selected questions from HW 1-4. Readings KL 7.3 Practical constructions of hash functions. Pre13.pdf Rec13 Oct 24 In-Class Midterm Oct 26 Topics One-way functions. Hard-core predicates. Theoretical constructions of symmetric-key primitives. Readings KL 8.1.1-8.1.2 Definition and candidates of one-way functions. KL 8.1.3, 8.3 Hard-core predicates. KL 8.2, 8.4 Construction of PRG from OWP. KL 8.5 Construction of PRF from PRG GGM tree. KL 8.7 Assumptions for symmetric-key cryptography. Pre14.pdf Post14.pdf Rec14 Oct 31 Topics Basic group theory. Factoring and RSA assumptions. Discrete-Log and Diffie-Hellman assumptions. Readings KL 9.1.1-9.1.4, 9.3.1 Basic group theory. KL 9.2.1-9.2.2 Generating random primes. KL 9.2.3-9.2.4, BS 10.3 Factoring and RSA assumptions. KL 9.3.2, BS 10.5 Discrete-Log and Diffie-Hellman assumptions. KL 9.4, BS 10.6 Cryptographic applications. Pre15.pdf Post15.pdf Rec15 Nov 2 Topics FactoringRSA and DLOGCDHDDH assumptions. Key exchange and Diffie-Hellman protocol. Public-key encryption definitions. El Gamal encryption. RSA-based encryption. Trapdoor permutations. Readings KL 11.3, BS 10.4 Key exchange and Diffie-Hellman protocol. KL 12.2, BS 11.2-11.3 Public-key encryption definitions. KL 12.4.1, BS 11.5 El Gamal encryption. KL 12.5.1-12.5.3 RSA-based encryption. KL 15.1.1, BS 10.3, Pass-Shelat 2.11 Trapdoor permutations. Pre16.pdf Post16.pdf Rec16 Nov 7 Topics Public-key encryption from trapdoor permutations. Post-quantum PKE from learning with errors LWE assumption. Readings KL 15.1.2, BS 11.4 Public-key encryption from trapdoor permutations. KL 14.1-14.2 Quantum algorithms and their impact on cryptography. KL 14.3 Learning with errors LWE assumption and Regev encryption. Pre17.pdf Post17.pdf Rec17 Nov 9 Topics Homomorphic property of encryption schemes. Somewhat homomorphic encryption SWHE over integers. SWHE from LWE GSW. Readings Halevis tutorial Sec. 1 Introduction to FHE. Paper A conceptually simple construction of FHE over integers. Halevis tutorial Sec. 3 GSW protocol. Pre18.pdf Post18.pdf Rec18 Nov 14 Topics SWHE from LWE continued. Bootstrapping SWHE to FHE. Digital signatures. Hash-and-sign paradigm. RSA-based signatures. Random oracle model. Readings Halevis tutorial Sec. 3 GSW protocol. KL 13.1-13.2 Definition of digital signatures. KL 13.3 Hash-and-sign paradigm. KL 13.4 RSA-based signatures. Pre19.pdf Post19.pdf Rec19 Nov 16 Topics Identification schemes. Fiat-Shamir transform. Schnorrs identificationsignature schemes. Definition of zero-knowledge proofs ZKPs. Readings KL 13.5 Signatures from DLOG. Lindells notes Sec. 5.3, 6.1 Definition of ZKPs. Lindells notes Sec. 6.2 Perfect ZKP for Diffie-Hellman tuples. Pre20.pdf Post20.pdf Rec20 Nov 21 Topics Perfect ZKP for Diffie-Hellman tuples continued. ZKP for all NP. Non-interactive zero-knowledge proofs NIZKs. Readings Lindells notes Sec. 6.2 Perfect ZKP for Diffie-Hellman tuples. Lindells notes Sec. 7 ZKP for all NP. Pre21.pdf Post21.pdf Rec21 Nov 23 NO LECTURE Thanksgiving Nov 28 Topics ZKP for all NP continued. Non-interactive zero-knowledge proofs NIZKs. Definitions of secure multi-party computation. Readings Lindells note Sec. 1-2, 5 Motivation, definition, and practical use cases of MPC. Lindells tutorial Sec. 4.2, 6.2 Formal definitions for semi-honest and malicious MPC. Pre22.pdf Post22.pdf Rec22 Nov 30 Topics Definitions of MPC continued. Private set intersection. Oblivious transfer. Readings Paper by Ion et al. DDH-based PSI-sum with cardinality. Lindells note Sec. 3 Feasibility results of MPC. Chou-Orlandis paper A simple OT protocol. Pre23.pdf Post23.pdf Rec23 Dec 5 Topics Oblivious transfer continued. Semi-honest MPC for any function GMW protocol. Malicious MPC GMW compiler. Readings Evans-Kolesnikov-Rosuleks book Ch. 3.2 GMW protocol. Evans-Kolesnikov-Rosuleks book Ch. 6.5.1 GMW compiler. Pre24.pdf Post24.pdf Rec24 Dec 7 Topics Program obfuscation. Final review. Readings Jain-Lin-Sahais paper Indistinguishability obfuscation from well-founded assumptions. Pre25.pdf Post25.pdf Rec25 Calendar Zoom links are included in the Google Calendar event, as well as in the Hours queue. Staff Peihan Miao Professor pmiao Hello I work on cryptography, theory, and security. Im excited about bridging the gap between theory and practice in cryptography. Pronouns sheherhers Leah Namisa Rosenbloom Grad TA lrosenb3 I am studying cryptography for grassroots organizing with Anna Lysyanskaya and Seny Kamara. My favorite cryptographic primitive is a zero-knowledge proof of knowledge. Pronouns theythem Simon Greenblatt UTA scamposg Hi Im a second year Cybersecurity Masters student and I like to climb volcanos. Pronouns hehimhis Copyright 2023 CSCI 1510 Brown", "metadata": {"last_modified": "2023-12-07T19:40:17+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["CSCI 1510", "Introduction to Cryptography and Computer Security", "Introduction", "Welcome to Cryptography and Computer Security (CSCI 1510) at Brown!", "Resources", "Quick Links", "Textbooks", "Contact", "Homeworks", "Lectures", "Calendar", "Staff"], "word_count": 1529, "token_count_estimate": 2870}}, "https://cs.brown.edu/courses/csci1550/": {"text_content": "CSCI 1550 Probabilistic Methods in Computer Science Also available as CSCI 2540 for 2000-Level credit Course Information LectureSlides Calendar Homework About CSCI 15502540, Spring 2024, taught by Professor Eli Upfal . This is a course on the mathematics that motivates, formulates, and explains many of the great successes of computing, including statistical machine learning, Monte Carlo methods, and modern cryptography. Probability, randomness, and statistics play a key role in these and almost any other modern computer science application. This course introduces the novel mathematical and computation methods that were developed at the interplay of probability and computing. The course focuses on mathematical models, theorems and proofs, and leaves implementation and experiments to other courses. For more details, please refer to the course information page. Last Updated Jan 2024", "metadata": {"last_modified": "2024-01-26T01:35:13+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["\u2014 Probabilistic Methods in Computer Science", "Also available as", "for 2000-Level credit", "About"], "word_count": 128, "token_count_estimate": 171}}, "https://csci-1460-computational-linguistics.github.io/": {"text_content": "Natural Language Processing This course provides an introduction to the field of Natural Language Processing NLP. We will focus on a range of NLP tasks, including machine translation, question answering, text classification, as well as the underlying linguistic problems syntax, semantics, morphology that make building sytems to solve these tasks so challenging. This course will cover both traditional machine learning, information theoretic approaches as well as new deep learning approaches. Topics include Text Classification Word Embeddings Language Modeling Pretraining, Finetuning Prompting and In-Context Learning Machine Translation POS Tagging Syntactic and Semantic Parsing NLP and Social Responsibility Topics include Text Classification Word Embeddings Language Modeling Pretraining, Finetuning Prompting and In-Context Learning Machine Translation POS Tagging Syntactic and Semantic Parsing NLP and Social Responsibility prerequisites The course will be taught in Python and assumes coding fluency or a willingness to learn Python on your own time.Familiarity with machine learning, deep learning, andor linguistics is encouraged but not strictly required. overview Instructor Ellie Pavlick Instructor Office Hours Schedule Zoom Meeting HTA Mailing List cs1460headtaslists.brown.edu Location Time Tuesdays Thursdays 230- 350pm List 120 Course Materials Syllabus EdStem Forms Waitlist Anonymous Feedback Form Blocklist Form Collaboration Policy Form grading Below is the grading scheme for the course", "metadata": {"last_modified": "2023-11-30T20:13:19+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["Natural Language Processing", "prerequisites", "overview", "grading"], "word_count": 202, "token_count_estimate": 273}}, "https://cs.brown.edu/courses/csci1600/2021/": {"text_content": "Link Search Menu Expand Document CSCI 1600, Fall 2021 Information Office Hours Schedule Labs Circuit Checklist Component glossary 01 Introduction to Arduino 02 Sensors, Actuators, and IO 03 Embedded Programming and Memory 04 Clocks, Timers, and Watchdogs 05 Embedded Design and Engineering 06 Testing and Debugging 07 Networking and communication 08 Runtime monitoring Homeworks Homework 1 Homework 2 Homework 3 Homework 4 Homework 5 Homework 6 Homework 7 Homework 8 Project Information Staff This site uses Just the Docs , a documentation theme for Jekyll. Canvas Ed Discussion Embedded and Real-Time Software Latest announcements No Lab Section on Sep 9 First Tuesday lab is September 14 and first Thursday lab is September 16. See you then Welcome Welcome to the Fall 2021 course page for CSCI1600 All announcements Welcome to CSCI 1600, Embedded and Real-Time Systems This course introduces the concepts necessary to write software for embedded and real time systems, such as those found in Internet of Things devices, robots, and cars. The course emphasizes how embedded systems differ from traditional software systems and how these differences translate to challenges in the design, development, testing, and deployment of these systems. How do you design software that may be constrained by power and memory usage and timing What about software that needs to interface with sensors and other devices in the real world, and that may have safety implications if it malfunctions How do you model and verify devices that are interacting with the physical world This course aims to teach you specific engineering skills and considerations so that you can address these challenges. Course policies and expectations can be found on the Information page.", "metadata": {"last_modified": "2022-09-05T00:51:42+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "Embedded and Real-Time Software", "No Lab Section on Sep 9", "Welcome!", "", "Welcome to CSCI 1600, Embedded and Real-Time Systems!"], "word_count": 275, "token_count_estimate": 338}}, "https://brown-deep-learning.github.io/dl-website-s24/": {"text_content": "Welcome to Deep Learning DIVE IN Deep Learning Lectures Assignments Labs Hours Resources Staff Welcome to Deep Learning Over the past few years, Deep Learning has become a popular area, with deep neural network methods obtaining state-of-the-art results on applications in computer vision Self-Driving Cars, natural language processing Google Translate, and reinforcement learning AlphaGo. These technologies are having transformative effects on our society, including some undesirable ones e.g. deep fakes. This course is there to give students a practical understanding of how Deep Learning works, how to implement neural networks, and how to apply them ethically. We introduce students to the core concepts of deep neural networks and survey the techniques used to model complex processes within the contexts of computer vision and natural language processing. Throughout the course, we emphasize and require students to think critically about potential ethical pitfalls that can result from mis-application of these powerful models. The course is taught using the Tensorflow deep learning framework. Course CSCI 14702470 Professor Ritambhara Singh Location Salomon Center DECI Time MWF 1200-1250pm Syllabus Canvas Edstem Gradescope The Latest Lecture Transformers continued Recording Adobe Acrobat Reader icon Slides Homework Conceptual Language Models Due 318 Programming Language Models Due 322 Lab Debiasing Checkoff by 312 Lectures Monday, Wednesday, and Friday at 1200-1250pm in Salomon Center DECI Course offered in-person with recordings made available for reviewing. This schedule is subject to change. Week 1-4 Deep Learning Basics 124 Welcome to Deep Learning Recording Adobe Acrobat Reader icon Slides 126 Intro to Machine Learning Recording Adobe Acrobat Reader icon Slides 129 Perceptron and MNIST Recording Adobe Acrobat Reader icon Slides 131 Perceptron continued and Loss Functions Recording Adobe Acrobat Reader icon Slides 22 Optimization and Backpropagation Recording Adobe Acrobat Reader icon Slides 25 Backpropagation continued Recording Adobe Acrobat Reader icon Slides 27 Autodiff Recording Adobe Acrobat Reader icon Slides 29 Matrix representation of NNs GPUs Intro to Tensorflow Recording Adobe Acrobat Reader icon Slides 212 Multi-layer NNs and Activation Functions Recording Adobe Acrobat Reader icon Slides 214 Multi-layer NNs contd. Intro to CNNs Recording Adobe Acrobat Reader icon Slides Week 4-6 CNNs 216 CNNs Recording Adobe Acrobat Reader icon Slides 221 Multi-layer CNNs Recording Adobe Acrobat Reader icon Slides 223 Overfitting and regularization Recording Adobe Acrobat Reader icon Slides 226 Language Models and Word Embeddings Recording Adobe Acrobat Reader icon Slides Week 6-9 Language Models 228 Feedforward language models Recording Adobe Acrobat Reader icon Slides 31 Recurrent neural networks Recording Adobe Acrobat Reader icon Slides 34 LSTMs GRUs Recording Adobe Acrobat Reader icon Slides 36 Machine Translation Recording Adobe Acrobat Reader icon Slides 38 Attention Recording Adobe Acrobat Reader icon Slides 311 Transformers Recording Adobe Acrobat Reader icon Slides 313 Transformers continued and scaling deep learning systems Recording Adobe Acrobat Reader icon Slides 315 Scaling deep learning systems 318 Multi-modal learning using contrastive learning guest lecture by Michal Week 9 Interpretation 320 Interpretation of Neural Networks Week 10-11 Probabilistic Models 41 Unsupervised learning, Autoencoders 43 Variational Autoencoders 45 VAEs contd. and Generative adversarial networks 48 VAE and GANs contd Deepfakes 410 Diffusion guest lecture by Calvin Luo 412 Diffusion continued guest lecture by Calvin Luo Week 12-13 Reinforcement Learning 415 Introduction to reinforcement learning 417 Value Iteration 419 Deep Q learning 422 Policy gradient methods 424 Actor-critic methods Week 13 GNNs 426 Graph neural networks Assignments Assignments will be released at noon and due at 600pm U.S. Eastern Time. This schedule is subject to change. Assignment Out Due 0C Math Review Wednesday 124 Friday 22 0P Setup Wednesday 124 Friday 22 1C Beras Part 1 Conceptual Wednesday 131 Friday 29 1P Beras Part 1 Programming Wednesday 131 Wednesday 214 2C Beras Part 2 Conceptual Wednesday 214 Friday 223 2P Beras Part 2 Programming Wednesday 214 Wednesday 228 3C CNNs Conceptual Wednesday 228 Monday 34 3P CNNs Programming Wednesday 228 Friday 38 4C LMs Conceptual Monday 311 Monday 318 4P LMs Programming Monday 311 Friday 322 5C Image Captioning Conceptual Monday 41 Monday 48 5P Image Captioning Programming Monday 41 Friday 412 6C Variational Autoencoders Conceptual Friday 412 Friday 419 6P Variational Autoencoders Programming Friday 412 Friday 426 Final Project See the handout for full details Deliverable DateDue Project Check-in 1 Week beginning 34 Project Proposal Friday 315 600pm ET Project Check-in 2 Week beginning 48 Project Check-in 3 Week beginning 422 Final Check-in Optional Week beginning 429 Deep Learning Day Monday 56 Tuesday 57 Final Projects Due Friday 510 600pm ET Labs Check out this guide on opening labs and using Google Colaboratory . This schedule is subject to change. Lab From Until 0 Introduction to NumPy - No Checkoff Wednesday 124 Monday 129 1 Introduction to Machine Learning Wednesday 131 Tuesday 26 2 Optimizers Wednesday 27 Tuesday 213 3 TensorFlow Wednesday 214 Friday 216 or Tuesday 227 4 CNNs Wednesday 221 Tuesday 227 5 Debiasing Wednesday 36 Tuesday 312 6 LIME Wednesday 320 Tuesday 42 7 Autoencoders Wednesday 43 Tuesday 49 8 GANs Wednesday 410 Tuesday 416 9 Reinforcement Learning Wednesday 417 Tuesday 423 Lab 3 Tensorflow Those with lab sections on Wednesday, Thursday, and Friday will complete the lab during the week of 214. Those with lab sections on Saturday, Sunday, Monday, and Tuesday will complete the lab asynchronously and get it checked off the following week the week of 225. Hours Resources Forms Collaboration Form Anonymous Feedback Form Guides and Tutorials GitHub Guide Opening Up Labs Google Colaboratory Tutorial Working Remotely FastX Setup Guide ssh Guide Department Resources Capstone Information Linux Cheat Sheet Setting Up Email IT Services IT Loaner Laptops Organizations CAPS Women in Computer Science Mosaic Title IX Health and Wellness Advocates Diversity and Inclusion CS DUG Staff Professor csdeeplearningbrown.edu Professor and HTAs cs1470headtaslists.brown.edu All TAs cs1470taslists.brown.edu Do not email sensitive information, including Health Services Deans Notes, to any HTAs, UTAs, or STAs. Professor Ritambhara Singh sheher Paracanthurus hepatus Graduate TA Michal Golovanevsky sheher Octopus Mascot Jelly any Jellyfish HTAs Raymond Dai hehim Manta Ray Erica Song sheher Sea Otter Joe Dodson hehim Orca Karan Kashyap hehim Octopus Pranav Mahableshwarkar hehim Blobfish Earth Mokkamakkul hehim Manatee UTAs Julian Dai hehim Crab Calvin Eng hehim Whale Taj Gillin hehim Starfish Spandan Goel hehim Dolphin Naicheng Arnie He hehim Sea Turtle Amanda Hernandez Sandate sheher Walrus Woody Hulse hehim Anglerfish Kelvin Jiang hehim Penguin Bumjin Joo hehim Sea Otter Preetish Juneja hehim Dolphin Mohammed Khan hehim Octopus Philip LaDuca hehim Oyster Kyle Lam hehim Jellyfish Jennifer Li sheher Blue Whale Alyssa Loo sheher Narwhal Michael Lu hehim Sea Otter Ben Maizes hehim Narwhal Ken Ngamprasertsith hehim Elephant Seal Sophia Fang sheher Seahorse Aayush Setty hehim Whale Shark Jason Silva hehim Penguin Aryan Singh hehim Blue Whale Quinn Straus hehim Octopus Torsten Ullrich hehim Otter Mikayla Walsh sheher Squid Emily Wang sheher Beluga Whale Xilin Rice Wang hehim Manta Ray Xu hehim Dolphin Enyan Zhang hehim Flapjack Octopus Alex Zheng hehim Jellyfish Alex Zhou hehim Penguin STAs UTA-STAs Naphat Permpredanun hehim STA Orca Sameer Sinha hehim STA Otter Kyle Yeh hehim UTA-STA Marlin Lingze Zhang hehim UTA-STA Dolphin", "metadata": {"last_modified": "2024-03-13T17:39:15+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "", "", "", "", "Welcome to Deep Learning!", "The Latest", "Lectures", "Assignments", "Labs", "Hours", "Resources", "Staff"], "word_count": 1167, "token_count_estimate": 1758}}, "https://cs.brown.edu/courses/csci1600/2022/": {"text_content": "Link Search Menu Expand Document CSCI 1600, Fall 2022 Information Office Hours Schedule Labs Circuit Checklist Component glossary Connectivity Troubleshooting Reading MCU datasheets 01 Introduction to Arduino 02 Sensors, Actuators, and IO 03 Embedded Programming and Memory 04 Clocks, Timers, and Watchdogs 05 Embedded Design and Engineering 06 Testing and Debugging 07 Networking and communication 08 Runtime monitoring Project Information Staff This site uses Just the Docs , a documentation theme for Jekyll. Ed Discussion Gradescope Anonymous feedback form Embedded and Real-Time Software Latest announcements Welcome Welcome to the Fall 2022 course page for CSCI1600 To be fully enrolled in the class, you should register for one of the two lab sessions. The first lab will be on Monday September 12 and Tuesday September 13. All waitlist requests will be handled through Homework 0 linked from the Schedule page All remaining course announcements will be made through the EdSTEM board . . All announcements Welcome to CSCI 1600, Embedded and Real-Time Systems This course introduces the concepts necessary to write software for embedded and real time systems, such as those found in Internet of Things devices, robots, and cars. The course emphasizes how embedded systems differ from traditional software systems and how these differences translate to challenges in the design, development, testing, and deployment of these systems. How do you design software that may be constrained by power and memory usage and timing What about software that needs to interface with sensors and other devices in the real world, and that may have safety implications if it malfunctions How do you model and verify devices that are interacting with the physical world This course aims to teach you specific engineering skills and considerations so that you can address these challenges. Course policies and expectations can be found on the Information page. Anonymous Feedback Form Previous offerings By Prof. Zizyte 2021 By Prof. Reiss links to be updated soon", "metadata": {"last_modified": "2023-08-15T17:22:36+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "Embedded and Real-Time Software", "Welcome!", "", "Welcome to CSCI 1600, Embedded and Real-Time Systems!", "", ""], "word_count": 318, "token_count_estimate": 387}}, "https://cs.brown.edu/courses/csci1650/": {"text_content": "Toggle navigation CSCI 1650 Software Security and Exploitation Home Lectures Assignments CTF-1 CTF-2 CTF-3 CTF-4 Overview CSCI 1650 covers software exploitation techniques and state-of-the-practice mechanisms forhardening software. The course begins with a summary ofprevalent software defects, typically found inapplications written in memory unsafe languages,like CC , and proceeds with studyingtraditional and modern exploitation techniques, rangingfrom classical code injection and code reuse up to the latest goodies e.g., JIT-ROP .It also covers defenses against certain vulnerabilityclasses and the ways to bypass them. Students will beintroduced to advanced software exploitation techniquesand countermeasures, and study in depth the boundariesand effectiveness of standard hardening mechanisms,such as address space randomization and stack and heap protections . syllabus.pdf Prerequisites CSCI 1670 Operating Systems CSCI 0330 Introduction to Computer Systems CSCI 0300 Fundamentals of Computer Systems Grading 10 Participation Ed Discussion 90 Assignments CTF -like write-ups 0 Midterm 0 Final Acknowledgments This course would not be possible without the support andassistance of the following people Fall 22 Oren Kohavi HTA, Floria Tsui TA, Guangfeng Xu TA, John Fay TA, Kaki Su TA, Linus Sun TA, Vanessa Chang TA Fall 21 Zachary Espiritu HTA, Andrew Boden TA, Andrew Cooke TA, Maura Driscoll TA, Ben Givertz TA, Brandon Lee TA, Zachary Mothner TA, Ian Rackow TA, Daniel Ramirez TA, Alex Reuter TA, Marina Triebenbacher TA Fall 20 Brian Tracy HTA, Zsozso Biegl TA, Ethan Greenberg TA, Peter Harvie TA, Garret Kern TA, Cat Nguyen TA, Yue Sun TA Fall 19 Alexander Gaidis HTA, Di Jin GTA, Hannah Baackmaan-Friedlaender TA, Changmin Teng TA, David Liu TA, Mneera Abdullah TA Fall 18 Bessie Jiang HTA, Elisa Guerrant TA, Yujun Qin TA Fall 17 Frederick Rice HTA Fall 16 Luke Camery TA Meetings MW 3PM 420PM T hour MacMillan 117 Zoom Instructor Vasileios Vasilis Kemerlis httpscs.brown.eduvpk echo cs.brown.edused svpk Zoom Mon. 6PM 7PM Teaching Assistants Oren Kohavi HTA echo cs.brown.edused sokohavi CIT 348 Zoom Wed. 12PM 2PM Austin Phan TA echo cs.brown.edused saphan11 CIT 102 Zoom Sun. 2PM 4PM Hayley Kang TA echo cs.brown.edused shkang39 Zoom Sat. 2PM 4PM Isha Mody TA echo cs.brown.edused simody Zoom Mon. 6PM 8PM Kathy Li TA echo cs.brown.edused skli117 Zoom Fri. 930AM 1130AM Keitaro Nishijima TA echo knishijics.brown.edutr -d Zoom Thu. 8PM 10PM Maya Fleischer TA echo mfleisc1cs.brown.edutr -d Zoom Mon. 4PM 6PM Riyao Lin TA echo cs.brown.edused srlin45 Zoom Wed. 830PM 1030PM Stephen Rosa TA echo cs.brown.edused ssrosa5 CIT 348 Zoom Tue. 12PM 2PM Treetased Vividhwara TA echo tvividhwcs.brown.edutr -d CIT 348 Zoom Thu. 12PM 2PM Communication cs1650taslists.brown.edu Ed Discussion Hours TA Hours Google Calendar Anonymous Feedback Form Announcements 12062023 Review Day 12042023 Lecture 0x18 posted. 11292023 Lecture 0x17 posted. 11272023 Assignment 0x4 is due today. 11272023 Lecture 0x16 posted. 11202023 Lecture 0x15 posted. 11152023 Assignment 0x4 is due on 11272023 . 11152023 Lecture 0x14 posted. 11132023 Lecture 0x13 posted. 11082023 Assignment 0x4 posted. 11082023 Assignment 0x3 is due today. 11082023 Lecture 0x12 posted. 11062023 Lecture 0x11 posted. 11012023 Assignment 0x3 is due on 11082023 . 11012023 Lecture 0x10 posted. 10302023 Lecture 0xf posted. 10252023 Assignment 0x3 posted. 10252023 Assignment 0x2 is due today. 10252023 Lecture 0xe posted. 10232023 Lecture 0xd posted. 10182023 Assignment 0x2 is due on 10252023 . 10182023 Lecture 0xc posted. 10162023 Lecture 0xb posted. 10112023 Assignment 0x2 posted. 10112023 Assignment 0x1 is due today. 10112023 Lecture 0xa posted. 10092023 No class today. 10042023 Assignment 0x1 is due on 10112023 . 10042023 Lecture 0x9 posted. 10022023 Lecture 0x8 posted. 09272023 Assignment 0x1 posted. 09272023 Lecture 0x7 posted. 09252023 Lecture 0x6 posted. 09202023 Lecture 0x5 posted. 09182023 Lecture 0x4 posted. 09132023 Lecture 0x3 posted. 09112023 Lecture 0x2 posted. 09062023 Lecture 0x1 posted. 09062023 Welcome to CSCI 1650 2023 vpk Department of Computer Science Brown University", "metadata": {"last_modified": "2023-12-07T14:16:44+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 612, "token_count_estimate": 1246}}, "https://cs.brown.edu/courses/csci1515/spring-2024/": {"text_content": "CSCI 1515 Resources Assignments Lectures Calendar Staff CSCI 1515 Assignments Lectures Calendar Resources Staff CSCI 1515 Applied Cryptography IMPORTANT Room Change Starting from Wednesday February 7th, lectures will take place in Smith-Buonanno 106 Introduction Welcome to Applied Cryptography CSCI 1515 at Brown This course teaches cryptography from a practical perspective and provides hands-on experience in building secure systems. We first introduce foundational cryptographic algorithms including secret-key and public-key encryption schemes, message authentication codes, digital signatures, and hash functions, from which you will build secure communication and authentication systems. More advanced topics that are covered include zero-knowledge proofs, secure multi-party computation, fully homomorphic encryption, post-quantum cryptography, and differential privacy. You will learn to use these cryptographic techniques to develop more advanced applications such as secure online anonymous voting, secure computation, and private information retrieval. Besides the high-level design of these cryptosystems, this course also provides hands-on experience implementing them using tools from the existing crypto libraries such as CryptoPP and Microsoft SEAL. All the projects are written in C as it is the most widely used language in crypto libraries. Lectures take place every Monday and Wednesday from 300 - 420 PM , in Smith-Buonanno 106 Bio Med Center 202 Friedman Hall 208 and on Zoom . Resources Quick Links Syllabus EdStem Gradescope Course Notes Textbooks MOV Handbook of Applied Cryptography by Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone BS A Graduate Course in Applied Cryptography by Dan Boneh and Victor Shoup KL Introduction to Cryptography by Jonathan Katz and Yehuda Lindell R The Joy of Cryptography by Mike Rosulek Guides Development Environment Guide A Primer on Sockets A Primer on C Contact peihanmiaobrown.edu cs1515headtaslists.brown.edu cs1515taslists.brown.edu Assignments Project Release Due Project 0colon Cipher Jan 24 Feb 9 Project 1colon Signal Feb 7 Feb 16 Project 2colon Auth Feb 16 Mar 1 Project 3colon Vote Mar 1 Mar 20 Project 4colon Yaos Mar 20 Apr 12 Project 5colon PIR Apr 12 Apr 26 Final Project Apr 12 May 10 Homework Release Due HW1 Feb 7 Feb 14 HW2 Feb 16 Feb 23 HW3 Mar 1 Mar 8 HW4 Mar 20 Apr 5 HW5 Apr 12 Apr 19 Gearups will be held on Zoom please see the course calendar for links. Gearup Date Recording Slides CipherSetup Gearup Jan 29 Link Link Signal Gearup Feb 12 Link Link Auth Gearup Feb 19 Link Link Vote Gearup March 5 Link Link Yaos Gearup TBD Link Link PIR Gearup TBD Link Link Lectures indicates optional reading material. Date Topics and Readings Pre-Lec Notes Post-Lec Notes Scribe Notes Zoom Rec Jan 24 Topics Introduction and overview. Readings Course Syllabus MOV 1.1-1.2 Cryptography goals and primitives. Pre01.pdf Post01.pdf Link Rec01 Jan 29 Topics Encryption scheme basics. One-time pad OTP. Computational assumptions. Factoring assumption. Readings KL 1.2 Kerckhoffs Principle. R 1.2 One-time pad. KL 2.4 Shannons Theorem. KL 3.1 Computational security. MOV 3.3 RSA problem. KL 9.2 Factoring assumption. BS 16.5 Quantum attacks on factoring. Pre02.pdf Post02.pdf Link Rec02 Jan 31 Topics RSA assumption and RSA encryption. Diffie-Hellman assumptions. ElGamal encryption. Diffie-Hellman key exchange. Message integrity. RSA signature scheme. Readings KL 9.2 RSA assumption. KL 12.5.1 Plain RSA encryption. KL 12.5.2 Padded RSA encryption. MOV 3.7, KL 9.3.1-9.3.2 Diffie-Hellman assumptions. BS 15.1-15.3 Elliptic curve groups. MOV 8.4 ElGamal encryption. MOV 12.6.1 Diffie-Hellman key exchange. BS 16.5 Quantum attacks on discrete log. Pre03.pdf Post03.pdf Link Rec03 Feb 5 Topics Chosen-message attack CMA security. RSA signature scheme. Authenticated encryption. Cryptographic hash functions. Birthday attacks. Random oracle model. Readings KL 4.1-4.2 Definition of message authentication codes MACs. KL 13.1-13.2 Definition of digital signatures. KL 13.4 RSA signature. KL 5.1-5.3 Authenticated encryption. R 11.1 Collision-resistant hash functions. KL 6.5 Random oracle model. Pre04.pdf Post04.pdf Link Rec04 Feb 7 Topics Cryptographic hash functions continued. Applications of hash functions. Putting it all togethercolon secure messaging. Signal Diffie-Hellman ratchet. Pseudorandom generator PRG. Pseudorandom function PRF. Readings BS 8.6 SHA256. BS 8.7.2, 8.10.5 HMAC and HKDF. KL 13.3 Hash-and-Sign paradigm. Signal double ratchet algorithm. R 6.1 Definition of PRF. Pre05.pdf Post05.pdf Link Rec05 Feb 12 Topics Pseudorandom functionpermutation PRFPRP. Block cipher and modes of operation. CBC-MAC. Readings R 6.1, 6.3, 6.5 PRFPRP and block cipher. R 8.1 Block cipher modes of operation. R 5.1, 6.2 PRG from block cipher. R 10.3 CBC-MAC. Pre06.pdf Post06.pdf Link Rec06 Feb 14 Topics Password-based authentication. Two-factor authentication. Putting it all togethercolon secure authentication. Readings BS 18.3-18.4 Password-based authentication. Pre07.pdf Post07.pdf Link Rec07 Feb 19 NO LECTURE Long Weekend Feb 21 Topics Certificates and public key infrastructure PKI. Case studycolon secure shell protocol SSH. Case studycolon secure messaging and group chats. Case studycolon Single Sign-On SSO authentication. Readings BS 13.8 Certificates and PKI. Paper Security of group chats in Signal, Whatsapp, and Threema. Paper Sec. 2 Kerberos overview. Pre08.pdf Post08.pdf Link Rec08 Feb 26 Topics Definition of zero-knowledge proofs. Proof of knowledge. Examplecolon Schnorrs identification protocol. Examplecolon Diffie-Hellman tuple. Sigma protocols. Readings Lindells notes Sec. 6 Definition of zero-knowledge proof. BS 19.1.1 Honest verifier zero knowledge HVZK. BS 19.1 Schnorrs identification protocol. BS 19.4 Sigma protocols. BS 19.5.2 Chaum-Pedersen protocol for Diffie-Hellman tuples. Pre09.pdf Post09.pdf Link Rec09 Feb 28 Topics Anonymous online votingcolon an overview. Examplecolon Diffie-Hellman tuple continued. Non-interactive zero-knowledge NIZK proofs. Fiat-Shamir heuristic. Homomorphism of ElGamal encryption. Readings BS 19.5.2 Chaum-Pedersen protocol for Diffie-Hellman tuples. BS 20.3 Fiat-Shamir heuristic. BS 19.2 Schnorr signature. BS 19.3 ECDSA signature. Pre10.pdf Post10.pdf Link Rec10 Mar 4 Topics ElGamal threshold encryption. ZKP for ANDOR statements. Anonymous online voting. Readings KL 15.3.3 ElGamal threshold encryption. BS 19.7 ZKP for ANDOR statements. Pre11.pdf Post11.pdf Link Rec11 Mar 6 Topics ZKP for OR statements continued. RSA blind signature scheme. Putting it all togethercolon anonymous online voting. Prime-order groups. Readings BS Exercise 13.15 Blind signatures. KL 9.3.3 Working in subgroups of Zp. Pre12.pdf Post12.pdf Link Rec12 Mar 11 Topics More examples of sigma protocols. Commitment schemes. Zero-knowledge proofs for all NP. Succinct Non-Interactive Arguments SNARGs. Readings BS 19.5.1, 19.5.3 More examples of sigma protocols. Lindells notes Sec. 7 Zero-knowledge proof for all NP. Pre13.pdf Post13.pdf Link Rec13 Mar 13 Topics Succinct Non-Interactive Arguments SNARGs from PCP. Introduction to secure multi-party computation MPC. Readings Thalers book Sec. 7 Compiling a PCP into a succinct argument. Lindells note Sec. 1-2, 5 Motivation, definition, and practical use cases of MPC. Pre14.pdf Mar 18 Topics Feasibility results of MPC. Yaos garbled circuits and optimizations. Readings Lindells note Sec. 3 Feasibility results of MPC. Yakoubovs note Sec. 1 Yaos garbled circuits and optimizations. Mar 20 Topics Oblivious transfer OT. Putting it all togethercolon 2PC for any function. GMWcolon MPC for any function. Readings Paper Sec. 1 A simple OT protocol. Paper OT extension. Evans-Kolesnikov-Rosuleks book Ch. 3.2 GMW protocol. Mar 25 NO LECTURE Spring Break Mar 27 NO LECTURE Spring Break Apr 1 Topics Malicious securitycolon GMW compiler. Cut-and-choose for garbled circuits. Private set intersection. Readings Evans-Kolesnikov-Rosuleks book Ch. 6.5.1 GMW compiler. Paper Malicious 2PC via cut-and-choose for garbled circuits. Paper Sec. 3.1 DDH-based PSI-sum with cardinality. Apr 3 Topics Information-theoretic MPC. Introduction to fully homomorphic encryption. Somewhat homomorphic encryption over integers. Readings Evans-Kolesnikov-Rosuleks book Ch. 3.3 BGW protocol. Halevis tutorial Sec. 1 Introduction to FHE. Paper A conceptually simple construction of FHE over integers. Apr 8 Topics GSWcolon SWHE from LWE. Readings Halevis tutorial Sec. 3 GSW protocol for SWHE. Paper Security of lattice-based cryptosystems. Apr 10 Topics BFVcolon SWHE from RLWE. Putting it all togethercolon private information retrieval. Readings Paper Sec. 3-4 BFV protocol for SWHE. Paper PIR from SWHE BFV. Paper PIR from RGSW. Apr 15 Topics Bootstrapping SWHE to FHE. Practical constructions of block cipher. Readings Paper PIR from additively homomorphic Regev encryption. KL 6.2.1 Substitution-permutation network SPN. KL 6.2.2-6.2.3 Feistel network and DES. Apr 17 Topics Secure hardwarecolon secure enclaves Intel SGX hardware security module HSM. Readings Paper Intel SGX explained. Apr 22 Topics Cryptography in blockchain. Differential privacy. Readings Paper Bitcoin. Paper Vadhans tutorial on differential privacy. Paper Deep learning with differential privacy. Apr 24 Topics Privacy-preserving machine learning and federated learning. Readings Paper Secure aggregation for federated learning. Calendar Zoom links are included in the Google Calendar event, as well as in the Hours queue. Staff Peihan Miao Professor pmiao Hello I work on cryptography, theory, and security. Im excited about bridging the gap between theory and practice in cryptography. Pronouns sheherhers Jack Cheng HTA jcheng46 Hi Im a senior and I enjoy exploring. Pronouns hehimhis Colby Anderson UTA cander23 Im a senior. Im a Product Manager, CS concentrator, and lover of all athletics. Harys Dalvi UTA hdalvi Hello Im a junior studying computer science and physics. I enjoy cryptography, ML, thermodynamics, language learning, and long walks in nature. Sudatta Hor UTA shor1 I like boxing and Shaq ONeal. Chenxin Liu UTA cliu248 I am currently a second-year masters student. Feel free to reach out for any course-related queries or to share your favorite food spots Pronouns sheherhers Nishchay Parashar UTA nparasha Hey Im Nishchay, a final-year masters student from New Delhi, India. Always excited to talk about classic rock music, an absolute need for every being to love Roger Federer and the latest YouTube rabbit hole you are into Michael Youssef UTA myousse2 Hey Im a junior and Im a fan of cryptography. Camille Zhang UTA czhan152 Hi Im Camille, a senior concentrating in CS from NorCal. I pretty much spend most of my time dancing, so come watch my last spring show April 5th and 6th - this plug was mandatory as Co-Director of DAEBAK Copyright 2024 CSCI 1515 Brown", "metadata": {"last_modified": "2024-03-13T01:05:19+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["CSCI 1515", "Applied Cryptography", "[IMPORTANT] Room Change: Starting from Wednesday February 7th, lectures will take place in", "!", "Introduction", "Welcome to Applied Cryptography (CSCI 1515) at Brown!", "Resources", "Quick Links", "Textbooks", "Guides", "Contact", "Assignments", "Lectures", "Calendar", "Staff", "Jack Cheng \ud83d\udc23", "Colby Anderson \ud83e\udd19", "Harys Dalvi \ud83d\udc0a", "Sudatta Hor \ud83d\udcaa", "Chenxin Liu \ud83c\udf67", "Nishchay Parashar \ud83d\udc7e", "Michael Youssef \ud83e\udd14", "Camille Zhang \ud83d\ude43"], "word_count": 1580, "token_count_estimate": 2748}}, "https://cs.brown.edu/courses/csci1680/f14/syllabus.html": {"text_content": "Textbooks You can follow the content of the course using either one of two books Computer Networks A Systems Approach 6th edition, by Larry Peterson and Bruce Davie. Computer Networking A Top-Down Approach 6th edition, by James F. Kurose and Keith W. Ross We will indicate besides each lecture below which sections of Peterson correspond to the lecture. Programming Help C mini-course Beejs Guide to Network Programming PThreads I and PThreads II Introduction to Asynchronous Programming Sockets Helpsession Grading Your final grade for the course will be based on the following weights 45 Programing Projects 4 5 Snowcast, 10 IP, 25 TCP, 5 Final Project 15 Homeworks 3 15 Midterm Exam 25 Final Exam The three written homework assignments will all be done individually.The first program, Snowcast, will also be done individually, while the remainingprograms will be completed in groups of two 2. Schedule Date Topics Notes Readings Thu 0904 L1 - Intro pdf pptx Snowcast out 1.1-1.3 Tue 0909 L2 - Layering pdf pptx 1.4, 1.5 Thu 0911 L3 - Physical Layer pdf pptx Snowcast milestone 2.1, 2.3 Tue 0916 L4 - Link Layer pdf pptx 2.4,2.5 Thu 0918 L5 - Switching pdf pptx Snowcast due 1159pm HW1 out 2.6,3.1 Tue 0923 L6 - Link Layer Wrap-up Use the slides from lecture 05 3.1 cont Thu 0925 L7 - IP Intro pdf pptx HW1 due 1159pm IP Assignment out 4.1.1-4.1.7, 4.3.1-4.3.2 Tue 0930 L8 - IP Continued pdf pptx 4.2 Thu 1002 L9 - Intra-domain routing IP Milestone. Use slides from lecture 08 4.3.3 Tue 1007 No Class Rodrigo out for a conference Thu 1009 L10 - Inter-domain routing 1 Intro to BGP pdf pptx HW2 out 4.3.3 Tue 1014 L11 - Inter-domain routing 2 Policy and Security pdf pptx 4.3.3, but goes beyond book. BGP Wedgies are described in RFC 4264 Thu 1016 L12 - Network Layer Wrap-up pdf pptx 4.1.7 ICMP, 4.3.5 IPv6, 4.4.1 Multicast Fri 1017 HW2 due 1159pm Mon 1020 TCP out Tue 1021 Midterm Up to material covered on 1016. Thu 1023 L13 - Transport Layer I pdf pptx UDP and TCP intro. 5.1, 5.2.1-5.2.3 Tue 1028 L14 - Transport Layer II pdf pptx 5.2.4-5.2.8 6.3 Thu 1030 L15 - Fun with Congestion Control pdf pptx HW3 Out 6.4.3. Some content not in book. Sat 1101 TCP milestone I Tue 1104 L16 - Transport Layer Wrapup Thu 1106 L17 - DNS pdf pptx 9.1.3 Tue 1111 L18 - Web pdf pptx HW3 due 9.12 Sat 1108 TCP milesonte II Thu 1113 L19 - CDN and P2P pdf pptx 9.4-9.4.3 Tue 1118 L20 - Data RPC pdf pptx How to write your own application-level protocol. 5.3 Thu 1120 L21 - Wireless pdf pptx 2.8 intro, 2.8.2 Tue 1125 L22 - Security pdf pptx 8.1, 8.2, 8.4.3 Thu 1127 No class Thanksgiving Mon 1201 Final Project Out Tue 1202 L23 - SDNs pdf pptx Thu 1204 L23 - Wrap-up pdf pptx Sun 1207 Start Reading Period Thu 1211 Final project due Sat 1220 Final Exam, 2 pm Everything presented in class is fair game. More emphasis on material after midterm.", "metadata": {"last_modified": "2014-12-15T22:00:36+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["", "", "Textbooks", "Programming Help", "Grading", "Schedule"], "word_count": 514, "token_count_estimate": 912}}, "https://cs.brown.edu/courses/csci1730/2020/interpreter.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Quizius Mystery Languages Implementation Reflection Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines 1 Interpreter 1.1 Introduction 1.2 Reading 1.3 Assignment 1.4 Features to Implement 1.5 Grammar 1.6 Testing 1.7 Starter Code 1.8 What To Hand In On this page 1.1 Introduction 1.2 Reading 1.3 Assignment 1.3.1 Errors 1.4 Features to Implement 1.4.1 Desugaring 1.4.1.1 and and or 1.4.1.2 let 1.4.2 Environment 1.4.3 Binary Operators 1.4.4 Conditionals 1.4.5 Functions 1.5 Grammar 1.5.1 Abstract Syntax 1.6 Testing 1.6.1 How We Test Tests 1.6.2 Guidelines for Testing Your Interpreter 1.6.3 Debugging 1.7 Starter Code 1.8 What To Hand In prev up next 1 Interpreter 1.1 Introduction 1.2 Reading 1.3 Assignment 1.3.1 Errors 1.4 Features to Implement 1.4.1 Desugaring 1.4.1.1 and and or 1.4.1.2 let 1.4.2 Environment 1.4.3 Binary Operators 1.4.4 Conditionals 1.4.5 Functions 1.5 Grammar 1.5.1 Abstract Syntax 1.6 Testing 1.6.1 How We Test Tests 1.6.2 Guidelines for Testing Your Interpreter 1.6.3 Debugging 1.7 Starter Code 1.8 What To Hand In 1.1 Introduction For this assignment, you will write an interpreter for the Paret language pared-down Pyret described below. 1.2 Reading Please read chapters 2 7 of PLAI 2e . 1.3 Assignment We have provided a function parse which consumes an expression in the Paret languages concrete syntax, S-Exp , and returns the abstract syntax representation of that expression an Expr . parse S-Exp - Expr parse only accepts expressions that follow Parets grammar . You will implement two functions desugar and interp . desugar Expr - Expr which consumes an abstract syntax tree i.e. an Expr , as returned by parse , replaces all instances of syntactic sugar described below with desugared equivalents, and returns the result. interp Expr - Value which consumes a desugared abstract syntax tree i.e. the Expr returned by desugar and returns a Paret Value . interp should assume that its given an Expr from desugar . If interp is given an Expr containing a sugar- form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree AST first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right One might say weve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. Whats important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function which wraps around those two functions and parse to write test cases for your interpreter. 1.3.1 Errors We have provided a function raise-error for throwing errors, as well as a type InterpError , which contains all the error cases that your interpreter might run into define-type InterpError err-if-got-non-boolean val Value err-bad-arg-to-op op Operator val Value err-unbound-id name Symbol err-not-a-function val Value You can throw an error by using raise-error and providing the correct InterpError . For example raise-error err-bad-arg-to-op op-plus v-str str Pay careful attention to how interp s evaluation order specification impacts which errors are thrown. For example, str 5 bad hello false bad 6 not function 7 bad should all raise err-bad-arg-to-op op-plus v-str bad . 1.4 Features to Implement 1.4.1 Desugaring Racket macros, which youll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well its easy to miss some details when desugaring, especially in regards to evaluation order 1.4.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated. Thus, the second argument of a short-circuited expression should never throw an error. 1.4.1.2 let let should accept a single identifier-value pair and a body. let evaluates the value, binds it to id, and evaluates the body with the newly bound identifier in scope. For example, the following should evaluate to 3 let x 1 x 2 let should disallow recursive definitions. That is, in let id expr body , id should be bound in body but not in expr . The desugaring of sugar-let may not be obvious, so heres a hint What Expr s allow us to extend the identifiers bound within a given environment And how would we make that type of Expr actually do that 1.4.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of identifiers in scope. define-type-alias Env Hashof Symbol Value Since Env is a Hashof , you can use Plaits built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables What happens if you use make-hash , which creates mutable hash tables instead Try replacing one with the other and see. If none of your tests fail, you arent testing enough You should have at least one failing test, if not several, when you make this switch. interp should allow identifier shadowing , meaning that if you bind an identifier that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound identifier, interp should raise the err-unbound-id exception with the name of the identifier. 1.4.3 Binary Operators Paret includes binary addition and number equality testing num , as well as string appending and string equality testing str . In place of having separate syntactic forms for each of , num , , and str , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant define-type Operator op-plus op-append op-str-eq op-num-eq When you implement these operators, you should use Plaits for op-plus , string-append for op-str-eq , string for op-str-eq , and for op-num-eq . Evaluation should raise a err-bad-arg-to-op error for non-numeric values passed to and num operations, and for non-string values passed to and str operations. The op part of the error is the Operator that was called, and val is the Value it was given that had the wrong type. Argument types to Operator s should be checked from left to right. For example, true string should raise err-bad-arg-to-op op-plus v-bool true . In line with interp s evaluation order specification, err-bad-arg-to-op should only be raised after evaluating the arguments to the operator. 1.4.4 Conditionals if -expressions in Paret have three parts cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit i.e. only evaluate the relevant branch. If cond evaluates to a non-Boolean Value , an err-if-got-non-boolean error should be raised with val being the offending Value . 1.4.5 Functions Functions in Paret are unary i.e. they take exactly 1 argument. Heres two examples of functions and their applications lam x x 3 2 lam y 5 1 These should both evaluate to 5. Its possible that when attempting to perform a function application, the value in the function position isnt actually a function e.g., you might have 12 . In this case you should raise a err-not-a-function exception, where val is the value that was applied e.g., 1 . In line with interp s evaluation order specification, err-not-a-function should only be raised after evaluating the function-position expression and its argument. 1.5 Grammar The grammar of Paret is as follows expr num string id true false expr expr expr expr num expr expr str expr expr if expr expr expr and expr expr or expr expr let id expr expr lam id expr expr expr where id is an identifier i.e., variable, lam defines anonmyous functions, and expr expr is a function application. 1.5.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . define-type Value v-num value Number v-str value String v-bool value Boolean v-fun param Symbol body Expr env Env define-type Expr e-num value Number e-str value String e-bool value Boolean e-op op Operator left Expr right Expr e-if cond Expr consq Expr altern Expr e-lam param Symbol body Expr e-app func Expr arg Expr e-id name Symbol sugar-and left Expr right Expr sugar-or left Expr right Expr sugar-let id Symbol value Expr body Expr 1.6 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid whens the last time you ran into an implementation bug. You need to uphold this standard. This isnt a course in something like AI, where we dont even know what the right answer might be In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 1.6.1 How We Test Tests Its probably useful for you to understand how we test your tests. Whats the job of a test suite i.e., set of tests Its to find errors in a program. Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it. In short, test suites are like sorting hats, putting programs in a good or bad bin. If you are a mathy person, you might call a test suite a classifier . So, heres how we will test your test suites. We construct a collection of implementations for the problem. One is known to be correct because we built it that way we call this a wheat . The rest are known to be incorrect because we intentionally introduce errors we call each of these a chaff . Your test suites job is to separate the wheat from the chaff . That is, we will run the wheat and each of the chaffs against your test suite and see what happens On a wheat On a chaff ------------------------------------------------ all tests passed GREAT Not great some tests failed Ooops GREAT All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, thats not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, thats definitely a problem because it should never happen. It quite likely means youve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheat and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We wont do things like that, both because its cruel and because real implementations are very rarely buggy in this way. Instead, we will make reasonable mistakes but not all of them will be easy. In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite see details below, it not be accompanied by your implementation otherwise, when we try to load ours, DrRacket will complain. 1.6.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret languages concrete syntax S-Exp and returns a Paret Value eval S-Exp - Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file though you are welcome to and encouraged to individually test these functions in your code file. Theres good reason for this there is more than one correct desugaring, so any tests you write may be implementation-specific. And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly. In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form test-raises-interp-error name expr interp-error Tests that the given expr raises the given interp-error . Example usage can be found in the testing stencil. Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned because of the differences in representation. For instance, you may write test-pred My predicate test v-fun eval lam x 5 t Reminder In Plait, you can add a to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write test-equal Dont write this test eval lam x 5 v-fun x e-num 5 hash list because our representation of closures may not match your exact representation. You are, of course, welcome to write test cases of the latter form in your code file. 1.6.3 Debugging You may find it useful to use Plaits trace to help understand the control flow of your interpreter. For instance, if you write trace interp then all subsequent calls includingand especiallyrecursive calls to interp will be presented with their arguments and results. Please do not include calls to trace in your final submissions. 1.7 Starter Code Weve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , and interp , but you are welcome to add any helper functions that you need for your implementation. Weve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing e.g. a helper function or interp or desugar directly. Do not modify the contents of support.rkt and test-support.rkt . 1.8 What To Hand In You will submit two files for this assignment interpreter.rkt , which should be uploaded to the Code drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the Tests drop on Gradescope. You can update your submissions as many times as you want before the deadline. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:07+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 2666, "token_count_estimate": 3511}}, "https://brown-cs1570.pages.dev": {"text_content": "CS1570 Design and Analysis of Algorithms Fall 2023 Course Info This is a core undergraduate Computer Science course on the foundations of algorithmic theory and applications. The questions it aims to answer are What are the different algorithmic archetypes How can we analyze the performance of algorithms Which design guidelines should be followed towards achieving efficient algorithms What data structures can be used for specific algorithmic tasks We will cover these questions and, in the process, explore the use of algorithms in important applications such as artificial intelligence, data management, network analysis, and geographic information systems. The course has lectures, written homework assignments, and exams. Syllabus Gradescope Edstem Anonymous Feedback Form Pseudocode Guide Proof Guide Lectures Lectures are held in-person on Tuesdays and Thursdays from 230 to 350p.m. in CIT 241. Lecture slides will be posted on EdStem and recordings will be available on Panopto. Lecture Topic Date Introduction 0907 Preliminary Concepts 0912 Comparison-Based Sorting 0914 Searching Non-Comparison Sorting 0919 Greedy Algorithms I 0921 Greedy Algorithms II 0916 Dynamic Programming Algorithms I 0928 Dynamic Programming Algorithms II 1003 Divide Conquer Algorithms I 1005 Divide Conquer Algorithms II 1010 Basic Data Structures 1012 Tree Data Structures 1017 Hash-Based Data Structures 1019 Graph Algorithms I 1026 Graph Algorithms II 1031 Text Processing Pattern Matching 1102 Computational Geometry I 1107 Computational Geometry II 1109 Limits of Computation I 1111 Limits of Computation II 1116 Limits of Computation III 1128 External Memory Algorithms I 1130 External Memory Algorithms II 1205 Assignments All assignments must be typeset using L a T e X and submitted on Gradescope . Please refer to the syllabus for the class collaboration and late submission policy. Assignment Out Due Template Solution Getting Started 0907 0914 Proof Techniques 0912 0919 Searching Sorting 0919 0926 Greedy Algorithms 0926 1003 Dynamic Programming 1003 1012 Divide Conquer 1012 1019 Data Structures 1026 1102 Graph Algorithms 1102 1109 String Algorithms Computational Geometry 1109 1130 Complexity Theory 1130 127 Hours Hours will follow an open format, where students can work together in groups to brainstorm solutions and ask the TA for help when needed. In order to safeguard everyones health, please refrain from going to in-person hours if you are feeling unwell or experiencing any symptoms. Reach out to the TA staff to inquire about the availability of remote TA hours. March 2024 Sun Mon Tue Wed Thu Fri Sat 25 26 27 28 29 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1 2 3 4 5 6 Nothing scheduled for today Resources Course Syllabus You can find the course syllabus here The course collaboration policy and late day policy for all assignments are also included in the syllabus. Anonymous Feedback Form If you have any feedback for the course staff, please feel free to submit it here All submissions are welcome L a T e X Resources For this course your solutions must be typeset using L a T e X . Below are some resources that you might find helpful Overleaf is an online L a T e X editor that you can use to write your solutions. Overleaf L a T e X Documentation is a great resource for learning L a T e X . Detexify is a tool that allows you to draw a symbol and get the corresponding L a T e X code. Pseudocode Guide contains our recommendations for typesetting pseudocode in L a T e X . The CS1570 class file is used to apply our styles and macros for your L a T e X documents. Youll want this if you prefer not to use our Overleaf template. Department Resources The CS department provides many resources to help students succeed in their courses. Undergraduate Missive Diversity and Inclusion Student Advocates for Diversity and Inclusion Women in Computer Science MOSAIC Brown CS Health And Wellness If you need accommodation for your physical and mental health, please feel free to reach out to Professor De Stefani we want to support you as much as we can in the most comfortable way for you. It is important to note that TAs should not be handling health and accomodations information , so inquiries should be directed towards the professor only . Resources for physicalmental health, accessibility, and accommodations can be found here . Staff You can reach the entire course staff at cs1570taslists.brown.edu , the HTA and Professor at cs1570htaslists.brown.edu and just the Professor at lorenzodestefanibrown.edu . Lorenzo De Stefani Professor Hammad Izhar HTA Luke Choi UTA Nishchay Parashar UTA Neil Xu UTA Michael Youssef UTA Bin Zhang UTA", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": ["CS1570: Design and Analysis of Algorithms"], "word_count": 782, "token_count_estimate": 1060}}, "https://cs.brown.edu/courses/csci1730/2020/generators.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Quizius Mystery Languages Implementation Reflection Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines 9 Generators 9.1 Introduction 9.2 Reading 9.3 Part 1 Language Comparison 9.4 Part 2 Implementation 9.5 What To Hand In On this page 9.1 Introduction 9.2 Reading 9.3 Part 1 Language Comparison 9.4 Part 2 Implementation 9.4.1 Grammar 9.4.2 Yielding a Value 9.4.2.1 Example Usage 9.4.3 Implementation Hints 9.4.4 Starter Code 9.5 What To Hand In prev up next 9 Generators 9.1 Introduction 9.2 Reading 9.3 Part 1 Language Comparison 9.4 Part 2 Implementation 9.4.1 Grammar 9.4.2 Yielding a Value 9.4.2.1 Example Usage 9.4.3 Implementation Hints 9.4.4 Starter Code 9.5 What To Hand In 9.1 Introduction In this assignment, you will implement generators. 9.2 Reading Chapter 14.3 of PLAI 2e. Optional Reading This article provides a very nice introduction to generators in the Icon programming language, which is no longer used but inspired most modern work on generators. Generators in Icon were central to the language, not an added-on feature, and this shows how they are integrated into the language. Notice, in paricular, how the truthy-falsy nature of the language appears to be a win early on, but becomes problematic later on. You can see other examples on Wikipedia . Its worth noting that Icon was created in the late 1970s 9.3 Part 1 Language Comparison Consider the following program written in Python 3 run it online x 0 def ab global x b x 3 def c alambda yield 1 yield x gen c printnextgen printnextgen Weve translated the above program into this seemingly equivalent Racket program run it online require racketgenerator define x 0 define a b b set x 3 define c generator a lambda yield 1 yield x c c First, confirm that these programs look equivalent that is, we might expect the generators in both to yield 1 , then yield 3 . Then, run both programs. Answer the following questions Do they behave the same way If not, why do they differ You are welcome to consult the Web within the rules set down in the syllabus for help understanding their behaviors. 9.4 Part 2 Implementation You will now emulate Python 3 generators in Racket by adapting your aci implementation from the ACI assignment to implement the generator construct generator arg-name body which defines an unary function. This function returns a generator with routine body , and any references to arg-name within body are bound to the functions argument. Be very careful when youre reading this specthe generator construct defines a function , not a generator . Applying the function defined by generator the syntactic construct produces a generator in the semantic sense. In addition to the base constructs from the aci language that is, everything except web-read , the language for a generator s body should support the following new forms yield exp which yields the value of exp from the generator. We need our aci implementation because of yield aci provides the continuation needed to store the generators current state before yielding. yield ... itself should evaluate to void . Also, programs may nest yield s, and inner yield s should yield before outer yield s. loop exp which infinitely runs exp . We dont need loop to understand generators, but it makes it easier to write interesting programs e.g., streams. Additionally, because we are trying to mimic Python, your generator should not allow the use of yield or loop inside of lambda , just as in the example above. Any programs that attempt to do either should result in an error a syntax error is acceptable here. The body of a generator should be able to support references to definitions defined outside of the body for example, functions and variables previously declared in a define statement, though those outer definitions do not need to support the constructs in the generator language such as yield and loop . To do this, you should update your aci macro such that function applications do not pass their current continuation to the callee. Instead, the function applications result should be given to the continuation just as with atomic values. This modification to how continuations interact with function applications matches Pythons semantics. Finally, you should implement the next function, which takes a generator as an argument, resumes computation of the generator from the point at which it last yield ed, and returns the next value that the generator yield s. If the generator has reached the end of its body, next should call raise-stop-iteration-error defined in the support code to signal that the generator has been exhausted. If the generator never reaches the end of its body and never reaches a yield , next may loop infinitely. 9.4.1 Grammar Your final generator macro implementation should handle the following grammar generator generator id gen-expr gen-expr basic-expr yield gen-expr loop gen-expr basic-expr num string true false gen-expr gen-expr function application lambda id basic-expr set id gen-expr begin gen-expr gen-expr gen-expr gen-expr string-append gen-expr gen-expr 9.4.2 Yielding a Value When you need to yield a value, you should use letec to escape from the generator and return a value. This creates an escape continuation . Escape continuations are analogous to return statements in languages like Python when applied to an argument, the continuation unwinds the current stack out of letec and returns the argument. Your program must call the escape continuation within the dynamic extent of letec . In other words, you must call the continuation before the continuations letec and the point where the escape continuation would unwind to pops off the stack. Otherwise, Racket will raise an error. Pay attention to the distinction between the continuation created by letec echo-charlie and the continuations weve seen in lecture, created by letcc charlie-charlie. letcc s continuations allow you to jump back to the copy of the stack where the continuation was made, regardless of where the continuation was called. In contrast, letec s continuations are only allowed to escape the current stack they dont preserve a copy of the stack to permit the program to resume the computation. 9.4.2.1 Example Usage The following use of letec works because the escape continuation k is invoked before the letec call that defined k has popped off the stack 1 letec k k 5 the letec expression evaluates to 5 When the escape continuation k is called, the application of the continuation unwinds the stack back to the invocation of letec . Then, the letec expression evaluates to the value passed to k . Thus, the above program evaluates to 6 . We can even bind the escape continuation k to a new variable, and call the escape continuation via that variable hint define hold dummy variable 1 letec k begin set hold k hold 5 However, the following example results in an error since k is invoked after the letec call that defined k has popped off the stack define hold dummy variable 1 letec k begin set hold k 3 hold 5 error continuation application attempt to jump into an escape continuation Make sure you understand why the semantics of letcc would allow the third program to work if we were to replace letec with letcc . Because of these semantics, youll need to carefully consider how you use letec to return values. Specifically, every time we call next on a generator, wed like to return the yielded value to this specific invocation of next . However, defining a continuation only saves the current stack at the time the continuation was defined. As such, youll need to figure out a way to update the escape continuation used by yield every time you call next or youll end up using an old escape continuation. 9.4.3 Implementation Hints We recommend that you create a struct that stands for generators exactly what this struct looks like is up to you. You may find it helpful to nest your aci macro inside your generator macro try implementing generator without doing this and see what you run into. You can nest a define-syntax construct within another define-syntax construct by moving the inner macro inside of a particular pattern branch of your outer macro define-syntax outer-macro syntax-rules some-pattern let define-syntax inner-macro syntax-rules another-pattern 1 2 1 2 can be whatever you want inner-macro bar outer-macro foo You might find it tricky to know how to catch uses of loop and yield inside of lambda . Think about how you wrote your lambda case in ACI. In ACI, it was legal for a web-read to appear in the body of a lambda , so it was necessary to use aci on the body of a lambda in order to handle possible web-read s. In this assignment, a world where yield and loop arent allowed to appear inside of lambda s, do you need to handle your lambda case in the same way Finally, you might find implementing loop tricky. You might start by expanding loop s body into another call to loop , but that can cause your aci macro to never terminate. Instead, try implementing it via a helper function that consumes the continuation representing loop s body and runs this continuation repeatedly its up to you to figure out how to do this, though. 9.4.4 Starter Code Weve provided starter code for your implementation at generators.rkt . This includes a template for your generator macro as well as the next function. Weve also provided a stencil for your test cases at generators-tests.rkt and testing support code at test-support.rkt . You should check that you can run your generators-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing. 9.5 What To Hand In You will submit two files for this assignment generators.rkt , which should be uploaded to the Code drop on Gradescope. generators-tests.rkt , which should be uploaded to the Tests drop on Gradescope. Finally, submit your answer to Part 1 Language Comparison to the Question drop on Gradescope. You can update your submissions as many times as you want before the deadline. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:07+00:00", "scraped_at": "2024-03-13T22:15:22+00:00", "headings": [], "word_count": 1726, "token_count_estimate": 2196}}, "https://cs.brown.edu/courses/csci1730/2020/testing-guidelines-section.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Quizius Mystery Languages Implementation Reflection Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines 10 Testing Guidelines 10.1 Testing Guidelines On this page 10.1 Testing Guidelines 10.1.1 Provided Library 10.1.2 Error- Handling 10.1.3 Check Your Understanding prev up next 10 Testing Guidelines 10.1 Testing Guidelines 10.1.1 Provided Library 10.1.2 Error-Handling 10.1.3 Check Your Understanding 10.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions called wheat and chaff respectively that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignmentsome assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a defineprovide-test-suite test-suite-name ... statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to and encouraged to write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so youll need to use either Rackets or Plaits built-in testing utilities. 10.1.1 Provided Library You will always have access to the following forms test-equal name actual expected test-not-equal name actual expected Tests that actual and expected evaluate to the same value in the case of test-not-equal , different values. test-true name expr test-false name expr Tests that expr evaluates to t in the case of test-false , f . test-pred name pred expr Tests that expr returns a value that satisfies the given pred predicate. test-raises-error-with-substring name expr substr Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms see the assignment specs for more information. 10.1.2 Error-Handling When we run your tests, they can result in an error either due to an intentionally raised error or a bug in a chaff. It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this test-equal Works with Num primitive eval 2 2 v-num 4 However, dont write this define result eval 2 2 this is not caught by test-equal test-equal result v-num 4 That said, if you need to define intermediary variables in a test case, you can use a begin or let statement test-equal Multi-statement test case let result eval 2 2 result v-num 4 10.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a Tests upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome and encouraged to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once its done running, it will immediately give you feedback on Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, were going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while youre implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:11+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 834, "token_count_estimate": 1074}}, "https://brown-csci1660.github.io/handin-wiki/": {"text_content": "CS1660 Handin Wiki Home Bash Scripting Managing Processes Go syntax Attacks breakout env-vars listconf path-byp perm-conf racecond symlinkt exfil-pi CS1660 Handin Wiki Home Welcome to the CS1660 Handin Wiki This site contains documentation for some of the vulnerabilites available in the Handin project. Each page is labeled according to the tag listed in the handout. In addition to the vulnerability specific documentation, we have also compiled some documentation on specific technical components that may be useful for this project. Bash Scripting Everything you to know about Bash-shell programming Advanced Bash-Scripting Guide Managing Processes Linux Commands for process management Foreground and Background processes Go syntax A tour of Go Go Playground Go packages Next Built with MkDocs using a theme provided by Read the Docs . Next", "metadata": {"last_modified": "2024-03-09T15:53:08+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Welcome to the CS1660 Handin Wiki", "Bash Scripting", "Managing Processes", "Go syntax"], "word_count": 126, "token_count_estimate": 161}}, "https://cs.brown.edu/courses/csci1730/2020/tinf.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Quizius Mystery Languages Implementation Reflection Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines 6 Type Inference 6.1 Introduction 6.2 Reading 6.3 The Language 6.4 Assignment 6.5 Features to Implement 6.6 Testing 6.7 Starter Code 6.8 What To Hand In On this page 6.1 Introduction 6.2 Reading 6.3 The Language 6.3.1 Grammar 6.4 Assignment 6.4.1 Term s 6.5 Features to Implement 6.5.1 Desugaring with Label s 6.5.2 Label Environment 6.5.3 The Inference Algorithm 6.5.3.1 Phase 1 Constraint Generation 6.5.3.2 Phase 2 Unification 6.5.4 Exceptions 6.6 Testing 6.7 Starter Code 6.7.1 Set Library 6.8 What To Hand In prev up next 6 Type Inference 6.1 Introduction 6.2 Reading 6.3 The Language 6.3.1 Grammar 6.4 Assignment 6.4.1 Term s 6.5 Features to Implement 6.5.1 Desugaring with Label s 6.5.2 Label Environment 6.5.3 The Inference Algorithm 6.5.3.1 Phase 1 Constraint Generation 6.5.3.2 Phase 2 Unification 6.5.4 Exceptions 6.6 Testing 6.7 Starter Code 6.7.1 Set Library 6.8 What To Hand In 6.1 Introduction In this assignment, you will implement the type inference algorithm we studied in lecture on the untyped Paret language. 6.2 Reading Chapter 15.3.2 of PLAI 2e. 6.3 The Language The Paret language for this assignment is nearly the same as the Typed Paret language from Type Checker , except that the type annotations on lam and empty expressions have been removed putting them back in is, after all, the job of type inference. We have also reintroduced and and or expressions back into the language as syntactic sugar. We also have changed let from a base expression into syntactic sugar. Thus, you will need to implement a desugarer that converts and , or , and let expressions into functionally equivalent expressions. 6.3.1 Grammar The grammar of Untyped Paret is as follows expr num string true false expr expr expr expr num expr expr str expr expr if expr expr expr id expr expr first expr rest expr is-empty expr link expr expr empty lam id expr let id expr expr and expr expr or expr expr 6.4 Assignment Refer to the support.rkt file for the definition of LExpr . As usual, we have provided a function parse , which consumes an expression in Parets concrete syntax and returns the abstract syntax representation of that expression. However, the parser in this assignment returns an LExpr , which is exactly the same as an Expr , except that each LExpr has an additional label field and e-lam also has a param-label field. Label s are used to stand for program points in the type inference algorithm. define-type-alias Label Symbol Given the updated Paret language and the updated LExpr abstract syntax, you will implement two functions desugar and type-of . desugar LExpr - LExpr which consumes an abstract syntax tree i.e. an LExpr , as returned by parse , replaces all instances of sugar-and , sugar-or , and sugar-let with desugared equivalents, and returns the result. type-of LExpr - Term that consumes a Paret program in abstract syntax form. If the program is well-typed, type-of returns the type of that program represented as a Term as defined below otherwise, it raises an exception. type-of should assume that its given an LExpr from desugar . Thus, type-of should assume that there are no sugar-and s, sugar-or s, or sugar-let s in the input Expr . Once you have implemented desugar and type-of , you should use the provided type-infer function analogous to type-check from Type Checker to write test cases for your type checker in your testing file. 6.4.1 Term s As discussed in lecture, Term s describe the type of a subexpression of a program and are used in the constraint generation process. The language of Term s is as follows define-type Term t-var label Label t-con head Symbol args Listof Term t-var denotes a term variable also referred to as a type variable . A type variable t-var g123 can be read as the type of the expression or program position labeled g123 . t-con denotes a term constructor , which builds up a more complicated term from a list of subterms. For example, t-con - list t-var g123 t-var g123 is a representation of the more familiar a - a . Primitives are also represented this way. For example, t-con Num empty is a representation of the type Num . For convenience, we provide helper functions to simulate the Type language of Type Checker in the language of Term . For example, t-num produces t-con Num empty t-num , t-bool , t-str , t-fun , and t-list are all provided, and you can reference the support code for their definitions. However, these are helper functions and not type variants , so you will not be able to match against them in a type-case expression. 6.5 Features to Implement 6.5.1 Desugaring with Label s When producing desugared expressions, you may need to create fresh Symbol s. For example, you may need to generate new Label s for non-sugar LExpr s. To do this, you should use the built-in gensym function, which generates a unique, unused Symbol . You may also use gensym if you need to create Term s with unknown types. 6.5.2 Label Environment Your type inference algorithm should use a label environment LEnv to keep track of label identifiers that are in scope. define-type-alias LEnv Hashof Symbol Label For convenience, we provide a get-label function that consumes a LExpr and retrieves its Label . 6.5.3 The Inference Algorithm In the starter code, we provide templates for two optional helper functions constraint-gen and unify . constraint-gen LExpr - Setof Constraint unify Setof Constraint - Substitution The two phases of the inference algorithm discussed in lecture and discussed below map to these two helper functions. We suggest using these two function templates to guide your overall type-of implementation, but they are not requiredwe will not be testing these functions directly, and you are free to ignore them or change them as you wish. 6.5.3.1 Phase 1 Constraint Generation Recall that Constraint s relate program subexpressions by describing how they work together in a successful execution. The language of Constraint s is define-type Constraint eq l Term r Term Constraint s equate two Term s, often a type variable to the type of some other expression. For example, a Constraint that would be generated for the LExpr e-num g123 5 is eq t-var g123 t-num 6.5.3.2 Phase 2 Unification The process used to solve constraints is known as unification . In unification, a unifier algorithm is given a set of equations e.g. Constraint s, and each Constraint maps a type variable t-var to a Term . Given a consistent set of Constraint s, we try to unify them in such a way that every t-var gets assigned the correct type. To do this, our unifier should generate a mapping from variables Label s to Term s that do not contain any variables. We define the Substitution alias to represent this mapping define-type-alias Substitution Hashof Label Term Unification should always terminate. Thus, your unifier should perform an occurs check that causes it to terminate given a circular Constraint . Specifically, given the Constraint eq replace with , you should raise ti-err-fails-occurs-check replace with if replace is a strict subterm of with . Make sure you can construct a test case for this Make sure you understand why replace with should pass the occurs check. You may find the high-level description of unification here helpful as well. 6.5.4 Exceptions The full set of exceptions is as follows define-type TypeInferenceError ti-err-fails-occurs-check replace Term with Term ti-err-constructor-mismatch t1 Term t2 Term ti-err-unbound-id name Symbol Given the Constraint eq replace with , you should raise ti-err-fails-occurs-check replace with if replace is a strict subterm of with . Given the Constraint eq t1 t2 , you should raise ti-err-constructor-mismatch t1 t2 if t1 and t2 are t-con s with different head symbols. Given an expression that references an unbound identifier, you should raise ti-err-unbound-id with the name of the identifier. The priority of TypeInferenceError s is unspecifiedwhen multiple TypeInferenceError s could be raised in a program, your program just needs to raise one of the valid exceptions. The reason for this is that the Constraint s in a Paret program are really a set of Constraint s rather than a list of Constraint s. Thus, the order in which your unifier views each Constraint can change the order in which errors are raised. Be careful when youre writing test cases against wheats and chaffs 6.6 Testing Unlike type-check from Type Checker , type-infer can produce types with variables. For example, the term lam x x might produce t-fun t-var g123 t-var g123 . Since Label s are random, writing tests for types with variables can be difficult. To help you write deterministic tests, we provide a function normalize Term - Term that consumes a Term and renames all t-var label s to be lowercase letters in alphabetical order relative to how they appear in the Term . For example, normalizing the type inferred for lam x lam y empty should produce t-fun t-var a t-fun t-var b t-list c which is equivalent to t-con - list t-var a t-fun t-var b t-list c You should use normalize when writing test cases in your testing file, or your test cases may cause the wheats to unexpectedly fail. You are not permitted to use normalize in your actual implementation. Finally, in addition to the testing forms documented in the Testing Guidelines , we provide the following testing forms test-error-fails-occurs-check name expr test-error-constructor-mismatch name expr test-error-unbound-id name expr These test that the given expr raises the correct error. Example usage can be found in the testing stencil. 6.7 Starter Code Weve provided starter code for your implementation at type-inference.rkt and support code at support.rkt . You are not allowed to change the signature of desugar , type-of , and type-infer , but you are welcome to add any helper functions that you need for your implementation. Weve also provided a stencil for your type-check test cases at type-inference-tests.rkt and testing support code at test-support.rkt . You should check that you can run your type-inference-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing. 6.7.1 Set Library As mentioned previously, it may be useful to think of the Constraint s in a Paret program as a set of Constraint s rather than a list of Constraint s. Plait does not have a built-in set library, so we provide a Setof a abstraction in the support.rkt file Setof a Type for an immutable set containing elements of type a . empty-set Creates an empty set. set .... Convenience macro around list-set returns a Setof a containing all of the elements listed in .... . list-set Listof a - Setof a Returns a Setof a containing all of the elements in the input Listof a . set-list Setof a - Listof a Returns a Listof a containing all of the elements in the input Setof a . We also provide the following Setof a utility functions set-empty Setof a - Boolean set-count Setof a - Number set-member Setof a, a - Boolean set-add Setof a a - Setof a set-remove Setof a a - Setof a set-union Setof a, Setof a - Setof a set-pick Setof a - Pick a Picks an arbitrary element out of the set, and returns a Pick data structure. define-type Pick a pick-none pick-some element a rest Setof a If the set is empty, a pick-none is returned. Otherwise, a pick-some is returned, and the rest of the set without the picked value is stored in the rest field of the pick-some . The element returned in a pick-some is not guaranteed to be the same between applications of set-pick on the same Setof a . You are not required to use the provided Setof a interface, but you may find it helpfulespecially since the templates for our suggested constraint-gen and unify functions utilize the Setof a abstraction. 6.8 What To Hand In You will submit two files for this assignment type-inference.rkt , which should be uploaded to the Code drop on Gradescope. type-inference-tests.rkt , which should be uploaded to the Tests drop on Gradescope. You can update your submissions as many times as you want before the deadline. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:11+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 2102, "token_count_estimate": 2867}}, "https://cs.brown.edu/courses/csci1730/2021/interpreter.html": {"text_content": "Fall 2021 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits Assignments SMo L Mystery Languages Implementation Analysis Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines 3 Interpreter 3.1 Introduction 3.2 Assignment 3.3 Features to Implement 3.4 Grammar 3.5 Testing 3.6 Starter Code 3.7 What To Hand In On this page 3.1 Introduction 3.2 Assignment 3.2.1 Errors 3.3 Features to Implement 3.3.1 Desugaring 3.3.1.1 and and or 3.3.1.2 let 3.3.2 Environment 3.3.3 Binary Operators 3.3.4 Conditionals 3.3.5 Functions 3.4 Grammar 3.4.1 Abstract Syntax 3.5 Testing 3.5.1 How We Test Tests 3.5.2 Guidelines for Testing Your Interpreter 3.5.3 Debugging 3.6 Starter Code 3.7 What To Hand In prev up next 3 Interpreter 3.1 Introduction 3.2 Assignment 3.2.1 Errors 3.3 Features to Implement 3.3.1 Desugaring 3.3.1.1 and and or 3.3.1.2 let 3.3.2 Environment 3.3.3 Binary Operators 3.3.4 Conditionals 3.3.5 Functions 3.4 Grammar 3.4.1 Abstract Syntax 3.5 Testing 3.5.1 How We Test Tests 3.5.2 Guidelines for Testing Your Interpreter 3.5.3 Debugging 3.6 Starter Code 3.7 What To Hand In 3.1 Introduction For this assignment, you will write an interpreter for the Paret language pared-down Pyret described below. 3.2 Assignment We have provided a function parse which consumes an expression in the Paret languages concrete syntax, S-Exp , and returns the abstract syntax representation of that expression an Expr . parse S-Exp - Expr parse only accepts expressions that follow Parets grammar . You will implement two functions desugar and interp . desugar Expr - Expr which consumes an abstract syntax tree i.e. an Expr , as returned by parse , replaces all instances of syntactic sugar described below with desugared equivalents, and returns the result. interp Expr - Value which consumes a desugared abstract syntax tree i.e. the Expr returned by desugar and returns a Paret Value . interp should assume that its given an Expr from desugar . If interp is given an Expr containing a sugar- form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree AST first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right One might say weve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. Whats important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function which wraps around those two functions and parse to write test cases for your interpreter. 3.2.1 Errors We have provided a function raise-error for throwing errors, as well as a type InterpError , which contains all the error cases that your interpreter might run into lang racket define-type InterpError err-if-got-non-boolean val Value err-bad-arg-to-op op Operator val Value err-unbound-var name Symbol err-not-a-function val Value You can throw an error by using raise-error and providing the correct InterpError . For example lang racket raise-error err-bad-arg-to-op op-plus v-str str Pay careful attention to how interp s evaluation order specification impacts which errors are thrown. For example, lang racket str 5 bad hello false bad 6 not function 7 bad should all raise err-bad-arg-to-op op-plus v-str bad . 3.3 Features to Implement 3.3.1 Desugaring Racket macros, which youll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well its easy to miss some details when desugaring, especially in regards to evaluation order 3.3.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated. Thus, the second argument of a short-circuited expression should never throw an error. 3.3.1.2 let let should accept a single variable-value pair and a body. let evaluates the value, binds it to the variable, and evaluates the body with the newly bound variable in scope. For example, the following should evaluate to 3 lang racket let x 1 x 2 let should disallow recursive definitions. That is, in let var expr body , var should be bound in body but not in expr . The desugaring of sugar-let may not be obvious, so heres a hint What Expr s allow us to change the variables bound within a given environment 3.3.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of variables in scope. define-type-alias Env Hashof Symbol Value Since Env is a Hashof , you can use Plaits built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables What happens if you use make-hash , which creates mutable hash tables instead Try replacing one with the other and see. If none of your tests fail, you arent testing enough You should have at least one failing test, if not several, when you make this switch. interp should allow variable shadowing , meaning that if you bind a variable that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound variable, interp should raise the err-unbound-var exception with the name of the variable. 3.3.3 Binary Operators Paret includes binary addition and number equality testing num , as well as string appending and string equality testing str . In place of having separate syntactic forms for each of , num , , and str , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant lang racket define-type Operator op-plus op-append op-str-eq op-num-eq When you implement these operators, you should use Plaits for op-plus , string-append for op-append , string for op-str-eq , and for op-num-eq . Evaluation should raise a err-bad-arg-to-op error for non-numeric values passed to and num operations, and for non-string values passed to and str operations. The op part of the error is the Operator that was called, and val is the Value it was given that had the wrong type. Argument types to Operator s should be checked from left to right. For example, lang racket true string should raise err-bad-arg-to-op op-plus v-bool true . In line with interp s evaluation order specification, err-bad-arg-to-op should only be raised after evaluating the function-position expression and its argument. 3.3.4 Conditionals if -expressions in Paret have three parts cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit i.e. only evaluate the relevant branch. If cond evaluates to a non-Boolean Value , an err-if-got-non-boolean error should be raised with val being the offending Value . 3.3.5 Functions Functions in Paret are unary i.e. they take exactly 1 argument. Heres two examples of functions and their applications lam x x 3 2 lam y 5 1 These should both evaluate to 5. Its possible that when attempting to perform a function application, the value in the function position isnt actually a function e.g., you might have 12 . In this case you should raise a err-not-a-function exception, where val is the value that was applied e.g., 1 . In line with interp s evaluation order specification, err-not-a-function should only be raised after evaluating the function-position expression and its argument. 3.4 Grammar The grammar of Paret is as follows expr num string var variable a.k.a. identifier true false expr expr expr expr num expr expr str expr expr if expr expr expr and expr expr or expr expr let var expr expr lam var expr anonymous function expr expr function application 3.4.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . lang racket define-type Value v-num value Number v-str value String v-bool value Boolean v-fun param Symbol body Expr env Env define-type Expr e-num value Number e-str value String e-bool value Boolean e-op op Operator left Expr right Expr e-if cond Expr consq Expr altern Expr e-lam param Symbol body Expr e-app func Expr arg Expr e-var name Symbol sugar-and left Expr right Expr sugar-or left Expr right Expr sugar-let var Symbol value Expr body Expr 3.5 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid whens the last time you ran into an implementation bug. You need to uphold this standard. This isnt a course in something like AI, where we dont even know what the right answer might be In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 3.5.1 How We Test Tests Its probably useful for you to understand how we test your tests. Whats the job of a test suite i.e., set of tests Its to find errors in a program. Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it. In short, test suites are like sorting hats, putting programs in a good or bad bin. If you are a mathy person, you might call a test suite a classifier . So, heres how we will test your test suites. We construct a collection of implementations for the problem. Some are known to be correct because we built them that way we call each of these a wheat . The others are known to be incorrect because we intentionally introduce errors we call each of these a chaff . Your test suites job is to separate the wheat from the chaff . That is, we will run each of the wheats and chaffs against your test suite and see what happens On a wheat On a chaff ------------------------------------------------ all tests passed GREAT Not great some tests failed Ooops GREAT All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, thats not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, thats definitely a problem because it should never happen. It quite likely means youve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheats and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We wont do things like that, both because its cruel and because real implementations are very rarely buggy in this way. Instead, we will make reasonable mistakes but not all of them will be easy. In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite see details below, it not be accompanied by your implementation otherwise, when we try to load ours, DrRacket will complain. 3.5.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret languages concrete syntax S-Exp and returns a Paret Value eval S-Exp - Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file though you are welcome to and encouraged to individually test these functions in your code file. Theres good reason for this there is more than one correct desugaring, so any tests you write may be implementation-specific. And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly. In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form test-raises-interp-error name expr interp-error Tests that the given expr raises the given interp-error . Example usage can be found in the testing stencil. Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned because of the differences in representation. For instance, you may write test-pred My predicate test v-fun eval lam x 5 t Reminder In Plait, you can add a to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write test-equal Dont write this test eval lam x 5 v-fun x e-num 5 hash list because our representation of closures may not match your exact representation. You are, of course, welcome to write test cases of the latter form in your code file. 3.5.3 Debugging You may find it useful to use Plaits trace to help understand the control flow of your interpreter. For instance, if you write trace interp then all subsequent calls includingand especiallyrecursive calls to interp will be presented with their arguments and results. Do not include calls to trace in your final submissions. 3.6 Starter Code Weve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , or interp , but you are welcome to and might need to add helper functions for your implementation. Weve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing e.g. a helper function or interp or desugar directly. Do not modify the contents of support.rkt and test-support.rkt . 3.7 What To Hand In You will submit two files for this assignment interpreter.rkt , which should be uploaded to the Code drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the Tests drop on Gradescope. You can update your submissions as many times as you want before the deadline. prev up next", "metadata": {"last_modified": "2021-12-02T13:25:07+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 2658, "token_count_estimate": 3494}}, "https://cs.brown.edu/courses/csci1730/": {"text_content": "csci1730 Programming Languages Next showing Fall 2023 Past editions. You can find newer reviews on the Critical Review site. Some old links may no longer work because they change their URLs. Offering Review Fall 2022 Fall 2021 Fall 2020 Fall 2019 Fall 2018 review Fall 2017 Fall 2016 review Fall 2015 review Fall 2014 review Fall 2013 review Fall 2012 review Fall 2010 review Fall 2008 review Fall 2007 review Fall 2005 review Fall 2004 review Fall 2003 review Fall 2002 review Fall 2001 review Fall 2000", "metadata": {"last_modified": "2023-09-04T19:26:06+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 87, "token_count_estimate": 135}}, "https://cs.brown.edu/courses/csci1730/2020/tcheck.html": {"text_content": "Fall 2020 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Credits Assignments Quizius Mystery Languages Implementation Reflection Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 ACI 8 Lazy 9 Generators 10 Testing Guidelines 5 Type Checker 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.5 Grammar 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In On this page 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.4.1 Type Environment 5.4.2 Lists 5.4.3 Exceptions 5.5 Grammar 5.5.1 Abstract Syntax 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In prev up next 5 Type Checker 5.1 Introduction 5.2 Reading 5.3 Assignment 5.4 Features to Implement 5.4.1 Type Environment 5.4.2 Lists 5.4.3 Exceptions 5.5 Grammar 5.5.1 Abstract Syntax 5.6 Testing Guidelines 5.7 Starter Code 5.8 What To Hand In 5.1 Introduction In this assignment, you will implement a static type checker for an extension of the Paret language, Typed Paret. 5.2 Reading Chapter 15.1 15.2 of PLAI 2e. 5.3 Assignment As in Interpreter , we have provided a function parse , which consumes an expression in Typed Parets concrete syntax and returns the abstract syntax representation Expr of that expression. You will implement one function called type-of type-of Expr - Type that consumes a Paret program in abstract syntax form. If the program is well-typed, type-of returns the Type of that program otherwise, it raises an exception. Once you have implemented type-of , you should use the provided type-check function analogous to eval from Interpreter to write test cases for your type checker in your testing file. For simplicity, Typed Paret does not have syntactic sugar. let has been converted into a non-sugar expression so type-of will handle let expressions directly, and and and or have been removed from the language. 5.4 Features to Implement 5.4.1 Type Environment The type language you will work with is define-type Type t-num t-bool t-str t-fun arg-type Type return-type Type t-list elem-type Type which, respectively, represent the types of numbers, Booleans, strings, one-argument functions, and homogenous lists. Just as how Interpreter had an Env for mapping identifiers to values, your interpreter should use a type environment TEnv to keep track of the types of identifiers in scope. define-type-alias TEnv Hashof Symbol Type In type-of , if the program binds an identifier that is already bound, the new binding should take precedence. This is known as identifier shadowing . The new binding shadows the existing binding. 5.4.2 Lists Paret now contains support for lists via the constant empty and the operations link , is-empty , first , and rest . Lists in Paret are homogeneous all elements in the list must have the same type. A question to briefly consider What is the Type of the empty list Its polymorphic it can be a list of any type at all Because it has no elements, theres nothing to constrain its type. However, because our type checker is not polymorphic, we handle this with a simple expedient we require that every empty list be annotated with a type for the elements that will eventually be linked to it. Naturally, the elements that eventually are linked to it must be consistent with that annotated type. Thus, our typed list semantics are as follows empty empty t makes an empty list whose elements have type t . link t, List t - List t link x y prepends the element x to the list y . first List t - t first x returns the first element of x . rest List t - List t rest x returns the list x except for the first element of x . is-empty List t - Bool is-empty x returns true if x is empty otherwise, it returns false . Whenever these type signatures are violated, the type checker should raise a tc-err-bad-arg-to-op exception. Error-checking link should occur in the following manner If the type of the second argument to link isnt a List t , the arg-type of tc-err-bad-arg-to-op should be the type of the second argument. If the second argument to link is a List t but the type of the first argument is not t , then the arg-type of tc-err-bad-arg-to-op should be the type of the first argument. For example, link hello 3 link 2 empty Bool should all raise tc-err-bad-arg-to-op op-link t-num . 5.4.3 Exceptions Most of the exceptions your type-checker can raise are just like the errors from Interpreter , but with a type instead of a value. There are two new kinds of exceptions, though tc-err-bad-arg-to-fun should be raised when a function is applied to an argument of the wrong type. func-type is the type of the function being applied, and arg-type is the type of the argument it was applied to. tc-err-if-branches should be raised when an if statement has branches that have different types. then-type is the type of the then branch, and else-type is the type of the else branch. For instance, if true 3 three should raise tc-err-if-branches t-num t-str . However, tc-err-if-got-non-boolean takes precedence over tc-err-if-branches . For example, if non-bool 5 five should raise tc-err-if-got-non-boolean t-str rather than tc-err-if-branches t-num t-str . Thus, the full set of exceptions is as follows define-type TypeCheckingError tc-err-if-got-non-boolean cond-type Type tc-err-bad-arg-to-op op Operator arg-type Type tc-err-bad-arg-to-un-op op UnaryOperator arg-type Type tc-err-unbound-id name Symbol tc-err-not-a-function func-type Type tc-err-bad-arg-to-fun func-type Type arg-type Type tc-err-if-branches then-type Type else-type Type For tc-err-bad-arg-to-op , argument types to Operator s should be checked from left to right . For example, true string should raise tc-err-bad-arg-to-op op-plus t-bool . Finally, your type-checker should type-check by performing a post-order traversal of the AST first, traverse all of the children of an expression from left to right, then check the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. For example, str 1 bad 1 bad false bad 2 not function 3 bad if true 4 bad 4 bad should all raise tc-err-bad-arg-to-op op-plus t-str . 5.5 Grammar The grammar of Typed Paret is as follows expr num string true false expr expr expr expr num expr expr str expr expr if expr expr expr id expr expr lam id type expr let id expr expr link expr expr first expr rest expr is-empty expr empty type type Num Str Bool List type type - type Our parse function expects and enforces spaces around and - , so keep that in mind when youre writing test cases. 5.5.1 Abstract Syntax Refer to Type Environment for the definitions of TEnv and Type . define-type Expr e-num x Number e-bool x Boolean e-str x String e-op op Operator left Expr right Expr e-un-op op UnaryOperator expr Expr e-if cond Expr consq Expr altern Expr e-lam param Symbol arg-type Type body Expr e-app func Expr arg Expr e-id name Symbol e-let id Symbol value Expr body Expr e-empty elem-type Type define-type Operator op-plus op-append op-num-eq op-str-eq op-link define-type UnaryOperator op-first op-rest op-is-empty 5.6 Testing Guidelines For the purposes of testing, we have defined a type-check function that calls parse and type-of for you. type-check consumes an expression in Parets concrete syntax S-Exp and returns a Paret Type type-check S-Exp - Type You should use type-check in your testing file when writing test cases. You should not directly test type-of in your testing file. In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form test-raises-type-checker-error name expr type-checker-error Tests that the given expr raises the given type-checker-error . Example usage can be found in the testing stencil. 5.7 Starter Code Weve provided starter code for your implementation at type-checker.rkt and support code at support.rkt . You are not allowed to change the signature of type-check and type-of , but you are welcome to add any helper functions that you need for your implementation. Weve also provided a stencil for your type-check test cases at type-checker-tests.rkt and testing support code at test-support.rkt . You should check that you can run your type-checker-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing. 5.8 What To Hand In You will submit two files for this assignment type-checker.rkt , which should be uploaded to the Code drop on Gradescope. type-checker-tests.rkt , which should be uploaded to the Tests drop on Gradescope. You can update your submissions as many times as you want before the deadline. prev up next", "metadata": {"last_modified": "2020-11-30T13:40:11+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 1434, "token_count_estimate": 2050}}, "https://cs.brown.edu/courses/csci1730/2021/testing-guidelines-section.html": {"text_content": "Fall 2021 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Electronics Policy Staff Capstone Credits Assignments SMo L Mystery Languages Implementation Analysis Implementation 1 Stacks 1 2 Stacks 2 3 Interpreter 4 Stacks 3 5 Macros 6 OMac 7 SMo LTalk 8 Type Checker 9 Type Inference 10 ACI 11 Lazy 12 Generators 13 From Assertions to Security 14 Testing Guidelines 14 Testing Guidelines 14.1 Testing Guidelines On this page 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error- Handling 14.1.3 Check Your Understanding prev up next 14 Testing Guidelines 14.1 Testing Guidelines 14.1.1 Provided Library 14.1.2 Error-Handling 14.1.3 Check Your Understanding 14.1 Testing Guidelines In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. We grade your tests by running them against correct and incorrect solutions called wheat and chaff respectively that we have written to see whether your tests can tell the difference. In every Implementation assignment where we collect test cases, we will provide two additional files A test-support.rkt file. The test-support.rkt file provides specific testing forms that you should use when writing tests for the wheats and chaffs. You should not use any external testing library other than those specifically provided otherwise, we will not be able to grade your test suite. Please make sure to use the test-support.rkt file specifically provided with each assignmentsome assignments will have assignment-specific testing forms to help you when testing. A starter file in which you should write your test suite. This test suite will contain a defineprovide-test-suite test-suite-name ... statement, where test-suite-name is some identifier. You should make sure to write all of your test expressions within this statement otherwise, we will not be able to grade your test suite. The testing stencils provide examples of how to do this. While you should never include implementation-specific test cases within your testing file, you are welcome to and encouraged to write implementation-specific test cases within your implementation file. For example, you may find it helpful to write test cases against your helper functions. However, your implementation file does not have access to the forms defined in test-support.rkt , so youll need to use either Rackets or Plaits built-in testing utilities. 14.1.1 Provided Library You will always have access to the following forms test-equal name actual expected test-not-equal name actual expected Tests that actual and expected evaluate to the same value in the case of test-not-equal , different values. test-true name expr test-false name expr Tests that expr evaluates to t in the case of test-false , f . test-pred name pred expr Tests that expr returns a value that satisfies the given pred predicate. test-raises-error-with-substring name expr substr Tests if the given expr raises an error that contains the substring substr . Some assignments will have specific testing forms see the assignment specs for more information. 14.1.2 Error-Handling When we run your tests, they can result in an error either due to an intentionally raised error or a bug in a chaff. It is important that invocations of your functions in your tests are caught by a testing statement from our provided testing library, each of which will handle the error automatically. Without a testing statement to handle an error, the test running could terminate due to the error, and you will receive no credit. Thus, you should write this test-equal Works with Num primitive eval 2 2 v-num 4 However, dont write this define result eval 2 2 this is not caught by test-equal test-equal result v-num 4 That said, if you need to define intermediary variables in a test case, you can use a begin or let statement test-equal Multi-statement test case let result eval 2 2 result v-num 4 14.1.3 Check Your Understanding Implementation assignments that ask for test cases will have a Tests upload on Gradescope for you to submit your test cases. Prior to the assignment deadline, you are welcome and encouraged to upload your testing file to the Gradescope drop early . When you do this, Gradescope will automatically run all of the wheats and a subset of the chaffs against your test suite. Once its done running, it will immediately give you feedback on Whether your test suite passed all of the wheats Which of the starter chaffs your test suite caught We provide you this functionality to help you check your understanding of the problem and to encourage you to explore the more interesting edge cases in the specification. Specifically, the starter subset of chaffs on Gradescope are designed to help catch any misunderstandings of the problem statement you may have. However, when we evaluate the comprehensiveness of your final test suite, were going to run it against many more chaffs, which will mainly focus on errors that might occur during implementation. In other words, make sure you keep developing your test cases while youre implementing your functions, even if you caught all of the chaffs, since catching all of the initial Gradescope chaffs may not be sufficient to getting the highest possible evaluations on testing. prev up next", "metadata": {"last_modified": "2021-12-02T13:25:08+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 850, "token_count_estimate": 1101}}, "https://cs.brown.edu/courses/csci1730/2022/interpreter.html": {"text_content": "Fall 2022 Programming Languages Syllabus and Course Policies Assignments Diversity and Professionalism Staff Capstone Credits Assignments SMo L Mystery Languages Implementation Analysis Implementation 1 Interpreter 2 Macros 3 OMac 4 SMo LTalk 5 Type Checker 6 Type Inference 7 Lazy 8 From Assertions to Security 9 Testing Guidelines 1 Interpreter 1.1 Introduction 1.2 Assignment 1.3 Features to Implement 1.4 Grammar 1.5 Testing 1.6 Starter Code 1.7 What To Hand In On this page 1.1 Introduction 1.2 Assignment 1.2.1 Errors 1.3 Features to Implement 1.3.1 Desugaring 1.3.1.1 and and or 1.3.1.2 let 1.3.2 Environment 1.3.3 Binary Operators 1.3.4 Conditionals 1.3.5 Functions 1.4 Grammar 1.4.1 Abstract Syntax 1.5 Testing 1.5.1 How We Test Tests 1.5.2 Guidelines for Testing Your Interpreter 1.5.3 Debugging 1.6 Starter Code 1.7 What To Hand In contents prev up next 1 Interpreter 1.1 Introduction 1.2 Assignment 1.2.1 Errors 1.3 Features to Implement 1.3.1 Desugaring 1.3.1.1 and and or 1.3.1.2 let 1.3.2 Environment 1.3.3 Binary Operators 1.3.4 Conditionals 1.3.5 Functions 1.4 Grammar 1.4.1 Abstract Syntax 1.5 Testing 1.5.1 How We Test Tests 1.5.2 Guidelines for Testing Your Interpreter 1.5.3 Debugging 1.6 Starter Code 1.7 What To Hand In 1.1 Introduction For this assignment, you will write an interpreter for the Paret language pared-down Pyret described below. 1.2 Assignment We have provided a function parse which consumes an expression in the Paret languages concrete syntax, S-Exp , and returns the abstract syntax representation of that expression an Expr . parse S-Exp - Expr parse only accepts expressions that follow Parets grammar . You will implement two functions desugar and interp . desugar Expr - Expr which consumes an abstract syntax tree i.e. an Expr , as returned by parse , replaces all instances of syntactic sugar described below with desugared equivalents, and returns the result. interp Expr - Value which consumes a desugared abstract syntax tree i.e. the Expr returned by desugar and returns a Paret Value . interp should assume that its given an Expr from desugar . If interp is given an Expr containing a sugar- form, its behavior is undefined. Finally, interp should evaluate programs by performing a post-order traversal of the abstract syntax tree AST first, evaluate all of the children of an expression from left to right, then evaluate the expression itself. This makes it unambiguous which error to raise if there are multiple errors in the AST. Why evaluate our expressions from left to right One might say weve chosen this as a matter of convention, but ultimately the choice is completely arbitrary. Strictly speaking, we could define our language to evaluate sub-expressions from right to left and that would be just fine. Whats important is that an explicit evaluation order choice is made so the language has clearly defined semantics. Once you have implemented desugar and interp , you should use the provided eval function which wraps around those two functions and parse to write test cases for your interpreter. 1.2.1 Errors For throwing errors you can use Rackets error message convention which looks like error symbol message string where a symbol is written as a single quote followed by a variable. Such a symbol name can look like interp-error abc or xyz would also work but we recommend keeping useful names. Here is an example of how you can throw an error lang racket error interp-error unbound variable was found Some examples of expressions that should raise errors are lang racket str 5 bad hello false bad 6 not function 7 bad These should all throw the standard error as per the convention specified above. However, we recommend having useful messages in the strings to keep track of the types of errors and edge cases you are covering this also comes in handy when debugging 1.3 Features to Implement 1.3.1 Desugaring Racket macros, which youll write later in the course, are themselves syntactic sugar. However, we are not asking you to use Racket macros for anything in this assignment. As described previously, Paret contains several forms of syntactic sugar and , or , and let . desugar should convert sugar-and , sugar-or , and sugar-let Expr s into functionally equivalent, non-sugar Expr s. There are multiple implementation strategies for desugar . Be sure to test it well its easy to miss some details when desugaring 1.3.1.1 and and or and consumes two boolean expressions. It evaluates to true if both boolean expressions are true otherwise, it evaluates to false . or consumes two boolean expressions. It evaluates to true if at least one boolean expression is true otherwise, it evaluates to false . desugar should convert sugar-and and sugar-or Expr s in such a way that, when interp interprets the desugared code, and and or short-circuit . In and expressions, this means that if the first argument of and evaluates to false , the second argument to and is not evaluated and the and expression evaluates to false . Similarly, if the first argument of or evaluates to true , the second argument to or should not be evaluated. Thus, the second argument of a short-circuited expression should never throw an error. 1.3.1.2 let let should accept a single variable-value pair and a body. let evaluates the value, binds it to the variable, and evaluates the body with the newly bound variable in scope. For example, the following should evaluate to 3 lang racket let x 1 x 2 let should disallow recursive definitions. That is, in let var expr body , var should be bound in body but not in expr . The desugaring of sugar-let may not be obvious, so heres a hint What Expr s allow us to change the variables bound within a given environment 1.3.2 Environment Your interpreter should use an environment, Env , to keep track of the Value s of variables in scope. define-type-alias Env Hashof Symbol Value Since Env is a Hashof , you can use Plaits built-in hash table functions on your Env . For your environment, make sure you use hash , which creates immutable hash tables What happens if you use make-hash , which creates mutable hash tables instead Try replacing one with the other and see. If none of your tests fail, you arent testing enough You should have at least one failing test, if not several, when you make this switch. interp should allow variable shadowing , meaning that if you bind a variable that is already bound, the new binding takes precedence. When in doubt, your interpreter should behave just as SMoL would. When interp encounters an unbound variable, interp should raise an error. 1.3.3 Binary Operators Paret includes binary addition and number equality testing num , as well as string appending and string equality testing str . In place of having separate syntactic forms for each of , num , , and str , parse converts these operators into a single AST datatype variant, e-op , which denotes the operation to use via an Operator variant lang racket define-type Operator op-plus op-append op-str-eq op-num-eq When you implement these operators, you should use Plaits for op-plus , string-append for op-append , string for op-str-eq , and for op-num-eq . Evaluation should also raise an error for non-numeric values passed to and num operations, and for non-string values passed to and str operations. Here we throw an error when the operator is receiving the wrong type of value, for example lang racket true string 1.3.4 Conditionals if -expressions in Paret have three parts cond , which should evaluate to a Boolean Value consq , which evaluates if cond evaluated to true altern , which evaluates if cond evaluated to false if statements should short-circuit i.e. only evaluate the relevant branch. If cond evaluates to a non-Boolean Value , an error should be raised. 1.3.5 Functions Functions in Paret are unary i.e. they take exactly 1 argument. Heres two examples of functions and their applications lam x x 3 2 lam y 5 1 These should both evaluate to 5. Its possible that when attempting to perform a function application, the value in the function position isnt actually a function e.g., you might have 12 . In this case you should raise an error as well. 1.4 Grammar The grammar of Paret is as follows expr num string var variable a.k.a. identifier true false expr expr expr expr num expr expr str expr expr if expr expr expr and expr expr or expr expr let var expr expr lam var expr anonymous function expr expr function application 1.4.1 Abstract Syntax Refer to Environment for the definition of Env and Binary Operators for the definition of Operator . lang racket define-type Value v-num value Number v-str value String v-bool value Boolean v-fun param Symbol body Expr env Env define-type Expr e-num value Number e-str value String e-bool value Boolean e-op op Operator left Expr right Expr e-if cond Expr consq Expr altern Expr e-lam param Symbol body Expr e-app func Expr arg Expr e-var name Symbol sugar-and left Expr right Expr sugar-or left Expr right Expr sugar-let var Symbol value Expr body Expr 1.5 Testing We care that you test programs well. Programming langauge implementations are expected to be rock-solid whens the last time you ran into an implementation bug. You need to uphold this standard. This isnt a course in something like AI, where we dont even know what the right answer might be In addition to the quality and correctness of your code, you will be evaluated on the quality and correctness of your tests. 1.5.1 How We Test Tests Its probably useful for you to understand how we test your tests. Whats the job of a test suite i.e., set of tests Its to find errors in a program. Examples help you understand the problem before you start writing code, tests help you catch errors in the program as and after you write it. In short, test suites are like sorting hats, putting programs in a good or bad bin. If you are a mathy person, you might call a test suite a classifier . So, heres how we will test your test suites. We construct a collection of implementations for the problem. Some are known to be correct because we built them that way we call each of these a wheat . The others are known to be incorrect because we intentionally introduce errors we call each of these a chaff . Your test suites job is to separate the wheat from the chaff . That is, we will run each of the wheats and chaffs against your test suite and see what happens On a wheat On a chaff ------------------------------------------------ all tests passed GREAT Not great some tests failed Ooops GREAT All tests passing a wheat, and at least one test failing on a chaff, is exactly what we are hoping for. If all tests pass on a chaff, thats not ideal, but you may miss some chaffs, so it may be okay. But when any tests fail on a wheat, thats definitely a problem because it should never happen. It quite likely means youve misunderstood the problem statement, or perhaps the problem statement is ambiguous, or something like that. This should get cleared up right away. The quality of your test suite is then a measure of whether you passed the wheats and how many chaffs you caught. Of course, we can make the latter arbitrarily hard. For instance, we could define a chaff that always works correctly except when the given list has, say, exactly 1729 elements. We wont do things like that, both because its cruel and because real implementations are very rarely buggy in this way. Instead, we will make reasonable mistakes but not all of them will be easy. In short, we will be running your test suite against our implementations. Therefore, it is very important that when you turn in your test suite see details below, it not be accompanied by your implementation otherwise, when we try to load ours, DrRacket will complain. 1.5.2 Guidelines for Testing Your Interpreter Please read the Testing Guidelines for guidelines on how to write tests for the Implementation assignments. For the purposes of testing, we have defined an eval function that calls parse , desugar , and interp for you. eval consumes a program in the Paret languages concrete syntax S-Exp and returns a Paret Value eval S-Exp - Value You should use eval in your testing file when writing test cases. You should not directly test desugar and interp individually in your test file though you are welcome to and encouraged to individually test these functions in your code file. Theres good reason for this there is more than one correct desugaring, so any tests you write may be implementation-specific. And, of course, your submitted test cases should indirectly test desugaring, because you should test that and and or let work correctly. In addition to the testing forms documented in the Testing Guidelines , we provide the following testing form test-raises-error test-name expr Tests that the given expr raises an error. Example usage can be found in the testing stencil. Finally, recall that programs can evaluate to functions. However, you may have chosen a different representation for closures than we did. Therefore, your tests in your test file should only check that such a program returned a function, and not rely on the specific function returned because of the differences in representation. For instance, you may write test-pred My predicate test v-fun eval lam x 5 t Reminder In Plait, you can add a to the end of the name of any given type variant to create a function that returns true if the expression evaluates to that type variant. However, you may not write test-equal Dont write this test eval lam x 5 v-fun x e-num 5 hash list because our representation of closures may not match your exact representation. You are, of course, welcome to write test cases of the latter form in your code file. 1.5.3 Debugging You may find it useful to use Plaits trace to help understand the control flow of your interpreter. For instance, if you write trace interp then all subsequent calls includingand especiallyrecursive calls to interp will be presented with their arguments and results. Do not include calls to trace in your final submissions. 1.6 Starter Code Weve set up a GitHub Classroom assignment that contains all necessary stencil code and support code here . Weve provided starter code for your implementation at interpreter.rkt and support code at support.rkt . You are not allowed to change the signature of eval , desugar , or interp , but you are welcome to and might need to add helper functions for your implementation. Weve also provided a stencil for your eval test cases at interpreter-tests.rkt and testing support code at test-support.rkt . You should check that you can run your interpreter-tests.rkt file successfully in DrRacket before submittingif you cant, it means that a definition is missing or youre trying to test a function that you shouldnt be testing e.g. a helper function or interp or desugar directly. Do not modify the contents of support.rkt and test-support.rkt . 1.7 What To Hand In You will submit to two Gradescope drops for this assignment interpreter.rkt , which should be uploaded to the Code drop on Gradescope. interpreter-tests.rkt , which should be uploaded to the Tests drop on Gradescope. You may also select the entire interp repository to submit to both drops on Gradescope. You can update your submissions as many times as you want before the deadline. contents prev up next", "metadata": {"last_modified": "2022-12-16T14:38:50+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 2602, "token_count_estimate": 3340}}, "https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdDVtFFyFD9zYmpdvcjwPMSWQQqVSkL_zQXWLtCjZPLVA_Vng%2Fviewform&followup=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdDVtFFyFD9zYmpdvcjwPMSWQQqVSkL_zQXWLtCjZPLVA_Vng%2Fviewform&ifkv=ATuJsjxNkUpn4ajdCkNomphqpmtbBaqbETOQBqD_1Ui18My31VLTu14JZZAl3ZKAtOQ77Ul-Odzq9g&ltmpl=forms&osid=1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-1475883527%3A1710368122833669": {"text_content": "Sign in to continue to Forms Email or phone Forgot email Not your computer Use a private browsing window to sign in. Learn more about using Guest mode Next Create account", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Sign in"], "word_count": 31, "token_count_estimate": 32}}, "https://cs.brown.edu/courses/csci1680/f23/": {"text_content": "CSCI1680 Computer Networks Fall 2023 Home Lectures Assignments CalendarHours Staff Resources Policies Quick links Zoom Join lectures here EdStem Used for announcements, online questions, etc. Gradescope Submit homework and exams here, and receive grades for all assignments Panopto View recorded lectures here Hours Used to manage queuing for allone-on-one office hours Extension request form Used to manage queuing for all one-on-one office hours At-a-glance CSCI 1680 is an undergraduate course in computer networks. We will coverthe technologies supporting the Internet, from Ethernet and WiFithrough the routing protocols that govern the flow of traffic, andthe web technologies that are generating most of it. A major concern isunderstanding the protocols used on the Internet how they work, theirshortcomings, what the issues are, and what improvements are on the horizon. Lectures TTh 0900-1020 EDT All lectures will be recorded and streamed live via Zoom . Location CIT 368 Prerequisites Students are expected to have taken an introductorysystems course, eg. CSCI 0330, CSCI 0300, CSCI 1310, CSCI1330, or musthave consent of the instructor. If you have questions about whether this course is a good fit for you,please feel free to contact the instructor Learning Goals This course teaches the principles behind the organization ofcomputer networks, from those connecting two computers to one of thelargest technological systems we have ever built, the Internet. Thisknowledge can be useful at multiple levels, from building your ownnetworked programs, designing new communication protocols as newtechnologies arise, debating whether networkproviders can treat different types of traffic differently orgovernments can eavesdrop on conversations, and understanding how,for example, Pakistan could at one point inadvertently bring downYoutube for half of its users. We teach you about layering and the end-to-end principle, abouthow to encode information to be transmitted by manipulating somephysical property of a medium, how to scale communications beyond afew nodes through hierarchy and through more sophisticated lookupstructures, how the Internet works at the local and global levels,including how its connected computers can share the capacity of thelinks between them with some notion of fairness. We teach you howthe Web, Bittorrent, Netflix, and other applications work, includinghow to write your own. We teach you how wireless communications workat a basic level, and how the issues involved in trying tocommunicate securely. The course uses two main learning mechanisms classroom lectures bythe instructor with some live demonstrations, and hands-on programmingprojects. Homework assignments aredesigned to give you more practice with the theory and designaspects of networking. The four projects aim to give you substantialexperience in building and using networked programs. Except for thefirst project, projects are done in pairs, and have, for the mostpart, little support code. These assignments are designed to helptrain you to work in groups, as in almost no software engineeringcareer will involve working alone, and to help strengthen yoursoftware design skills. You can complete projects in any of foursystems programming languages C,C, Go, or Rust, which all of these have similar networking APIs, tohelp you build your software skills in a direction of your choosing. Topics For a list of topics, see the Schedule . Expected workload Coursework consists of 4 programming projects, 6 written homeworks,and weekly post-lecture quizzes. This course does not have exams.For more details on what each assignment entails, see CourseMechanics . In addition to 3 hours per week in lecture 36 hours total, youshould expect to spend 3-4 hours on each homework assignment, with themajority of your time dedicated to the four projects, which arelong-term programming assignments. The first and last project shouldtake between 2030 hours each, and the larger projects should take5060 hours each, with the work spread out over several weeks. Intotal, you should expect your time commitment will be at least 180hours over the course of the semester. Perhaps the single most important advice for this class is to startthe projects early and work steadily over the assigned time donot leave the projects to the final week or days before thedeadline . Each project has intermediate milestones before thefinal deadline, which aim to provide feedback midway and stimulateearly progress. 2023 Nick DeMarinis Site powered by Jekyll Minimal Mistakes Department of Computer Science Brown University All materials on this site are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License . Title image courtesy of The OPTE Project .", "metadata": {"last_modified": "2023-12-14T19:22:24+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Quick links", "At-a-glance", "Learning Goals", "Topics", "Expected workload"], "word_count": 705, "token_count_estimate": 940}}, "https://cs.brown.edu/courses/csci1800/lectures.html": {"text_content": "C Lectures - CSCI 1800 Toggle navigation CS1800 Home Assignments Calendar Lectures Readings Sections Resources Staff 2020 Lectures Readings Lectures Lecture Date Lecture Topic Class Notes Readings Technology Policy Overview 01 January 22 Introduction Click for Readings Required Readings World War C The New Cybernormal Carnegie Reporter, June 7, 2018 The 2018 State of the Digital Union Optional Resources Strengthening Federal Cybersecurity Results of the Cyber Innovation Ideation Initiative , December 2015. True tales of mostly white-hat hacking Cyber-Security as an Academic Discipline 02 January 27 Policy Overview Click for Readings Readings Compare and contrast themes bw U.S. administrations International Strategy for Cyberspace Prosperity, Security, and Openness in a Networked World, by The White House, May 2011 National Cyber Strategy of the United States of America, by The White House, September 2018 Lucas Kello, The Meaning of the Cyber Revolution Perils to Theory and Statecraft International Security 2013 Optional Resources The Wests Crisis of Confidence by Carl Bildt, Project Syndicate, April 19, 2018 Under the Sea The Vulnerability of the Commons , Foreign Affairs Magazine, JanuaryFebruary 2015 Issue. Trump Us Cyber Diplomacy Lessons from the First Great Cyberwar Era , A. M. Rutkowski, Info, Vol. 12, No. 1, February 2010. 60 Minutes Show on Cyber War Sabotaging the System 12 , June 13, 2010. A minute video. 03 January 29 Intro to Hardware and Software Click for Readings Readings How the Internet Got Its Rules How a 22-Year-Old Discovered the Worst Chip Flaws in History by Jeremy Kahn, Alex Webb, and Mara Bernath, Bloomberg Technology, January 17, 2018 What He Did on His Summer Break Exposed a Global Security Flaw by Isabella Kwai, The New York Times, January 30, 2018 Optional Resources A Tiny Computer Attracts a Million Tinkerers , by John Biggs of the New York Times. Computer Architecture 04 February 3 Hardware and Software Vulnerabilities Click for Readings Readings Definition of a security vulnerability. Common web vulnerabilities explained. Software Security The Million Dollar Dissident , by Bill Marczak and John Scott-Railton, August 2016 Optional Resources Intel Speculative Chip Vulnerability EU Bug Bounties 05 February 5 The Role of Intelligence and Information Sharing Mike Steinmetz, President, Digital Executive and Director and General Partner, College Hill Ventures Guest Click for Readings Readings 18 U.S. Code B 1385 - Use of Army and Air Force as posse comitatus , Legal Information Institute, Retrieved, January 13, 2020 Emergency Management and National Guard DutiesAuthorities , Retrieved January 13, 2020, Executive Order Improving Critical Infrastructure Cybersecurity , The White House, February 12, 2013 Executive Order 13691, Promoting Private Sector Cybersecurity Information Sharing , The White House, February 13, 2015 Intelligence Reform and Terrorism Prevention Act of 2004 Obama Administration Releases Long Awaited New E.O. 12333 Rules on Sharing of Raw Signals Intelligence Information Within IC by Jane Chong, LAWFARE, January 12, 2017 How the IC Works , Office of the Director of National Intelligence, 2009 Presidential Policy Directive 21 Implementation , Interagency Security Committee, February 2015 Security Breach and Spilled Secrets Have Shaken the N.S.A. to Its Core New York Times, November 12, 2017 Worldwide Threat Asessment of the US Intelligence Community , by Daniel R. Coats, Director of National Intelligence, January 29, 2019 06 February 10 Design and Operation of the Internet Click for Readings Readings Beginners Guide to Internet Protocol IP Addresses Packets, routers, and reliability This is a six minute, 25 second video narrated by Vint Cerf, one of the Fathers of the Internet 07 February 12 Internet Naming and Routing Protocols Click for Readings Readings Chapter 6.1 of Introduction to Computer Security . Please use the password in class email to access. Chapter 6.1 required the rest of the chapter for reference. Understanding Autonomous Systems Optional Resources Intro to BGP4, inter-AS routing February 18 Long Weekend Security 08 February 19 Cyber Exploits Click for Readings Readings The Security Dilemma of Cyberspace Ancient Logic, New Problems , by Lucas Kello, 2017 The New Norm Trend Micro Security Predictions for 2020 US Electrical Grid Hacked By Russia Wired Guide To Data Breaches Optional Resources Deep Web and Cyber Crime Wikileaks Files Show the CIA Repurposing Hacking Code to Save Time, Not to Frame Russia by Kim Zetter, The Intercept, March 8, 2017 Economic Impact of Cybercrime No Slowing Down , McAfee and CSIS, February 2018 Leaked Files Show How the NSA Tracks Other Countries Hackers by Kim Zetter, The Intercept, March 6, 2018 09 February 24 Attribution and Privacy Click for Readings Readings Attributing Cyber Attacks , Rid and Buchanan. Beyond Attribution Seeking National Responsibility for Cyber Attacks , Jason Healey, 2011 Originally published in the Brown Journal of World Affairs A Guide to Cyber Attribution , Office of the Director of Natl Intelligence, September 2018 4 Pages Optional Resources A Survey of Challenges in Attribution The Dark Side of the Digital Revolution Examines the approach taken by autocratic governments to obtain control over Internet communications. 10 February 26 Major Cyber Attacks Click for Readings Readings Stuxnet and the Limits of Cyber Warfare by Jon R. Lindsay, Security Studies , August 2013 Inside Project Raven USA Karma Web War I The Cyberattack that Changed the World. Optional Resources Significant Cyber Incidents CSIS large database of prominent cyber attacks since 2006. APT1 Exposing One of Chinas Cyber Espionage Units , Mandiant, 2013. Advanced Persistent Threats ASymantec Perspective , Symantec Exploit Kits published by F-Secure. SON OF STUXNET The Digital Hunt for Duqu, a Dangerous and CunningU.S.-Israeli Spy Virus by Kim Zetter, TheIntercept, November 12, 2014 11 March 2 Secure Communications and Authorization Click for Readings Readings The 2013 Symantec Internet Security Threat Report , Volume 18, published April 2013. Mark Risher on Google Advanced Protection , The Lawfare Podcast, October 2018 Ed Snowden taught me to smuggle secrets past incredible danger. Now I teach you. Optional Resources NIST Cryptographic Standards and Guidelines Development Process. Todd Lindeman. A Connected World. Michael Horowitz. A Chromebook offers Defensive Computing when traveling. 12 March 4 Cyber Conflict Click for Readings Readings Joseph S. Nye, Deterrence and Dissuasion in Cyberspace , International Security 2017 Cyber War will not Take Place by Thomas Rid, Journal of Strategic Studies, October 2011 Erik Gartzke, The Myth of Cyberwar Bringing War in Cyberspace Back Down to Earth , International Security 2013 Optional Resources Lora Saalman. Little Grey Men China and the Ukraine Crisis. Fergus Hanson. Norms of Cyberwar in Peacetime. Tipping the Scales the attribution problem and the feasibility of deterrence against cyberattack. Treasury and Justice officials pushed for economic sanctions on China over commercial cybertheft. Exaggerating Chinese Cyber Threat. Economics 13 March 9 Bitcoin and Blockchains Click for Readings Readings Block Chain 2.0 The Renaissance of Money. Banking Is Only The Beginning 55 Big Industries Blockchain Could Transform , 2019 Whats Blockchain Actually Good For, Anyway For Now, Not Much. , 2019 Optional Resources Heres one easy way to get exposure to bitcoin ahead of the Winklevoss ETF. Inside the Jordan Refugee Camp that Runs on Blockchain , 2018 14 March 11 Cyber Economics Click for Readings Readings Peter W. Singer. The Oceans 11 of Cyber Strikes. Ken Hu. As Technology Advances, Heres How to Make Sure No One is Left Behind , 2020 Data Breach Response A Guide for Business , Federal Trade Commission 2019 Ernst Young on 48th Davos World Economic Forum , 2018, Translated from original Russian 15 March 16 Canceled Internet Governance 16 March 30 Transborder Issues Click for Readings Readings The Way Forward Working Together to Tackle Cybercrime , speech by FBI Director Wray, 2019 What we can learn from ISIS about using the internet to counter terrorism , 2018 How the U.S. Hacked ISIS , a podcast episode by NPR, 2019 MayIt Please the Court .5 pages A Primer on Microsoft Ireland, the Supreme CourtsExtraterritorial Warrant Case 2.5 pages Optional Resources The CLOUD Act, S.2383H.R. 4943 Coalition Letter on CLOUD Act 17 April 1 Internet Governance Click for Readings Readings Milton L. Mueller. Network and States The Global Politics of Internet Governance, pp.1-13. Joseph S. Nye, Jr. The Regime Complex for Managing Global Cyber Activities. Matthias Spielkamp. Internet governance - why you should care. Bruce W. McConnell John E. Savage. Exploring Multi-Stakeholder Internet Governance. Follow download link. Read pp.2-10. Optional Resources Nationalistic Hierarchies vs Multi-stakeholder Networks. ICANN, Russia, China and Internet Reform. The Clarifying Lawful Overseas Use of Data CLOUD Act , signed into law in March 2018, is explained in this article by the Electronic Privacy Information Center EPIC. The WIRED Guide to Data Breaches by Lily Hay Newman, Wired, December 7, 2018 GDPR impact complex, expert warns by Warwick Ashford, Computer Weekley, November 15, 2017 Cross-Border Data Sharing Under the CLOUD Act What is net neutrality 18 April 6 International Norms Process Click for Readings Readings From Articulation to Implementation Enabling progress on cybersecurity norms. In Cyberwar there are no rules Jay Healey and Tim Maurer. What itll take to forge peace in cyberspace , Christian Science Monitor, New Dimensions, March 2017 Tim Maurer. Cybersecurity in a Complex Environment Translantic Divergence and Diplomatic Achievements. Optional Resources Richard Boucher. Watching Cybernorms Get Made. Whats Next for the U.S. and China in Cyberspace. The Norm against Economic Espionage for the Benefit of Private Firms Some Theoretical Reflections. The 2015GGE Norms Contemporary Topics 19 April 8 Social Media and Propaganda Click for Readings Readings The Global Disinformation Order 2019 Global Inventory of Organised Social Media Manipulation , The Oxford Internet Institute, 2019 The Existential Threat from Cyber-Enabled Warfare , Herbert Lin, 2019 Information operations on Twitter principles, process, and disclosure , Twitter, 2019 How We Respond to Inauthentic Behavior on Our Platforms , Facebook, 2019 Can New Forensic Tech Win War On AI-Generated Fake Images by Steven Melendez, FastCompany, April 4, 2018 Optional Resources Russia Deployed Its Trolls to Cover Up the Murder of 298 People on MH17 , 2019 Can New Forensic Tech Win War On AI-Generated Fake Images by Steven Melendez, FastCompany, April 4, 2018 Report Haglund was quick to pick up on Russias information campaigns How IT Threatens Democracy by Kofi Annan The Big Loophole That Helped Russia Exploit Facebook Doctored Photos The Psychology Of Fake News Video Resources Inside Russias Network of Bots and Trolls Synthesizing Obama Learning Lip Synch from Audio Real-Time Face Capture and Reenactment of RGB Videos Sneak Peek at VoCo, Adobes audio editor How To Spot A Deepfake Like The Barack ObamaJordan Peele Video by Craig Silverman, BuzzFeed, April 17, 2018 This deepfake video starring Jordan Peele as Barack Obama shows how easy its getting to create convincing audio and video fakes. Heres how to fight back. Face2Face Real-Time Face Capture and Reenactment of RGB Videos . The techniques used to produce this video are described here . 20 April 13 AI and Ethics Click for Readings Readings The WIRED Guide to Artificial Intelligence , 2018 Artificial Intelligence and EthicsEthics and the dawn of decision-makingmachines by Jonathan Shaw, HarvardMagazine, January-February, 2019 Artificial Intelligence Rules More of Your Life. Who Rules AI by Heidi Vogt, The Wall Street Journal, March 13, 2018 One Month, 500,000 Face Scans How China Is Using A.I. to Profile a Minority , NYT, 2019 Optional Readings 2018 ACM Code of Ethics and Professional Conduct Draft 3 The Business of War Google Employees Protest Work for the Pentagon by Scott Shane and Daisuke Wakabayashi, The New York Times, April 4, 2018 Artificial Intelligence Seeks an Ethical Conscience by Tom Simonite, Wired, December 7, 2017 The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems 21 April 15 Engineering for Security Click for Readings Readings Making Security Sustainable by Ross Anderson, Communications of the ACM, Vol. 61 No. 3, Pages 24-26, 2018 Cybersecuritys Human Factor Lessons from the Pentagon by James A. Winnefeld Jr., Christopher Kirchhoff, and David M. Upton, Harvard Business Review, September 2015 Rethinking Cybersecurity Strategy, Mass Effect, and States by James Andrews Lewis, Center for Strategic and International Studies, January 9, 2018 Security Development Lifecycle OWASP Top Ten Surviving in the cyber wilderness By Peter Loshin, TechTarget, December 7, 2017 22 April 20 Defense in Depth Click for Readings Readings Thomas Rid. Think Again Cyberwar , Foreign Policy, MarchApril, 2012 John Arquilla. Cyberwar Is Already Upon Us , Foreign Policy, MarchApril, 2012xs Ellen Nakashima. U.S. accelerating cyberweapon research , Washington Post, March 18, 2012. Video Resources NSA TAO Chief on Disrupting Nation State Hackers by Rob Joyce, USENIX Enigma Conference, January 28 2016 3455 minutes Optional Resources 2015 DoD Law of War Manual 1200 Pages -- for reference only DavidSanger. A Eureka Moment for Two Times Reporters North Korea 23 April 22 Future Directions Click for Readings Readings Alternate Cybersecurity Futures , The Atlantic Council, 2019 Diversity in Cybersecurity , by John Knight, Jack Davidson, Anh Nguyen-Tuong, Jason Hiser, and Michele Co, Computer, 2016 Shuffler Fast and Deployable Continuous Code Re-Randomization by King, Gobieski, Williams-King, Blake, Yuan, Colp, Zheng, Kermerlis, Yang and Aiello, OSDI, 2016 21 April 13 Cyber Threats Minds and Machines Both At Risk, Vinh Nguyen, National Intelligence Council Guest", "metadata": {"last_modified": "2020-04-22T17:54:13+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["2020 Lectures & Readings"], "word_count": 2160, "token_count_estimate": 3201}}, "https://cs.brown.edu/courses/csci1820/": {"text_content": "CSCI 1820 Algorithmic Foundations of Computational Biology Welcome to CSCI 1820 What is computational biology Computational biology is an interdisciplinary field which draws upon computer science, biology and mathematics. Much biological research today relies on powerful high-throughput computational tools which apply theoretical computation principles and statistical methods to gain insights into vast datasets, enabling advances in genomics, biochemistry, epidemiology, and personalized medicine. This fundamental pairing harnesses both rigorous computational approaches to solving complex problems and centuries of biological study to infer new knowledge, verify novel findings, and probe the frontiers of current understanding. In CSCI 1820, youll not only learn about both seminal and cutting-edge algorithms in the field of computational biology, but also have the opportunity to implement them yourself and see their power in action", "metadata": {"last_modified": "2020-01-16T20:39:23+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["CSCI 1820", "Algorithmic Foundations of", "Computational Biology", "Welcome to CSCI 1820!"], "word_count": 127, "token_count_estimate": 158}}, "https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdidNOnBgQGuES0uafuVXwLOqx-1HxX8Ulib1YJot5bYwARDw%2Fviewform%3Fusp%3Dsend_form&followup=https%3A%2F%2Fdocs.google.com%2Fforms%2Fd%2Fe%2F1FAIpQLSdidNOnBgQGuES0uafuVXwLOqx-1HxX8Ulib1YJot5bYwARDw%2Fviewform%3Fusp%3Dsend_form&ifkv=ATuJsjz62ccmQOLX5FHeo65RRMDIQQQKktoGjj38NML6EVvzWPNQylfjcI1TG2g9YSlTdPv3iMHWnQ&ltmpl=forms&osid=1&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1863184646%3A1710368122981222": {"text_content": "Sign in to continue to Forms Email or phone Forgot email Not your computer Use a private browsing window to sign in. Learn more about using Guest mode Next Create account", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Sign in"], "word_count": 31, "token_count_estimate": 32}}, "https://cs.brown.edu/courses/csci1950-h/": {"text_content": "Home Asgns Docs Staff Resources Announcements 1222015 HW0 is out its due before Tuesdays class. CS195-H is primarily aimed at JuniorSenior MathCS concentrators who have taken a 100-level math course that involves some topology e.g., MA106, MA141, MA126, ... and who know how to program, and preferably have some experience with Matlab andor Mathematica Click here for a very brief tutorial of Matlab. Class will meet 100-220 pm on Tuesdays and Thursdays in CIT 316 .", "metadata": {"last_modified": "2015-01-22T21:08:35+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 76, "token_count_estimate": 110}}, "https://brown-cs181-fall22.github.io/": {"text_content": "Home Resources Lectures Assignments Calendar Staff CS181 WELCOME TO CS 181, COMPUTATIONAL MOLECULAR BIOLOGY QuickLinks Syllabus Collaboration Policy Late Policy Gradescope EdStem Anonymous Feedback Form Course Information The aim of this course is to provide an introduction to computational molecular biology. The course is organized into six chapters Sequence Alignment Combinatorial Pattern Matching Phylogenetic Trees Hidden Markov Models Genome Assembly Genomic Privacy Each chapter is devoted to a class of basic computational problems related to the analysis of DNA, RNA, and protein sequences and their molecular function. Our journey in each chapter is driven by a set of beautiful algorithms. A beautiful algorithm is one that is rigorous, practical, elegantly simple, and easy to implement. In addition to these beautiful algorithms, each chapter contains a Foundations section that gives a detailed presentation of the biological problems discussed as well as the theoretical computer science and statatistical results that led to the invention of the algorithms. This class provides a serious introduction to the field of computational biology both for potential concentrators and for those who may take only a single course in the subject. Historical note CS181 was first taught at Brown 23 years ago by Professor Franco Preparata i.e. before the completion of the Human Genome Project. This years offering is the 24rd incarnation of this foundational course in computational biology. See the Resources page for a biology primer written by Prof. Preparata. FAQ Who takes the course As an interdisciplinary course, CS181 attracts a diverse group of students. Past students have ranged from sophomores concentrating in Computer Science and Computational Biology through Ph.D. students in Computer Science, Applied Mathematics, and Biology. The course staff will do its best to ensure that all students have a chance to succeed. Please do not hesitate to talk to a member of the course staff if you have trouble deciding whether CS181 is a good fit for you. What biology background is needed There are no biology prerequisites, and no prior biology knowledge is assumed the material that you need to know will be covered in class. Students whose backgrounds are in the life sciences, however, will be expected to dig deeper into the biology. What computer science and mathematics background is needed Officially, one of CS16, CS18, CS200, or CS19 i.e. a yearlong introduction to computer science. This can be waived by the instructor especially for life science students. Students in the course generally have some prior exposure to basic concepts of discrete math graphs, recurrence relations, discrete probability random variables, independence, and algorithms big-O notation, pseudocode. What programming background is needed This is not a programming-heavy course, although there will be programming assignments. The goal of these assignments is to gain a deeper understanding of the algorithms by implementing them and testing them on real data. Thus, some rudimentary programming skills arrays, loops, functions, etc. are required. Any language can be used, but common languages like Python will make it easier for the TAs to help you. I am experienced in molecular biology, but do not have any formal mathematical or computational training. Can I take the course We attempt to make the course genuinely accessible for students without a computer science background. At the same time, all students in the class should be prepared to complete medium-scale programming assignments, learn some new mathematical concepts, and reason about algorithms in a rigorous manner. Please reach out to a member of the course staff if you are unsure of your background. I am interested in learning how to analyze -Seq data from my advisors lab. Will this course help me Possibly, but perhaps not in the way that you expect. The goals of CS181 are to teach the algorithmic concepts that underlie a wide variety of software that is used to analyze biological data, particularly in genetics, genomics, and proteomics. The course will not teach you how to use any particular biological software package. Rather, you will learn how this software works, and more importantly for the long-term, how to think about biological problems in a computational way. Thus, when the latest and greatest technology for measuring DNARNAprotein is released in 5 or 10 years time, you will have some algorithmic skills to work with this data, without waiting for the rest of the community to develop tools. If your interests are more narrowly focused on a particular, near-term application, another course might be more appropriate. Can I get graduate credit for this course Yes To get it, you will need to do all undergraduate coursework in the class plus a final research project defined in discussions with the professor. Work for the final project consists of 1 a piece of code implementing a new algorithm or analysis or simulation, 2 a short written paper about your project and algorithmscode, and 3 a comprehensive powerpoint and a final project presentation to the class. Please email the professor for more information about this. made with by ezhang29, hvenkata, and the fall 2022 staff based on work by glee73 and others", "metadata": {"last_modified": "2022-12-13T20:52:16+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 838, "token_count_estimate": 1008}}, "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/calendar.html": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2018 Calendar Home Syllabus Calendar People Gallery Links Project Ideas How to Hand Stuff In How to We use a Google Team Drive to manage group emails and submissions. Please email the TA your prefered email accounts and we will add you as a member e.g., send Fumeng both your personal and brown accounts. Inside the drive, you deliver your assignments to the subfolder theduedate yourBrownShortID .ext. For example, Fumeng could upload her first assignment to 09-11-2018 as fyang7.txt . Due All handins are due by 9AM the same day of class to allow for review before class. Please get your reviews and readings done in time. A significant aspect of the class is to get different points of view for interdisciplinary research problems. Itll make classes much more fun and valuable if everybody participates and expresses an opinion. Its not fair to others to make them always carry the weight of leading the discussions. Prepare for a dynamic and open discussion in almost every class. How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright issues. These links will appear styled like this , as opposed to the public links . The userpwd is specific to the Vis group website VisWeb it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it well give it out the first day of class. Almost all of the readings we will do are online to reduce copying effort and costs, and to keep color imagery intact. Printing them for your own use is fine. Please look at the color images in color, though Some of the files are pretty big 40-50 Mb. Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 back to top Date Topic Assignment Thu 96, 2018 Introduction Goals Organization Schedule Definition of Visualization To Do Send Fumeng fumengyang at brown.edu two things 1 your prefered gmail accounts and 2 a small photo of yourself to include on the website Fumeng will send your the username and password to access the protected files. Test if you can use the team drive after Fumeng adds you. Week 2 back to top Date Topic Assignment Tue 911, 2018 Open problems in Visualization What makes a good problem Reading Read before class, with an eye toward your essay Toolsmith II paper Brooks - this describes how to do computer science, which is the home discipline for scientific visualization. Top Scientific Visualization Research Problems Johnson one of the following Visualization in Scientific Computing McCormick, DeFanti, Brown - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of whats in them when you need the information there later. Computational Science Ensuring Americas Competitiveness Presidents Information Technology Advisory Committee, also CRA NIH Workshop Recommendations and httpwww.nitrd.govpubs Top 10 Unsolved Information Visualization Problems Chen suggested reading Part of a lobbying effort for national funding, the Data and Visualization Corridors gives a 1999 perspective on what was limiting progress in high-end visualization. Read the executive summary and quickly flip through the rest of the document to get a feel for more research topics. Bill Hibbards vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables 9am Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 913, 2018 Review and discuss NSF ITR proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal Watch this animation on YouTube about NSFs review process NSF Grant Proposal Guide 2004 describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Skim whole thing Read I.B, II.C.2.a-f, II.C.2.h-k, III intro, III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research ITR Program Announcement . Typically, NSF accepts both unsolicited grant applications for whatever a proposer thinks is worth doing and solicited applications. Applications are solicited via a Program Announcement PA, sometimes called a Request for Proposals RFP. This is one example of what they are looking for. Read proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You dont need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. After writing your own review see Deliverables, read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables 9am Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of four possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborators list - You will need to meet with at least three of the four possible collaborators and report on those meetings on 925. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what youll need to hand in as a report . Coordinate with other class members for interviewing to avoid duplicating collaborator effort. Week 3 back to top Date Topic Assignment Tue 918, 2018 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images Laidlaw Evaluating project possibilities Reading NSF Faculty Early Career Development CAREER Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images Laidlaw. This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. After writing your own review see Deliverables, read NSF reviews of the proposal, then add any new discussion questions to your review. Deliverables 9am Write your own review using this form of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 920, 2018 VR demos in the YURT Discuss project ideas Note Class will meet at the YURT 180 George Street Reading Read Request For Proposals RFP Browse previous CSCI2370 proposals linked on the Ideas page Deliverables 9am Three possible proposal titles as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Week 4 back to top Date Topic Assignment Tue 925, 2018 Review and discuss NIH proposal Quantitative Inverse Electrocardiography Johnson Reading Read Quantitative inverse electrocardiography Johnson. This proposal is more than 15 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualization of bioelectric fields , MacLeod et al. Read NIH guide to proposals , focusing on the specification of a proposal pg. 1-16, research plan details pg. 17, review criteria pg. 34, and other interesting and relevant parts you find Read this PowerPoint presentation about the NIH proposal review process Deliverables 9am Interview reports as yourBrownShortID.txt Your review of Johnsons NIH grant as yourBrownShortID-2.txt Thu 927, 2018 Review and discuss NSF proposal Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science Laidlaw et al. Reading Read MRI Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science Laidlaw et al. Skim HCC Small Collaborative Research Immersive Visualization and 3D Interaction for Volume Data Analysis Bowman, Socha, and Laidlaw and CHS Small How Much Virtual Reality is Enough Deliverables 9am Your review of the Cave proposal as yourBrownShortID.txt Week 5 back to top Date Topic Assignment Tue 102, 2018 Visualization tools Visualizing multi-dimensional data Reading Read Visualization Handbook s table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project Google for the authors web pages and see what other stuff they are working on. If youre interested in reading more, the book is available at the Sciences Library SciLi. Deliverables 9am Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Look here Question 3 Where do I search for research papers for links to research publications. Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. Thu 104, 2018 more Visualization Handbook Deliverables 9am Sign up for a presentation time in the spreadsheet posted in the Google drive Collaborators Meetings Proposal Presentations top-level, the same file used for collaborators meetings, but use the second tab. Preliminary proposal handed in as yourBrownShortID.pdf A template for your proposal can be downloaded here. See the README inside for more instructions. Make sure your proposal is saved as a pdf. Week 6 back to top Date Topic Assignment Tue 109, 2018 Proposal presentations Reading Begin reading proposals from the shared Google Team Drive 10-11Preliminary Proposals Deliverables 9am Presentation slides handed in as yourBrownShortIDslides.pptx or pdf Thu 1011, 2018 Improving proposals and examples Walking Walking-in-Place Flying Evaluating visualizations Reading Walking Walking-in-Place Flying, in Virtual Environments , Usoh et al., In Proceedings of SIGGRAPH, 1999. Empirical Studies in Information Visualization Evaluation Seven Scenarios , Lam et al., IEEE TVCG 18, 9 September 2012. Read proposals from the shared Google Team Drive 10-11Preliminary Proposals Deliverables 9am Find your review assignment within the same folder the top level of the shared drive. Review of the first-draft proposals assigned to you. Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Fumengs proposal, he should hand in a file called fyang7bydhl.txt. Week 7 back to top Date Topic Assignment Tue 1016, 2018 Walkthrough of a project budget Insight-based evaluation what is it, and should you use it Link to paper for in-class activity An Insight-Based Methodology for Evaluating Bioinformatics Visualizations , Saraiya et al., TVCG, 2005. Deliverables 9am Final proposal handed in as yourBrownShortID.pdf Thu 1018, 2018 Study section evaluate, score, fund proposals Link for in-class activity Table of linked reviews and NIH-style proposal scores TBD Reading Read final proposals from the shared Google Team Drive 10-18allproposals.pdf Find your in the spreadsheet posted within the same folder the top level of the shared drive. Deliverables 9am Review the final proposals assigned to you. For the final proposals, you only need to hand in reviews for the three proposals where you are R1, R2, or R3. You must read the proposals for which you are R3R4 and be prepared to discuss them in class. Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Fumengs proposal, he should hand in a file called fyang7bydhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Week 8 back to top Date Topic Assignment Tue 1023, 2018 No Class IEEE Visualization Conference in Berlin, Germany Start the CITI online course , which will certify you to perform human subjects research, like user studies, at Brown. Thu 1025, 2018 No Class IEEE Visualization Conference in Berlin, Germany Finish the CITI online course and send your passing Completion Report pdf to the TA. If you do not pass on your first try, you must retake the quizzes until you receive a passing grade. Week 9 back to top Date Topic Assignment Tue 1030, 2018 Class cancelled Deliverables 9am Hand in a summary statement on your Primary proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposerbyyourBrownShortID .txt. Thu 111, 2018 Class cancelled Week 10 back to top Date Topic Assignment Tue 116, 2018 Check-in on projects Review VIS 2018 program Keywords, topics in VIS papers Finding related work In class, we will quickly read and evaluate recent visualization papers from the 2018 IEEE visualization conferences. Mega-sheet with Related Work and VIS paper scores IEEE VIS 2018 Program Thu 118, 2018 Check-in on projects Review VIS 2018 program Relate your project to the VIS conference Week 11 back to top Date Topic Assignment Tue 1113, 2018 Check-in on project schedules What is going well Challenges and questions Deliverables 9am Prepare a Gatt chart for your project progress Be ready to show and discuss your project progressGatt chart with others in class Thu 1115, 2018 Reading VIS 2018 papers TBD Week 12 back to top Date Topic Assignment Thu 1120, 2018 No Class. Happy Thanksgiving If you have urgent questions, please contact Fumeng. Thu 1122, 2018 No Class. Happy Thanksgiving If you have urgent questions, please contact Fumeng. Week 13 back to top Date Topic Assignment Tue 1127, 2018 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Bring in your schedules for the final 2 weeks. Project groups will have time to update the class about progress. Start your presentations. Next week, well have a dress rehearsal for final presentations. Look ahead in the calendar for more info about our expectations. Project progress check-in Read VIS 2018 papers Thu 1129, 2018 Class review forms to be filled out Research abstracts what to report and how much In class, we will look at examples of successful two-page research abstracts. Project progress check-in Read VIS 2018 papers Week 14 back to top Date Topic Assignment Tue 124, 2018 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress check-in Read VIS 2018 papers Thu 126, 2018 Class review forms to be filled out Research abstracts what to report and how much Project progress check-in Read VIS 2018 papers Week 15 back to top Date Topic Assignment Tue 1211, 2018 Last class Presentation Dress Rehearsal In class, each group will deliver a 8-10 minute presentation about its project. The audience will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times remember to focus on contributions and results, and dont go over 10 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in class to revise your final presentation. Deliverables 9am Hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Thur 1213, 2018 Reading period Hand in a PDF of Your Draft 1159pm EST By the end of the day, hand in a draft of your final report. Your report should be a two-page extended abstract pdf for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which she is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. Week 16 back to top Date Topic Assignment Mon 1217, 2018 Final Project Presentation Present your Final Project and Results 2pm Before the presentation slot, hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Plan for 5-6 minutes of presentation. You will have access to a large displayprojector to present your slides. You will have an few minutes after your talk to answer questions from the audience. Tue 1218, 2018 Final Reports Due Hand in Final Report 1159pm EST By the end of the day, hand in a two-page extended abstract pdf for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which she is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for 1213 your draft submission. If youre wondering, heres what we did last time 2016 calendar", "metadata": {"last_modified": "2018-12-05T19:53:31+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 3115, "token_count_estimate": 4068}}, "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/ideas.html": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2018 Project Ideas Home Syllabus Calendar People Gallery Links Project Ideas Ideas Compiled for Students Note Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "metadata": {"last_modified": "2020-09-06T19:04:44+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 143, "token_count_estimate": 211}}, "https://cs.brown.edu/courses/csci2300/": {"text_content": "CSCI 2300 Human-Computer Interaction Seminar Spring 2023 This seminar covers methods for conducting research in human-computer interaction HCI. These topics will be pursued through independent reading, assignments, and class discussion. The seminar comprises four assignments that not just apply HCI research methods but push the envelope of what has been done before. The assignments are designed to be meaningful and potentially discover something new in the field, and students will also attend HCI faculty candidate talks this semester as part of this course. We will have readings that teach HCI methods and provide examples of research contributions, sometimes alongside the reviews of those papers as they were evaluated for publication. The goal of this course is to provide students with the background necessary to perform research in HCI and the skills required to conduct human-centric research. Students who take this course should have a particular interest in HCI research, or wish to learn fundamental skills that will help them with a user interface design or usability evaluation career. There will be little or no content in this course about interface design, but students will find other topics in CSCI 1300 User Interfaces relevant. Enthusiastic students who have not taken CSCI 1300 should have independently gained HCI experience or be a graduate student studying a related topic, and be able to manipulate software and data to investigate the research questions posed in class. The course is capped at about 20 students, and there is no waitlist or addition enrollment possible at this point. The Collaboration Policy should be read and signed in class on February 8. Main Themes Spring 2023 1 HCI methods, especially empirical experimental design 2 social mechanisms in digital communication 3 self-experimentation 4 AI and crowdwork ethics 5 creatively learning and learning creativity Course Staff Instructor Jeff Huang , 245 CIT, jeff at cs dot brown dot edu Meeting Times 430pm-7pm Wednesday at 241 CIT. Office hours on Wed 230-330pm. The seminar is fully in-person, without a remote option. Assignments Evaluating Social Mechanisms Compare and contrast fast-prototyped social apps that we design together that each apply different norms and constraints using a variety of mechanisms to see how small changes affect wellness, trust, privacy, and enjoyment. Self-Experiment Designs Rather than conducting generalizable experiments on samples of the population, you will perform an N 1 experiment a self-experiment to see how changing your behavior affects your own outcomes Constructing an Ethical Framework What should modern human subjects review look like for computing studies Propose a change to the federal common rule from which institutional review boards derive their rules, to consider modern perspectives of labor, data ownership, power dynamics, and the risks of deanonymization. Measuring Creativity Well be reviewing measures of creativity and inspiration thats typically used for human-generated content, and seeing how they perform on AI-generated content. What is creativity, and is there something there thats unique to humans Grading 15 points - Readings 13 points - HCI faculty candidate talks 18 points - Evaluating Social Mechanisms assignment 18 points - Self-Experiment Designs assignment 18 points - Constructing an Ethical Framework assignment 18 points - Measuring Creativity assignment Readings should be done before class on the date a reading is due. For each reading, please write to the Slack channel a short novel comment not a rephrase of what someone said earlier about the research contributionfindings from the work, and a short novel comment about your assessment of the workpaper. Comments are encouraged to be in response to existing comments in the channel. Additionally, each reading discussion will be led by two students who will work together to prepare a presentation for the class. Assignments are due at the beginning of class on the date it is marked in in the schedule below, with a midpoint check-in on the dates marked mid where well discuss progress so far. Students should attend at least 4 faculty candidate talks and submit a combined review of their research quality and potential, with a final comparison between the HCI research work and visions that were presented by each faculty candidate. Grading is done solely by the instructor. The thresholds for ABC cutoffs are 908070. Time Allocation Total time spent in and out of class for this course is estimated at 180 hours. Over the 15 weeks of this course, students will spend 2 and a half hours in class each week or 37.5 hours total. Although specific out-of-class time investments may vary for individual students, a reasonable estimate to support this courses learning outcomes is 145 total out-of class hours, or on average, about 10 hours weekly over a 15-week term. Out-of-class preparation will regularly include about 1-2 hours per class of reading and writing the comments addressing the reading about 70 hours total, along with presentations. In addition to this ongoing preparation time, students are expected to allocate about 65 hours over the course of the term to writing the four assignments. Finally, approximately 5 hours will be spent attending HCI faculty candidate talks. Accessibility and Accommodations Statement Brown University is committed to full inclusion of all students. Please inform me early in the term if you may require accommodations or modification of any of course procedures. You may speak with me after class, during office hours, or by appointment. If you need accommodations around online learning or in classroom accommodations, please be sure to reach out to Student Accessibility Services SAS for their assistance sasbrown.edu, 401-863-9588. Undergraduates in need of short-term academic advice or support can contact an academic dean in the College by emailing collegebrown.edu. Graduate students may contact one of the deans in the Graduate School by emailing graduateschoolbrown.edu. Classwork Schedule Day Topics Reading Due Assignment Jan 25 Topic overview, HCI research, and reading critically Keshav - How to Read a Paper Kostakos - The Big Hole in HCI Research Feb 1 Topic social relationships and norms Gilbert - Predicting Tie Strength With Social Media Wei - TikTok and the Sorting Hat , Seeing Like an Algorithm , and American Idle S out Feb 8 Topic social prototyping and evaluation Bernstein - The trouble with social computing systems research Epstein - Revisiting Piggyback Prototyping Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems S mid Feb 15 Topic validity Ernala - Methodological Gaps in Predicting Mental Health States from Social Media Triangulating Diagnostic Signals Losh - Reliability, Validity, Causality, And Experiments Norvig - Warning Signs in Experimental Design and Interpretation Feb 22 Topic experiment design Gwern - Weather and My Productivity or one of their other QS reports Daskalova - Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments S in, X out Mar 1 Topic interventions, causality Discussions from online about AB experiments read in order 1 2 3 4 Munson - The Importance of Starting With Goals in N-of-1 Studies X mid Mar 8 Topic crowdwork ethics Marcus - How I Learned to Stop Worrying and Love the Crowd Alkhatib - Examining Crowd Work and Gig Work Through The Historical Lens of Piecework Mar 15 Topic HCI ethics Brown - Five Provocations for Ethical HCI Research Amershi - Guidelines for Human-AI Interaction X analysis Mar 22 No in-person class, share assignment midpoint X in, E out Mar 29 Spring Break Apr 5 Topic ideation Siangliulue - Providing Timely Examples Improves the Quantity and Quality of Generated Ideas Tohidi - Getting the Right Design and the Design Right Testing Many Is Better Than One E in, C out Apr 12 Topic working with participants Buchenau - Experience Prototyping Dell - Yours is Better Participant Response Bias in HCI Apr 19 Topic design research Odom - Slow Interaction Design Zimmerman - Research Through Design as a Method for Interaction Design Research in HCI C mid1 on Apr 17 Apr 26 Class moved to next week C mid2 May 3 Topic systems vs evaluation Landay - I give up on CHIUIST Greenberg - Usability Evaluation Considered HarmfulSome of the Time CHI - Selecting a Subcommittee read the descriptions of each subcommittee and check out abstracts from papers that catch your eye C in We will look at the corresponding reviews for some of these papers in class to see what the original reviewers had to say about it.", "metadata": {"last_modified": "2023-04-10T07:27:25+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["CSCI 2300: Human-Computer Interaction Seminar", "Main Themes (Spring 2023)", "Course Staff", "Meeting Times", "Assignments", "Grading", "Time Allocation", "Accessibility and Accommodations Statement", "Classwork Schedule"], "word_count": 1370, "token_count_estimate": 1703}}, "https://csci1951a-spring-2024.github.io/": {"text_content": "Welcome to CS1951A Home Assignments Final Project Final Project Examples Hours Resources Staff Cannot save changes Viewing What is Data Science Data is the core of all domains from material science to healthcare. Mastering big data requires a set of skills spanning a variety disciplines, from distributed systems to statistics to machine learning. This course will provide an overview of the wide area of data science, with a particular focus on to the tools required to store, clean, manipulate, visualize, model, and ultimately extract information from large amounts of data. Syllabus Course Calendar Lecture Slides Material Panopto Overview 1 Instructor Lorenzo De Stefani 2 Instructor Office Hours Fridays 345 - 525 PM. Sign up for a slot here 3 HTA Mailing List cs1951aheadtaslists.brown.edu 4 Lecture Dates Mondays Wednesdays 5 Lecture Time 300 - 420 PM 6 Lecture Location Salomon Center 001 Topics Covered Database Design and SQL Web Scraping Data Cleaning Hypothesis Testing Machine Learning Mapreduce Differential Privacy Correlation vs Causation Final Project Throughout the entire course you will be working on a data science project which seeks to answer an interesting and important real-world question. You will be collecting your own data, cleaning it, modeling it, visualizing it, and finally presenting your results in a poster session at the end of the course. You will work in groups of four, and will be assigned a mentor TA to help you through the process. Additionally, your project can be used as a capstone with just a few extra requirements, fully integrating what you will have learned in the course, and building a fully-functional data science application. Prerequisites The formal prerequisites to this course are CSCI 0160, 0180, or 0190. Additional experience in software engineering is recommended, including CSCI 0320 or 1320. This course is taught in Python 3.7, but no prior experience is necessary. We will provide several resources to get students started with Python at the beginning of the course. It is suggested that students also have experience in statistics APMA 1650 or CSCI 1450 and linear algebra MATH 0520, MATH 0540, or CSCI 0530 for the statistics and machine learning portion of this course. 2024 CS1951A Staff Computer Science Department Brown University", "metadata": {"last_modified": "2024-03-13T19:26:42+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["", "", "", "Overview", "", "", "", "", "", "", "", "", ""], "word_count": 364, "token_count_estimate": 480}}, "https://cs.brown.edu/courses/csci2370/2020/calendar.html": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2020 Calendar Home Syllabus Calendar People Links Project Ideas How to Hand Stuff In How to We use a Google Drive folder to manage homeworks and some other shared resources. If you havent been added to it, please send TA, FumengYang at brown.edu, your brown email address. Inside the folder, you will deliver your assignments to the subfolder theduedate yourBrownShortID .ext. For example, Fumeng could upload her first assignment to 09-15-2020 as fyang7.txt . Due All handins are due by 9AM the same day of class to allow for review before class. Please get your reviews and readings done in time. A significant aspect of the class is to get different points of view for interdisciplinary research problems. Itll make classes much more fun and valuable if everybody participates and expresses an opinion. Its not fair to others to make them always carry the weight of leading the discussions. Prepare for a dynamic and open discussion in almost every class. How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright and privacy issues. These links will appear styled like this , as opposed to the public links . The userpwd is specific to the Vis group website VisWeb it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it well give it out the first day of class. Almost all of the readings we will do are online. Printing them for your own use is fine. Please look at the color images in color, though Some of the files are pretty big 40-50 Mb. Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 back to top Date Topic Assignment Thu 910, 2020 Introduction Goals Organization Schedule Summary of class Research contributions, Marching Cubes paper, 2018 course abstracts, 2014 course abstracts. Week 2 back to top Date Topic Assignment Tue 915, 2020 Open problems in Visualization What makes a good problem Logistics Send Fumeng fumengyang at brown.edu a small photo of yourself to include on the website . Make sure you can use the shared google drive. Email Fumeng if you need help. Reading Read, with an eye toward your essay below and also to discuss in class Toolsmith II paper Brooks - this describes how to do computer science, which is the home discipline for scientific visualization. Top Scientific Visualization Research Problems Johnson one of the following Visualization in Scientific Computing McCormick, DeFanti, Brown - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of whats in them when you need the information there later. Computational Science Ensuring Americas Competitiveness Presidents Information Technology Advisory Committee, also CRA NIH Workshop Recommendations and httpwww.nitrd.govpubs Top 10 Unsolved Information Visualization Problems Chen suggested reading Part of a lobbying effort for national funding, the Data and Visualization Corridors gives a 1999 perspective on what was limiting progress in high-end visualization. Read the executive summary and quickly flip through the rest of the document to get a feel for more research topics. Bill Hibbards vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables 9am Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 will have influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 917, 2020 Review and discuss NSF ITR proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal Watch this animation on YouTube about NSFs review process NSF Grant Proposal Guide 2004 describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Note that this is the version that was in effect when this proposal was written. There have been several versions since then, so refer to the latest when you write your own NSF proposals Skim whole thing Read I.B, II.C.2.a-f, II.C.2.h-k, III intro, III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research ITR Program Announcement . Typically, NSF accepts both unsolicited grant applications for whatever a proposer thinks is worth doing and solicited applications. Applications are solicited via a Program Announcement PA, sometimes called a Request for Proposals RFP. This is one example of what they are looking for. Read proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You dont need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. AFTER writing your own review see Deliverables, read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables 9am Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of three possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborators list - You will need to meet with at least three possible collaborators and report on those meetings on 929. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what youll need to hand in as a report . Coordinate with other class members for interviewing to avoid duplicating collaborator effort. Week 3 back to top Date Topic Assignment Tue 922, 2020 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images Laidlaw Evaluating project possibilities Reading NSF Faculty Early Career Development CAREER Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. AFTER writing your own review see Deliverables, I would have had you read of the proposal, then add any new discussion questions to your review. But somehow the file with the reviews in it has disappeared. They are even missing from the NSF website, so I cant regenerate them as of 2020. Sorry... Deliverables 9am Write your own review using this form of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 924, 2020 Discuss project ideas Reading Read Request For Proposals RFP Browse previous CSCI2370 proposals linked on the Ideas page Deliverables 9am Three possible proposal titles and summaries as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Clearly identify the research contributions. Week 4 back to top Date Topic Assignment Tue 929, 2020 Review and discuss NIH proposal Quantitative Inverse Electrocardiography Johnson Discuss interviews Searching literature for related work Reading Read Quantitative inverse electrocardiography Johnson. This proposal is more than 15 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualizing bioelectric fields , MacLeod et al. sorry about the pictures... Read NIH guide to proposals , skimming over the structure of a submission pg. 1-15, the nfocusing on the research plan details pg. 15-18, review criteria pg. 34, and other interesting and relevant parts you find. Read this PowerPoint presentation about the NIH proposal review process Deliverables 9am Interview reports as yourBrownShortID.txt Your review of Johnsons NIH grant as yourBrownShortID-2.txt Thu 101, 2020 Review and discuss additional NSF proposals Proposal needs Visualizing multi-dimensional data Research contributions, yes again Reading The following proposals give a flavor for different styles of proposal, and some of them were not funded. You do not need to read them carefully, but skim through them looking for new and interesting observations to share with the class. MRI Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science Laidlaw et al. and its reviews . HCC Small Collaborative Research Immersive Visualization and 3D Interaction for Volume Data Analysis Bowman, Socha, and Laidlaw and its reviews . Here is one that was not funded CHS Small How Much Virtual Reality is Enough and its reviews . I have many more proposals that you can read, particularly unfunded ones -. If you are interested, reach out Deliverables 9am A list of at least five interesting and reaonably rich sharable observations for the class. Hand in as usual. Do not duplicate observations already handed in. I suggest editing your observations in the handin directory to avoid duplication. If you have less rich observations, include more Week 5 back to top Date Topic Assignment Tue 106, 2020 Visualization tools Paraview volume rendering Proposal challenges Reading Read Visualization Handbook s table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project Google for the authors web pages and see what other stuff they are working on. If youre interested in reading more, the book may be available at the Sciences Library SciLi -- it was at some point -. Some chapters are likely available online. Many topics will have Wikipedia pages or other tutoial-level pages that will help you become visualization experts. Read The Value of Visualization , and The Value of Infovis . Look for ways to understand and motivate the contributions of your proposed projects. Can you find papers that cite these that are helpful This could lead to some things for your literature review and related work sections. Deliverables 9am Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Google Scholar is the main place to search for research papers, but there is a list of other options here Question 3 Where do I search for research papers . Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. The first item in your literature search should be the paper you think would be most valuablefor the class to all read and discuss. Clearly label it as such. Install Paraview on your computer from the first step in the tutorial. Also download the tutorial.vtk file. Bring to class. Thu 108, 2020 more Visualization Handbook Reading Read the three papers listed in in your co-students literature review handins from last class. Make a listof five discussion observations or questions, just as you did for the three proposals last week.You should be focused on finishing your proposal drafts, so if you need to do these readingsquickly that is ok. Deliverables 9am Sign up for a presentation time in the spreadsheet posted in the Google drive Collaborators Meetings Proposal Presentations top-level, the same file used for collaborators meetings, but use the second tab. Preliminary proposal handed in as yourBrownShortID.pdf. This should be a full draft, ready for comments by reviewers. A template for your proposal can be template for your proposal can be downloaded here. See the README inside for more instructions. The overleaf read-only repos can be found at proposals and final reports . Make sure your proposal is saved as a pdf. Week 6 back to top Date Topic Assignment Tue 1013, 2020 Proposal presentations, 5 minutes each Reading Begin reading proposals from the shared Google Drive folder Deliverables 9am Presentation slides handed in as yourBrownShortIDslides.pptx or pdf. Davidmuch prefers pptx with all videos and images embedded in the file. Google slidesis not ok... you can create in it, but convert and submit as pptx and make surethat everything plays correctly without the presenter being you. Thu 1015, 2020 Improving proposals and examples Insight-based evaluation what is it, and should you use it Evaluating visualizations Reading An Insight-Based Methodology for Evaluating Bioinformatics Visualizations , Saraiya et al., TVCG, 2005. Empirical Studies in Information Visualization Evaluation Seven Scenarios , Lam et al., IEEE TVCG 18, 9 September 2012. Read proposals from the shared Google Team Drive 10-11Preliminary Proposals Deliverables 9am Find your review assignment within the same folder the top level of the shared drive. Review of the first-draft proposals assigned to you. Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Fumengs proposal, he should hand in a file called fyang7bydhl.txt. Week 7 back to top Date Topic Assignment Tue 1020, 2020 Walking Walking-in-Place Flying Walkthrough of a project budget Link to paper for in-class activity Walking Walking-in-Place Flying, in Virtual Environments , Usoh et al., In Proceedings of SIGGRAPH, 1999. Deliverables 9am Final proposal handed in as yourBrownShortID.pdf Thu 1022, 2020 Study section evaluate, score, fund proposals Link for in-class activity Table of linked reviews and NIH-style proposal scores TBD Reading Read final proposals from the shared Google Team Drive 10-18allproposals.pdf Find your in the spreadsheet posted within the same folder the top level of the shared drive. Deliverables 9am Review the final proposals assigned to you. For the final proposals, you only need to hand in reviews for the three proposals where you are R1, R2, or R3. You must read the proposals for which you are R3R4 and be prepared to discuss them in class. Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Fumengs proposal, he should hand in a file called fyang7bydhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Week 8 back to top Date Topic Assignment Tue 1027, 2020 IEEE Visualization Conference online Start the CITI online course , which will certify you to perform human subjects research, like user studies, at Brown. Thu 1029, 2020 IEEE Visualization Conference online Finish the CITI online course and send your passing Completion Report pdf to the TA. If you do not pass on your first try, you must retake the quizzes until you receive a passing grade. Deliverables 9am Hand in a summary statement on your Primary proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposerbyyourBrownShortID .txt. Week 9 back to top Date Topic Assignment Tue 113, 2020 ELECTION DAY -- Brown Holiday No class Thu 115, 2020 Check-in on projects Review VIS 2020 program Relate your project to the VIS conference Deliverables 9am Be ready to explain and discuss your project progress with others in class.A Gantt chart can be a good way to showexplain progress. Mega-sheet with Related Work and VIS paper scores Vis 20 items start on row 1209, so be prepared to do some scrolling. Week 10 back to top Date Topic Assignment Tue 1110, 2020 Vis 20 Redux Discussion with Fumeng and David about Vis Conference. Where would your project fit at the conference Read VIS 2020 papers review IEEE VIS 2020 Program may need login and papers with your project in mind bring any questions about the conference Thu 1112, 2020 Project checkins Read VIS 2020 papers prepare for project checkins continue thinking about final presentations and reports Week 11 back to top Date Topic Assignment Tue 1117, 2020 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress check-in Read VIS 2020 papers Thu 1119, 2020 Class review forms to be filled out Research abstracts what to report and how much Project progress check-in Read VIS 2020 papers Week 12 back to top Date Topic Assignment Tue 1124, 2020 No class. Happy Thanksgiving Thu 1126, 2020 No class. Happy Thanksgiving Week 13 back to top Date Topic Assignment Tue 121, 2020 Penultimate class Last project progress check, finalize contributions, schedule review Prepare slides showing your contributions. Include visuals, graphs, and anyother results that will make the contributions clearer. It is fine to haveplaceholder visuals or graphs. Make sure that the captions for those makeclear what the audience should be able to see eventually in each slide. Deliverables 9am Hand in a pdf of your slides Name the file login1login2 .pdf corresponding to the group members. Thu 123, 2020 Last class Reading period Presentation Dress Rehearsal e In class, each project will deliver an 8 minute presentation about their project. This is a dress rehearsal for the 8-minute final presentation on 128. The audience will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times remember to focus on contributions and results, and dont go over 8 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in or after class to revise your final presentation. Deliverables 9am Hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Hand in a PDF of Your Draft 1159pm EST By the end of the day, hand in a draft of your final report. Your report should be a two-page extended abstract pdf for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which she is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. Week 14 back to top Date Topic Assignment Tue 128, 2020 Final Project Presentation Present your Final Project and Results 2pm Before the presentation slot, hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Plan for a maximum of 8 minutes of presentation. You will have a few minutes after your talk to answer questions from the audience. Feedback on other reports 1159pm Provide feedback about each of the other reports in a Slack DM to the author, me, and Fumeng. Aim for suggestions that could be handled in the remaining few days, thoughts on what worked, or lessons that the authors could take with them for future projects. Thu 1210, 2020 Final Reports Due Hand in Final Report 1159pm EST By the end of the day, hand in a two-page extended abstract pdf for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which she is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for your draft submission. If youre wondering, heres what we did last time 2018 calendar", "metadata": {"last_modified": "2020-11-27T21:22:40+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 3547, "token_count_estimate": 4548}}, "https://cs.brown.edu/courses/csci1971/": {"text_content": "Assignments Lectures Hours Documents Staff Class is held in person Tuesday and Thursday from 1840-2000 in CIT 101 . First class is Thursday Sept 7th. Welcome to 2D Game Engines This is a largely student-run course, similar to an independent study, and youll learn lots of techniques needed to create a fledgling game engine. These topics include animation, simple AI, collision detection, physics, and raycasting. You will create a game engine of your own over the course of the semester, adding a few features to it each week. At the same time, you will also create a series of games using your engine that demonstrate the use of the features you add. Near the end of the semester, you will design and implement a final project that uses your game engine to create a complete, polished game. Assignments to do released design check due Tic Sep 12 Sep 13-14 Sep 19 Alc I Sep 19 Sep 20-21 Sep 26 Alc II Sep 26 Sep 27-28 Oct 3 Wiz I Wiz Extras Oct 3 Oct 11-12 Oct 17 Wiz II Wiz Extras Final Project Idea Oct 17 Oct 18-19 Oct 24 Nin I Final Project Groups DUE MON 1030 Oct 24 Oct 25-26 Oct 31 Nin II Nin Extras Oct 31 Nov 1-2 Nov 7 Final I Nov 7 Nov 14 Final II Nov 14 Nov 28 Final III Nov 28 Dec 5 Final IV Dec 5 Dec 19 Lectures If you have trouble accessing any of these materials, please email us Well be happy to make accommodations. Sep 7 Course Intro, Basic Architecture PPT Sep 12 Graphics 1, Input 1 PPT Sep 19 Component-Based Design, Game World, Viewports, Content Management PPT Sep 27 Graphics II, Collisions I PPT Oct 3 Physics I, Map Generation Space Partitioning PPT Oct 17 Decision Making, Pathfinding, Final Project Overview PPT Oct 24 Physics II, Collisions II PPT Oct 31 Raycasting, SavingLoading PPT Nov 7 Sound PPT Nov 7 Data persistence PPT Nov 7 Text Boxes PPT Nov 7 Networking PPT Nov 7 Procedural Generation PPT Nov 7 Animation State Machines PPT Hours Refer to the calendar below for the most up-to-date TA hours. Check out how remotein-person hours will work here . Design Checks take place from Wednesday-Thursday the week each assignment is released. Documents Here are some documents that might be useful to you as you take this course Course Missive Collaboration Policy Global Requirements IntelliJ Setup Guide Git Guide Anonymous Feedback Form frequently asked questions How will remotein-person hours work Check out this handy guide here How much work is it Based on the work from the previous few years of class, we estimate that the projects should take roughly 15-20 hours per weekly checkpoint. There is also a two hour lecture each week and a weekly design check. Do I have to be a video game expert to take this course Nope While it does help to have some familiarity with the different types of 2D video games out there, we will explain everything you need to know in order to do the projects. Can I take this course before CS 32 Yes. The pre-requisite for this course is any intro CS sequence. You will be maintaining and improving upon your code and projects throughout the course so this helps out a bit with preparing for CS 32. Where can I get sprites and images for the projects There are a handful of places that you can find free assets online such as opengameart.org , itch.io , and many more. If you do use resources you find online make sure to give credit and cite. Although it isnt a part of your grade we love to see custom art and designs in submissions. Where do you go to find inspiration Think about what kind of games youve liked playing in the past, and ask yourself how youd improve upon them. If you were offered the chance to make a spinoff, what new direction would you take it in Theres a lot of game archetypes out there, and we wont constrain you to a single one of them. You can absolutely turn a dungeon crawler project into Stardew Valley as long you use the same engine features. You can make metroidvanias, puzzle games, visual novels, arcade games, simulations, remakes, whatever you want. Links for more inspiration. Can I reuse a game I make here for my CS 32 final project That depends on how the CS 32 TAs feel about it, but in general, you cant reuse work you submitted for one class for a similar assignment in another class. Your experience creating game engines, however, will allow you to make an even better game for your CS 32 final project. Can I reuse a game I made in CS15CS32etc for my final project here You can reuse the same concept, sure, but keep in mind youll have to build it all with the game engine you wrote throughout the semester. Porting over the idea is perfectly fine, though. What should I bring to the design check Design checks in this course are not the same as design checks in CS15161718. We expect you to have thought about the project and have a good idea of how you will solve some of the central problems it involves, but its OK if you havent written any code or made a diagram of your class design. The later you do your design check, though, the more progress we will expect you to have made. Why is this class sometimes designated cs1971 We have two course codes. Dont ask whywe dont know either. Hopefully you will never see the other one. Can you show me some final projects done by students from a long time ago Sure thing, buddy. Fall 2022 Fall 2021 Fall 2013 Fall 2012 Staff Prof. James Tompkin jtompkin hehimhis Previously pushed pixels presently professes PowerPoints. Favorite video games X-COM with respect to time sunk Currently playing Disco Elysium and WeKatamari REROLL Daniel Cho HTA dcho24 hehimhis Favorite video games Dark Souls 2 Currently playing Terraria Josh Abramson jabrams8 hehimhis Favorite video games Celeste Currently playing Doom Eternal Farran Regan na theythem Favorite video games Stardew Valley Currently playing Valorant Brown University CSCI 1950N Prof. James Tompkin cs1950ntaslists.brown.edu", "metadata": {"last_modified": "2023-11-07T19:35:04+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Assignments", "Lectures", "Hours", "Documents", "frequently asked questions", "Staff", "Prof. James Tompkin", "Daniel Cho (HTA)", "Josh Abramson", "Farran Regan"], "word_count": 1046, "token_count_estimate": 1344}}, "https://cs.brown.edu/courses/csci2370/2018/brown-cs237-fall18-website/": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2018 Home Page Home Syllabus Calendar People Gallery Links Project Ideas Time TueThu 1030-1150AM Location CIT Building, Room 506 Professor David H. Laidlaw CIT 521, dhl at cs.brown.edu TA Fumeng Yang CIT 509, fumengyang at brown.edu Description Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality cave applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites programming experience, some graphics experience, and problem ideas. Permission of the instructor required. New Final proceedings for 2018 are now available pdf previous years 2016 2014 2012 2010 2007 2006 2005 2004 2003 2002 2000 1999 as VR Design for Science BrownRISD, now CS137 Brown Brown CS Brown CS Visualization", "metadata": {"last_modified": "2020-08-17T20:27:35+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 180, "token_count_estimate": 269}}, "https://cs.brown.edu/courses/csci2370/2020/ideas.html": {"text_content": "Project Ideas Home Syllabus Calendar People Links Project Ideas Ideas Compiled for Students Note Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 .", "metadata": {"last_modified": "2020-09-21T16:49:30+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 136, "token_count_estimate": 198}}, "https://cs.brown.edu/courses/csci2370/2021/calendar.html": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2021 Calendar Home Syllabus Calendar People Links Project Ideas How to Hand Stuff In How to We use a How to Read Papers and Proposals Some of the readings needed for the class are password protected due to copyright and privacy issues. These links will appear styled like this , as opposed to the public links . The userpwd is specific to the Vis group website VisWeb it is not the same as your CS account. Make sure to contact the instructors to get the username and password if you forget it well give it out the first day of class. Almost all of the readings we will do are online. Printing them for your own use is fine. Please look at the color images in color, though Some of the files are pretty big 40-50 Mb. Finally, please respect the grant proposals you will be reading. They are not published documents and should not be circulated outside of class. Please make sure that you destroy any copies of those documents when you are finished with them for class. Calendar Week 1 back to top Date Topic Assignment Thu 99, 2021 Introduction Goals Organization Schedule Summary of class Research contributions, Marching Cubes paper, 2018 course abstracts, 2020 course abstracts, virtual whiteboard for class activities. Logistics Make sure the course is in your Banner shopping cart before Friday Week 2 back to top Date Topic Assignment Tue 914, 2021 Open problems in Visualization What makes a good problem Logistics Send David DavidLaidlaw at brown.edu a small photo of yourself to include on the website . Make sure you can use the shared google drive. Email David if you need help. Reading Read, with an eye toward your essay below and also to discuss in class Toolsmith II paper Brooks - this describes how to do research in computer science, which is the home discipline for scientific visualization. Top Scientific Visualization Research Problems Johnson one of the following Visualization in Scientific Computing McCormick, DeFanti, Brown - set the stage for scientific visualization and its funding back in 1987. Read the executive summary and sections I-III. Skim through appendix A and read the sections that are most interesting to you. Read section A.3. Skim through appendices B and C so you have some idea of whats in them when you need the information there later. Computational Science Ensuring Americas Competitiveness Presidents Information Technology Advisory Committee, also CRA NIH Workshop Recommendations and httpwww.nitrd.govpubs Top 10 Unsolved Information Visualization Problems Chen suggested reading Bill Hibbards vis viewpoints column The Top Five Problems that Motivated My Work . Another vis viewpoints column by David Duke et al. Do You See What I Mean . Research and Development Agenda for visual analytics developed to define the directions and priorities for future research and development programs focused on visual analytics tools. Illuminating the Path Deliverables 9am Personal background handed in as yourBrownShortID.txt A fictional essay, 250-750 words. The setting is 5-20 years in the future, and the story should describe how CSCI2370 will have influenced that future you. In particular, it should describe a plausible way that you will have solved or addressed one or more of the visualization research topics from the readings. Hand in as yourBrownShortID-2.txt, as described for personal background handin. Thu 916, 2021 Review and discuss NSF ITR proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. Evaluating project possibilities Reading These readings will give you a feel for what goes into a research grant proposal Watch this animation on YouTube about NSFs review process NSF Grant Proposal Guide 2004 describes how to write a grant proposal. While some of the instructions are specific to NSF, much of the document gives good advice on how to write any proposal. Note that this is the version that was in effect when this proposal was written. There have been several versions since then, so refer to the latest when you write your own NSF proposals Skim whole thing Read I.B, II.C.2.a-f, II.C.2.h-k, III intro, III.A, III.E-F, VI.G Guidelines for proposal writing NSF Information Technology Research ITR Program Announcement . Typically, NSF accepts both unsolicited grant applications for whatever a proposer thinks is worth doing and solicited applications. Applications are solicited via a Program Announcement PA, sometimes called a Request for Proposals RFP. This is one example of what they are looking for. Read proposal Understanding Unsteady Bioflows through Simulation, Modeling, Visualization, Art, and Psychology Laidlaw et al. . This is a proposal in response to the ITR solicitation. It was successful and was partially funded September 2004. You dont need to understand all, but try to get the big picture as an example of a multi-disciplinary research project. AFTER writing your own review see Deliverables, read NSF reviews of the proposal and add any new discussion questions to your review. Read the RFP for class projects Consult the list of project ideas Deliverables 9am Hand in your own review for the ITR grant as yourBrownShortID .txt Hand in a list of three possible collaborators for your class project as yourBrownShortID-2 .txt. The collaborators can be from class or from other disciplines. The RFP for class projects will help you understand more about the criteria for judging a project idea. Possible collaborators can be from the class, the list of project ideas suggested by various researchers around campus, and any personal contacts you have. Describe the discipline of each possible collaborator and how it is distinct from your area. At least two must be contributors to the list of project ideas or established researchers. Collaborators list - You will need to meet with at least three possible collaborators and report on those meetings on 928. These meetings will help you develop the interdisciplinary part of the project. Get started scheduling these meetings and look at what youll need to hand in as a report . Coordinate with other class members and David for interviewing to avoid duplicating collaborator effort. David will try to be present at the first meeting with each collaborator as a mostly-silent facilitator. Week 3 back to top Date Topic Assignment Tue 921, 2021 Review of NSF CAREER proposal Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images Laidlaw Evaluating project possibilities Reading NSF Faculty Early Career Development CAREER Program Announcement Read annual status report to NSF . Once again, this gives a feel for what NSF is interested in. Shape Capture and Modeling for Wrist Dynamics and Ancient Pottery Analysis using Manifold Surfaces and Signed-Distance Volume Images This is a second example of an interdisciplinary visualization proposal. The application areas are quite different and the proposal is more focused on visualization. Skim the whole proposal, then read the Project Summary and Project Description. AFTER writing your own review see Deliverables, I would have had you read of the proposal, then add any new discussion questions to your review. But somehow the file with the reviews in it has disappeared. They are even missing from the NSF website, so I cant regenerate them as of 2020. Sorry... Deliverables 9am Write your own review using this form of the CAREER proposal and hand it in as yourBrownShortID.txt. Do the review before reading the NSF reviews. Continue interviewing possible collaborators. Thu 923, 2021 Discuss project ideas Reading Read Request For Proposals RFP Browse previous CSCI2370 proposals linked on the Ideas page Deliverables 9am Three possible proposal titles and summaries as yourBrownShortID-2.txt. For each, include a brief description, a list of participants, and your evaluation of the proposal you imagine. Use the RFP to guide your project ideas and to self-evaluate them. Clearly identify the research contributions. Week 4 back to top Date Topic Assignment Tue 928, 2021 Review and discuss NIH proposal Quantitative Inverse Electrocardiography Johnson Discuss interviews Searching literature for related work Reading Read Quantitative inverse electrocardiography Johnson. This proposal is more than 25 years old, so the work is not current. It does show an excellent example of a successful non-clinical NIH grant proposal. Non-clinical work is often quite difficult to get funded by NIH. Note the structure of the proposal, with well-formulated hypotheses to test. Skim the whole thing and read the four sections starting with Specific Aims. Read partial list of resulting papers Read Visualizing bioelectric fields , MacLeod et al. sorry about the pictures... Read NIH guide to proposals , skimming over the structure of a submission pg. 1-15, then focusing on the research plan details pg. 15-18, review criteria pg. 34, and other interesting and relevant parts you find. Read this PowerPoint presentation about the NIH proposal review process Deliverables 9am Interview reports as yourBrownShortID.txt Your review of Johnsons NIH grant as yourBrownShortID-2.txt Thu 930, 2021 Review and discuss additional NSF proposals Proposal needs Visualizing multi-dimensional data Research contributions, yes again Reading The following proposals give a flavor for different styles of proposal, and some of them were not funded. You do not need to read them carefully, but skim through them looking for new and interesting observations to share with the class. MRI Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science Laidlaw et al. and its reviews . HCC Small Collaborative Research Immersive Visualization and 3D Interaction for Volume Data Analysis Bowman, Socha, and Laidlaw and its reviews . Here is one that was not funded CHS Small How Much Virtual Reality is Enough and its reviews . I have many more proposals that you can read, particularly unfunded ones -. If you are interested, reach out Deliverables 9am A list of at least five interesting and reaonably rich sharable observations for the class. Hand in as usual. Do not duplicate observations already handed in. I suggest editing your observations in the handin directory to avoid duplication. If you have less rich observations, include more Week 5 back to top Date Topic Assignment Tue 105 2021 Visualization tools Paraview volume rendering Proposal challenges Reading Read Visualization Handbook s table of contents. For the class, see if the topics in the book suggest some readings related to your project. Are there any new ideas in there for a different project Google for the authors web pages and see what other stuff they are working on. If youre interested in reading more, the book may be available at the Sciences Library SciLi -- it was at some point -. Some chapters are likely available online. Many topics will have Wikipedia pages or other tutorial-level pages that will help you become visualization experts. Read The Value of Visualization , and The Value of Infovis . Look for ways to understand and motivate the contributions of your proposed projects. Can you find papers that cite these that are helpful This could lead to some things for your literature review and related work sections. Deliverables 9am Hand in results from literature search as yourBrownShortID.txt You should do this search on the project you are most seriously considering doing out of all the ideas you have. Google Scholar is the main place to search for research papers, but there is a list of other options here Question 3 Where do I search for research papers . Continue developing your project proposal, filling in any weaknesses, fleshing out the related work section, etc. Be prepared to briefly describe the project idea you are most seriously considering and any issues, concerns, problems, etc. that we can discuss in class. The first item in your literature search should be the paper you think would be most valuablefor the class to all read and discuss. Clearly label it as such. Install Paraview on your computer from the first step in the tutorial. Also download the tutorial.vtk file. Bring to class. Thu 107, 2021 more Visualization Handbook citing related work Reading Read the top papers listed in in your co-students literature review handins from last class. Make a listof five discussion observations or questions for each, just as you did for the three proposals last week.You should be focused on finishing your proposal drafts, so if you need to do these readingsquickly that is ok. entire Visualization Handbook Deliverables 9am Preliminary proposal handed in as yourBrownShortID.pdf. This should be a full draft, ready for comments by peer reviewers. A template for your proposal can be template for your proposal can be downloaded here. See the README inside for more instructions. The overleaf read-only repos can be found at proposals and final reports . Make sure your proposal is saved as a pdf. Week 6 back to top Date Topic Assignment Tue 1012, 2021 Proposal presentations, 10 minutes each 15 discussion Reading Read proposals from the shared Google Drive folder Deliverables 9am Presentation slides handed in as yourBrownShortIDslides.pptx or pdf. Davidmuch prefers pptx with all videos and images embedded in the file. Google slidesis not ok... you can create in it, but convert and submit as pptx and make surethat everything plays correctly without the presenter being you. Reviews of the first-draft proposals assigned to you . Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Ugurs proposal, he should hand in a file called ugurbydhl.txt. Thu 1014, 2021 Improving proposals and examples Insight-based evaluation what is it, and should you use it Evaluating visualizations Response to reviewers Reading and Revising An Insight-Based Methodology for Evaluating Bioinformatics Visualizations , Saraiya et al., TVCG, 2005. Empirical Studies in Information Visualization Evaluation Seven Scenarios , Lam et al., IEEE TVCG 18, 9 September 2012. Build in ideas from papers in your response to reviewers below. Deliverables 9am Your response to reviewers document. It should be the first part of the final proposal that you hand in next week, and the handin today should also include the preliminary proposal. The response should include all the reviews, with each review point responded to following the point. Distinguish the review text from the response text -- indent one or italicize one, etc. Numbering the individual responses or the comments can help in referring back to something that was commented on and addressed in an earlier part of the response. The response should not debate the comment, it should explain how the final proposal has been changed to address the comment. Or how it will be changed -- the changes dont have to be made yet. This is the first time for these responses, so please ask if its not clear what to do. Week 7 back to top Date Topic Assignment Mon 1018, 2021 Not a class stuff due MONDAY Deliverables 9am Final proposal handed in as yourBrownShortID.pdf Date Topic Assignment Tue 1019, 2021 Study section evaluate, score, fund proposals Link for in-class activity Table of linked reviews and NIH-style proposal scores TBD Reading Read final proposals from the shared Google folder Deliverables 9am Review the final proposals . Use a separate form for each review you write, and name the file proposerbyreviewer .txt when you hand it in. For instance, if David reviews Ugurs proposal, he should hand in a file called ugurbydhl.txt. Respond to the quick questions in this form as yourBrownShortID.txt Thu 1021, 2021 Walking Walking-in-Place Flying Walkthrough of a project budget Maybe VIS video previews Link to paper for in-class activity Walking Walking-in-Place Flying, in Virtual Environments , Usoh et al., In Proceedings of SIGGRAPH, 1999. The video preview or fast-forward URL httpswww.youtube.complaylistlistPLjHCTOW5ojrfs6pMGQBc33-lQ8tGTanlE The gsheet for notesevaluations httpsdocs.google.comspreadsheetsd1DZsxxn8iayvmLXm5EJq1fv9umD6jqKrRIglcViPq20Ieditgid0 Week 8 back to top Date Topic Assignment Tue 1026, 2021 IEEE Visualization Conference online Work on projects Thu 1028, 2021 IEEE Visualization Conference online Deliverables 9am Hand in a summary statement on your Primary proposal. Try to capture all the discussion points for the proposal. The length should be however long it takes for you to adequately summarize the discussion. Name the file proposerbyyourBrownShortID .txt. Week 9 back to top Date Topic Assignment Tue 112, 2021 Check-in on projects Review VIS 2021 program Relate your project to the VIS conference Be ready to explain and discuss your project progress with others in class.A Gantt chart can be a good way to showexplain progress. Mega-sheet with Related Work and VIS paper scores Vis 21 items start on row 1574, so be prepared to do some scrolling. Thu 114, 2021 Read VIS 2021 papers Be prepared with any questions about the conference. Week 10 back to top Date Topic Assignment Tue 119, 2021 Vis 20 Redux Discussion with David and grad student Fumeng about Vis Conference. Where would your project fit at the conference review IEEE VIS 2021 Program may need login and papers with your project in mind Look over Fumeng Yangs google scholar profile Bring any questions about the conference Thu 1111, 2021 Project checkins Read VIS 2021 papers prepare for project checkins continue thinking about final presentations and reports Week 11 back to top Date Topic Assignment Tue 1116, 2021 outlining final papers overleaf draft 20 minutes from ready to share Thu 1118, 2021 Week 5 check-in on project schedules Discussion of final plans for projects Remaining challenges and questions Project progress presentation Week 12 back to top Date Topic Assignment Tue 1123, 2021 No class. Happy Thanksgiving Thu 1125, 2021 No class. Happy Thanksgiving Week 13 back to top Date Topic Assignment Tue 1130, 2021 Penultimate class not quite... Last project progress check, finalize contributions, schedule review Prepare slides showing your contributions. Include visuals, graphs, and anyother results that will make the contributions clearer. It is fine to haveplaceholder visuals or graphs. Make sure that the captions for those makeclear what the audience should be able to see eventually in each slide. Deliverables 9am Hand in a pdf of your slides Name the file login1login2 .pdf corresponding to the group members. Thu 122, 2021 in-class system evaluation of projects Week 14 back to top Date Topic Assignment Tue 127, 2021 Ultimate class Presentation Dress Rehearsal In class, each project will deliver an 8 minute presentation about their project. This is a dress rehearsal for the 8-minute final presentation on 127. The audience will have 5 minutes to ask questions after each talk. You should practice your presentation before class at least three times remember to focus on contributions and results, and dont go over 8 minutes. We will critique presentations as a class in preparation for the public final presentations. Use the feedback you receive in or after class to revise your final presentation. Deliverables 9am Hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Feedback on other reports 1159pm Provide feedback about each of the other reports in a Slack DM to the author and David. Aim for suggestions that could be handled in the remaining few days, thoughts on what worked, or lessons that the authors could take with them for future projects. Weeks 15-16 back to top Date Topic Assignment Wed 1215, 2021, 2pm Final Project Presentation Present your Final Project and Results 2pm Before the presentation slot, hand in a pdf of your slideshow one per group. Name the file login1login2 .pdf corresponding to the group members. Plan for a maximum of 8 minutes of presentation. You will have a few minutes after your talk to answer questions from the audience. Mon 1220, 2021 Final Reports Due Hand in Final Report 1159pm EST By the end of the day, hand in a two-page extended abstract pdf for your project as yourBrownShortID.pdf. For groups, each student must write his or her own report, in which she is listed as the first author and the other group members as co-authors. Your abstract must match the formatting requirements for our class proceedings . Templates for Word and latex can be downloaded here . Please use the finalReport templates. See the README inside for more instructions. P.S. the link here is the same as the link for your draft submission. If youre wondering, heres what we did last time 2020 calendar", "metadata": {"last_modified": "2021-12-01T21:31:42+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 3338, "token_count_estimate": 4325}}, "https://cs.brown.edu/courses/csci2370/2021/ideas.html": {"text_content": "Project Ideas Home Syllabus Calendar People Links Project Ideas Ideas Compiled for Students Note Brown-internal or password protected links are styled like this , as opposed to public links . You can also find the list of ideas proposed in previous years 2000 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . Proposals and Projects from Previous Years Click on the year numbers to review some of the individual project proposals students made in 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , and 2018 . The resulting final projects , completed in groups, can be reviewed here for 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , and 2020 .", "metadata": {"last_modified": "2021-09-15T14:40:08+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 138, "token_count_estimate": 202}}, "https://cs.brown.edu/courses/csci2370/2020/": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2020 Home Page Home Syllabus Calendar People Links Project Ideas Time TueThu 1030-1150AM Location brown.zoom.usmylaidlaw, maybe CIT 165 Professor David H. Laidlaw CIT 521, davidlaidlaw at brown.edu, brown.zoom.usmylaidlaw TA Fumeng Yang CIT 509, fumengyang at brown.edu Description Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites programming experience, some graphics experience, and problem ideas. Permission of the instructor required. previous years 2018 2016 2014 2012 2010 2007 2006 2005 2004 2003 2002 2000 1999 as VR Design for Science BrownRISD, now CS137 Brown Brown CS Brown CS Visualization", "metadata": {"last_modified": "2020-08-28T21:17:21+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 171, "token_count_estimate": 273}}, "https://cs2240.graphics/": {"text_content": "CSCI 2240 Advanced Computer Graphics Monday Wednesday Friday, 1100am - 1150am, CIT 368 Teaching Staff Instructor Grad TA HTA HTA Daniel Ritchie Aditya Ganeshan Coco Kaleel Anh Truong UTA UTA Mandy He Yuanbo Li Contact Information Slack This course uses Slack for announcements and discussion. If you have questions about the class materials or assignments, requests for clarification, cool graphics-related stuff you want to share, or anything else that may be of interest to the class as whole, post them here. If you have an atypical question that you are certain will not be of interest to any other student, you can DM the instructor andor TAs. Instructor email If you want to request an extension on an assignment, discuss SEAS accommodations, or have any other issues regarding private or sensitive information, email the instructor directly. Course Calendar Course Description CSCI 2240 is an advanced computer graphics course.It assumes prior experience with the fundamentals of computer graphics, typically by having completed an introductory computer graphics course. The course explores several key areas of 3D graphics---rendering, geometry processing, simulation, and optimization---taking a mathematically-sophisticated approach to each.We will study computational approximations to the physics of light transport and the motion of deformable objects, algorithms for processing 3D triangle meshes, and optimization-based techniques for manipulating 3D shapes.The course culminates with an open-ended, group final project in which students choose a recent research paper of interest and implement the techniques it describes. Past Projects Learning Goals Students who complete this course will Understand the physics of light transport and be able to implement approximate solutions to the rendering equation. Understand the strengths and weakness of different geometry representations and be able to build efficient algorithms for processing and manipulating meshes. Know how to pose graphics problems as quadratic optimization problems and solve the resulting sparse linear systems. Understand the continuum mechanics governing the motion of solid objects and be able to simulate them through finite element approximations. Build depth of knowledge in one area of computer graphics by completing an open-ended final project. Be able to read technical papers in the graphics literature and implement the algorithms they describe. More holistically completing this course will take you from I know the fundamentals of computer graphics to I can read and implement graphics research papers and contribute to new graphics research. Students who complete this course will be well-prepared to begin an academic research career in computer graphics or to join an industrial research and development lab. Accordingly, this course is challenging. On your journey to becoming an independent graphics researcherpractitioner, expect to be pushed out of your comfort zone. It is totally normal to struggle with some assignments in this course to which the TAs can attest. If you feel stuck, remember were here for you Take advantage of office hours and ask for help from your fellow students on Slack. Prerequisites The following skills will be necessary for this course Computer Graphics This course assumes familiarity with the fundamentals of computer graphics, such as 3D transformations, viewing and projection, basic illumination models, raytracing, and OpenGL. Browns introductory computer graphics course, CSCI 1230 , is a prerequisite for this course. Similar courses from other institutions may also be acceptable. Software Engineering The assignments in this course, and particularly the final project, require you to design, develop, and debug large pieces of software. The project work required for CSCI 1230 should be sufficient preparation. If you took an introductory graphics course elsewhere that did not emphasize large software projects, you should have experience with building such projects from other courses. Math The techniques we will explore in this course are based on physics concepts, involve geometric calculations in three-space, andor require solving large systems of equations. Familiarity with linear algebra and vector calculus are important for successfully understanding and applying these techniques. If you are not sure whether you canshould take the course, we encourage you to show up to the first class and talk to the instructor. Textbook There is no required textbook this semester. Readings relevant to each course assignment will be posted on this website.Optionally, you might consider purchasing The Graphics Codex , which costs only 10 and provides reference materials which can be useful for the first part of the course on rendering. Grading Policy Your final grade will be determined by a written assignment, four programming assignments, and a final project, as well as your in-class participation. Percentage-wise, the final grade will break down roughly as follows 5 nbsp nbsp Assignment 0 16 nbsp Assignment 1 15 nbsp Assignment 2 14 nbsp Assignment 3 14 nbsp Assignment 4 30 nbsp Final project 6 nbsp nbsp Class participation These percentages are estimates, and the final percentage values may vary as we deem necessary. For example, if a particular assignment turns out to be more difficult that we expected, we may at our discretion adjust the grade breakdown such that that assignment is less heavily weighted. Late Submissions If you submit an assignment late, 10 of the maximum possible score will be subtracted for each day that is late. Submission within 24 hours after the deadline counts as one day late, within 48 hours after the deadline counts as two days late, and so on. However, you are allowed three 3 late days for the semester. Late days will be factored in at the end of the semester and distributed such that you get the most points possible. Because we do this, use of late days will not be reflected in the initial grade report for your assignments. Sometimes there are special circumstances during the semester that result in exceptions to this late policy. All such circumstances require an official note from the Deans . In general, they only provide support notes on behalf of students who are experiencing disruptive medical or personal circumstances, including those related to Title IX situations, that affect their ability to do academic work in a timely way. You should manage other special circumstances such as interviews, personal travel or extra-curricular factors using the late day policy above. Regrade Requests If you believe that an error was made in grading one of your assignments, please submit a regrade request via Gradescope within one week of receiving your grade . Any regrade requests received after this date will not be considered. Community Service Points We like to reward students who are good course citizens. If you find or fix a bug in any of our assignment code, share a useful resource with the rest of class, or make an especially helpful contribution to discussion in class or on Slack, then the teaching staff may award you extra credit---the precise amount and how it factors in to your final grade is up to our discretion. Please note that posting solutions to parts of assignments is not good course citizenship, nor is showing off how much you know about something. When in doubt, talk to a member of the teaching staff before sharing with the rest of the class. Time Commitment Activity Hours In class 40 Assignments 80 4 19 x 4 Final Project 40 Office hours, Piazza, etc. 20 Total 180 Capstone This course may be used as a capstone course for an Sc.B. degree. Talk to the instructor about registering 2240 as your capstone course. Assignments Assignment Release Date Due Date 0 Radiometry in Flatland Flatland 124 22 1 Path Tracing Path 22 Milestone 29, Final 216 2 Geometry Processing Mesh 216 Milestone 226, Final 36 3 Finite Element Simulation FEM 36 320 4 As-Rigid-As-Possible Surface Modeling ARAP 318 45 Final Project 124 Proposal 41, Milestone 1 415, Milestone 2 429, Presentation 510 Two Minute Papers In the spirit of this YouTube channel , we will be starting each class with a brief student presentation of a recent research paper.Everyone is expected to present once this is a large part of your class participation grade . Sign up for a presentation slot by filling out this spreadsheet . Empty slots in the schedule will be filled by a student selected uniformly at random from the set of students who have not yet presented. Format A brief oral presentation with a hard cutoff at 5 minutes, so please aim to be shorter than that, accompanied by visual aid. Slides are nice, but not required you may show figures directly from the paper, or any existing video that supplements the paper. Resources List of Suggested Papers How to Read a CS Research Paper How to Read a Technical Paper How to Read a Paper Kayvon Fatahalians Clear Talk Tips Course Schedule Date Topic Slides Video Assignments Jan 24 Introduction and Overview Sign the collaboration policy Google form by next class. Fill out this when2meet so we can schedule hours. Check out the Eigen tutorial . pptx video Flatland out Final project out Jan 26 Radiometry pptx video Jan 29 Rendering Equation Monte Carlo Integration pptx video Jan 31 Path Tracing Uniform Hemisphere Sampling pptx video Feb 2 Russian Roulette BRDFs pptx video Path out Flatland due Feb 5 Tone mapping, more BRDFs pptx video Feb 7 Direct Lighting pptx video Feb 9 Advanced Sampling pptx video Path milestone due Feb 12 Advanced Materials Light Transport Algorithms pptx video Feb 14 Meshes Geometry Processing pptx video Feb 16 More Geometry Processing Subdivision pptx video Path due Mesh out Feb 19 No class university long weekend Feb 21 More Subdivision pptx video Feb 23 Mesh Simplification pptx video Feb 26 More Simplification Remeshing Filtering pptx video Mesh milestone due Feb 28 Geometry Representations pptx video Mar 1 More Geometry Representations pptx video Mar 4 Simulation Intro, Implementation, Forces pptx video Mar 6 Simulation Continuum Mechanics pptx video Mesh due FEM out Mar 8 Simulation Finite Element Method pptx video Mar 11 Optimization Intro pptx video Mar 13 Linear Solvers pptx video Mar 15 ARAP paper discussion Mar 18 ARAP discussion continued ARAP out Mar 20 Paper discussions FEM due Mar 22 Paper discussions Mar 25 No class spring break Mar 27 No class spring break Mar 29 No class spring break Apr 1 Weekly project group meetings begin Final project proposal due Apr 5 ARAP due Apr 15 Final project milestone 1 due Apr 29 Final project milestone 2 due May 10 Final project presentations Final project due General Course Policies Diversity Inclusion Our intent is that this course provide a welcoming environment for all students who satisfy the prerequisites. Our TAs have undergone training in diversity and inclusion, and all members of the CS community, including faculty and staff, are expected to treat one another in a professional manner. If you feel you have not been treated in a professional manner by any of the course staff, please contact either the instructor, Ugur Cetintemel Dept. Chair, Tom Doeppner Vice Chair or Laura Dobler diversity inclusion staff member. If you feel more comfortable speaking with a fellow student about your concern, you can confidentially reach out to the Diversity Inclusion Student Advocates . We will take all complaints about unprofessional behavior seriously. Prof. Krishnamurthi has good notes on this area.To access student support services and resources, and to learn more about diversity and inclusion in CS, please visit this webpage . Brown welcomes students from all around the country and the world, and their unique perspectives enrich our learning community. To empower students whose first language is not English, an array of support is available on campus, including language and culture workshops and individual appointments. For more information, contact the English Language Learning Specialists at ellwritingbrown.edu . Academic Integrity Academic dishonesty will not be tolerated. This includes cheating, lying about course matters, plagiarism, or helping others commit a violation. Plagiarism includes reproducing the words of others without both the use of quotation marks and citation. Students are reminded of the obligations and expectations associated with the Brown Academic and Student Conduct Codes . Collaboration Policy For all assignments in this course, feel free to discuss problems, ideas, and course material with other students in the class. For written math problems whose solution is a single number, you are welcome to compare numbers with other students. However, you may not share your derivation of that number. For programming assignments, showing, copying, or any other form of sharing code is not permitted, with one exception you may look at another students code to help them debug under the supervision of TA at TA hours. You may use third-party software, data, or other resources including large language models such as ChatGPT or Github Copilot, as long as they do not provide the solution directly. You must properly cite them i.e. in your assignment README and clearly state what work is your own. As a general policy for this course and for the rest of your academic career if you use any idea, text, code, or data from elsewhere, then cite it. Accommodations Brown University is committed to full inclusion of all students. Please inform the instructor if you have a disability or other condition that might require accommodations or modification of any of these course procedures. You may email the instructor, come to his office hours, or speak with him after class, and your confidentiality will be respected. We will do whatever we can to support accommodations recommended by SEAS. For more information, contact Student and Employee Accessibility Services SEAS at 401-863-9588 or SEASbrown.edu. Students in need of short-term academic advice or support can contact one of the deans in the Dean of the College office. Mental Health Being a student can be very stressful. If you feel you are under too much pressure or there are psychological issues that are keeping you from performing well at Brown, we encourage you to contact Browns Counseling and Psychological Services CAPS . They provide confidential counseling and can provide notes supporting extensions on assignments for health reasons. Incomplete Policy We expect everyone to complete the course on time. However, we certainly understand that there may be factors beyond your control, such as health problems and family crises, that prevent you from finishing the course on time. If you feel you cannot complete the course on time, please discuss with the instructor the possibility of being given a grade of Incomplete for the course and setting a schedule for completing the course in the upcoming year. Thanks to Tom Doeppner and Laura Dobler for text on accommodation, mental health, and incomplete policy.", "metadata": {"last_modified": "2024-03-13T17:34:55+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 2404, "token_count_estimate": 2940}}, "https://cs.brown.edu/courses/csci2370/2021/": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2021 Home Page Home Syllabus Calendar People Links Project Ideas Time TueThu 1030-1150AM Location maybe CIT 506 -- attendance mandatory Professor David H. Laidlaw CIT 521, davidlaidlaw at brown.edu, brown.zoom.usmylaidlaw Description Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites programming experience, some graphics experience, problem ideas, motivation. Permission of the instructor required. Final project reports from past years, completed in groups 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , and 2020 . Websites from past years 2020 2018 2016 2014 2012 2010 2007 2006 2005 2004 2003 2002 2000 1999 as VR Design for Science BrownRISD, now CS137 Brown Brown CS Brown CS Visualization", "metadata": {"last_modified": "2021-09-08T13:58:59+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 200, "token_count_estimate": 313}}, "https://cs.brown.edu/courses/csci2370/2022/": {"text_content": "CSCI2370 Interdisciplinary Scientific Visualization fall 2022 Home Page Home Syllabus Calendar People Links Project Ideas Time TueThu 1030-1150AM Location maybe CIT 506 -- attendance mandatory Professor David H. Laidlaw CIT 521, davidlaidlaw at brown.edu, brown.zoom.usmylaidlaw Description Learn how to do interdisciplinary scientific visualization research, from soup to nuts, in one semester. Projects will involve the solution of scientific problems using computer graphics, modeling, and visualization. Working in small groups, students will identify scientific problems, propose solutions involving computational modeling and visualization, evaluate the proposals, design and implement the solutions, apply them to the problems, evaluate their success, and report on results. Examples might include interactive software systems, immersive virtual reality applications, quantitative analysis tools, or new applications of existing visualizations methods. Suggested prerequisites programming experience, some graphics experience, problem ideas, motivation. Permission of the instructor required. Final project reports from past years, completed in groups 1999 , 2000 , 2003 , 2005 , 2007 , 2010 , 2012 , 2014 , 2016 , 2018 , 2020 , and 2021 , Websites from past years 2021 2020 2018 2016 2014 2012 2010 2007 2006 2005 2004 2003 2002 2000 1999 as VR Design for Science BrownRISD, now CS137 Brown Brown CS Brown CS Visualization", "metadata": {"last_modified": "2022-08-29T15:07:16+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 203, "token_count_estimate": 320}}, "https://cs.brown.edu/courses/csci2510/": {"text_content": "CSCI2510 Approximation Algorithms Spring 2018 Announcements Homework 5 , due on May 4 at 1100 Worked through this paper on an approximation scheme for packing and covering LPs Homework 4 Problems 7.2, 8.11, 11.2, 15.5, due at beginning of class on April 11. Homework 3 Problems 6.2, 8.2, due at beginning of class on March 14. Homework 2 Problems 7.4, 7.6, 7.8, due at beginning of class on March 5. Homework 1 due at beginning of class on February 16. Syllabus The course calendar lists a guess as to topics per lecture Instructor Professor Philip Klein email available at directory.brown.edu , CIT 511, office hours by appointment Topics The following chapters will be emphasized Topics are subject to change. Ch 1 Introduction Ch 4 Deterministic Rounding Ch 7 Primal-Dual Method Ch 8 Cuts and Metrics Ch 11 More Deterministic Rounding Ch 12 Randomized Rounding Ch 14 More Primal-Dual Method Ch 15 More Cuts and Metrics Time permitting, sum-of-squares method Assignments Problem sets will be assigned every 1 to 2 weeks. No exams will be given. Calendar, subject to change Resources Tutorial on sum-of-squares method Description Approximation algorithms deal with NP-hard combinatorial optimization problems by efficiently constructing a suboptimal solution with some specified quality guarantees. We study techniques such as linear programming and semidefinite programming relaxations, and apply them to problems such as facility location, scheduling, bin packing, maximum satifiability or vertex cover. Prerequisite one of the following CSCI 1510, 1550, 1810, 1950J, 1950L, any graduate-level course on algorithms including 2500A, 2500B, 2580. Collaboration Policy In finding solutions to the problems in this class, you are allowed to collaborate with other students in the class. However, you should not retain any written digitally or otherwise record from your period of collaboration, and you should write up your solutions on your own, and list the names of those with whom you collaborated. Please dont use sources other than the textbook and lectures in connection with doing the homework problems. Textbook The Design of Approximation Algorithms by David P. Williamson and David B. Shmoys.", "metadata": {"last_modified": "2018-04-23T16:46:04+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["CSCI2510: Approximation Algorithms (Spring 2018)", "Announcements", "Instructor", "Topics", "Assignments", "Calendar, subject to change", "Resources", "Description", "Collaboration Policy", "Textbook"], "word_count": 341, "token_count_estimate": 507}}, "https://cs.brown.edu/courses/info/csci2420/": {"text_content": "CSCI2420 Probabilistic Graphical Models Not offered this year Offered most years, last taught Fall 2018 Probabilistic graphical models provide a flexible framework for modeling large, complex, heterogeneous collections of random variables. After a brief introduction to their representational power, we provide a comprehensive survey of state-of-the-art methods for statistical learning and inference in graphical models. We discuss a range of efficient algorithms for approximate inference, including optimization-based variational methods, and simulation-based Monte Carlo methods. Several approaches to learning from data are explored, including conditional models for discriminative learning, and Bayesian methods for controlling model complexity. Programming experience required for homeworks and projects, which integrate mathematical derivations with algorithm implementations. PREREQUISITES CSCI1420 or APMA1690. Instructors CRN None", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Information for:", "CSCI2420", "Probabilistic Graphical Models"], "word_count": 116, "token_count_estimate": 164}}, "https://cs.brown.edu/courses/csci2590/": {"text_content": "CS2590 Advanced Cryptography The focus of this semester is zero-knowledge proofs and arguments. Starting from seminal works that introduced and formalized zero-knowledge, we will discuss different zero-knowledge protocols. We will see their applications in various settings such as identification protocols, secure computation and cryptocurrencies. We will then discuss more recent works on zero-knowledge succinct non-interactive arguments. zk-SNARGs and SNARKs Instructor Anna Lysyanskaya annacs.brown.edu Course TA Apoorvaa Deshpande acdeshpacs.brown.edu Meeting Times and Location Tuesdays and Thursdays 1030-1150 am, CIT 101 TA Hours Tuesdays 3-5 pm, CIT 102 Apoorvaa Thursdays 3-4 pm, CIT 501 Prof. Lysyanskaya, by appointment Latest Updates Problem Set 1 is out. It is due on February 21 in class. Link Sign-up sheet for presenting is now available. Please sign up before February 4. Link Course syllabus PDF file is now available. PDF Course Syllabus and Schedule Jan 24, 2019 Class Cancelled Jan 29, 2019 Course Overview Jan 31, 2019 Introduction to zero-knowledge, Definitions Papers Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems link O Goldreich, S Micali, A Wigderson, JACM, 1991 Zero-Knowledge A tutorial by Oded Goldriech link Feb 5, 2019 Lower bounds on zero-knowledge Papers On the Composition of Zero-Knowledge Proof Systems link O Goldreich and H Krawczyk, SIAM Journal of Computing, 1996 How to go beyond the black-box simulation barrier link B Barak, FOCS 2001 Definitions and properties of zero-knowledge proof systems link O Goldreich and Y Oren, Journal of Cryptology, 1994 Feb 7, 2019 Round complexity of zero-knowledge protocols Papers How to Construct Constant-Round Zero-Knowledge Proof Systems for NP link O Goldreich and A Kahan Zero Knowledge Proofs of Knowledge in Two Rounds link U Feige and A Shamir, CRYPTO 1989 Which Languages Have 4-Round Zero-Knowledge Proofs link J Katz Feb 12 and 14, 2019 Sigma protocols and Discrete-Log-based protocols Papers Efficient signature generation by smart cards link C Schnorr On Sigma Protocols Survey Paper link I Damgard A signature scheme with efficient protocols link J Camenisch and A Lysyanskaya, SCN 2002 Feb 19, 2019 No Class Presidents Day Feb 21, 2019 Fiat-Shamir Transformation Papers How to prove yourself Practical solutions to identification and signature problems link A Fiat and A Shamir, CRYPTO 1986 On the insecurity of the Fiat-Shamir paradigm link S Goldwasser and Kalai. Feb 26, 2019 Non-interactive zero-knowledge Papers Non-interactive zero-knowledge link M Blum, A De Santis, S Micali, G Persiano, SIAM Journal on Computing, 1991 Feb 28, 2019 Multi-prover Non-interactive zero-knowledge Papers Multiple Non-interactive zero-knowledge proofs under General Assumptions link U Feige, D Lapidot, A Shamir, SIAM Journal on Computing, 1999 March 5, 2019 NIZK Constructions based on bilinear maps Papers New Techniques for Non-interactive zero-knowledge link J Groth, R Ostrovsky, A Sahai, JACM 2012 March 7, 2019 Efficient Non-interactive Proofs for Bilinear Groups Papers Efficient Non-interactive Proofs for Bilinear Groups link J Groth and A Sahai, EUROCRYPT 2008 March 12, 2019 Randomizable and Malleable NIZK Proofs Papers Randomizable Proofs and Delegatable Anonymous Credentials link M Belenkiy, J Camenisch, M Chase, M Kohlweiss, A Lysyanskaya, S Meiklejohn, CRYPTO 2009 Malleable Proof Systems and Applications link M Chase, M Kohlweiss, A Lysyanskaya, S Meiklejohn, EUROCRYPT 2012 March 14, 2019 Fully Homomorphic Proofs Papers March 19, 2019 Computationally sound proofs, probabilistically checkable proofs PCPs Papers Computationally Sound Proofs link S Micali, FOCS 1994 March 21, 2019 Succinct NP Proofs Papers Succinct NP Proofs from an Extractability Assumption link G Di Crescenzo and H Lipmaa 2008 March 26 and 28, 2019 No Class Spring Break April 2, 2019 Succinct Non-interactive Arguments of Knowledge SNARKs Papers The Hunting of the SNARK link N Bitansky, R Canetti, A Chiesa, S Goldwasser, H Lin, A Rubinstein, E Tromer, Journal of Cryptology 2017 April 4, 2019 Implausibility of basing SNARKS on standard assumptions Papers Separating Succinct Non-Interactive Arguments From All Falsifiable Arguments link C Gentry and D Wichs April 9, 2019 SNARKS from Quadratic Spanning Programs Papers Quadratic Span Programs and Succinct NIZKs without PCPs link R Gennaro, C Gentry, B Parno, M Raykova, EUROCRYPT 2013. April 11, 2019 Efficient SNARKS from bilinear assumptions Papers On the Size of Pairing-Based Non-interactive Arguments link J Groth, EUROCRYPT 2016. April 16, 2019 Subversion SNARKs Papers Subversion Zero-Knowledge SNARKs link G Fuchsbauer, PKC 2018. April 18, 2019 Updateable CRS and Applications to zk-SNARKs Papers Updateable and Universal CRS and Applications to zk-SNARKs link J Groth and M Kohlweiss and M Maller and S Meiklejohn and I Miers, CRYPTO 2018. April 23, 2019 Bulletproofs Papers Bulletproofs Short Proofs for Confidential Transactions link B Bnz and J Bootle and D Boneh and A Poelstra and P Wuille and G Maxwell, IEEE SnP 2018. April 25, 2019 STARKs Transparent SNARKs Papers Scalable, Transparent, and Post-quantum Secure Computational Integrity link E Ben-Sasson and I Bentov and Y Horesh and M Riabzev April 30, 2019 Last Class Concluding Remarks on ZK Proofs and Arguments", "metadata": {"last_modified": "2019-04-22T13:44:21+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 806, "token_count_estimate": 1417}}, "https://cs.brown.edu/courses/csci2730/": {"text_content": "cs273 Programming Language Theory Spring 2016 Spring 2015 Fall 2011 Fall 2009 Spring 2002", "metadata": {"last_modified": "2016-01-27T15:39:36+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [], "word_count": 14, "token_count_estimate": 25}}, "https://cs.brown.edu/courses/csci2750/": {"text_content": "CS2750 Topics in Parallel and Distributed Computing Spring 2014 Tuesday and Thursday 100-220 CIT 368 Schedule Starting Points Course Information Grades and Assignments Course Information Simply put, the goal of this course is to hone certain coreskills essential for success as a researcher or practitioner of ComputerScience. Imagine that some day your boss, or thesisadvisor, or principal investor, or president, or spouse says you have a weekto please bring me up to date on state-of-the-art Foozle research. Failurewill be a CLM career limiting move. What will you do The goal of this course is to take a snapshot of currentresearch topics in distributed and concurrent computing. We will start with papers published in the principal conferences in thisarea. Progress at the forefront of research is often incrementalone researcher publishes a paper posing a question or claiming a result, and a sequence of follow-on papers improve the result or alterthe question. For this reason, we willorganize our approach around the idea of clusters of papers. A cluster consists of one primary paper, the one to read if youcan read only one, together with two or three secondary papers. Theprimary paper may have been the first to formulate the problem or technique, orit may have provided the best solution to the problem, or perhaps it is simplythe most readable. Schedule Slides Course Missive Phoenix Grades andAssignments Participation 10of course grade Research papers are often poorlywritten, sometimes make exaggerated or misleading claims, and occasionallycontain errors or major ambiguities imagine that. I expect students tocontribute to the discussion by asking questions, making observations, andsubjecting material to critical scrutiny. These skills will be useful in anyarea of science. Most important the course wont be any fun withoutlively participation from the studio audience. Presentations40 of course grade Students will work in teams of two ,and each team should plan to make about four presentations. In consultation with theinstructor, each team will Identify a topic, Identify an primary paper see above, and Identify two or three secondary papers. The team will give a presentation on the topic, with anemphasis on The basic problem or technique, A critical evaluation of the primary paper, The context and depth provided by secondary papers, and Open research questions. Teams are advised, but not required, to show theirpresentations to the instructor before the presentation. Each presentation will have 80 minutes one classperiod. At least one week before thepresentation, the team will post the primary paper to the web page. At the timeof the presentation, the team will deliver to the instructor some version ofthe presentation suitable for posting on the course web page. Depending on the course enrollment, teams may have topresent more than once. Paper Evaluations10 of course grade A paper evaluation form consists of Your name The paper name Summarize the paper no more than five sentences Most important strengths no more than three, one sentence each Most important weaknesses no more than three, one sentence each State one problem or issue left open no more than three sentences. Paper evaluations will be graded on a scale of one to three.The default grade is two. Insightful reviews get three, and disappointingreviews get one. Students will email evaluations of primary papers to theinstructor cs275.browngmail.com before the start of the class in which the paper is presented. Late orincomplete evaluations get no credit. Students are required to evaluate atleast two-thirds of the primarypapers presented. PresentationEvaluations 10 of course grade You are also required to evaluate presentations. Why First,if you have to write a review of someone elses talk, you had better pay attention.Second, if you know that your own talk is being evaluated by the studioaudience not just the instructor, then you may try harder to appeal to them.In the Real World, when you graduate, you will have to capture the attentionof intelligent, well-educated audiences that know little or nothing about yourfield. Sharpen your skills now. A presentation evaluation form must contain thefollowing fields Name Your name Presenters whos talking Vision how well did the presenters explain why thearea matters Style did the presenters mumble, fail to make eyecontact, speak too quickly, too slowly, or what Exposition were the PowerPoint slides too busy, toougly, or just right QA How well did the presenters seem to know thematerial Were they honest about admitting when they dont know something Comments anything else you would like to say. Presentation evaluations will be graded on a scale of one tothree. The default grade is two. Insightful evaluations get three, anddisappointing evaluations get one. Evaluations for talks where I suspect thereviewer was not physically present get zero. Presentation evaluations are intended to be helpful. It isOK to be frank otherwise whats the point but be polite no matter how youare provoked. I will merge and edit presentation evaluations and forward themto the presenters. Your evaluations will be kept anonymous, and I retain theright to edit or suppress intemperate or inappropriate comments. Students will email evaluations of presentations theinstructor cs275.browncs.brown.edu before Friday 500 PM inthe week in which the presentation occurred. Late or incomplete evaluations getno credit. Students are required to evaluate at least two-thirds of the presentations. Project 30 ofcourse grade The final project requirements are the same as for thepresentation, except that You work alone, not in a team, and You write a term paper, not a presentation. You may choose to work on the same topic as your presentation, but the papers covered should not be the same Consult the instructor if there is any question. Missive Introductionslides Some StartingPoints PODC 2013 DISC 2013 Transact 2013 ASPLOS 2013 EuroSys 2013 OSDI2012 PPoPP 2013 SPAA 2013 Some of these pages have links to the papers, and some havetitles only. You may need to use search engines or contact the authors. Instructor MauriceHerlihy Maurice Herlihy", "metadata": {"last_modified": "2014-01-23T02:46:16+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": [""], "word_count": 958, "token_count_estimate": 1228}}, "https://cs.brown.edu/courses/csci2950-p/": {"text_content": "Probabilistic Graphical Models News Lectures Assignments Resources Probabilistic Graphical Models CSCI 2950-P Special Topics in Machine Learning, Spring 2013 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Graduate Teaching Assistant Jason Pacheco , lastnamefirstinitial-at-cs-dot-brown-dot-edu. Office Hours Erik Sudderth Tuesdays 230-400pm, CIT room 509 . Jason Pacheco Thursdays 230-400pm, CIT room 361 . Lectures Tuesdays and Thursdays, 100-220pm, CIT room 506 . Past Courses Fall 2011 Applied Bayesian Nonparametrics . Spring 2010 Learning Inference in Probabilistic Graphical Models . Announcements May 2, 2013 Final project presentations will be on Tuesday, May 7 at 100pm in Lubrano CIT 477. Lunch will be served April 2, 2013 We have extended the deadline for project proposals to April 4, and have also made the homework late submission policy slightly more flexible. See the assignments page. March 4, 2013 As listed on the assignments page, we have extended the deadlines for some homeworks. Course project proposals are now due on Tuesday, April 2. February 28, 2013 Additional instructions on formatting and electronic homework submission are now listed on the assignments page. February 19, 2013 See the assignments page for additional details regarding homework assignments, including handin instructions, collaboration policies, and late submission policies. Homework 1 is due on March 1, 2013. January 30, 2013 The printed course reader, containing Jordans An Introduction to Probabilistic Graphical Models , will be available at Metcalf Copy Center by Friday morning possibly earlier. January 29, 2013 To receive email announcements, please register for the course as an auditor, if not taking for credit. A welcome message was sent to registered students this afternoon. January 28, 2013 Staff office hours will be held on Tuesdays and Thursdays, after lecture. Readings are posted on the course calendar . January 23, 2013 The first lecture will be held at 100pm on Thursday, January 24.", "metadata": {"last_modified": "2013-05-06T03:05:42+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Probabilistic Graphical Models", "Announcements"], "word_count": 312, "token_count_estimate": 481}}, "https://cs.brown.edu/courses/csci2950-p/fall2011/": {"text_content": "Applied Bayesian Nonparametrics News Lectures Assignments Resources Applied Bayesian Nonparametrics CSCI 2950-P Special Topics in Machine Learning, Fall 2011 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Graduate Teaching Assistant Jason Pacheco , lastnamefirstinitial-at-cs-dot-brown-dot-edu. Office Hours Erik Sudderth Mondays 200pm-300pm, Tuesdays 400pm-500pm, CIT room 509 . Jason Pacheco Tuesdays 1200pm-100pm, CIT room 361 . Further discussion in MLRG . Lectures Tuesdays and Thursdays, 230pm-350pm, CIT room 506 . Past Courses Spring 2010 Learning Inference in Probabilistic Graphical Models . Announcements November 3, 2011 Prof. Sudderth will hold additional office hours on Friday, November 4 from 300-400pm. On Monday, November 7 his office hours will be held from 300-400pm. On Tuesday, November 8 his office hours are cancelled. November 1, 2011 The deadline for submission of project proposals has been extended until Monday, November 7 at 1159pm. October 6, 2011 Please welcome our new part-time teaching assistant, Jason Pacheco. Jason will hold office hours on Tuesdays at noon in CIT 361, and also coordinate discussions of course material in the Machine Learning Reading Group . October 3, 2011 Prof. Sudderths office hours are cancelled on Tuesday October 4 due to Michael Jordans distinguished lecture , and Monday October 10 due to the holiday weekend. September 21, 2011 Please follow the instructions sent to the course mailing list to submit preferences for the readings youd like to present. Note also that the first reading comments are due on Thursday, Sept. 22. September 17, 2011 All registered students should now be members of the courses Google group brown.course.csci.2950p.2011-fall.s01 . This list will be used for reading comments, as well as course announcements.", "metadata": {"last_modified": "2011-11-03T13:48:33+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Applied Bayesian Nonparametrics", "Announcements"], "word_count": 279, "token_count_estimate": 452}}, "https://cs.brown.edu/courses/csci2950-p/spring2010/": {"text_content": "Learning Inference in Probabilistic Graphical Models News Lectures Assignments Resources Learning Inference in Probabilistic Graphical Models CSCI 2950-P Special Topics in Machine Learning, Spring 2010 Brown University Department of Computer Science Course Information See the syllabus . Instructor Professor Erik Sudderth , lastname-at-cs-dot-brown-dot-edu. Office Hours Wednesdays 300pm-500pm, CIT room 509 . Lectures Mondays and Wednesdays, 1030am-1150am, CIT room 506 . Announcements May 7, 2010 Course project presentations will be held on Monday, May 10 from 1000am-1200pm in Lubrano CIT 477. The deadline for submitting final project reports has been extended to Wednesday, May 19. May 3, 2010 Prof. Sudderths normal office hours on Wednesday, May 5 are cancelled. His final office hours of the semester will instead be on Thursday, May 6 from 130-330pm. April 13, 2010 On Wednesday, April 14, the class will meet in a different room, CIT 367. We will return to CIT 506 next week. March 15, 2010 For the remainder of the semester, Prof. Sudderths Tuesday office hours are cancelled. His Wednesday office hours have been extended to 300-500pm. March 5, 2010 All classes and office hours are cancelled for the week of March 8-12. Please check the updated schedule for more details. We will makeup these lectures during reading week May 3-7. February 16, 2010 Addition of many links to tutorials, courses, books, and software for graphical models. These resources may be useful in preparing for course projects. February 10, 2010 A Google group, brown-cs295-p , has been setup to post comments on the course readings. Please follow these detailed instructions to join this group, and post your comments in the specified style. February 9, 2010 The primary course mailing list, cs295-p at cs, has now been setup. Students taking the course who did not receive a welcome message should contact the instructor.", "metadata": {"last_modified": "2010-05-12T02:21:29+00:00", "scraped_at": "2024-03-13T22:15:23+00:00", "headings": ["Learning & Inference in Probabilistic Graphical Models", "Announcements"], "word_count": 299, "token_count_estimate": 459}}, "https://cs.brown.edu/courses/info/csci2950-v/": {"text_content": "CSCI2950-V Topics in Applied Cryptography Not offered this year Offered occasionally, last taught Fall 2020 This course surveys recent developments in applied cryptography. Research in this field is motivated by privacy and security issues that arise in practice from areas like cloud computing, databases, surveillance and finance. Topics will vary each year. Prerequisite CSCI 1660 required CSCI 1510 strongly recommended. Instructors Seny F Kamara CRN 16599", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI2950-V", "Topics in Applied Cryptography"], "word_count": 66, "token_count_estimate": 94}}, "https://cs.brown.edu/courses/info/csci2951-i/": {"text_content": "CSCI2951-I Computer Vision for Graphics and Interaction Offered this year and most years Fall 2024 Computer vision reconstructs real world information from image and video data computer graphics synthesizes dynamic virtual worlds interaction lets us explore these worlds and machine learning allows us to map between domains across vision, graphics, and interaction. In visual computing, these fields converge to exploit both models of visual appearance and databases of examples to generate and interact with new images. This enables applications from the seemingly simple, like semantic photo editing, to the seemingly science fiction, like mixed reality. In this seminar, we will discover the state-of-the-art algorithmic contributions in computer vision which make this possible. Please join us Prerequisites CSCI 1430, 2240, CLPS 1520, COGS 1200 or ENGN 1610. Instructors James H Tompkin Course Home Page httpscs.brown.educoursescsci2951-i Location TBD Meeting Time TBD Exam Group TBD CRN None", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI2951-I", "Computer Vision for Graphics and Interaction"], "word_count": 144, "token_count_estimate": 203}}, "https://cs.brown.edu/courses/csci2950-u/s18/": {"text_content": "Quick Summary This is a PhD-level course focusing on the infrastructure advancements and challenges in the next generation of cloud computing an environment which moves beyond virtual machines and containers to flexible composition of fine-grained services. We will focus on applications, datacenters, networking, orchestration, monitoring, among other things. Focus on research read, review and present papers, final research project Graduate students or advanced undergrads with consent of instructor Not a traditional networking course not CSCI1680 We will use a conference review system link coming soonto post reviews and hold discussions about papers, and Piazza for announcements and general comments questions. It is mandatory to register for both. Overview This class is a graduate seminar that focuses on current research topics innetworking, distributed, and operating systems. The focus this semester is onadvanced networking. This course is suitable for graduate students and advanced undergraduates inComputer Science or in other disciplines that wanto to understand how recent developmentsin networking, from technology to policy impact how we use, program, and interact with networks. The course will consist of a mix of lectures by the instructor and guests, andpresentations by the students, followed by discussions. We will read a goodnumber of papers, and students will write reviews of each paper read, before theclass in which the paper is discussed. The other major component of the course is a final research project ona topic related to the course. There is considerable flexibility in the topic of the project, with apreference for topics related to the students own research if applicable. Theprojects will preferably be done in groups of two, but individual projects are welcome. The best projects of the course could be turned into research publications with further development. Lecture time TuTh 230-350 Location Lubrano, CIT Instructor Rodrigo Fonseca rfonsecacs.brown.edu Office CIT 329, OH by appointment", "metadata": {"last_modified": "2018-01-31T03:46:20+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["", "", "Quick Summary", "Overview", "Instructor"], "word_count": 300, "token_count_estimate": 374}}, "https://cs.brown.edu/courses/csci2951-i/": {"text_content": "CSCI 2951-I Computer Vision for Graphics and Interaction Fall 2022, MW 1500 to 1620, CIT 101 Instructor James Tompkin Faculty StyleGAN interpolation video Contact Everything is through Slack. James office hour appointment slot signups are here top left . Course Description How does computer vision enable new interactive graphical applications, and how can we improve them Computer vision strives to understand, interpret, and reconstruct information about the real world from image and video data. Computer graphics models dynamic virtual worlds to be synthesized in realistic or stylized ways. In visual computing, these fields are converging since both disciplines create and exploit models describing the visual appearance of objects and scenes. Interaction allows us to explore these worlds, and to use ourselves and our environments directly as interfaces. Machine learning and deep learning allows us to define mappings between domains across vision, graphics, and interaction, and to generate new data such as images from recombining existing databases. Combined, these disciplines enable applications from the seemingly simple, like semantic photo editing, to the seemingly science fiction, like mixed reality. In this seminar course, we will discover the state of the art algorithmic contributions in computer vision which make these new applications possible. We will concentrate on recent research results that were published at top-tier conferences and journals from problem fields such as reconstruction of static and dynamic 3D scenes, computational photography and videography, multi-view camera systems, generative methods for image formation, and vision-based interaction devices. Each week, we will read state-of-the-art papers, present them, and discuss their contributions, impact, and limitations. Then, we will develop projects which implement and extend these ideas. Beyond computer vision, this course will help us learn how to quickly interpret and assess academic papers, and how to give effective and engaging presentations. Please join us Learning Objectives Upon completion of this course, students will have Practical experience reading academic papers, and the skill to digest them quickly Created effective presentations to explain state-of-the-art techniques, by learning how to critique and how to respond to critique Formed, discussed, and evaluated many project ideas, and gained experience creating structured research project proposals Developed practical research project skills and demonstrated these on an unsolved computer vision problem Familiarity with the state of the art in reconstructing and generating images computationally. Course Structure The course is spilt into two halves. In the first half, we will read research papers, present them, and discuss their contributions, impact, and limitations. We will build upon our analyses and discussions to propose projects which would further the state of the art. Then, in the second half, we will try and do it we will break into teams and implement projects which further the state of the art. First HalfReview, Ideation, and Proposal We will read two papers per week, and think about their successes and limitations. For each paper, everyone will submit two questions plus a project ideas for discussion by noon on the day of the seminar . 3-6 hours per week In class, we will present the papers. Each student will present at least once, and depending on enrollment this could be individually or in groups. Before the presentation, each student must meet with James to go over the work. 5 hours prep 30 minute presentation As a class and with a student discussion leader assigned randomly on the day, we will critique the presentation and discuss its strengths and how it could have been improved. 10 minutes After the presentation, together we will discuss the papers in detail to understand them and to generate new ideas. Each student will act as the discussion moderator at least once. 30 minutes In groups, we will develop these ideas into project proposals to try to extend the state of the art. We will critique these proposals in class. 2 proposals 8 hours per proposal self-determined but cycling groups. Second HalfImplementation Teams and projects will finalize. Teams will implement their research projects. In class, we will work together to resolve problems and integrate ideas. We will review and critique progress at regular intervals. Finally, we will present our projects to the rest of the visual computing group, and eat cake. Grading 25 paper questions, contribution and improvement in discussion and critique. 25 presentation skill improvement and overall quality. 50 project effort and outcome. Time Commitment Tasks Hours In class 40 Paper reading 35 Paper presentation 5 Projects Proposals 10 Discussion 10 Implementation 80 Total 180 Capstone This class can be taken as a capstone. Talk to James about the expected standard and additional work across the course. Prerequisites This is a graduate course, but undergraduates are welcome As a graduate class, we expect you to be somewhat self-guided be prepared to read beyond the course material, and to explore and discover for yourself. Students should know something about visual computing before taking this course, e.g., having taken an existing vision, graphics, or deep learning course. Any other interested students should get in touch with James CSCI 1230 Introduction to Computer Graphics Should be OK for more experienced students Knowing something about machinedeep learning will help. CSCI 1290 Computational Photography This is a hybrid graphicsvision course, so it should put you in good stead. CSCI 1300 Interface Design It will be tough, unless you know some more fundamental techniques in visual computing. CSCI 1420 Machine Learning Please expect to learn some graphics by yourself. CSCI 1430 Computer Vision ENGN 1610 Image Understanding Some of the graphics concepts may be tougher this isnt primarily a recognition course. CSCI 1490 Deep Learning Many topics will touch on deep learning please expect to learn about graphics. CSCI 2240 Interactive Computer Graphics Great Please expect to learn about machinedeep learning by yourself. Late Submissions and Late Days Due to the form of the class, there are no late submissions or late days. We expect you to attend every session, but let James know if you have any special requirements. For sickness and other issues of wellbeing, please obtain a note from health services and we will accommodate. Course Notes Paper Reading We expect you to read every paper in preparation for the upcoming presentation and discussion. Reading these papers may be difficult initially, and students are not expected to understand everything. However, students are expected to actively engage in discussions to further their understanding of the presented material, with the help of the instructor and the class, within a supportive and creative atmosphere. Ideas that are developed during the seminar discussion are intended to directly influence your projects. Paper Presentations What is the research context for this paper What connections exist to previous work we have read What is the research problem that this paper is trying to solve Cut away the extraneous details and explain it in simple terms. What is the contribution over exist works, and how significant is this contribution What was difficult to understand in their method Any interesting nuance or tricks How is the work validated, and in what areas could this be improved What is good about the work What are the limitations of the work How could it be improved What comes next Demos are welcome Code or executables may be available for the techniques, and you should feel free to show them off. Likewise, for video material, but dont just play it without providing any insight. Leading the Discussion Each session, one student will be randomly selected as the discussion leader. They will receive a digest of the submitted questions before the seminar. Their goal is to briefly summarize the strengths and weaknesses of the technique, raise questions appropriately throughout the discussion, covers future work ideas, and keep order. Reading References How to Read and Present Academic Papers Reading Slides PDF 2MB Keshav, How to Read a Paper, SIGCOMM Computer Communication Review 2007 DOI Fong, Reading a Computer Science Research Paper, SIGCSE Bulletin 2009 DOI McGuire, How to Read Rendering Research Papers, UWaterloo Advanced Ray Tracing Course 2019 PPTX Presenting Slides PPTX 10MB PDF 4MB Fatahalian, Tips for Giving Clear Talks McGuire, How to Present a Research Paper, UWaterloo Advanced Ray Tracing Course 2019 PPTX Further reading material General terminology Dictionary of Computer Vision and Image Processing , by Fisher et al. If you find a word or concept that you do not understand, then please consider looking here. Note Full text is available in Online Resources section. Python Numpy Python ProgrammerNumpy in 5 minutes YouTube UCSB Numpy Tutorial Numpy Tutorial A Simple Example-based Guide Linear Algebra Immersive Linear Algebra , by J. Strm, K. strm, and T. Akenine-Mller. Interactive visualizations 3 Blue 1 Brown httpwww.3blue1brown.com Geometric interpretation Linear Algebra playlist Stanford CS229 review httpcs229.stanford.edusectioncs229-linalg.pdf Probability Seeing Theory httpstudents.brown.eduseeing-theory MagnussonBayesian Inference httprpsychologist.comd3bayes Image processing PowellKernels httpsetosa.ioevimage-kernels Neural Networks and Machine Learning Michael Nielson httpneuralnetworksanddeeplearning.com Chris Olah httpcolah.github.io Distill httpdistill.pub Weipractical advice httplamda.nju.edu.cnweixsprojectCNNTricksCNNTricks.html Multi-view Geometry Hartley and Zisserman Multiple View Geometry in Computer Vision or online Brown Library Tentative Schedule Date Topic Reading Slides More info First halfReview, Ideation, and Proposal Wed 07 Sep Intro Mon 11 Sep How to read, present, question Approximating Reflectance Functions using Neural Networks, Gargan and Neelamkavil, Eurographics Workshop on Rendering Techniques 1998 Wed 13 Sep Paperoverview Neural Fields in Visual Computing and Beyond , Xie and Takikawa et al., Eurographics STAR 2022 Mon 19 Sep Paperbasic application Learning Continuous Image Representation with Local Implicit Image Function , Chen et al., CVPR 2021 Wed 21 Sep Paperbasic application DeepSDF Learning Continuous Signed Distance Functions for Shape Representation , Park et al., CVPR 2019 Mon 26 Sep Paperarchitecture Implicit Neural Representations with Periodic Activation Functions , Sitzmann and Martel et al., NeurIPS 2020 Wed 28 Sep Papersignals BACON Band-limited Coordinate Networks for Multiscale Scene Representation , Lindell et al., CVPR 2022 Mon 03 Oct Paperforward maps NeRF Representing Scenes as Neural Radiance Fields for View Synthesis , Mildenhall, Srinivasan, Tanick et al., ECCV 2020 Wed 05 Oct Paperhybrid representations Instant Neural Graphics Primitives with a Multiresolution Hash Encoding , Mller et al., SIGGRAPH 2022 Mon 10 Oct Indiginous Peoples Dayno class Wed 12 Oct Trial proposal session Mon 17 Oct Paperpriorsconditioning pixelNeRF Neural Radiance Fields from One or Few Images , Yu et al., CVPR 2021 Wed 19 Oct Papermanipulation Decomposing NeRF for Editing via Feature Field Distillation , Kobayashi et al., NeurIPS 2022 Mon 24 Oct Papermotion VideoINR Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution , Chen et al., CVPR 2022 Wed 26 Oct Papermateriallighting NeRFactor Neural Factorization of Shape and Reflectance Under an Unknown Illumination , Zhang et al., SIGGRAPH Asia 2021 Mon 31 Oct Project market Halloween bonus points for costumes Wed 02 Nov Final project proposal session Second halfImplementation Mon 07 Nov Papergenerative images DreamFusion Text-to-3D using 2D Diffusion , Poole et al., arXiv 2022 Zero-Shot Text-Guided Object Generation with Dream Fields , Jain et al., CVPR 2022 Wed 09 Nov Papergenerative shape Learning Disentangled Neural Mesh-based Implicit Field for Geometry and Texture Editing , Yang and Bao et al., ECCV 2022 Mon 14 Nov Paperdigital humans SMPLicit Topology-aware Generative Model for Clothed People , Corona et al., CVPR 2021 PIFu Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization , Saito et al., ICCV 2019 Wed 16 Nov Studio session Mon 21 Nov Studio session Wed 23 Nov Thanksgivingno class Mon 28 Nov Studio session Wed 30 Nov Project review Mon 05 Dec Studio session Wed 07 Dec Studio session Fri 09 Dec New England Computer Vision Workshop MIT Class field trip Fri 16 Dec Final presentations General Policy Welcome Our intent is that this course provide a welcoming environment for all students who satisfy the prerequisites. Our TAs have undergone training in diversity and inclusion, and all members of the CS community, including faculty and staff, are expected to treat one another in a professional manner. If you feel you have not been treated in a professional manner by any of the course staff, please contact any of James the instructor, John Hughes Dept. Chair, Tom Doeppner Director of Undergraduate Studies, David Laidlaw Director of Graduate Studies, or Laura Dobler diversity and inclusion staff member. We will take all complaints about unprofessional behavior seriously. Your suggestions are encouraged and appreciated. Please let James know of ways to improve the effectiveness of the course for you personally, or for other students or student groups.To access student support services and resources, and to learn more about diversity and inclusion in CS, please visit httpcs.brown.eduaboutdiversityresources . Prof. Krishnamurthi has good notes on this area. Quiet Hours This class runs quiet hours from 9pm to 9am every day. Please do not expect a response from us via any channel. Likewise, we wont ask you to do anything between these times, either, like hand in projects. Academic Integrity, Collaboration, and Citation Feel free to talk to your friends about the concepts in the projects, and work through the ideas behind problems together, but be sure to always write your own code and perform your own write up. You are expected to implement the core components of each project on your own, but the extra credit opportunties often build on third party data sets or code. Feel free to include results built on other software, as long as you credit correctly in your handin and clearly demark your own work. In general, if you use an idea, text, or code from elsewhere, then cite it. Brown-wide, academic dishonesty is not tolerated. This includes cheating, lying about course matters, plagiarism, or helping others commit a violation. Plagiarism includes reproducing the words of others without both the use of quotation marks and citation. Students are reminded of the obligations and expectations associated with the Brown Academic and Student Conduct Codes . Accommodations Brown University is committed to full inclusion of all students. Please inform me if you have a disability or other condition that might require accommodations or modification of any of these course procedures. You may email me, come to office hours, or speak with me after class, and your confidentiality is respected. We will do whatever we can to support accommodations recommended by SEAS. For more information contact Student and Employee Accessibility Services SEAS at 401-863-9588 or Enable Javascript to see the email address . Students in need of short-term academic advice or support can contact one of the deans in the Dean of the College office. Mental Health Being a student can be very stressful. If you feel you are under too much pressure or there are psychological issues that are keeping you from performing well at Brown, we encourage you to contact Browns Counseling and Psychological Services . They provide confidential counseling and can provide notes supporting extensions on assignments for health reasons. Incomplete Policy We expect everyone to complete the course on time. However, we certainly understand that there may be factors beyond your control, such as health problems and family crises, that prevent you from finishing the course on time. If you feel you cannot complete the course on time, please discuss with James Tompkin the possibility of being given a grade of Incomplete for the course and setting a schedule for completing the course in the upcoming year. Electronic Etiquette Laptops are discouraged, please, except for class-relevant activities, e.g., to help answer questions and show items relevant to discussion. No social media, email, etc., because it distracts not just you but other students as well. Read Shirky on this issue Why I Just Asked My Students to Put Their Laptops Away , or Rockmore The Case for Banning Laptops in the Classroom . We will release course lecture material online. In considering laptop use for note taking, please be aware that research has shown note taking on paper to be more efficient than on a laptop keyboard Mueller and Oppenheimer , as it pushes you to summarize the content instead of transcribe it. Acknowledgements Portions of this seminar design are from Stefanie Tellexs CSCI 2951-R course, from Christian Theobalt and his CVfCG course Max-Planck-Institute for Informatics , with special thanks to Christian Richardt . Thanks also to James Hays and CSCI2951-T Data-Driven Computer Vision course Brown University , with special thanks to Genevieve Patterson . Thanks to Karras et al. StyleGAN, CVPR 2019 and to Dmitry Nikitko , whose software I used to make the Brown CS faculty bust teaser. Thanks to Tom Doeppner and Laura Dobler for the text on accommodation, mental health, and incomplete policy. Thank you to the previous students who helped to improve this class. Previous course runs 2019 Fall 2018 Spring 2017 Fall", "metadata": {"last_modified": "2023-06-13T13:59:20+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CSCI 2951-I:", "Computer Vision for Graphics and Interaction", "Fall 2022, MW 15:00 to 16:20, CIT 101", "Contact", "Course Description", "Learning Objectives", "Course Structure", "Grading", "Time Commitment", "Capstone", "Prerequisites", "Late Submissions and Late Days", "Course Notes", "Paper Reading", "Paper Presentations", "Leading the Discussion", "Reading References", "Tentative Schedule", "General Policy", "Welcome!", "Quiet Hours", "Academic Integrity, Collaboration, and Citation", "Accommodations", "Mental Health", "Incomplete Policy", "Electronic Etiquette", "Acknowledgements"], "word_count": 2754, "token_count_estimate": 3605}}, "https://cs.brown.edu/courses/csci2951-h/": {"text_content": "Menu Main Page Material Paper Review Form Main Page As advances in technology allow for the collection and storage of vast amounts of data, the task of efficiently analyzing the data and assessing the significance of the discoveries has become a major challenge in algorithms design. This graduate courseseminar deals with algorithmic tools and techniques for the organization, manipulation and processing of large amounts of data. This course focuses on mathematically well founded algorithmic and statistical techniques. Instructor Eli Upfal Time Wednesday, 1500 - 1720 Location CIT-506", "metadata": {"last_modified": "2013-02-04T15:10:30+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CSCI-2951H:", "Algorithms for Big Data"], "word_count": 87, "token_count_estimate": 106}}, "https://cs.brown.edu/courses/csci2390/2023/": {"text_content": "CSCI 2390 Privacy-Conscious Computer Systems Home Schedule Assignments Projects Submission Fall 2023 How can we design computer systems that protect users privacy This special topics course investigates this question. Course Summary. The goal of CSCI 2390 is to understand privacy-related challenges for computer systems, learn what design trade-offs we face as engineers, and to identify new research directions that might help address these challenges. We will examine research papers on distributed system design, privacy-preserving, and secure computing techniques, and discuss how to apply these ideas in practice. The goal is to understand if, and how, we can answer questions like these What happens to information we entrust to web services e.g., email, photo sharing, social networks how do companies store, process, and share it What requirements does privacy legislation such as the EUs GDPR impose on the computer systems involved Can better protect this sensitive data, both against leaks and against unauthorized or unethical use We will look at web services, datacenter systems, distributed communication systems, and machine learning systems. During class, you will present and discuss papers, finish small hands-on assignments, work on a research project, and present your project at the end of the semester. Enrollment. CSCI 2390 is a graduate-level class, but undergraduates are very welcome to enroll Please check the prerequisites and email Malte if youre unsure whether you meet them. Logistics Instructor Malte Schwarzkopf maltecs.brown.edu . HTA Livia Zhu lzhu17cs.brown.edu . GTA Kinan Dak Albab kdakalbacs.brown.edu . Time TuTh, 230-350pm. Room CIT 477. Missive Syllabus Anonymous Feedback Links Prior CSCI 2390 offering Fall 2021 , Fall 2020 , Fall 2019 . CSCI 1380 Distributed Computer Systems and MITs 6.824 Distributed Systems Engineering . MITs 6.S974 Decentralized Applications .", "metadata": {"last_modified": "2023-11-07T14:22:52+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": [], "word_count": 283, "token_count_estimate": 398}}, "https://cs.brown.edu/courses/csci2951-j/": {"text_content": "Topics in Advanced Algorithmics Algorithmic Game Theory, 3D Computational Geometry, Quantum Computing WhoClaire Mathieu and Franco P. Preparata When MF 130-250 Where CIT 506 What The first half of the course up until Spring break will be on connecting computer science to economics introduction to mechanism design, combinatorial auctions, computational efficiency in mechanisms, profit maximization, distributed aspects, cost sharing, and online mechanisms.The second half of the course consists of two topics in algorithmic theory 3D-computational geometry, its model and foundations, convex hulls, intersection, proximity introduction to quantum computing, foundations, networks, notable algorithms, and a critical review. Evaluation There will be one numerical grade for each half of the course, then the two grades will be reconciled by the two instructors into a final letter grade.Each student can choose whether they want a letter grade or prefer SNC. Algorithmic Game Theory Claire Mathieu Here is how it will be. Assignments Assignment 1 due Feb 4 at 130pm. Assignment 2, handed out in class, is due Feb 18 at 130pm, say. Office hours M 3-5, CIT 555 and and Or is it or by appointment. Schedule Class on Wednesday 213 at 130pm, root CIT Library 4th floor to make up for Friday 28 snowday. W 213 First class at a special time, On Wednesday 123 at 130pm, room CIT 506. We covered Book chapter 1 sections 1.1.1, 1.1.2, 1.1.4, 1.3.1, 1.3.3, 1.3.4, and 1.3.5. did not finish the proof, which is not in the book The second class will be on Friday 125 at 130pm. Please read section 1.3.5 before then so that you can follow the end of the proof. There will be no class on 128 and 131 Claire is at a conference. To make up for it, on the week of 23 there will be three classes instead of two, on M 24, W 26 , and F 28. References Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory . Cambridge University Press, New York, NY, USA,2007. You can view the entire book online by going to the first page of the preface viewable on Amazon for exampleand folowing the instructions therein. David Bindel, Jon M. Kleinberg, and Sigal Oren. How bad is forming yourown opinion CoRR, abs1203.2973, 2012 Ioannis Caragiannis, Angelo Fanelli, Nick Gravin, and Alexander Skopalik. Efficient computation of approximate pure nash equilibria in congestiongames .In Proceedings of the 2011 IEEE 52nd Annual Symposium on Foundations of Computer Science, FOCS 11, pages 532541, Washington, DC,USA, 2011. IEEE Computer Society Richard Cole, Vasilis Gkatzelis, and Vahab S. Mirrokni. Coordination mech-anisms for weighted sum of completion times in machine scheduling . CoRR,abs1010.1886, 2010. Paul W. Goldberg, Christos H. Papadimitriou, and Rahul Savani. The com-plexity of the homotopy method, equilibrium selection, and lemke-howsonsolutions . CoRR, abs1006.5352, 2010. Nicole Immorlica, Adam Tauman Kalai, Brendan Lucier, Ankur Moitra,Andrew Postlewaite, and Moshe Tennenholtz. Dueling algorithms . CoRR,abs1101.2883, 2011. Jon Kleinberg and Sigal Oren. Mechanisms for misallocating scienticcredit . In Proceedings of the 43rd annual ACM symposium on Theory ofcomputing, STOC 11, pages 529538, New York, NY, USA, 2011. ACM. Stefano Leonardi and Tim Roughgarden. Prior-free auctions with orderedbidders . In Proceedings of the 44th symposium on Theory of Computing,STOC 12, pages 427434, New York, NY, USA, 2012. ACM. 3D Computational Geometry Franco Preparata Quantum Computing Franco Preparata", "metadata": {"last_modified": "2013-02-13T18:11:00+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Topics in Advanced Algorithmics: Algorithmic Game Theory, 3D Computational Geometry, Quantum Computing"], "word_count": 548, "token_count_estimate": 938}}, "https://cs.brown.edu/courses/csci2951-k/spring-2019/": {"text_content": "Topics in Collaborative Robotics Home Schedule Mini Proposal 1 Mini Proposal 2 Proposal Midterm Checkpoint Final Project Home The aim of this course is to study how people can collaborate withrobots on complex tasks. People who have taken the course in the pasthave completed projects that resulted in being featured in the NewYorker magazine , papers at top robotics venues. w o alums from the course, Eric Rosen and Sidd Karamcheti, were given honorable mention for the CRA Undergraduate Research award Meeting Time TuesdayThursday 1030-12pm Meeting Location CIT 115. Instructor Stefanie Tellex TAs Ben Abbatematteo Piazza httpspiazza.combrownspring2018cs2961khome After taking this course, you will be able to Describe and critically evaluate approaches that researchers haveused to enable robots to interact with humans using language andgesture, bridging from language to perceptual and motor actions. Identify open research questions in this area. Complete a researchproject addressing one or more of these research questions. Course requirements This graduate seminar will consist of readings from the technical literature as well as a final project. Grades will be determined by 20 Attendance and participation 10 Project proposal. 10 Midterm checkpoint 20 Project presentation. 40 Project written document. Prerequisites This class is designed to be accessible to a wide variety of studentswith different backgrounds. If you are unsure if you meet theprerequisites, please contact Stefanie. The course staff will workwith you to design a project that works for you. Freshman have takenthis class and done well. Familiarity with robotics, machine learning, computationallinguistics, and artificial intelligence are all useful. CS 141, 142,146, 148 are all good courses to have taken. We do not expectstudents to have background in all of these areas we expect thatstudents with diverse backgrounds will teach and learn from each otherin this multi-disciplinary research area. Initial class exerciseswill help facilitate these relationships and build teams of studentsfrom different backgrounds. Class Attendance You are expected to attend each class and take part in discussions andwork with your team. If you are unable to attend class, please let thecourse staff know ahead of time. Final Project Students are expected to complete a research project that advances thestate-of-the-art in collaborative robotics. Two-person teams arestrongly encouraged for the projects, as this area is highlyinterdisciplinary and each team member can bring something unique tothe collaboration. Class exercises will facilitate project ideas andteam formation. At the end of the semester, you will write a project report, formattedas a conference paper. Final projects will be published on the courseweb site. Special Needs Please inform me if you have a disability or other condition thatmight require some modification of any of these course procedures. Youmay speak with me after class or during office hours. For moreinformation, contact Students and Employee Accessibility Services at401-863-9588 or SEASbrown.edu. Schedule The first few classes will consist of background readings andteam-building activities. Students will perform practice projectproposals, which will consist of a discussion and critique of thereadings. Most class meetings will be lab classes where the staffwill circulate and discuss your project with you. You are expected toattend all class meetings to meet with your team, work on yourproject, and discuss progress with the course staff. You will also begiven card access to the robot lab, and you can work in the lab at anytime even when class is not meeting.", "metadata": {"last_modified": "2019-01-24T07:15:56+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Home", "Course requirements", "Prerequisites", "Class Attendance", "Final Project", "Special Needs", "Schedule"], "word_count": 544, "token_count_estimate": 715}}, "https://cs.brown.edu/courses/csci2951-l/": {"text_content": "CSCI 2951L Human-Computer Interaction Seminar Spring 2014 This seminar covers methods for conducting research in human-computer interaction HCI. These topics will be pursued through independent reading, assignments, and class discussion. The seminar comprises four assignments that not just apply HCI research methods but push the envelope. The assignments are designed to be meaningful and have the potential to be widely visible or to be published. We will have readings that teach HCI experimental research methods and provide examples of valuable contributions. The goal of this course is to provide students with the background necessary to perform research in HCI and the skills required to conduct human-centric research. There will be little or no content in this course about user interfaces, but students will find topics in CSCI 1950i User Interfaces relevant. Enthusiastic students who have not taken CSCI 1950i should contact the instructor for a registration override code. The class will meet in room 506, CIT from 100pm-150pm MWF. Instructor Jeff Huang , 407 CIT, jeff at cs dot brown dot edu Teaching Assistant Alexandra Papoutsaki , 507 CIT, alexpap at cs dot brown dot edu Assignments Crowdsourcing assignment Experiment with different crowdsourcing models to generate an accurate database of all computer science professors, including metadata like degrees, subfield, rank, and advisor. You will each be responsible for a handful of universities and we will aggregate the data at the end to make the database public , and publish the lessons learned. Experiment bughunt Comb through six empirical papers from CHIUIST and identify experimental errors. We will aggregate this information to find out what are the common mistakes in HCI research, and publish our findings online. Redesign assignment Create a provocative redesign of a classic interface using the design research approach. For example, you may change the user model from action-object to object-action, or use real-world metaphors to design affordances. Popular online examples dontclick.it , boarding pass redesign , automotive gesture touchscreens . Fitts Law study Run a variant of the classic Fitts Law experiment, which can be combined as a class for a meta-analysis that can potentially be submitted for publication as a class. Grading 12 Reading summaries 18 Crowdsourcing assignment 18 Redesign assignment 18 Experiment bughunt 18 Fitts Law study 16 Participation Schedule Day Topic Reading Due Assignment Jan 22 Overview Jan 24 Introduction Grudin - Three faces of human-computer interaction Jan 27 Crowdsourcing Kittur - Crowdsourcing user studies with Mechanical Turk Crowdsourcing assignment out Jan 29 Crowdsourcing Marcus - How I Learned to Stop Worrying and Love the Crowd Jan 31 Crowdsourcing Feb 3 Crowdsourcing Bernstein - Soylent a word processor with a crowd inside Feb 5 Assignment midpoint Crowdsourcing assignment mid Feb 7 Online Experiments Kohavi - Controlled experiments on the web Feb 10 Online Experiments Discussions from online read in order 1 2 3 4 Feb 12 Assignment review Crowdsourcing assignment due Feb 14 Experimental Methods Losh - Reliability, Validity, Causality, And Experiments Experiment bughunt out Feb 19 Experimental Methods Wobbrock - Practical Statistics for HCI ps4hci.key.pdf Chap 1 2 Feb 21 Experimental Methods Kapstein - Rethinking Statistical Analysis Methods for CHI Feb 24 Experimental Methods Nuzzo - Scientific method Statistical errors Cairn - HCI... Not As It Should Be Feb 26 Experimental Methods Dell - Yours is Better Participant Response Bias in HCI Feb 28 Assignment midpoint Experiment bughunt mid Mar 3 Design Research Tohidi - Getting the Right Design and the Design Right Testing Many Is Better Than One Mar 5 Design Research Kane - Usable Gestures for Blind People Mar 7 Design Research Mar 10 Assignment review Experiment bughunt due Mar 12 Design Methodology Redesign assignment out Mar 14 Design Methodology Norman - The Design of Everyday Things Mar 17 Design Methodology Zimmerman - Research through design as a method for interaction design research in HCI Mar 19 Assignment mid Redesign assignment mid Mar 21 Qualitative Methods Adams - A qualitative approach to HCI research Mar 31 Methodology McGrath - Methodology Matters Doing Research in the Behavioral and Social Sciences Apr 2 Assignment review Redesign assignment due Apr 4 Fitts Law MacKenzie - Fitts law as a research and design tool in human-computer interaction Fitts Law study out Apr 7 Fitts Law Soukoreff - Towards a standard for pointing device evaluation Apr 9 Fitts Law Apr 11 Fitts Law Shoemaker - Two-Part Models Capture the Impact of Gain on Pointing Performance Apr 14 Assignment midpoint Fitts Law study mid Apr 16 Systems Landay - A Guide to Systems Applications Research Olsen - Evaluating User Interface Systems Research Apr 18 Systems Dixon - Prefab Apr 21 Systems Fitchett - Improving Navigation-Based File Retrieval Apr 23 Assignment review Fitts Law study due Apr 24 Social Computing Symposium Best Paper Award winner we will look at the corresponding reviews in class to see what reviewers liked about them. If you have trouble accessing this paper, an alternate link is httpcs.brown.educoursescsci2951-llastname.pdf. Resources Course Missive Collaboration Policy Google Group Forum for Reading Comments", "metadata": {"last_modified": "2014-10-27T04:28:36+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CSCI 2951L: Human-Computer Interaction Seminar", "Instructor", "Teaching Assistant", "Assignments", "Grading", "Schedule", "Resources"], "word_count": 826, "token_count_estimate": 1099}}, "https://cs.brown.edu/courses/csci2951-o/": {"text_content": "CS2951-O Overview Lectures Staff Foundations of Prescriptive Analytics Professor Serdar Kadioglu serdarkcs.brown.edu Teaching Assistant Anirudh Narsipur anirudhnarsipurbrown.edu Mailing Lists cs2951ostudent, cs2951oheadtas, cs2951otaslists.brown.edu Class Hours Fri 3pm - 520pm Class Room CIT 316 Office Hours TBD Syllabus Course Syllabus EdStem All enrolledprospective students should have access Academic Code Academic Honor Code Announcements Past offerings Course evaluations 20172018 , 20222023 . Course Description We are undoubtedly in the middle of an Analytics Revolution that enabled turning huge amounts data into insights, and insights into predictions about the future. At the final frontier, Prescriptive Analytics aims to identify the best possible outcome given a certain objective function and a set of constraints. With that goal in mind, this course provides students with a comprehensive overview of the theory and practice of how to apply Prescriptive Analytics through optimization technology. A wide variety of state-of-the-art techniques are studied including Boolean Satisfiability, Constraint Programming, Linear Programming, Integer Programming, Local Search Meta-Heuristics, and Large-Scale Optimization. The students are exposed to the industrially relevant software packages such as IBM Optimization Studio. The practical challenges encountered in implementing such systems are also explored. Additionally, the life-cycle of decision support systems is discussed and problems from real-life application domains such as planning, scheduling, resource allocation, supply-chain management, and logistics are addressed. Course Objectives The primary goal of this course is to introduce the fundamental ideas behind optimization technology to the extent that you can utilize this knowledge to build your own solvers based on various paradigms. Both complete and incomplete search methods, particularly tree-search and heuristic techniques will be covered in order to present different trade-offs. By the end of this course you will be able to transform a given optimization problem into analytical models with complementary strengths, and then, tackle it using off-the-shelf general purpose solvers andor writing your own custom solutions. This course shall also complement descriptive and predictive analytics as it connects data-centric approaches with their optimum decision-making counterpart. Inclusive Course Goals To ensure that students are able to plan around conflicts and obligations without adversely impacting their grades, we aim to set deadlines that plan around student obligations as best we can and provide extensions when appropriate. To ensure that students can voice their own concerns about the course, we aim to hold sufficient office hours and make it clear to whom students can go and how to voice their concerns.", "metadata": {"last_modified": "2024-01-31T15:48:02+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Foundations of Prescriptive Analytics", ""], "word_count": 396, "token_count_estimate": 525}}, "https://cs.brown.edu/courses/csci2951-r/": {"text_content": "CS 2951R Personal Informatics Seminar Spring 2016 Data science for data about you. Computing is expanding our ability to collect and process data about our everyday lives. This seminar covers personal informatics, the collection of data from daily activities for reflection and self-experimentation. We will cover methods for knowing more about yourself through using technology to track different types of data and how to interpret them, and run controlled experiments on yourself. We will learn about self-reflection and visualization, experimental design, time-series analysis and apply them to domains of location, sleep, activity, time spent, health and wellness. These topics will be pursued through independent reading, assignments, class discussion, and a semester-long self-tracking and experimentation project. Students should already be comfortable working programmatically with data, and preferably taken a course in data science, machine learning, user interfaces, or probabilitystatistics. The seminar will have limited enrollment. Please fill out this form to apply . Note if youve taken CS 1300 , then CS 2951R is more organic, smaller and intimate, less formal, and a bit more like an experiment in itself We will use Slack for sharing content and posting comments about readings, and the only written handin will be one assignment writeup A0. Reading comments should be interesting things you noticed in the reading that youd like us to talk about in class. The assignments will be opportunities for you to do something fun with your own data, and you will share the findings in short show and tells in class. Course Time and Location Location 477 CIT Lubrano Time 100-220pm on Tuesdays and Thursdays Instructor Jeff Huang , 407 CIT, jeff removee cs .brown.edu Office hours Tuesdays 230-400pm Schedule Day Topic Class Discussion Assignment Jan 28 Keeping Track Didion - On Keeping a Notebook Sunday Times - Memories are made of disks Feb 2 Quantified Self Wolf - The quantified self watch the TED Talk video Choe - Understanding Quantified-Selfers Practices in Collecting and Exploring Personal Data A0 out Feb 4 Quantified Self Watch 2 Quantified Self talk videos Butterfield - Ethnographic Assessment of Quantified Self Meetup Groups skim Feb 9 Data Location Parecki - Everywhere Ive Been Data Portraits Powered by 3.5 years of data and 2.5 million GPS Points Thudt - Visual Mementos Reflecting Memories with Personal Data A1 out Feb 11 Data Location Neuhaus - UrbanDiary A Tracking Project Capturing the beat and rhythm of the city A0 discuss Feb 16 Knowing Yourself Li - Understanding my data, myself supporting self-reflection with ubicomp technologies A1 check Feb 18 Knowing Yourself Neisser - Five kinds of self-knowledge Prepare a question for Jin Young Kim guest visitor via Skype A0 stage1 Feb 23 Holiday Feb 25 Time Spent Charts from the American Time Use Survey look through the charts Yao - A Day in the Life of Americans Short tutorial by Jeff to Learn D3 in 60 Seconds A1 share A0 stage2 Mar 1 Time Spent Scollon - Experience Sampling Promises and Pitfalls, Strengths and Weaknesses A1 share A2 out Mar 3 Self-Visualizations Felton - Annual Reports Dancy - Data Prepare a question for Nicholas Felton guest visitor via Skype Mar 8 Data Health and Wellness Bentley - Health Mashups Presenting statistical patterns between wellbeing data and context in natural language to promote behavior change Prepare a question for Chris Dancy guest visitor via Skype A2 check Mar 10 Self-Experiments Roberts - The unreasonable effectiveness of my self-experimentation Augemberg - Quantified Self How-To Designing Self-Experiments Short tutorial by Jeff to Learn statistical testing in 60 Seconds Mar 15 Self-Experiments Kratochwill - Single-Case Intervention Research Design Standards Daskalova - A Cohort of Self-Experimenters Lessons Learned from N1 Personal Informatics Experiments A0 stage3 Mar 17 Data Motion and Activity OSullivan - Physical Computing Sensing Movement chapter Short tutorial by Jeff to Learn supervised learning in 60 Seconds Mar 22 Data Motion and Activity Sachs - Sensor Fusion on Android Devices A Revolution in Motion Processing A2 share A3 out Mar 24 Behavior Change Consolvo - Activity Sensing in the Wild A Field Trial of UbiFit Garden A2 share Mar 29 Holiday Mar 31 Holiday Apr 5 Behavior Change Fogg - Tiny Habits Klasnja - Microrandomized Trials An Experimental Design for Developing Just-in-Time Adaptive Interventions A3 check Apr 7 Data Sleep Choe - SleepTight Low-burden, self-monitoring technology for capturing and reflecting on sleep behaviors A3 share Apr 12 Data Sleep Winter - Personal Sleep Monitors Do They Work Daskalova - SleepCoacher Combining Computational and Clinician-Generated Sleep Recommendations A3 share A4 out Apr 14 Data Social Dabbish - Understanding Email Use Predicting Action on a Message A3 share Apr 19 Time-Series Analysis Penn State - Intervention Analysis Brodersen - Causal Impact Alonso - Autoregressive-moving-average ARMA model optional Keogh - Symbolic Aggregate approXimation SAX Tutorial optional Apr 21 Data Social Wolfram - The Personal Analytics of My Life WolframAlpha - Personal Analytics for Facebook A4 check Apr 26 Data Social Viegas - Digital Artifacts for Remembering and Storytelling PostHistory and Social Network Fragments A0 check Apr 28 Models of Personal Informatics Epstein - A Lived Informatics Model of Personal Informatics A4 share May 3 Models of Personal Informatics Li - A stage-based model of personal informatics systems A4 share May 5 Show and Tell A0 share Assignments A0 You vs You - A hypothesis-driven self-experiment study you perform on yourself A1 The Road Taken - Collecting and revisiting past places you have been and routes you have taken A2 My Life in Pictures - Make visuals that allow you to compare your time spent with a larger population A3 From Motions to Actions - An exercise of classifying raw motion sensor data into activities A4 Unrequited Mail - Make an email assistant bot to let senders know when to expect a response Important things to know Collaboration policy if you use something code, an idea, text, etc. that you didnt come up with yourself, cite it By popular vote, laptopsphones should not be used in class except to share something, or to show the reading. The late policy is extensions can be requested with a reasonable explanation. Moderating everyone should moderate 2 papers, which involves leading the discussion short summary and open with questions and asking academic authors the backstory for the paper. Reading comments you should make substantive comments for each reading on Slack adding to the discussion. Getting help TA Nedi can help you with the technical parts of the assignments. She has weekly office hours at Wed 11am-1pm in 409 CIT. Grading 5 Moderating - Leading reading discussions in class 20 Readings - Reading comments on Slack and discussions in class 25 Assignment A0 10 Assignment A1 15 Assignment A2 10 Assignment A3 15 Assignment A4 Papers Following This Course Self-E Smartphone-Supported Guidance for Customizable Self-Experimentation Nediyana Daskalova, Eindra Kyi, Kevin Ouyang, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, Jeff Huang CHI 2021 Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Han Sha, Jeff Huang IMWUT 2017 Self-Experiments Website", "metadata": {"last_modified": "2021-08-07T22:22:21+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CS 2951R: Personal Informatics Seminar", "Course Time and Location", "Instructor", "Schedule", "Assignments", "Important things to know", "Grading", "Papers Following This Course"], "word_count": 1169, "token_count_estimate": 1586}}, "https://cs.brown.edu/courses/csci2951-s/": {"text_content": "CSCI 2951-S Distributed Computing through Combinatorial Topology Spring 2016 Instructor Maurice Herlihy LocationCIT 477 Meeting TimeJ TTh 230-350 Updates 27 Feb Homework 1 out. Homeworks Homework 1 due 4 March Homework 2 due 15 March Homework 3 due 4 April Homework 4 due 26 April Papers for Student Presentations 7 April Marshall Rental Harmony SpernerS Lemma in Fair Division 12 April Kyle Unreliable Failure Detectors for Reliable Distributed Systems Grading Every two weeks, students will be assigned a set of exercises, most of which will be taken from the textbook. There will be 4 such homeworks. Toward the end of the class,students will also be required to present one or more research papersthe exact number will depend on enrollment.Students are welcome to form teams of 2 or 3,but a team of k students must present k papers. Each student will also do a final project consisting of a 10-page written report on a research paper no teams. The final grade will be based on 23 homeworks 16 presentations 16 final project. Textbook Distributed Computing Through Combinatorial Topology Tentative Calendar Collaboration Policy You are encouraged to talk to one another about problems, homwork and otherwise, but everything you write and hand in must be your own work.Email your solution to mphcs.brown.edu. Please submit a PDF file produced via LaTeX. Slides Introduction pptx PDF 2-process systems pptx PDF Combinatorial Topology pptx PDF Colorless Wait-Free Computation pptx PDF Colorless Tasks in Different Models pptx PDF Byzantine-Resilient Colorless Computation pptx PDF Simulations and Reductions pptx PDF Manifold Tasks pptx PDF Connectivity pptx PDF Wait-Free Computability for General Tasks pptx PDF Renaming and Oriented Manifolds pptx PDF Some suggested papers for final projects Dmitry Kozlov, Topology of the immediate snapshot complexes Michael Erdmann, On the Topology of Discrete Strategies Eli Gafni, Petr Kuznetsov, Ciprian Manolescu, A generalized asynchronous computability theorem Herbert Edelsbrunner and John Harer, Persistent Homology --- a Survey Vin de Silva and Robert Ghrist, Coverage in Sensor Networks via Persistent Homology", "metadata": {"last_modified": "2016-04-10T16:14:33+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CSCI 2951-S", "Distributed Computing through Combinatorial Topology", "Spring 2016", "Updates", "Homeworks", "", "Papers for Student Presentations", "", "", "Grading", "", "", "Textbook:", "", "Tentative Calendar:", "Collaboration Policy", "Slides", "Some suggested papers for final projects"], "word_count": 328, "token_count_estimate": 476}}, "https://cs.brown.edu/courses/csci2951-t/": {"text_content": "CSCI2951-T Data-driven Computer Vision Class Blog Spring 2016, TR 900 to 1020am, CIT 477. Instructor Genevieve Patterson Figure from Deep Visual-Semantic Alignments for Generating Image Descriptions. Andrej Karpathy and Li Fei-Fei, CVPR 2015. Final Projects May 10, 2016 Rapid content based image retrieval by Gustave Marques Netto Determining artifact date and culture from images by Christine Whalen A House Share Price Predictior using a Deep Neural Network by Adam Lesnikowski Deep Learning for Natural Image Segmentation Priors by Gabe Hope Invariant Superpixel Features for Object Detection Localization by Sam Kelly Course Description Course Catalog Entry Investigates current research topics in data-driven object detection, scene recognition, and image-based graphics. We will examine data sources, features, and algorithms useful for understanding and manipulating visual data. We will pay special attention to methods that harness large-scale or Internet-derived data. There will be an overview of the current crowdsourcing techniques used to acquire massive image datasets. Vision topics such as scene understanding and object detection will be linked to graphics applications such as photo editing. These topics will be pursued through independent reading, class discussion and presentations, and projects involving current research problems in Computer Vision. The goal of this course is to give students the background and skills necessary to perform research in computer vision for image detection. Students should understand the strengths and weaknesses of current approaches to research problems and identify interesting open questions and future research directions. Students will hopefully improve their critical reading and communication skills, as well. Course Requirements Reading and Summaries Students will be expected to read one paper for each class. For each assigned paper, students must write a two or three sentence summary and identify at least one question or topic of interest for class discussion. Interesting topics for discussion could relate to strengths and weaknesses of the paper, possible future directions, connections to other research, uncertainty about the conclusions of the experiments, etc. Reading summaries must be posted to the class blog by 1159pm the day before each class. Feel free to reply to other comments on the blog and help each other understanding confusing aspects of the papers. The blog discussion will be the starting point for the class discussion. If you are presenting you dont need to post a summary to the blog. Class participation All students are expected to take part in class discussions. If you do not fully understand a paper that is OK. We can work through the unclear aspects of a paper together in class. If you are unable to attend a specific class please let me know ahead of time and have a good excuse.Many of the papers covered in this course will have publicly available code andtutorials for running their systems and experiments. For these papers, students will beexpected to run the basic versions of the systems. Students are not expectedto re-implement an entire system or set of experiments. The purpose of these tutorialexercises is to familiarize students with running code written by other researchers. Studentswill be expected to identify strengths and weaknesses of the systems they attemptto run. Presentations Depending on enrollment, students will lead the discussion of one or two papers during the semester. Ideally, students would implement some aspect of the presented material and perform experiments that help understand the algorithms. Presentations and all supplemental material should be ready one week before the presentation date so that students can meet with the instructor, go over the presentation, and possibly iterate before the in-class discussion. For the presentations it is fine to use slides and code from outside sources for example, the paper authors but be sure to give credit. Semester projects Students are expected to complete a state-of-the-art research project on topics relevant to the course. Students will propose a research topic part way through the semester. After a project topic is finalized, students will meet occasionally with the instructor to discuss progress. Students will present their progress on their semester project twice during the course and the course will end with final project presentations. Students will also produce a conference-formatted write-up of their project. Projects will be published on the this web page. The ideal project is something with a clear enough direction to be completed in a couple of months, and enough novelty such that it could be published in a peer-reviewed venue with some refinement and extension. Prerequisites Strong mathematical skills linear algebra, calculus, probability and statistics and previous imaging graphics, vision, or computational photography courses are needed.It is strongly recommended that students have taken one of the following courses or equivalent courses at other institutions CSCI 1230, Introduction to Computer Graphics CSCI 1290, Computational Photography CSCI 1430, Introduction to Computer Vision CSCI 2240, Interactive Computer Graphics ENGN 1610, Image Understanding If you arent sure whether you have the background needed for the course, you can try reading some of the papers below or you can simply come to class during the shopping period. Textbook We will not rely on a textbook, although the free, online textbook Computer Vision Algorithms and Applications by Richard Szeliski is a helpful resource. Grading Your final grade will be made up from 20 Reading summaries posted to class blog 20 Classroom participation and attendance, including completion of coding tutorials and project progress reports 20 Paper presentations, including partial system implementation or testing 40 Semester project Office Hours Genevieve Patterson, Tuesday and Thursday 100-230pm, CIT 551 Tentative Schedule Date Paper Paper, Project page Presenter Thurs, Jan 28 Introduction the state of vision and crowdsourcing. Genevieve Tues, Feb 2 Microsoft COCO Common Objects in Context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick. ECCV 2014. project page , paper Genevieve Tues, Feb 2 Tropel Crowdsourcing Detectors with Minimal Training. Genevieve Patterson, Grant Van Horn, James Hays, Serge Belongie, Pietro Perona. Human Computation HCOMP 2015. pdf Genevieve Thurs, Feb 4 CVPR 2014 Tutorial on Deep Learning . Graham Taylor, MarcAurelio Ranzato, and Honglak Lee. Read only the first two sets of labeled Introduction and Supervised learning . CVPR 2014 tutorial Genevieve Tues, Feb 9 ImageNet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton. NIPS 2012. pdf Genevieve Thurs, Feb 11 The SUN Attribute Database Beyond Categories for Deeper Scene Understanding. Genevieve Patterson, Chen Xu, Hang Su, James Hays. IJCV 2014. project page Genevieve Tues, Feb 16 Object Detectors Emerge in Deep Scene CNNs. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba. ICLR, 2015. project page , arXiv Sam also read Learning Deep Features for Scene Recognition using Places Database. B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. NIPS 2014. project page , pdf , demo na Thurs, Feb 18 Understanding Deep Image Representations by Inverting Them. Aravindh Mahendran, Andrea Vedaldi. CVPR 2015. arXiv Christine Feb 23 No class. Everyone Thurs, Feb 25 Diagnosing error in object detectors. Derek Hoiem, Yodsawalai Chodpathumwan, and Qieyun Dai. ECCV 2012. project page Genevieve Tues, Mar 1 Project Status Updates. Everyone Thurs, Mar 3 DeepBox Learning Objectness with Convolutional Networks. Weicheng Kuo, Bharath Hariharan, Jitendra Malik. ICCV 2015. arXiv Gabe also read Selective Search for Object Recognition. J. R. R. Uijlings, K. E. A. van de Sande, T. Gevers, A. W. M. Smeulders. IJCV 2013. project page na Tues, Mar 8 Fast R-CNN. Ross Girshick. ICCV 2015. arXiv , code Gustavo also read Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. NIPS 2015. pdf na Thurs, Mar 10 Fully Convolutional Networks for Semantic Segmentation. Jonathan Long, Evan Shelhamer, Trevor Darrell. CVPR 2015. arXiv Sam Tues, Mar 15 Learning Visual Similarity for Product Design with Convolutional Neural Networks. Sean Bell, Kavita Bala. Siggraph 2015. author page , pdf Gustavo also read Learning Deep Representations for Ground-to-Aerial Geolocalization. Tsung-Yi Lin, Yin Cui, Serge Belongie, James Hays. CVPR 2015. pdf na Thurs, Mar 17 What makes Paris look like Paris Carl Doersch, Saurabh Singh, Abhinav Gupta, Josef Sivic, and Alexei A. Efros. Siggraph 2012. project page Adam Tues, Mar 22 Special Presentation by Zhile Ren. Three-Dimensional Object Detection and Layout using Clouds of Oriented Gradients. Zhile Ren and Erik B. Sudderth. Zhile Ren Thurs, Mar 24 Learning Visual Biases from Human Imagination. Carl Vondrick, Hamed Pirsiavash, Aude Oliva, Antonio Torralba. NIPS 2015. project page Christine Mar 26 - Apr 3 Spring Break. Everyone Tues, Apr 5 Project Status Updates. Everyone Thurs, 47 Deep Neural Decision Forests. Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, and Samuel Rota Bulo. ICCV 2015. Project page Gabe Tues, Apr 12 Vision for Robotics. Presentation from the Tellex Lab. na Stefanie Tellex and John Oberlin Thurs, Apr 14 VQA Visual Question Answering. S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, and D. Parikh. ICCV, 2015. project page , arXiv Christine also read Visual Turing test for computer vision systems. Geman, Donald, etal. Proceedings of the National Academy of Sciences 112.12 20153618-3623. PNAS page na Tues, Apr 19 Exploring Nearest Neighbor Approaches for Image Captioning. Jacob Devlin, Saurabh Gupta, Ross Girshick, Margaret Mitchell, C Lawrence Zitnick. arXiv, 2015. arXiv Adam Thurs, Apr 21 How do humans sketch objects Mathias Eitz, James Hays, and Marc Alexa. Siggraph 2012. project page Gabe Tues, Apr 26 Quizz Targeted crowdsourcing with a billion potential users. Ipeirotis, Panagiotis G., and Evgeniy Gabrilovich. Proceedings of the23rd international conference on World wide web. ACM, 2014. pdf Gustavo Thurs, Apr 28 Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes. Pierre-Yves Laffont, Zhile Ren, Xiaofeng Tao, Chao Qian, James Hays. Siggraph 2014. project page Genevieve Tues, May 3 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. Alec Radford, Luke Metz, Soumith Chintala. 2015. project page , arXiv Sam Tues, May 10 Final Project Presentations 9am - approx. 1130am Everyone Note Final Project reports due 1159 PM EST on Tues May 10. Suggested Topics Date Paper Paper, Project page Presenter Crowdsourcing and Human Computation Micro Perceptual Human Computation for Visual Tasks. Yotam Gingold, Ariel Shamir, Daniel Cohen-Or. ACM Transactions on Graphics ToG 2012 project page Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. R. Girshick, J. Donahue, T. Darrell, J. Malik. CVPR 2014. arXiv Learned Representations, ConvNets, Visualizations Going Deeper with Convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. 2014. arXiv Object Proposals ConvNet detection and segmentation Visualizing and Understanding Convolutional Networks. Matthew D Zeiler, Rob Fergus. ECCV 2014. pdf Weakly Supervised and Unsupervised ConvNets Unsupervised Visual Representation Learningby Context Prediction. Carl Doersch, Abhinav Gupta, Alexei A. Efros. ICCV 2015. project page Images and Words Visual Madlibs Fill in the blank Description Generation and Question Answering. Licheng Yu, Eunbyung Park, Alexander C. Berg, Tamara L. Berg. ICCV, 2015. project page , pdf Generative ConvNets Learning to Generate Chairs, Tables and Cars with Convolutional Networks. Alexey Dosovitskiy, Jost Tobias Springenberg, Maxim Tatarchenko, Thomas Brox. CVPR 2015. arXiv A Neural Algorithm of Artistic Style. Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. 2015. implementation , arXiv Aggregating local descriptors into a compact image representation VLAD. H. Jegou, M. Douze, C. Schmid, and P. Perez. In Proc. CVPR, 2010. pdf Siamese Ranking Triplet ConvNets Joint Embeddings of Shapes and Images via CNN Image Purification. Yangyan Li, Hao Su, Charles Ruizhongtai Qi, Noa Fish, Daniel Cohen-Or, Leonidas Guibas. Siggraph Asia 2015. project page Attribute-based Representations Automatic attribute discovery and characterization from noisy web data. Berg, Tamara L., Alexander C. Berg, and Jonathan Shih. Computer VisionECCV 2010. Springer Berlin Heidelberg, 2010. 663-676. pdf Discovering the Spatial Extent of Relative Attributes. Fanyi Xiao, Yong Jae Lee. ICCV 2015. pdf Discriminative Feature Discovery Misc Learning to predict where humans look. T. Judd, K. Ehinger, F. Durand, and A. Torralba. IEEE International Conference on Computer Vision ICCV, 2009. project page Learning a Discriminative Model for the Perception of Realism in Composite Images. Jun-Yan Zhu, Philipp Krahenbuhl, Eli Shechtman, Alexei A. Efros. ICCV 2015. project page Sketch-Based 3D Shape Retrieval Using Convolutional Neural Networks. Fang Wang, Le Kang, Yi Li. CVPR 2015. arXiv Multi-view Convolutional Neural Networksfor 3D Shape Recognition. Hang Su, Subhransu Maji, Evangelos Kalogerakis, Erik Learned-Miller. ICCV 2015. project page Sketch2Photo Internet Image Montage. ACM SIGGRAPH ASIA 2009, ACM Transactions on Graphics. Tao Chen, Ming-Ming Cheng, Ping Tan, Ariel Shamir, Shi-Min Hu. project page Eulerian video magnification for revealing subtle changes in theworld. Wu, Hao-Yu, et al. ACM Trans. Graph. 31.4 2012 65. project page A High Performance CRF Model for Clothes Parsing. E Simo-Serra,S Fidler, F Moreno-Noguer, R Urtasun Computer VisionACCV 2014. pdf , code Previous topics which you should know Date Paper Paper, Project page Presenter Fundamental representations Object recognition from local scale-invariant features , David Lowe, ICCV 1999. pdf , project page Video Google A Text Retrieval Approach to Object Matching in Videos. Sivic, J. and Zisserman, A. Proceedings of the International Conference on Computer Vision 2003 pdf , project page Histograms of Oriented Gradients for Human Detection. Navneet Dalal and Bill Triggs. In Proceedings of IEEE Conference Computer Vision and Pattern Recognition, 2005. .pdf Beyond Bags of Features Spatial Pyramid Matching for Recognizing Natural Scene Categories. S. Lazebnik, C. Schmid, and J. Ponce, CVPR 2006. pdf , slides Databases ImageNet A Large-Scale Hierarchical Image Database. J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei. IEEE Computer Vision and Pattern Recognition CVPR, 2009 pdf , project page LabelMe a Database and Web-based Tool for Image Annotation. B. C. Russell, A. Torralba, K. P. Murphy, W. T. Freeman. International Journal of Computer Vision, 2008. pdf , project page 80 million tiny images a large dataset for non-parametric object and scene recognition. A. Torralba, R. Fergus, W. T. Freeman. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.3011, 2008. pdf , project page Describing Objects by Their Attributes. A. Farhadi, I. Endres, D. Hoiem, and D.A. Forsyth. CVPR 2009 project page SUN Database Exploring a Large Collection of Scene Categories J. Xiao, K. Ehinger, J. Hays, A. Oliva, and A. Torralba. IJCV 2014. project page , pdf Other previous topics Date Paper Paper, Project page Presenter Painting-to-3D Model Alignment Via Discriminative Visual Elements. Mathieu Aubry, Bryan Russell Josef Sivic. ToG 2013. project page DeCAF A Deep Convolutional Activation Feature for Generic Visual Recognition. Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell. 2013. arXiv Image Melding combining inconsistent images using patch-based synthesis. Soheil Darabi, Eli Shechtman, Connelly Barnes, Dan B Goldman, Pradeep Sen. Siggraph 2012. project page Ground-truth dataset and baseline evaluations for intrinsic image algorithms. R. Grosse, M.K. Johnson, E.H. Adelson and W.T. Freeman. ICCV 2009 project page Intrinsic Images in the Wild. Sean Bell, Kavita Bala, Noah Snavely. Siggraph 2014. project page First Person Hyperlapse Videos. Johannes Kopf, Michael Cohen, Richard Szeliski. Siggraph 2014. project page Depixelizing Pixel Art. Johannes Kopf and Dani Lischinski. Siggraph 2011. project page Photo tourism Exploring photo collections in 3D. Noah Snavely, Steven M. Seitz, Richard Szeliski. Siggraph 2006. pdf , project page Acknowledgements This course was originally created by James Hays, and is also being taught this semester at Georgia Tech. Ideas for the organization and content of this course came from many other researchers such as Svetlana Lazebnik, Kristin Grauman, Antonio Torralba, Derek Hoeim, and Alexei Efros. Related Graduate Seminars at other Universities Learning-Based Methods in Vision Alexei Efros, CMU and Leonid Sigal, Disney Research Pittsburgh Object Recognition Kristin Grauman, UT Object Recognition and Scene Understanding Antonio Torralba, MIT Machine Learning Techniques in Image Analysis Svetlana Lazebnik, UNC Internet Vision Tamara Berg,Stony Brook Visual Scene Understanding Derek Hoiem, UIUC", "metadata": {"last_modified": "2016-05-24T16:21:55+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CSCI2951-T Data-driven Computer Vision", "Spring 2016, TR 9:00 to 10:20am, CIT 477.", "Instructor:", "", "", "Final Projects (May 10, 2016)", "Course Description", "Course Requirements", "Prerequisites", "Textbook", "Grading", "Office Hours:", "Tentative Schedule", "Suggested Topics", "Previous topics (which you should know)", "Other previous topics", "Acknowledgements", "Related Graduate Seminars at other Universities"], "word_count": 2600, "token_count_estimate": 4210}}, "https://cs.brown.edu/courses/csci2951-t/finals/alesnikowski/": {"text_content": "A House Share Price Predictior using a Deep Neural Network Adam Lesnikowski Problem Motivations Approach Dataset Simplifying Assumptions Modifying a Classification Net for Regression deep features Support Vector Regressors Data Preparation Results Further Steps Figures Try It httppricepredictor.adamlesnikowski.com Contact httpwww.adamlesnikowski.com", "metadata": {"last_modified": "2016-05-24T16:52:47+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["A House Share Price Predictior using a Deep Neural Network"], "word_count": 40, "token_count_estimate": 68}}, "https://cs.brown.edu/courses/csci2951-t/finals/cwhalen/": {"text_content": "Motivation Who made this Why did they make it How old is it Where did it come from These are just a few questions the average visitor to any museum might have when viewing an artifact. Luckily for the visitor, objects in museums tend to be accompanied by helpful little tags, answering all of these questions and more. Though this is sufficient for the typical visitor viewing an artifact in a museum, what is a layman to do when faced with an unknown object he found in a field How can that person answer the questions above without a helpful little tag An expert might draw upon his knowledge of similar objects to emulate this, and to answer who and when, I have created a dataset which contains images of artifacts in the Metropolitan Museum of Art and all associated data. I used this dataset to train classifiers which predict Culture and Creation DateDate Range for images of objects. Data Set Creation The Metropolitan Museum of Art has recently updated its online image collection, and released around 400,000 images as OASC Open Access Scholarly Content. The Metropolitan Museum of Art appears to have around 571,722 artifacts total which have been assigned ID numbers. Not all of these artifacts have images associated with them, and some of them have more than one image associated with them. This implies that there will be fewer than 400,000 OASC artifacts with images. Downloading Image Data I have scraped the Met website using code from this github repository .For all image IDs in between 1 and 571,722, I access the content located at httpwww.metmuseum.orgartcollectionsearch ID .If the content on that page had the OASC tag and contained an image, then I write relevant fields to a JSON file. This process takes about 3 seconds per ID, which meansthat fully checking all IDs will take about 20 days to complete. At the time of performing analysis on the dataset, I had queried 300,000 IDs and collected approximately 80,000sets of object imagejson data pairs. Culture Categories I processed the Culture field by keeping the first set of capitalized words and ignoring both parenthetical comments and words like North, East, etc. This resulted in the following list of cultures with more than 500 instances Japanese 12802 French 9759 American9029 Chinese8197 Italian 6559 British5419 German 3339 Greek 3192 Roman 2870 Cypriot 1305 Spanish 1052 Dutch 940 Indian 989 Flemish 805 Etruscan 795 Indonesian768 Minoan 533 Date Categories There were two different types of date field contained in my data. The first was a categorical date field date categories and their counts are displayed below No date provided14,842 images 8000 B.C. - 2000 B.C.238 images 2000 B.C. - 1000 B.C.558 images 1000 B.C. - A.D. 15,345 images A.D. 1 - A.D. 5002,119 images A.D. 500 - A.D. 10001,219 images A.D. 1000 - A.D. 14001,076 images A.D. 1400 - A.D. 16004,970 images A.D. 1600 - A.D. 180026,813 images A.D. 1800 - A.D. 190023,112 images A.D. 1900 - present1,946 images generally not yet released for OASC The artifacts for which I collected information are not evenly distributed across categories. The majority 49,925 out of 82,028 of my artifacts date from between 1600 and 1900. Date Ranges The second type of date field is a description of the estimated creation date. This is entered in natural language, and usually implies either a single date or range of dates. In order to parse these dates, I used the yearrange parser from this repository . Example fields from my dataset and parsed values are shown below ca. 1890 -start1890,end1890,circatrue early 19th century -start1800,end1824 1800-1810 -start1800,end1810 1804-14 -start1804,end1814 1860s -start1860,end1869 June 12, 1871 -start1871,end1871 1880 -start1880,end1880,circatrue dated 1769 -start1769,end1769 first half of the 10th century -start900,end949 after 1875 -start1875,end1875 4th century B.C. - The yearrange parser failed on some of the values in my dataset. It was not intended to handle B.C. dates, or any dates that have fewer than 3 digits in the year, so I have only considered dates where the start year is 1000 or later. This results in a start date, and end date, and a possible circa field. The circa field will exist if there is any implied uncertainty in the provided date ranges for example, ca., , probably. T-SNE I performed T-SNE on both culture and date range. I randomly selected 5000 images and 200 features from the 4096-dimensional output of the last convolutional layer of VGG-16. The results are shown below. As a future extension, I would like to make these results interactive, so that the space of images can be explored by viewing the image corresponding to any given point. The plots of the results of T-SNE on the inputs are shown below. Culture is on the left, and Date is on the right. Classification SVM on CNN Features I performed classification on culture and date category, for all images in my dataset. I used multiple 1-vs.-all SVM classifiers trained on the output of the final convolutional layer of VGG-16. Note that the culture and date category values are all mutually exclusive. My Culture SVMs achieve 0.533 accuracy on my test set, and the Date SVMs achieve 0.438 accuracy. The confusion matrices for the 17-class Culture categorization and the 9-class Date categorization are displayed below. Culture The values on the left are the true values for an image, and values on the top are the predicted values. If we look at the confusion matrix above, the results look promising.If we look at the Cypriot row, we see activation with other ancient Mediterranean cultures, like Etruscan, Greek, and Roman. British often gets confused with other Europeancultures. Date Category Convolutional Neural Net I trained a CNN which took in a 128x128x3 image and output a value between 1 and 17, mapping to the culture. I trained with approximately 5000 images, with at least 600 images from each culture.I used a batch size of 100, and allowed training to run for 65 epochs. The accuracy was approximately 0.4, but it may have continued to improve if I had allowed it to run longer. Regression I also attempted regression using the start date and end date I found by parsing the date description. As in classification, I used features from the final convolutional layer of VGG-16,and performed multivariate linear regression to predict an estimated start and end date. I calculated the average interval overlap, which was the average of the percent of overlap between thetrue start and end dates and the estimated start and end dates. The average interval overlap was 15.07. Future Extensions I would like to improve upon the date parser, to add handling for dates earlier than the year A.D. 1000. I would also like to do something with the circa field, like extending the interval by some amount based on the number of significant figures in the date. In other words, ca. 1000 likely implies more uncertaintly than ca. 1955, and I would like to account for this. I would like to finish downloading all items with images and the OASC tag. This will likely be updated on the github page below in the next few days. Currently, I am only using a single image per item,even though some items have many images. It may be helpful to include all images for a given item, rather than just the primary image. There is a lot more work which could be done on both classification and date regression. Finally, I would like to know how well humans perform on the same task. I would like to use this data set to run a task on Amazon Mechanical Turk, to determine human accuracy and typical human confusions. Conclusion I have created a novel dataset of 80,000 images, which contains information on culture, date category, and date interval. I achieved 53 accuracy on classification with 17 cultures, and 43 accuracy with 9 date categories.I also was able to estimate the date interval given an image with 15 average interval overlap. Dataset Download and Details The full dataset of images and json files can be downloaded here . This currently has data for 82,238 items. imagesfullset.zip is a folder which contains all images. The file name for each image is the item ID and .jpg. json-collections-data.zip is a folder containing all json files. The file name is the item ID which the data refers to and .json. fullartcleaneddated.xlsx is a csv file which has Image Id, Image URL, Date, Culture, and other fields. This is the cleaned data file I used for classification. References Data Collection Metropolitan Museum of Art, www.metmuseum.org httpsgithub.commetmuseum-medialabcollections-api httpsgithub.comjeresignode-yearrange Machine Learning CIFAR Network httpwww.vlfeat.orgmatconvnettraining MatConvNet httpwww.vlfeat.orgmatconvnet VGG-VeryDeep-16 Very Deep Convolutional Networks for Large-Scale Image Recognition, Karen Simonyan and Andrew Zisserman, arXiv technical report, 2014 Visualizations T-SNE httpslvdmaaten.github.iodrtoolbox , Matlab Toolbox for Dimensionality Reduction", "metadata": {"last_modified": "2016-05-24T15:56:42+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Christine Whalen: Determining Artifact Date and Culture from Images", "Motivation", "Data Set Creation", "Classification", "Regression", "Future Extensions", "Conclusion", "Dataset Download and Details", "References:"], "word_count": 1465, "token_count_estimate": 2071}}, "https://cs.brown.edu/courses/csci2952-a/starting.html": {"text_content": "Some Starting Points for Presentations J. Bonneau et al. SoK Research Perspectives and Challenges for Bitcoin and Cryptocurrencies M Herlihy. Blockchains from a Distributed Computing Perspective Bitcoin S. Nakamoto. Bitcoin A Peer-to-Peer Electronic Cash System I Eyal and E G Sirer. Majority is not EnoughBitcoin Mining is Vulnerable I Eyal et al. Bitcoin-NG A Scalable Blockchain Protocol K Croman et al. On Scaling Decentralized BlockchainsA Position Paper Y Sompolinsky and A Zohar. Accelerating Bitcoins Transaction Processing Fast Money Grows on Trees, Not Chains Mike Hearn. The resolution of the Bitcoin experiment Vivek Wadhwa R.I.P., Bitcoin. Its time to move on. Other Blockchains J. Chen and S. Micali. Algorand Hyperledger White Paper C Copeland and H Zhong. Tangaroa a Byzantine Fault Tolerant Raft Tendermint E Kokoris-Kogias et al. OmniLedger A Secure, Scale-Out, Decentralized Ledger S Popov. The Tangle L Baird. Hashgraph Smart Contracts I Sergey and A Hobor. A Concurrent Perspective on Smart Contracts L Luu et al. Making Smart Contracts Smarter N Atzei et al. A Survey of Attacks on Ethereum Smart Contracts SoK . T Dickerson et al. Adding Concurrency to Smart Contracts X Boyen et al. Blockchain-Free Cryptocurrencies Atomic Swaps M Herlihy. Atomic cross-chain Swaps . Decred cross-chain atomic swapping S Bowe and D Hopwood. Hashed Time-Locked Contract transactions Atomic cross-chain trading Offchain transactions M Green and I Miers. Bolt Anonymous Payment Channels for Decentralized Currencies J. Poon and T Dryja. The Bitcoin Lightning Network Proof of Stake V Buterin and V Griffith. Casper the Friendly Finality Gadget Kiayias et al. Ouroboros A Provably Secure Proof-of-Stake Blockchain Protocol Consensus and Theory J.A. Garay et al. The Bitcoin Backbone Protocol Analysis and Applications Y. Sompolinsky et al. SPECTRE Serialization of Proof-of-work Events Confirming Transactions via Recursive Elections A Kiayias and G Panagiotakos. On Trees, Chains and Fast Transactions in the Blockchain A Kiayias and G Panagiotakos. Speed-Security Tradeoffs in Blockchain Protocols R Pass and E Shi. The Sleepy Model of Consensus Accountability M Herlihy and M Moir. Enhancing Accountability and Trust in Distributed Ledgers", "metadata": {"last_modified": "2018-01-23T21:58:57+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Some Starting Points for Presentations"], "word_count": 335, "token_count_estimate": 522}}, "https://cs.brown.edu/courses/csci2951-t/finals/ghope/": {"text_content": "CSCI 2951-T Deep Learning for Natural Image Segmentation Priors Gabriel Hope May 10, 2016 Image segmentation is an important problem in computer vision. Distinguishing different objects and regions within an image is an extreamly useful preprocessing step in applications that require full scene understanding as well as many applications for image processing and editing. There are several different ways to frame the segmentation problem in computer vision. For example, semantic segmentation is a common segmentation task that can viewed as an extension of object detection. In the semantic segmentation task, rather than finding bounding box for objects of a specified class, the goal is to find the boundaries of a target object at the pixel level. In this project, I look at the more general segmentation task, where the goal is to partition an image into regions that correspond to different objects or materials in the image. Correctness in this setting is often difficult to define precisely, as objects boundaries are often ill-defined should a t-shirt be considered the same object as the person who is wearing it. In this case, a common proxy for truth data are human-generated segmentations of images. Above An example of a good general segmentation for an image from 1. Many techniques have been proposed for the image segmentation task. Common examples include simple color-based K-means, graph-cutting approaches and Markov random fields 8. The work in this project is based on the Spatially Dependent Pitman-Yor model from Sudderth and Jordan 1 and extended by Ghosh and Sudderth 2 that extends nonparametric mixture models to the segmentation problem. In this project I extend this segmentation model to make use of large amounts of labeled image data by incorporating the output of deep networks into the prior distribution on image segmentations. Nonparametric Segmentation I will first give a brief, high-level overview of the spatially dependent Pitman-Yor proecss model for segmentation. This model uses a layered approach to segmentation, where segments are intuitively considered as overlapping layers rather than strictly adjacent regions. An easy way to understand the Spatially dependent Pitman-Yor model is to first treat it as a foreground-background segmentation model. In this context, the model assumes that images are generated using the following process First an assignment surface is randomly drawn for the image. This surface is drawn from a zero-mean Gaussian process and every point on the image has a corresponding point on the surface. In practice, this surface is represented by a height value for each pixel of the image. A draw of a Gaussian process over a finite number of points is equivalent to a draw from a multivariate Gaussian normal distribution, so in practice the heights for all the pixels are drawn jointly from a zero-mean multivariate Gaussian distribution. Determining what to use for the between-pixel covariances in this distribution is the fundamental problem explored in this project. Next a random threshold value is drawn from a standard normal distribution Or this threshold is set to 0. Pixels whose height on the assignment surface are above the threshold are assigned to the forground segment, while all other pixels are assigned to the background. Each segment is given a different random distribution such as a 3-d normal distribution and the pixels in each segment are drawn from the corresponding distribution. Above An illustration of assignment surfaces for different layers and the resulting segmentations from 1. The process above defines a distribution over possible segmentations and possible images. With a given image, the actual pixels are observed and it is possible to use variational inference to find an approximate posterior distribution for segmentation conditioned on the observed pixels. This is the technique that I used to generate the segmentations in this project. Above The graphical model for a simplified version of the foreground-background model where the threshold is fixed at 0. Extending this model to nonparametric segmentation segmentation with an abitrary number of segments is straightforward. The generative process is simply repeated so that pixels assigned the forground are further segmented using the same process. This process can be repeated until there are no more pixels left in the foreground to further segment. In this case the threshold distribution is modified so that the number of segments roughly follows a power-law distribution. Its important to note that this model does not acutally work on the pixels of the image directly. Instead, as a preprocessing step, the image is dived into 1000 superpixels using the SLIC algorithm 5. Each superpixel is represented by a 125-bin histogram of the colors in the superpixel as well as an 128-bin histogram of texton assignments. A texton is a cluster of responses from a set of texture filters. Each pixel in a given image is assigned a texton by first applying the set of filters centered at its location, then assigning the vector of responses to the nearest texton cluster. Because the superpixels are represented as histograms, the segment-specific distributions that generate them are assumed to be multinomial distributions, which in turn are drawn from a shared Dirichlet distribution. Above An image and the corresponding SLIC superpixel segmentation. Data For this project, I used the Berkeley Image Segmentation dataset 7 BSDS300 for evaluating segmentations and in some cases for training. This dataset consists of 300 natural photographs of a diverse set of scenes. The advantage of using this dataset is that it provides multiple human segmentations of each of the images that can be used as a proxy for ground truth segmentaions. Some examples from this dataset are shown below. Because computing each segmentation with the spatially dependent Pitman-Yor model is currently very slow, I only actually evaluted using a subset of 10 of the BSDS images. Above An example image from the BSDS dataset along with the corresponding human segmentations. Learning Segmentation Priors One can modify the segmentation prior for a given image by modifying the assignment surface covariances between pixels in the image. Intuitively, the covariance between two pixels should be high if the pixels are likely to be part of the same segment and low if they are likely to be part of different segments. The simplest approach to generating pixelwise covariances is to base the covariances on the distance between pixels so that pixels that are closer in the image have a higher covariance. In order to generate distance-based covariance between two superpixels, I took the mean of the coordiates of each superpixel and applied a Gaussian kernel to the difference as a distance measure. This approach creates covariances between 0 and 1, where pixels that are very close will have a covariance close to 1 and pixels that are very apart far will have covariance close to zero. The kernel width gamma was chosen by eye and is set to 0.005. The core of this project is to use a data-driven approach to generating appropriate pixelwise covariances for the segmentation model. My general approach to this problem was to use existing CNNs trained on large, labeled datasets to generate some kind of prediction for each pixel in an image. These predictions are then incorporated into the pixelwise covariances to improve them over the baseline distance-based covariances. The first network that I used in the project was a fully convolutional network for semantic segmentation from Long et. al 6. This network was trained for the semantic segmentation task on the Pascal VOC 2012 dataset. For a given image, this network outputs a 60-class including background probability vector at each pixel. Above An example image from BSDS. Above CNN predicted class probabilities for three different classes on the example image. The second network that I applied to this task was the depth map prediction network from Eigen et. al 4. This network was trained on the NYU Depth dataset and it outputs a predicted depth at each pixel in the image. Its output is designed to approximate the output of a standard depth sensor like a Microsoft Kinect. Above CNN predicted depth map for the example image. I considered two different approaches to incorporate the outputs of these networks into the superpixel covarianaces for each image. The first approach that I used was to simply take the mean network output for each superpixel and concatenate this output with the mean pixel location for each superpixel to create a feature vector for each superpixel rescaling the nework output to match the scale of the pixel locations. To compute the covariance between two pixels, I then simply used the same Gaussian kernel distance as before. Above An example segmentation using the depth-inclusive prior. For the second approach, I wanted to learn a relative weighting for each type of feature pixel locations, semantic segmentation outputs and depth. In this case I created a feature for each pair of superpixels by concatenating the euclidean distance between the locations, the euclidean distance between the semantic segmentation output vectors and the absolute difference between the depth predictions. I then took a subsample of 500 pairs of superpixels from each of 30 random images from the BSDS dataset and trained a logistic regression classifier to predict the probability that two superpixel are part of the same segement given a vector of feature distances. The truth labels for training were taken from the human segmentations of the BSDS dataset. This approach was inspired by the Ghosh and Sudderth paper 2, which also describes a technique for translating the probability that two pixels are part of the same segment into an appropriate covariance. Evaluation The results of segmentations can be subjective, so evalutaing by generated segmentations by eye is still one of the best ways to understand the performance of a segmentation algorithm. In addition to evaluating by eye, I also used the Probibalistic Rand Index 3 measure to evaluate segmentation using the BSDS human segmentations as ground truth. This is an extension to the Rand index measure for comparing clusterings that is better suited to evaluating image segmentations. The basic Rand index is defined as the number of element pairs that are correctly identified as being part of the same group or not divided by the total number of possible element pairs in the data. A Rand index will be between 0 and 1 and a higher index is better. Results The table below summarizes the probibalistic rand index evaluation of the segmentation model under different priors, averaged over all human segmentations for the images in my test set. Prior Average PRI Pixel Distances 0.672 Pixel Distances Semantic Output 0.695 Pixel Distances Depth 0.683 Pixel Distances Semantic Output Learned Weighting 0.526 Pixel Distances Depth Learned Weighting 0.691 Pixel Distances Semantic Depth Learned Weighting 0.5912 According to this measure the best segmentation prior is the one that incorporates the output of the semantic segmentation network naively instead of learning the relative weighting between features. Below are the segmentations from all 6 versions of the model on 2 sample images, one of the better examples and one of the worse ones. Future Work The most straighforward line of future work would be to replace the semantic segmentation or depth network that I used here with a network fine-tuned to the task of predicting pairwise pixel covariances. This is likely a difficult task that would require a vast number of general human segmentations. It could conceivably be accomplished by designing a network that maps an image into an alternate colorspace such that color distances can be mapped to covariances. Another important point of weakness in the spatially dependent Pitman-Yor process model is the representation of superpixels. As I described above, superpixels are represented as histograms of colors and texture responses across the contained pixels. This is a fairly naive representation for superpixels which may not be all that good for distinguishing object boundaries. By the nature of these features, two quite different looking superpixels could have similar representations. The representation also doesnt account for context around a superpixel and similarly doesnt account well for cases when different looking superpixels are still commonly part of the same object. A better approach to representation could be to learn representations for superpixels, possibly using convolutional neural networks. An approach in this vein would require a significant amount of additional research. As a first step, I explored replacing the texture filters used in the standard model with filters from a trained classification CNN to see if they might create features that better discriminate between different object types. The images below show the texture feature assignments of normal texture features across a sample image compared to the assignments using filters learned as the first layer output of the AlexNet CNN. While the CNN-filter responses appear to be more diverse, which could allow them to be more discriminative, the resulting segmentations are indistinguishable for this example. Discussion Ultimately, the results of this project are somewhat underwhelming. While the results show that incorporating the network ouputs can improve segmentations somewhat, the difference is very small and the small number of images that the final models were tested on means that the difference may not actually be significant. Still, it is possible that with more fine-tuning of both the pipline and the model settings, that my approach could make a more significant differnce. I intend to trying the ideas explored here in my future work on segmentation. I am particularly interested in the results of the model that incorporates estimated depth, as this model does not rely on specfic object types and could theoretically be applied to any scene regardless of content. The quality of the results was largely hampered by a number of issues the I encountered during the course of this project. Mainly these issues stemmed from the segmentation model itself. Inference for the spatially dependent Pitman-Yor process model is complex and the results can be dependent on how the algorithm is intialized, which can make comparing various tweaks to the model quite difficult. Furthermore, the code for inference is still unstable, under development by me and extremely slow. This made debugging difficult and made trying to fine-tune the segmentation pipeline an arduous process. Beacause iterating on changes the the priors and the model was so slow, many of the settings I used to generate the final results relied on guesswork rather than a pricipled comparison. References 1 Sudderth, Erik B., and Michael I. Jordan. Shared segmentation of natural scenes using dependent Pitman-Yor processes. Advances in Neural Information Processing Systems. 2009. 2 Ghosh, Soumya, and Erik B. Sudderth. Nonparametric learning for layered segmentation of natural images. Computer Vision and Pattern Recognition CVPR, 2012 IEEE Conference on. IEEE, 2012. 3 Unnikrishnan, Ranjith, and Martial Hebert. Measures of similarity. Application of Computer Vision, 2005. WACVMOTIONS05 Volume 1. Seventh IEEE Workshops on. Vol. 1. IEEE, 2005. 4 Eigen, David, Christian Puhrsch, and Rob Fergus. Depth map prediction from a single image using a multi-scale deep network. Advances in neural information processing systems. 2014. 5 Achanta, Radhakrishna, et al. SLIC superpixels compared to state-of-the-art superpixel methods. Pattern Analysis and Machine Intelligence, IEEE Transactions on 34.11 2012 2274-2282. 6 Long, Jonathan, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. 7 Martin, David, et al. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. Computer Vision, 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on. Vol. 2. IEEE, 2001. 8 Szeliski, Richard. Computer vision algorithms and applications. Springer Science Business Media, 2010. Copyright Gabriel Hope 2016", "metadata": {"last_modified": "2016-05-13T22:52:16+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Deep Learning for Natural Image Segmentation Priors", "Gabriel Hope", "Nonparametric Segmentation", "Data", "Learning Segmentation Priors", "Evaluation", "Results", "Future Work", "Discussion", "References"], "word_count": 2581, "token_count_estimate": 3203}}, "https://cs.brown.edu/courses/csci2952c/all.html": {"text_content": "2022 2020 2018", "metadata": {"last_modified": "2022-08-22T20:47:44+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": [], "word_count": 3, "token_count_estimate": 8}}, "https://cs.brown.edu/courses/csci2951-t/finals/gmarques/": {"text_content": "gmarques - CSCI 2951t Final Project Four top images retrieved using the leftmost image as the query Introduction Content based image retrieval tries to obtain similar images to the one used as query according to a feature. The objective is define a metric to compare this features and then obtain the k nearest neighbors for an image. For example, a basic approach would use the Euclidean distance from every pixel to the pixels in the original one. Clearly, this approach becomes extremely expensive as the set of images and the dimensions of each increase. To decrease the dimensionality of the feature different approaches are used GIST, LSH and PCA. In addition, binary function tends to make the process even faster since the similarity function becomes the Manhattan distance. Lin, 2015 defined a framework to use a neural network as an autoencoder. It was proved that the AlexNet fine tuned for image classification produced the state of art results in binary hash codes for image. In this work, I aim to expand the concept for object detection. Therefore, using one of the main approaches for object detection, Faster-RCNN , I trained an auto-encoder with objective to define features for object based image retrieval. Method The proposed framework is an application for the technique proposed by Lin, 2015 in content-based image retrieval. In this work, this term refers to, given an image images that have similar region proposals will be retrieved. Region proposals are defined as bounding boxes for an object of a specific class. In this case, Faster-RCNN is used as the object detector. This detector proves to be suitable for the task because it is a single neural network with no need for extra input or output information. Therefore, the latent layer in this network will be directly compressing the data used for object detector. It is also the state of art for object detection and it is reaching real time detection in some cases. By looking into the network structure and comparing to the original approach for ImageNet, the presence of the twin output layer for class probability and bounding box location does not allow a direct mapping of the framework into the network. However, in the last layers, Faster R-CNN presents a clear distinction between region localization and object classification. Following the framework, I decided to isolate the latent layer just for the classification output, as the feature will tend to ignore localization. The objective is to compress just information about the object classes. After including the new layer, the new network is fine-tuned for the desired data set. The objective it to reach a similar performance to the original detector. This indirectly proves that the information is being compressed otherwise, the output would not perform closely to the original structure. The output of the latent layer defines the binary code according to a threshold. Implementation Details The image retrieval algorithm first defines a set of features containing all the images that can be retrieved. These features are associated with the image. However, Faster R-CNN with the latent layer produces a feature for every proposal given the input image. In the configuration for the detector, the maximum number was 300 proposals. I did not increase this number because of processing limitations and it is out of the scope. However, most of the proposed object does not strongly define a class in the output, or if it does, many proposals will be referring the same object. As a result, these features are filtered using the object detector output as the factor to be considered. First, to address multiple proposal to the same object we apply non-max suppression. This algorithm is already implemented in Faster-RCNN. For a given set of bounding box and scores, it suppresses those with areas overlapping above a threshold the boxes with higher scores are given priority in the suppression. The remained features are then limited by another threshold, that defines the minimum confidence in a class for a proposal. For the network a GeForce Titan was used. In terms of the neural network, there are three different configuration for Faster-RCNN. Due to the difference in terms of processing between the original eights GPUs and this work, the smallest network was adopted. In this case, it was Zeiler Fergus Net , but problems to reach similar results to the original approach direct the approach towards VGG16 Net . A point that deserves mention is that even if it is deeper and more computationally expensive to train, VGG proved to be almost eight times faster. The reasons are still a topic of research. The nms rate was chosen originally from the default values. The same was done was done with the confidence threshold. For the auto encoder features the confidence was lowered to 0.6 to create more images in the set. The objective was to restrict to 1 to 2 regions per image, to keep it computational feasible and to avoid false positives. According to observations, the threshold can be selected to control the region proposals set size. In the experiments 0.3 and 0.8 for nms and confidence threshold returned 8521 features for 5000 images. Coincidentally, for the network with the autoencoder the number of features was the same. In terms of the learning rate, initially it was lowered because the network was not converging. However, by the time, the VGG16 Net proved to be reliable in terms of mAP, as the learning rate was increased the accuracy improved too. The learning rate was set in 0.01 the same used to train the original detector from ImageNet. Experiments For the experiments, first Faster-RCNN was trained in the configuration end to end that generates a single neural network responsible for the task. I followed the pre-set values in this case, 70000 interactions. The resulting network yielded 70.8 in mAP, a result close to 69.9 described in the paper. The next step was to include the latent layer and fine tune for the chosen data set. As the source code used was an implementation over Caffe, the original source code presented challenges to be extended. Consequently, I kept the same dataset to fine tune the autoencoder. It is clear that it can lead to an over fitted network. Mean accuracy for K images with images from Pascal VOC 2007 In this experiment, image proposals from 4 thousand images from PASCAL VOC 2007 were used to constitute the image set. To restrict the number of features the level of confidence and nms were used, as explained before. The testing set is composed by all the features of one thousand images from the testing dataset. The mean accuracy is calculated doing the average of the accuracy in each class. The accuracy in each class is calculated as following. Given a image proposal the k nearest neighbors are retrieved. A set of the classes present in these images are built. If the class that is in the queried proposal is in this set a hit is counted, otherwise it is a miss. Finally, these numbers are divided by the total number of classes of proposals, normalizing it. The auto encoder corresponds to 256 bits from the latent layerwhose activation function is sigmoid, the output was converted to binary with a 0.5 threshold. The fc7 is the 4096 feature from the network and pca is a 48 feature extracted from the fc7 feature through Principal Component Analysis. The last two features were not discretized. Mean accuracy for K images with images from Pascal VOC 2012 This chart presents a test with the same autoencoder but the images were taken from PASCAL VOC 2012, that includes images from the previous years. To create the pool of features, region proposals from 5000 images of the training set. To test, 2000 images from the validation set. The performance is similar to the 2007 analysis and the better performance of the auto encoder indicates that it is not as over fitted as expected. It is clear that as k increases fc7 will surpass the autoencoder performance. The worse performance of the pca in this experiment is surprising because the number of dimension was increased from 48 to 128. Accuracy per class Pascal VOC 2012 Analysing the accuracy in a finer grain, it is clear that the three approaches have the same problem. This can indicate that the problem is not related to the features, but maybe to limitations from the network. In other words, using a neural network and knn would not give a better result. However, the autoencoder outperforms other methods in with a small k. In terms of application this is important because as k increases the algorithm become less responsible for the retrieved proposals. Average time to retrieve k nearest neighbors PCA, k 1 PCA, k 5 PCA, k 10 PCA, k 20 FC7, k 1 FC7, k 5 FC7, k 10 FC7, k 20 AUTO, k 1 AUTO, k 5 AUTO, k 10 AUTO, k 20 AT 0.115 0.132 0.133 0.133 2.492 2.528 2.527 2.546 0.942 0.954 0.948 0.962 For the experiments the brute force was used as technique to get the k nearest neighbors. Comparing the average time to retrieve k images from a 5000 images set, the experiment shows that this set of different values of k practically does not affect the time. Comparing the time, the number of features affected considerably more the final time than data type. However, it is important to consider that PCA achieved the worst results and it also demands an extra step to define the model. Four top images retrieved using the leftmost image as the query Discussion and Possible next steps This approach is clearly not the most suitable for object based image retrieval as it completly ignores the location of the feature. It also demands that every proposal of the query image is considered valid. So, when the accuracy is evaluated, all three hundred proposals were used. The same strategy applied to build the set of images could be usedapplying non maximum suppression and a threshold in the score. This could be done as a next experiment. Faster R-CNN also imposed some problem, specially when training the autoencoder. Changing the data set is also another. I could not use a non PASCAL VOC because of time constraints to implement the code for a new dataset. On the other hand, there are tutorial with ImageNet. For the next steps, I would highlight a technique to select the proposals to be considered in the query image. Additionally, a more complete set of experiments with different data sets. Overall, however the autoencoder outperformed fc7 and pca in the tests. It shows that, in fact, the approach improves object retrieval for object detectors. In terms of over fitting, the tests with a different data set PASCAL VOC 2012 attest that it did not damage the accuracy. References Slides presentation with more experiments Project repository Faster RCNN repository Deep Learning Binary Hash Codes repository", "metadata": {"last_modified": "2016-05-13T22:51:55+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["gmarques - CSCI 2951t Final Project"], "word_count": 1826, "token_count_estimate": 2223}}, "https://cs.brown.edu/courses/csci2952-a/": {"text_content": "CS2952 A Blockchains and Cryptocurrencies 1030 to 1150 Tuesdays and Thursdays CIT 368 Official Song of CS2952 A Course Information Blockchain technology promises to revolutionize how modern society deals with trust. Although cryptocurrencies such as Bitcoin are in the news, the impact of this technology is likely to extend far beyond such speculative bubbles, encompassing topics ranging from identity management, to market making, to IOT security, and also CryptoKitties The goal of this course is to take a snapshot of current research topics in blockchains and related areas. We will start with a few tutorials by the instructor, but most of the course will consist of presentations by students. Progress at the forefront of research is often incremental one researcher publishes a paper posing a question or claiming a result, and a sequence of follow-on papers improve the result or alter the question. For this reason, we will organize our approach around the idea of clusters of papers. A cluster consists of one primary paper, the one to read if you can read only one, together with two or three secondary papers. The primary paper may have been the first to formulate the problem or technique, or it may have provided the best solution to the problem, or perhaps it is simply the most readable. Grades and Assignments Schedule Sign-up Texts and Other Resources under construction Starting Points for Presentations under construction Instructor Maurice Herlihy , CIT 341", "metadata": {"last_modified": "2018-02-27T13:00:21+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["CS2952 A \u2013 Blockchains and Cryptocurrencies", "Course Information", "Instructor"], "word_count": 238, "token_count_estimate": 286}}, "https://cs.brown.edu/courses/csci2952c/": {"text_content": "Learning with Limited Labeled Data Fall 2022 Course Description As machine learning is deployed more widely, researchers and practitionerskeep running into a fundamental problem how do we get enough labeled dataThis seminar course will survey research on learning when only limitedlabeled data is available. Topics covered include semi-supervised learning,transfer learning, weak supervision, few-shot learning, and zero-shot learning.Students will lead discussions on recent researchpapers and develop final research projects. Essential Info Instructor Stephen Bach a.k.a. Steve Class Meetings Tuesdays and Thursdays, 1-220 pm, CIT 316 Office Hours See the Canvas homepage for information. Textbook None Prerequisites Previous experience in machine learning is required through CSCI 1420 or equivalent research experience. Important Links Canvas for discussions, assignment guidelines, and additional class resources Past years for previous reading lists project ideas, etc. Contact For questions, discussion, and other course-related posts, use Canvas . If you have an atypical question that you are certain does not belong onCanvas, email the instructor. Course Schedule Introduction Sep 8 Introductions, an overview of the researchtopics we will cover during the semester, how to read a research paper. Suplemental reading Introduction to Semi-Supervised Learning. Olivier Chapelle, BernhardSchlkopf, and Alexander Zien. In Semi-Supervised Learning, MIT Press, 2006. PDF Online, requires Brown login Incidental Supervision Moving beyond Supervised Learning. Dan Roth.AAAI 2017. PDF How to Read a CS Research Paper Philip W. L. Wong. PDF How to Read a Technical Paper. Jason Eisner. Online How to Read a Paper. S. Keshav. PDF Semi-Supervised Learning Sep 13 MixMatch A Holistic Approach to Semi-Supervised Learning.David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raffel.Neural Information Processing Systems NeurIPS 2019. PDF Supplemental Zip Reviews Code Suplemental reading FixMatch Simplifying Semi-Supervised Learning with Consistency and Confidence.Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A. Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.Neural Information Processing Systems NeurIPS 2020. PDF Supplemental Reviews Code Sep 15 Semi-supervised Sequence Learning.Andrew M. Dai and Quoc V. Le.Neural Information Processing Systems NeurIPS 2015. PDF Reviews Suplemental reading Unsupervised Data Augmentation for Consistency Training.Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le.Neural Information Processing Systems NeurIPS 2020. PDF Supplemental Reviews Code Transfer Learning Sep 20 Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu.Journal of Machine Learning Research JMLR 211401-67, 2020. PDF Blog Code Suplemental reading XLNet Generalized Autoregressive Pretraining for Language Understanding.Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R. Salakhutdinov, and Quoc V. Le.Neural Information Processing Systems NeurIPS 2019. PDF Supplemental Zip Reviews Sep 22 Start of course survey due ELECTRA Pre-training Text Encoders as Discriminators Rather Than Generators.Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning.International Conference on Learning Representations ICLR 2020. PDF Reviews Code Suplemental reading BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.Meeting of the North American Association for Computational Linguistics NAACL 2019. PDF Sep 27 Big Transfer BiT General Visual Representation Learning.Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby.European Conference on Computer Vision ECCV 2020. PDF Code Supplemental reading TAGLETS A System for Automatic Semi-Supervised Learning with Auxiliary Data.Wasu Piriyakulkij, Cristina Menghini, Ross Briden, Nihal V. Nayak, Jeffrey Zhu, Elaheh Raisi, and Stephen H. Bach.Conference on Machine Learning and Systems MLSys 2022. PDF Code Sep 29 Learning Transferable Visual Models From Natural Language Supervision.Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.International Conference on Machine Learning ICML 2021. PDF Blog Supplemental reading SLIP Self-supervision meets Language-Image Pre-training.Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.ArXiv 2112.12750 2021. PDF Weakly Supervised Learning Oct 4 Snorkel Rapid Training Data Creation with Weak Supervision. Alexander Ratner,Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher R.Proceedings of the VLDB Endowment, 113269-282, 2017. PDF Code Supplemental reading Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm.A. P. Dawid and A. M. Skene.Journal of the Royal Statistical Society. SeriesC Applied Statistics, 28120-28, 1979. Online, requires Brown login Oct 6 Weakly Supervised Sequence Tagging from Noisy Rules.Esteban Safranchik, Shiying Luo, and Stephen H. Bach.AAAI Conference on Artificial Intelligence AAAI 2020. PDF Code Supplemental reading BERTifying the Hidden Markov Model for Multi-Source Weakly Supervised Named Entity Recognition.Yinghao Li, Pranav Shetty, Lucas Liu, Chao Zhang, and Le SongMeeting of the Association for Computational Linguistics ACL 2021. PDF Code Video Oct 11 Self-Training with Weak Supervision.Giannis Karamanolakis, Subhabrata Mukherjee, Guoqing Zheng, and Ahmed Hassan Awadallah.Conference of the North American Chapter of the Association for Computational Linguistics NAACL 2021. PDF Code Video Supplemental reading WRENCH A Comprehensive Benchmark for Weak Supervision.Jieyu Zhang, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, and Alexander Ratner.NeurIPS Datasets and Benchmarks Track 2022. PDF Supplemental Code Reviews Oct 13 Shoring Up the Foundations Fusing Model Embeddings and Weak Supervision.Mayee F Chen, Daniel Yang Fu, Dyah Adila, Michael Zhang, Frederic Sala, Kayvon Fatahalian, and Christopher R.Uncertainty in Artificial Intelligence UAI 2022. PDF Supplemental Zip Reviews Supplemental reading Language Models in the Loop Incorporating Prompting into Weak Supervision.Ryan Smith, Jason A. Fries, Braden Hancock, and Stephen H. Bach.ArXiv 2205.02318 2022. PDF Few-Shot Learning Oct 18 Prototypical Networks for Few-shot Learning.Jake Snell, Kevin Swersky, and Richard Zemel.Neural Information Processing Systems NeurIPS 2017. PDF Supplemental Zip Reviews Supplemental reading Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.Chelsea Finn, Pieter Abbeel, and Sergey Levine.International Conference on Machine Learning ICML 2017. PDF Oct 20 Project proposal due Language Models are Few-Shot Learners.Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.Neural Information Processing Systems NeurIPS 2020. PDF Supplemental reading On the Dangers of Stochastic Parrots Can Language Models Be Too Big .Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.ACM Conference on Fairness, Accountability, and Transparency FAccT 2021. PDF Oct 25 Learning How to Ask Querying LMs with Mixtures of Soft Prompts.Guanghui Qin and Jason Eisner.Conference of the North American Chapter of the Association for Computational Linguistics NAACL 2021. PDF Supplemental Video Supplemental reading The Power of Scale for Parameter-Efficient Prompt Tuning.Brian Lester, Rami Al-Rfou, and Noah Constant.Conference on Empirical Methods in Natural Language Processing EMNLP 2021. PDF Code Video Oct 27 How many data points is a prompt worthTeven Le Scao and Alexander Rush.Conference of the North American Chapter of the Association for Computational Linguistics NAACL 2021. PDF Supplemental Code Video Supplemental reading Cutting Down on Prompts and Parameters Simple Few-Shot Learning with Language Models.Robert Logan IV, Ivana Balazevic, Eric Wallace, Fabio Petroni, Sameer Singh, and Sebastian Riedel.Findings of the Association for Computational Linguistics 2022. PDF Code Nov 1 Conditional Prompt Learning for Vision-Language Models.Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu.IEEECVF Conference on Computer Vision and Pattern Recognition CVPR 2022. PDF Code Supplemental reading DualCoOp Fast Adaptation to Multi-Label Recognition with Limited Annotations.Ximeng Sun, Ping Hu, and Kate Saenko.ArXiv 2206.09541 2022. PDF Nov 3 Training language models to follow instructions with human feedback.Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.ArXiv 2203.02155 2022. PDF Supplemental reading None Nov 8 Election Day No class Zero-Shot Learning Nov 10 DeViSE A Deep Visual-Semantic Embedding Model.Andrea Frome, Greg S. Corrado, Jon Shlens, Samy Bengio, Jeff Dean, MarcAurelio Ranzato, and Tomas Mikolov.In Neural Information Processing Systems NeurIPS 2015. PDF Supplemental Zip Reviews Supplemental reading Zero-Shot Learning through Cross-Modal Transfer.Richard Socher, Milind Ganjoo, Christopher D. Manning, and Andrew Y. Ng.In Neural Information Processing Systems NeurIPS 2013. PDF Reviews Nov 15 Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs.Xiaolong Wang, Yufei Ye, and Abhinav Gupta.In IEEE Conference on Computer Vision and Pattern Recognition CVPR 2018. PDF Supplemental reading Rethinking Knowledge Graph Propagation for Zero-Shot Learning.Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, and Eric P. Xing.In IEEE Conference on Computer Vision and Pattern Recognition CVPR 2019. PDF Nov 17 Project status report due Multitask Prompted Training Enables Zero-Shot Task Generalization.Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush.International Conference on Learning Representations ICLR 2022. PDF Code Data Reviews Supplemental reading Benchmarking Generalization via In-Context Instructions on 1,600 Language Tasks.Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi.ArXiv 2204.07705 2022. PDF Data Nov 22 Do Prompt-Based Models Really Understand the Meaning of Their PromptsAlbert Webson and Ellie Pavlick.Meeting of the North American Association for Computational Linguistics NAACL 2022. PDF Code Supplemental reading Can language models learn from explanations in contextAndrew K. Lampinen, Ishita Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill.ArXiv 2204.02329 2022 PDF Nov 24 Thanksgiving No class Nov 29 Image Segmentation Using Text and Image Prompts.Timo Lddecke and Alexander Ecker.IEEECVF Conference on Computer Vision and Pattern Recognition CVPR 2022. PDF Supplemental Code Supplemental reading GLIPv2 Unifying Localization and Vision-Language Understanding.Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, Liunian Harold Li, Xiyang Dai, Lijuan Wang, Lu Yuan, Jenq-Neng Hwang, and Jianfeng Gao.ArXiv 2206.05836 2022. PDF Code Data Generation Dec 1 MixNMatch Multifactor Disentanglement and Encoding for Conditional Image Generation.Yuheng Li, Krishna Kumar Singh, Utkarsh Ojha, and Yong Jae Lee.IEEE Conference on Computer Vision and Pattern Recognition CVPR 2020. PDF Talk Code Video Supplemental reading Generating Object Stamps.Youssef Alami Mejjati, Zejiang Shen, Michael Snower, Aaron Gokaslan, Oliver Wang, James Tompkin, and Kwang In Kim.ArXiv 2001.02595 2020. PDF Dec 6 Zero-Shot Text-to-Image Generation.Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.ArXiv 2102.12092 2021. PDF Blog Supplemental reading Diffusion Models Beat GANs on Image Synthesis.Prafulla Dhariwal and Alexander Nichol.Neural Information Processing Systems NeurIPS 2021. PDF Supplemental Reviews Dec 20 Final project report due No class Learning Goals Students who complete this course will Acquire a working knowledge of the landscape of research on machinelearning with limited labeled data. Practice identifying and critically assessing the claims,contributions, and supporting evidence in machine learning research papers. Develop their ability to share scientific ideas via writing and discussion. Gain practical experience with the courses subject matter by applying andextending it to their own research interests though an open-ended project. Grading The following standards will be used to assign grades.Anyone who doesnt complete the standards to earn a B will receive NC. To Earn an A Participate actively in class discussions by asking questions, sharingopinions, and listening carefully to others. Meet all deadlines in the course schedule related to the research project. Submit two discussion questions to Canvas by 6 PM the evening before classfor assigned readings, missing no more than 3 readings. Attend class meetings, missing no more than 3 meetings. Fulfill the requirements below to earn a B. To Earn a B Conduct an original research project related to course materials and submita written report meeting the assignment guidelines. Lead the assigned class discussion demonstrating preparation and inclusion. Submit two discussion questions to Canvas by 6 PM the evening before classfor assigned readings, missing no more than 6 readings. Attend class meetings, missing no more than 6 meetings. Estimated Time Commitment Activity Hours Class Meetings 28 Readings 65 Submitting Discussion Questions 10 Preparing to Lead Discussion 2 Project Research 60 Project Proposal Status 10 Project Final Report 5 Total 180 General Course Policies Masking, COVID-19, and Other Health Issues Everyone attending class is required to wear a high-quality mask KN95 or better.Students who are leading discussions may optionally remove their masks while presenting.Attendance and discussion question policies will be flexible with respect to COVID-19and other health issues. Please contact the instructor if you have any issues. Diversity Inclusion The Brown computer science department has made it its mission to create andsustain a diverse and inclusive environment in which all students, faculty, andstaff can thrive. In this course, that responsibility falls on us all, students andteaching staff alike. In particular, Browns Nondiscrimination and Anti-Harassment Policy applies to all participants. If you have not been treated in an inclusive manner by any of the course members,please contact either me Stephen or the department chair Prof. Tamassia.Laura Dobler is also available as a resource for members of underrepresented groups. Additional resources are listed on the departments website. We, the computer science department, take all complaints about discrimination, harassment, and otherunprofessional behavior seriously. In addition, Brown welcomes students from all around the country and the world, and theirunique perspectives enrich our learning community. To empower students whose firstlanguage is not English, an array of support is available on campus, includinglanguage and culture workshops and individual appointments. For more information,contact the English Language Learning Specialists at ellwritingbrown.edu . Academic Integrity Academic dishonesty will not be tolerated. This includes cheating, lying aboutcourse matters, plagiarism, or helping others commit a violation. Plagiarismincludes reproducing the words of others without both the use of quotation marksand citation. Students are reminded of the obligations and expectations associatedwith the Brown Academic Code and Brown Code of Student Conduct .For project work, feel free to build on third-party software, datasets, or otherresources, as long as you credit them in your reports and clearly state whatwork is solely your own. As a general policy for this course and for the rest ofyour academic career if you use any idea, text, code, or data that you did notcreate, then cite it. Accommodations Brown University is committed to full inclusion of all students. Please informme if you have a disability or other condition that might require accommodationsor modification of any of these course procedures. You may email me, come to officehours, or speak with me after class, and your confidentiality is respected. Iwill do whatever I can to support accommodations recommended by SAS. For moreinformation contact Student Accessibility Services SAS at 401-863-9588 or SASbrown.edu . Mental Health Being a student can be very stressful. If you feel you are under too muchpressure or there are psychological issues that are keeping you from performingwell at Brown, I encourage you to contact Browns Counseling and Psychological Services CAPS .They provide confidential counseling and can provide notes supporting accommodationsfor health reasons. Incomplete Policy I expect everyone to complete the course on time. However, I understand thatthere may be factors beyond your control, such as health problems and familycrises, that prevent you from finishing the course on time. If you feel you cannotcomplete the course on time, please discuss with me Stephen the possibilityof being given a grade of Incomplete for the course and setting a schedule forcompleting the course in the upcoming year. Thanks to Tom Doeppner, Laura Dobler, and DanielRitchie for borrowed text.", "metadata": {"last_modified": "2022-10-28T16:05:39+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": [], "word_count": 2655, "token_count_estimate": 4590}}, "https://cs.brown.edu/courses/csci2952d/": {"text_content": "Skip to main content CSCI 2952D Computational Semantics Home current Lectures Assignments Staff Calendar Resources Natural language understanding is a holy grail of AI. And with the machine learning advancing at such a rapid pace, breakthroughs in automatic language understanding seem to be just around the corner.But what exactly are the current barriers in automating human-like language capabilities This course will dissect what makes language understanding so challenging, including both theoretical aspectslogic, formal semantics, pragmatics, knowledge representation and practical methods graphical models, game theory, neural networks. The course will be project-based, and will emphasize reading andcritiquing current research in computer science, linguistics, and cognitive science. Time and place Fall 2018 TTh 10.30 - 11.50, CIT 477 Lubrano Instructor Ellie Pavlick Prerequisites Machine Learning CSCI 1420 or Computational Linguistics CSCI 1460 Discussion Forum Piazza Office Hours See calendar page Course materials Syllabus Readings Last updated December 14, 2018. Feel free to reuse any of the contents of this course or this web page. Theme provided by Bootswatch .", "metadata": {"last_modified": "2018-12-14T23:51:55+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": [], "word_count": 167, "token_count_estimate": 234}}, "https://cs.brown.edu/courses/info/csci1360/": {"text_content": "CSCI1360 Human Factors in Cybersecurity Offered this year and every year Fall 2024 This course is designed to push you to think about cybersecurity as an idea with both physical and virtual elements. Throughout the course, we will examine the value of information, the importance of users, and the difficult balance between security and usability. The ultimate goal of this course is to give you the intellectual and scientific framework you need to create systems that are both secure and efficient to use. The course focuses on usable security practices, but also looks deeply at the way our society influences security. Instructors Ernesto Zaldivar Course Home Page httpscs.brown.educoursescsci1360 Location TBD Meeting Time TBD Exam Group TBD CRN None", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI1360", "Human Factors in Cybersecurity"], "word_count": 118, "token_count_estimate": 150}}, "https://cs.brown.edu/courses/csci2952o/": {"text_content": "Home Course Structure Schedule Policies Course Information This course is aimed at preparing graduate students and senior undergrads to do advanced work at the intersection of two important and popular fields computer vision and robotics. The course will focus on the latest advances through lectures, readings, and discussion groups. The lectures and readings will be designed to represent a mix of classical techniques as well as the most recent advances in the two fields. The unique highlight of this course is the inclusion of a practical component students will have to implement a project that combines computer vision and robotics by using cameras and a real robot arm. Students will form teams for this project and have exclusive access to a camera and a small robot arm both of which can be interfaced with the students laptops. Class Time Tu Th, 1030am-1150am CIT 316 in-person participation required Ed Discussion httpsedstem.orguscourses35893 News Class starts on Thursday, Jan 26th. The course will require in-person participation . Please registerrequest override directly on Courses Brown with a short note on how you meet the prerequisites. There is no need to email us. Learning Goals This course has two main learning goals. Students are expected to actively participate in class including discussions and group activities. Learn about the state of the art in computer vision and robotics . We will do this by reading a curated list of research papers on relevant topics. Understand research practice in computer science , with specific focus on the computer vision and robotics communities. We will learn how to effectively read papers, make presentations, critique and discuss research, and do a group research project. The course will also include exercises and a final project with a robot arm . Prerequisites This is an advanced course primarily meant for graduate students and advanced undergrads. But students at all levels are welcome to participate if they have the necessary preparation. You must have taken one or more of the following courses or equivalents before enrolling. CSCI 1430 Computer Vision CSCI 1951-R Introduction to Robotics CSCI 1470 Deep Learning CSCI 1230 Introduction to Computer Graphics Other Requirements This class has some additional requirements. In-person classroom participation is required . This is a discussion-based class and we cannot support hybrid instruction. However, classroom sessions will be recorded for offline viewing. Please follow the most recent health guidance found on the Healthy Brown website. You must have a WindowsMacLinux laptop to interface with a robot arm . Please reach out to the instructor if you need alternative arrangements. This course has a final project. Students must use the robot arm in some way for their final project. Contact If you would like to take this course, please registerrequest override directly on Courses Brown . If you are unsure about the prerequisites, please reach out to the instructor. Instructor Srinath Sridhar Email srinathbrown.edu Office Hours Book Appointment UTA Rugved Mavidipalli Email Rugved Mavidipalli Office Hours Th 4pm - 6pm Hours", "metadata": {"last_modified": "2023-02-09T12:03:00+00:00", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": [], "word_count": 495, "token_count_estimate": 593}}, "https://cs.brown.edu/courses/info/csci1951-i/": {"text_content": "CSCI1951-I CS for Social Change Not offered this year Offered occasionally, last taught Spring 2023 In this course, students will work in a studio environment to iteratively design, build, and test technical projects in partnership with different social change organizations. Students will be placed in small teams to collaboratively work on projects that will range from, for example, developing a chatbot to aid community engagement to building a mobile app to teach STEM to refugee kids. Through the course, we will also reflect on our positionality and ethics in engaging in social impact work and what it practically means to leverage technology to create social change on an everyday basis. Enrollment limited to 12. Entry to this course is through application only. Instructors Lachlan Kermode CRN 27296", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI1951-I", "CS for Social Change"], "word_count": 127, "token_count_estimate": 159}}, "https://cs.brown.edu/courses/info/csci1951-l/": {"text_content": "CSCI1951-L Blockchains Cryptocurrencies Offered this year and every year Spring 2025 Introduction to modern blockchain-based systems. Topics covered include consensus and distributed computing, examples cryptocurrencies, programming smart contracts, privacy and secrecy, transfer networks, atomic swaps and transactions, non-currency applications of blockchains, and legal and social implications. Students will do a programming project and a term project. Instructors Maurice P Herlihy Location TBD Meeting Time TBD Exam Group TBD CRN None", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI1951-L", "Blockchains & Cryptocurrencies"], "word_count": 70, "token_count_estimate": 98}}, "https://cs.brown.edu/courses/info/csci2952-f/": {"text_content": "CSCI2952-F Distributed Systems at Scale Microservices Management Not offered this year Offered most years, last taught Fall 2022 This seminar investigates and explores cutting edge challenges and issues in the emerging Microservices paradigm. Microservices are a specific cloud paradigm for enabling distributed systems and applications at scale. In particular, this course builds on the foundations provided by the initial distributed systems, networking and operating systems offering i.e., CSCI 1380, CSCI 1680, CSCI 1670 and explores how these concepts are used to realize, manage, and orchestrate microservices. The course is driven by materials from academic conferences and industrial blogs. The industrial blogs will provide context and motivation for different problems. The academic reasons will provide a deep divide into the technical details we will focus on reading, analyzing, critiquing and brainstorming academic papers. Students taking this class should be familiar with reading academic literature, performing critical analysis, and working on open ended problems with undefined solutions. More information httpcs.brown.educoursesinfocsci2952-f Instructors Theophilus A Benson CRN 19118", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "CSCI2952-F", "Distributed Systems at Scale: Microservices Management"], "word_count": 164, "token_count_estimate": 226}}, "https://cs.brown.edu/courses/ta/": {"text_content": "The Undergraduate Teaching Assistant UTA Program Our UTA program is unlike any other. It employs more than 400 undergraduates each semester, and every one of these students is given the chance to impact their course in meaningful ways and work closely with the professor, other UTAs, and other students. Students often find being a Brown CS UTA to be a formative part of their Brown experience and build long-lasting friendships through the program. UTAs and non-UTAs alike can use this page to better understand the program and all of the amazing opportunities that lie in store for a would-be UTA The UTA program is coordinated by the MTAs . The current MTAs are Allie Masthay, Elizabeth Jones, Christina Stepin, Tyler Gurth, Benjamin Schornstein, Nishka Pant, and Jiahua Chen. Want to learn more Check out the following resources UTA Hiring Publications", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:24+00:00", "headings": ["Information for:", "The Undergraduate Teaching Assistant (UTA) Program"], "word_count": 140, "token_count_estimate": 182}}, "https://cs.brown.edu/covid/": {"text_content": "COVID-19 Response Resources for CS Before continuing, please read the Brown CS 2020-21 Plan , which may replace some of the information below. Visit Browns COVID-19 website for the most up-to-date information Brown Coronavirus News and Information Brown University COVID-19 Site Remote Work Guide Teaching Continuity Guide Additional resources for Computer Science Students, Faculty and Staff are listed below. Working From Home Getting Started with FastX Getting Started with Zoom Connecting to CS using SSH or Mosh VPN to the CS Network Access your home directory using VS Code requires an active VPN connection When using VS Code connect to fastx-cluster.cs.brown.edu Filesystem Web InterfaceNo VPN needed Setting up SSHFS Getting Help Technical Staff TStaff Email problemcs.brown.edu Zoom httpsbrown.zoom.usj6775943824 While observing summer hours, the Zoom room will be available 8 a.m. to 4 p.m. Meeting ID 677 594 3824 Phone 1-301-715-8592 Enter meeting ID when prompted US Toll-Free 877-369-0926 or 877-853-5247 Sun Lab Consultants - help with remote access consultlists.cs.brown.edu System Status CS Classes Online Students CS Student Resources Faculty AV Options for Teaching in CS This is an evolving document. Please send comments or suggestions to problemcs.brown.edu .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "COVID-19 Response Resources for CS", "Working From Home", "Getting Help", "CS Classes Online"], "word_count": 188, "token_count_estimate": 271}}, "https://cs.brown.edu/courses/ta/hiring/": {"text_content": "TA Hiring TAing is a great way to dig a little bit deeper into the material for a course, get practice working in a group of peers, interact more closely with a professor, learn something about how courses are run, make some money, and have fun doing it If youve taken a CS class, we want you to apply To see courses hiring TAs, please check out the courses hiring page. For detailed position descriptions, see these pages for Head TAs , Undergraduate TAs , Socially Responsible Computing TAs formerly Ethics TAs, Head STAs , and Meta TAs . Brown University is an equal opportunityaffirmative action employer and strongly encourages applications from women, minorities, and protected persons. Click here for more information. The TA hiring process is coordinated by the Meta TAs . The CS UTAs, STAs, HTAs, HSTAs, MTAs, and several other categories of student workers in the CS department are members of a collective bargaining unit represented by the Teaching Assistant Labor Organization TALO. The employment of these student workers is subject to the 2023 Interim Agreement Between Brown and TALO Full Text, Plain Language Summary . Applications All undergraduate and Masters students are eligible to apply. PhD students are not eligible for HTA UTA STA positions, but PhD students in the Computer Science department may be hired as Graduate TAs. Graduate TAs are hired separately from this processspeak to your advisor if youre a Computer Science PhD student who wishes to become a Graduate TA. The MTA application for Fall 2024 is closed. The HTA application for Fall 2024 is closed. If you wish to apply late, you should contact the professor teaching the course for permission and submit your application here . The HSTA application for Fall 2024 is closed. The UTA application for Fall 2024 is available here . The STA application for Fall 2024 is available here . Spring 2024 Hiring Timeline MTA Hiring 129 MTA applications open 22 MTA applications close 5pm ET 25 - 212 MTA applicants are interviewed 215 Latest date that all MTA applicants hear back HTAHSTA Hiring 26 Fall 2024 HTA and HSTA applications open 210 Fall 2024 HTA and HSTA applications close 5pm ET 212 - 226 Fall 2024 HTA applicants are interviewed 34 Latest date that all Fall 2024 HTA applicants hear back UTASTA Hiring 228 Fall 2024 UTA and STA applications open 36 Fall 2024 UTA and STA applications close 5pm ET 311 - 417 Fall 2024 UTA and STA applicants are interviewed 424 Latest date that all Fall 2024 UTA and STA applicants hear back Questions First, check out these FAQs . If you dont find an answer, contact the MTAs for questions about the hiring process, the TA program as a whole, or MTAing the professor of the course for questions about HTAing a specific course the professor or HTAs of the course for questions about UTAing a specific course the Socially Responsible Computing HTAs HSTAs for questions about the STA program", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "TA Hiring", "Applications", "Questions"], "word_count": 498, "token_count_estimate": 649}}, "https://cs.brown.edu/courses/ta/pubs/": {"text_content": "Publications These are the documents maintained by the Meta-TAs for the UTA program. They are intended to help TAs do their job, to help students understand how to interact with their TAs, and to give others a bit of insight into how the program works in the department. These documents are maintained based heavily on suggestions from students, TAs, and faculty. By all means, if you have suggestions, please contact the Meta-TAs . Missives UTA Missive A guide for new and returning UTAs that contains basic information about the TA program. This document is updated regularly to reflect changes in the department. Last updated in January 2024. HTA Missive A guide for new and returning HTAs that contains detailed information on aspects of HTAing from hiring to policies to techincal resources. This document is updated regularly to reflect changes in the department. Last updated in January 2024. Links Jobs for Undergraduates This page lists the various opportunities for undergrads to work in the department. It includes the UTA, HTA, and Meta-TA job descriptions, which are maintained by the Meta-TAs. For more information about the Socially Responsible Computing program, see here . To learn more about becoming a Socially Responsible Computing Teaching Assistant STA, see here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Publications", "Missives", "Links"], "word_count": 206, "token_count_estimate": 263}}, "https://cs.brown.edu/degrees/": {"text_content": "Applying To Our Degree Programs We offer one of the best environments in the world for both research and education. Our faculty, students, resources, and location are just some of the reasons why you should study at Brown CS . Click any of the links below to apply to the appropriate program. Graduate Study This consists of a doctoral program and two Masters programs, the Master of Science in Computer Science and the Master of Science in Cybersecurity . The latter is a fully online degree that can be completed from anywhere in the world. Doctoral students can earn a Masters degree automatically, but students admitted for a Masters dont automatically transition to the PhD track. The Data Science Initiative also offers a Masters program that prepares students from a wide range of backgrounds for careers in data science. Rooted in a research collaboration among four very strong departments Applied Mathematics, Biostatistics, Computer Science, and Mathematics, it offers a rigorous, distinctive, and attractive education for people building careers in data science andor big data management. Undergraduate Study Our undergraduate program pioneered the idea of undergrads contributing to teaching and research at a time when few universities even offered CS courses. Today, no other institution gives students the same opportunities to be part of the universitys intellectual life, benefit from a community of collaborators, and advance the field. Undergraduate students also have the option of staying a fifth year to obtain a Masters degree.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Applying To Our Degree Programs", "Graduate Study", "Undergraduate Study"], "word_count": 243, "token_count_estimate": 278}}, "https://cs.brown.edu/degrees/doctoral/": {"text_content": "Our PhD Program Working with faculty who are leaders in the field, our PhD students conduct cutting-edge research, earning prestigious fellowships and awards . After graduation, they contribute widely to science, learning, culture, and their communities, earning honors in academia and industry. They also throw rubber chickens at each other. This page is for prospective PhD students. Current students, go here . We offer world-class research and education in an interdisciplinary environment for more detail on the below, click here A lower studentfaculty ratio than many of our peers Full financial support while completing the degree full tuition, health insurance, a generous stipend Teaching assistantships for students who want to hone their teaching skills Shared offices that overlook Browns scenic campus Opportunities to serve on important committees and organize seminars and other events Students can take courses from Harvard, MIT, RISD, and other institutions without additional cost see here for details and restrictions Brown CS makes it very easy to talk to a professor and join their research group. I was very surprised how much of a family feeling the department has...here you chat with everyone at the coffee machine. Emanuel Zgraggen, PhD student Additional Information How do I apply Why is Brown a great place to study CS at all levels What are the requirements for earning a PhD How do I transfer graduate credit from another institution Fill out this form and this one and send them to Elena Quinonez at fasamcs.brown.edu. What do young researchers working in industry say about the benefits of earning a PhD How can I learn more about the program Read our FAQ . How can I learn more about grad school application and life Professor Shriram Krishnamurthi gives answers. How do I ask additional questions Email link", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Our PhD Program", "Additional Information"], "word_count": 295, "token_count_estimate": 344}}, "https://cs.brown.edu/degrees/doctoral/applications/": {"text_content": "Applying To Our Doctoral Program Thanks for your interest If you havent already, please acquaint yourself with the PhD program and compare it to our Masters program . You may want to review the homepages of our faculty for information about their research interests, and if they have any instructions for applicants interested in them as a potential advisor. Please read the FAQ here . When youre ready, continue to the Official Online Application , but note the following To request an application fee waiver , please fill out the form here . Were especially eager to waive fees for applicants from underrepresented groups. Youll be notified as soon as possible if your request has been approved. Your application will be kept on hold until you either enter a waiver code or pay the application fee. If you belong to an underrepresented group in CS and want to receive feedback and guidance on your application , please fill in this form . Youll receive guidance from current Brown CS PhD students, either in the form of feedback on your application or a Zoom guidance session, as chosen by you in the form. Participation is completely optional, and its separate from the application process. While this program doesnt guarantee admission, we hope that itll be useful to you. You can learn more here . Application Requirements We expect strong results from our applicants in the following Record of grades or other academic performance Research experience or clear motivation of a research plan 3 recommendation letters you might suggest to your letter writers that they look at this site TOEFL or IELTS for applicants whose native language is not English Note the GRE is no longer mandatory, but may be included if desired Again, please read our FAQ . How To Apply The deadline for applications including test scores and letters of recommendation for entry in September is December 15 . We dont allow doctoral students to start at other times of the year. If your recommendation letters are arriving a day or two late due to circumstances beyond your control, go ahead and email us to give us a heads up. Please visit the graduate school website and complete the entire application on-line . You can get additional information from our FAQ and from the Graduate School s Web site. We strongly urge you to provide unofficial scanned copies of your transcripts as part of the electronic application. If youre accepted to the program, well ask you to mail an official copy of your transcript. Graduate applications are handled by a combination of Brown CS and the Graduate School. First, your application is formally processed by the Graduate School. Its content is then read by members of Brown CS, who forward their recommendations to the Graduate School. Finally, the Graduate School formally admits you to the program. Therefore, you may receive correspondence from either of these entities. Note that doctoral students can automatically earn a Masters degree on the way to completing their PhD, but Masters students dont automatically transition to the PhD track.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Applying To Our Doctoral Program"], "word_count": 513, "token_count_estimate": 563}}, "https://cs.brown.edu/degrees/masters/faq/": {"text_content": "Frequently Asked Questions About Our Masters Program We will begin accepting applications for Fall, 2024 entry on September 1, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Masters degree. 1 How much does a Masters degree cost Please see here . Most students take two courses per semester, but this page assumes four. Please adjust accordingly the actual tuition cost is the per-semester figure given, divided by four, and multiplied by the number of courses taken. We also offer a small number of merit-based, full-tuition scholarships to support Brown CS diversity and inclusion goals. If youre admitted, youll be given an opportunity to apply for them. 2 What are the admission criteria for the Masters program We consider numerous criteria, including academic performance, letters of recommendation, and industrial experience. We also consider GRE scores, TOEFL scores if relevant, motivation, work experience, awards, honors, prizes, and other accomplishments. Because Masters applicants are so diverse, no single set of criteria adequately covers all the cases. In more detail, were looking for Academic performance The GPA isnt the only criterion. Grades in computer science and related disciplines for example, math count more than grades in other areas. Current undergraduates should send us your Fall semester grades. Also, we take into account the fact that at some very competitive schools its very difficult to achieve a high GPA. Letters of recommendation Letters must give a detailed, factual, and candid evaluation of your capabilities. Rankings and comparisons with other students are very useful. Ask your recommenders to follow these guidelines. Remind your recommenders of deadlines to ensure they meet them. We routinely find ourselves unable to admit potentially qualified students because their letters of recommendation havent arrived in time. Work experience Please describe any work experience you might have. Obviously, not all applicants have work experience, but for those who do, some description of it helps us better evaluate your application. General GRE scores We dont require these, and we dont recommend that you take the GRE just for admission to our program. However, these scores provide an additional objective form of evaluation thats often helpful in determining your basic skills and comparing them to applicants from diverse backgrounds. Were aware that test performance can improve considerably with practice, some people dont perform well on tests, and that the verbal GRE is harder for some foreign applicants. TOEFLIELTS The TOEFLIELTS exam is required for applicants to the Computer Science ScM program unless you meet one of the exemption criteria see below Your first language is English You have received a degree or will obtain a degree from an institution where English is the sole language of instruction You have received a degree or will obtain a degree from an institution in the following countries Australia, Bahamas, Botswana, Cameroon, Canada except Quebec, Ethiopia, Ghana, Ireland, Kenya, Lesotho, Liberia, Malawi, New Zealand, Nigeria, Zimbabwe, South Africa, Sierra Leone, Swaziland, Tanzania, Gambia, Uganda, United Kingdom England, Scotland, Northern Ireland, Wales, West Indies, Zambia. If you meet one of the exemption criteria, you do not need to submit TOEFL or IELTS scores, but may choose to do so if you wish. If you do not meet one of the exemption criteria, you must submit TOEFL or IELTS exams. We dont consider applicants who have scored below 620 PBT or 260 CBT or IBT 105, and prefer scores higher than that. The corresponding minimum IELTS score is 8.0. If you need to request a TOEFLIELTS waiver due to financial hardship, please contact mastersadmissionsbrown.edu . Statement The statement that accompanies your application helps us learn more about you. Awards, honors, and prizes Unless theyre well known for example, an NSF fellowship or graduation with honors, please give details about them how many candidates how many awards what were the selection criteria. This is especially important for foreign applicants. If these awards are really important, wed expect your recommenders to mention them. Research experience Research experience isnt required for Masters applicants and many of our applicants dont have any, but you can use experience youve had to demonstrate your ability to handle graduate-level computer science material. 3 Can I still apply if I dont have all the material ready by the deadline Unfortunately not. We need a complete application, including letters of recommendation AND OFFICIAL SCORE REPORTS including TOEFL and IELTS when needed see 2 above before we can make admission decisions. Note that we dont require the GRE, and we dont recommend that you take it just for admission to our program. Therefore, please give your letter writers enough time to write and mail your letters of support. 4 When can I begin study Only in September, unless there are truly exceptional circumstances. 5 I cant afford the application fee. Can you waive it Application Fee Waiver Guidelines 1 The Application Fee is automatically waived for Active duty U.S. Military personnel, as well as U.S. Military veterans. Please be sure to list your status within the application. Domestic or international applicants who are membersalumni of certain programs listed within the application. 2 If you would like to request an Application Fee Waiver based on high-financial need Please complete the Application Fee Waiver Form found within the online application. The Application Fee Waiver Form is located under the section entitled Financial Information . You will see a link that says Application Fee Waiver Form. Please note this form is only accessible once you have started an application and selected your program of study. The Application Fee Waiver Form must be submitted no later than three days before the application deadline. Applicants will be notified by email regarding the outcome of their request and should not submit their application until receiving notification about their waiver . In addition, you will need to upload documentation that substantiates your financial hardship. 6 Do you have financial aid available for Masters students We offer a small number of merit-based, full-tuition scholarships that are used to support Brown CS diversity and inclusion goals. If youre admitted, youll be automatically considered for them. To find out how to apply to external sources for support, you can consult the Graduate Schools web page . Also note that there are very few, if any, funding sources available for international students. While we do assist all Brown CS Masters students in finding paid internships for the summers theyre here, international students must provide certified proof of financial support including travel to and from America adequate to meet annual expenses. Please see here for details. 7 Are scans of any of the application materials acceptable We encourage scanned copies as part of the initial application original documents are required if youre admitted and decide to enroll here. Please send all documents to the Graduate School Masters Study Enrollment Team Brown University 225 Dyer Street Box T Providence RI 02912 Sending materials to the Brown Graduate School is fine, but there will be additional delays in processing these materials. 8 Do you admit students only from certain elite universities and reject ones not from there We admit only outstanding students to our program. The institution you attended is just one of many indicators we consider. In particular, we recognize that excellent students graduate from all kinds of institutions its what they do there and after graduation that makes their applications stand out. Thus we do sometimes reject students from leading American and international institutions and accept students who did not attend such universities. 9 What kind of applicant are you looking for What kinds of courses should I take before I apply to strengthen my application There are exceptions, but typically we look for outstanding students who already have an undergraduate CS degree or the equivalent and are ready to take our Masters-level courses. Please see 2 above, where work experience, research experience, and other factors are discussed in detail. While we sometimes discount weaknesses in some areas if there are strengths in others, wed like to see most of the following courses An introductory Programming course An introductory Algorithms and Data Structures course A Computer Systems or a Software Engineering course preferably both A course on Discrete Mathematics and basic Probability A Linear Algebra course In addition, a student should have taken a more advanced course normally offered to juniors and seniors in at least one area of CS. 10 Ive earned my Bachelors degree from a three-year degree program. Can I still apply for a Masters degree The three-year programs we know about, specifically those in India, are acceptable, and students from those programs can apply. If youre coming from a program with which we are not familiar, we may need information from you before acting on your application. 11 Do I have to take the GRE General exam Brown CS doesnt require the General exam for Masters applicants. General test scores give us an additional objective form of evaluation, but on the other hand, some students have extremely strong records, and this strength is evident from their application. For such students, the General test score doesnt provide much additional information. In the end, its your call. 12 Do I have to take the GRE Subject exam No. Brown CS doesnt consider Subject exam results. 13 Where do I send my transcripts, score reports, and other materials If youre admitted and prompted to do so, please send supplemental materials to Masters Study Enrollment Team Brown University 225 Dyer Street Box T Providence RI 02912 Sending materials to the Brown Graduate School is fine, but there will be additional delays in processing these materials 14 Should I use the institution code, the department code, or both for the GRE and TOEFL The GRE institution code is 3094 and the GRE department code is 0402. For the TOEFL, you should use the school code, which is 3094, and the department code, 78. Note that the answers to these questions and many like them may be found here . 15 Who will be the primary readers of my application Your application in particular, your statement will be read primarily by Brown CS faculty. 16 Who decides whom to admit Officially, admissions are generated by the Graduate School of Brown University. In practice, Brown CS specifically, a group of faculty members evaluates your application and makes recommendations to the Graduate School, which typically follows our recommendations. 17 If admitted, will I have a faculty advisor How will they be chosen After admission, you will be assigned a faculty advisor based on your stated interests. If necessary, you can contact the Director of Graduate Studies for the Masters program cs-masters-infobrown.edu to request a new faculty advisor. 18 As a Masters student, what opportunities will I have to do research How do I start a research project We have a whole page devoted to this subject please see here . 19 What if I have other questions Please email us .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Frequently Asked Questions About Our Master's Program"], "word_count": 1828, "token_count_estimate": 2170}}, "https://cs.brown.edu/degrees/masters/applications/": {"text_content": "Applying To Our Masters Program We began accepting applications for Fall, 2024 entry on September 1, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Masters degree. Thanks for your interest in our Masters program If you havent already, please acquaint yourself with the program to make sure its a good fit for you. Note that doctoral students can automatically earn a Masters degree on the way to completing a PhD, but Masters students dont automatically transition to the PhD track. read our FAQ . It answers many of the questions you probably have. Application Requirements We expect strong results from applicants in all of the following items. While we dont require GRE scores, if you do supply them, we expect strong results here as well. Record of grades or other academic performance current undergraduates, send us your Fall semester grades Letters of reference you might suggest to your letter writers that they look at this site TOEFL or IELTS for applicants whose native language is not English and do not meet any of the exemption criteria Again, please read our FAQ . Applying We will begin accepting applications for Fall, 2023 entry on September 15, and the deadline is January 15. Please note that Spring entry is only available for Brown undergraduates who are doing a fifth-year Masters degree. Once the application system has closed, it wont reopen until September for new applications. Youll be notified by the School of Professional Studies if youre admitted. Please go here to apply. You can get additional information from our FAQ and from the School of Professional Studies site. We strongly urge you to provide unofficial scanned copies of your transcripts as part of the electronic application. Youll be prompted to mail an official copy of your transcript if youre accepted to the program. Graduate applications are handled by a combination of Brown CS and the School of Professional Studies. First, your application is formally processed by the School of Professional Studies. Its content is then read by members of Brown CS, who then forward their recommendations to the School of Professional Studies. Finally, the School of Professional Studies formally admits you to the program. Therefore, you may receive correspondence from either Brown CS or the School of Professional Studies. Financial Aid We will be awarding a small number of full-tuition scholarships to applicants who come from disadvantaged socioeconomic backgrounds, but who have accomplishments showing that they can overcome the negative effects of their backgrounds. If you are interested in such a scholarship, we will ask you to explain, as part of the application, the nature of your socioeconomic disadvantages and the accomplishments youve achieved in spite of it. Scholarships are awarded regardless of an applicants race, color, national origin, or gender.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Applying To Our Master's Program"], "word_count": 473, "token_count_estimate": 544}}, "https://cs.brown.edu/degrees/misc/jobs/assignments/": {"text_content": "Graduate Student Jobs and Assignments As of Fall 2023 Fac-Grad Liaisons FGL Thao Nguyen Aaron Traylor Fac-Grad-Masters Liaison FGML Muskaan Patel Sheridan Center Liaison Talie Massachi GSC Reps Catherine Chen Aidan LaBella Mentorship Program Czars Nihal Nayak Yanyan Ren Mental Health Well-Being Czar Position available Facilities Czar Position available Faculty Search Czars 3 Recommended Tuluhan Akbulut Oguzhan Colkesen Ruochen Zhang Recruitment Czars 3 Recommended Lakshita Dodeja Orientation Czars 3 Recommended Catherine Chen Anita De Mello Koch Sports Czar Sam Lobel PhD Lounge Czar William Rudman Social Czars Position Available GCB Czar Skye Thompson TGIF Czars Benjamin Spiegel Sam Thomas Tea Czars Elijah Rivera REST Czars Position available Info Khan Position available Rubber Chicken Khan Aditya Ganeshan Fridge Demon Anonymous Ergo Merc David Tao High Performance Computing Merc Sam Lobel Video Merc Position Available If you are interested in any of these positions, please contact the Fac-Grad Liaisons listed at the top.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Graduate Student Jobs and Assignments"], "word_count": 151, "token_count_estimate": 241}}, "https://cs.brown.edu/degrees/masters/reqs/": {"text_content": "Masters Program Requirements The requirements for a Masters of Science ScM degree in Computer Science consist of a basic component and an advanced component. All courses must be at the 1000-level or higher. Students must have a B average over all courses used to satisfy the requirements. All courses must be taken for a grade, and all grades must be C or better Ss may not be used. The courses in your program must be approved by the Director of Graduate Studies Masters as well as by your advisor. You can find the Masters contract here . Basic Component The basic component consists of six courses. None of these courses may be reading and research courses in particular, they cant be CSCI 2980. The six courses are chosen as follows Two must be CS courses that form a pathway see the explanation of pathways here . One must be a CS course in an area thats not listed in the chosen pathway it must not be a core course, must not be a grad course, and must not be a related course of the pathway. The three additional courses must be in CS or related areas, and must be approved by your advisor or the director of graduate studies Masters. Getting this approval will require you to show that the courses are relevant to your CS interests. In general, the more non-CS courses you wish to take, the stronger your justification must be. Advanced Component The advanced component requires you to complete one of the following four 2-course options. No Reading and Research courses may be used in options 3 and 4. An advanced course, as used below, is a 2000-level CS course. Internships, as used below, must be approved by the students advisor and are paid work in the area of the students Masters studies and are explained further below. The four options are Complete a research project as two instances of CSCI 2980 supervised and approved by your research advisor. Complete a research project as two instances of CSCI 2980 supervised and approved by your research advisor, and complete an internship. Complete two advanced courses not including CSCI 2980. Complete two advanced courses not including CSCI 2980 and complete an internship. Note that options 2 and 4 are known as the professional track. Consult the Masters Program Handbook for details. Rationale Students entering the Masters program typically have one of two goals they intend to pursue research careers in computer science and are preparing themselves to enter PhD programs, or they intend to become professional computer scientists and pursue careers in industry. In both cases, students should take collections of courses that not only give them strength in particular areas of computer science, but also include complementary areas that familiarize them with other ways of thinking about the field. For example, a student whose interests are in the practical aspects of designing computer systems should certainly take courses in this area, but should also be exposed to the mindset of theoretical computer science. In a rapidly changing discipline, there is much cross-fertilization among areas and students should have some experience in doing advanced work in areas not directly related to their own. Students whose goals are research careers should become involved as quickly as possible with research groups as part of their Masters studies, and demonstrate and learn about research by participating in it. The resulting research reports will serve to establish their suitability for entering PhD programs. Students whose goals are to be professional computer scientists should have some professional experience as part of their preparation. A certain amount of basic coursework is required before a student can qualify for a pedagogically useful internship. Students with limited experience in computer science should take a few advanced computer science courses before embarking on an internship. Other students, particularly those whose undergraduate degrees were at Brown, will likely have had internship experiences while undergraduates. Internships provide insights for subsequent courses and project work at Brown. Students without such experiences are at a disadvantage with respect to their peers. Thus we strongly encourage students who have not had such experience to choose one of options 2 or 4, for which internships are required. Note that these internships are not courses and the work is not evaluated as it would be for a course. Students advisors will assist them in choosing an internship, but it is up to students themselves to ensure that they get as much benefit as possible from their experiences. They must be able to take advantage of these experiences while completing their Masters projects we expect as high-quality work from them as we do from students who entered the program with prior internship experiences.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Master's Program Requirements", "Basic Component", "Advanced Component", "Rationale"], "word_count": 787, "token_count_estimate": 894}}, "https://cs.brown.edu/degrees/misc/jobs/jobs/": {"text_content": "Graduate Student Job Descriptions Faculty-Graduate Liaison FGL The FGL is a senior PhD candidate tasked with handling most faculty-grad interactions and concerns. This is the person to talk to if you hit a difficult moment in your grad career. Responsibilities include monitoring czar, khan, and merc activity, allocating office space, and controlling access to the grad nest egg. More details on the role can be found at the Fac-Grad Role Page . Faculty-Graduate-Masters Liaison FGML The FGML is a second-year Masters student tasked with working with the FGL to ensure faculty-grad interactions and concerns attend to the needs of the Masters students. This is the person to talk to if you hit a difficult moment in your grad career. Responsibilities include working closely with the FGL, planning and coordinating events, and checking in with Masters students to ensure things are going smoothly. Sheridan Center Liaison Coordinates announcements and solicits participation in Browns teaching-focused trainings through the Sheridan Center. The Sheridan Center Liaison helps support the excellence in teaching expected of teaching assistants and future faculty members at Brown. Graduate Student Council GSC Representatives Brown CS is currently entitled to 4 representatives in the Graduate Student Council. At least one of these representatives should be a Masters student. The Council itself is a collection of grad representatives from all departments. See the GSC page for more details. The CS Reps must attend the GSC meetings and represent Brown CS in graduate school affairs. In addition, they are responsible for filing the GSC rebate form, which funds the nest egg. Mentorship Program Czars These students help coordinate the mentorship program for new PhD students this involves recruiting new mentors each year from the pool of post-candidacy mentors, matching mentors to new PhD student mentees, and organizing any mentor-program events each term. Mental Health Well-Being Czar The Mental Health Czar informs graduate students about Counseling and Psychological Services CAPS at Brown, such as relevant mental-health events on campus. The Czar is also responsible to decrease the stigma surrounding using CAPS services, and promote awareness of mental well-being. Facilities Czar The Facilities Czar represents the graduate students on the Brown CS facilities committee. This committee is responsible for allocating money for and determining the specifications of new machines, monitors, and so on. Faculty Search Czars These students assist the faculty in recruiting and hiring new faculty. There is a czar for each area of the faculty search. Responsibilities include assisting in the creation of the short list of candidates, disseminating information about job talks to the graduate students, attending job talks in their area, organizing the graduate student-candidate interview, and presenting the graduate student opinion to the faculty search committee. Recruitment Czars The main responsibility of the Recruitment Czars is to organize the graduate-student recruitment weekends. This includes setting up facultystudent talks, organizing lunches and tours, and arranging housing. Students visiting at other times are also made welcome by the Recruitment Czars. Orientation Czars The complement to recruiting weekend is orientation week, when new students are welcomed to the department. The Orientation Czars set the weeks schedule and arrange for all the appropriate talks to take place. In addition, they arrange for the yearly photo collage to be made. Prior czars have accumulated their wisdom into the Orientation Czar Guide . Sports Czar The Sports Czar SC informs graduate students about ongoing physical and recreational activities in the campus. The SC can also sign up intramural teams and carry out tournament registration and reimbursement processes. It is the SCs responsibility to attend the captains meetings and scheduled sessions. The SC is the default administrator of group-specific email lists such as soccercs. Finally, the SC should initiate Brown CS tournaments and arrange training sessions time, weather, place, equipment, and so on. PhD Lounge Czar The PhD Lounge Czar is responsible for keeping track of facilities in the PhD lounge CIT 404. Social Czars The Social Czars are responsible for keeping a sense of community in the department by organizing at least one social event a month. They are responsible for organizing the Halloween party, and helping with the department holiday party. Grad Center Bar GCB Czar The GCB Czar organizes the weekly Brown CS GCB hangout. TGIF Czars The TGIF Czars there are usually two are responsible for providing food for the weekly TGIF social hour with funds provided by Brown CS. To learn from the accumulated wisdom of prior czars, see the TGIF Czarship Guide . Tea Czars Another two-person team, the Tea Czars organize the weekly Brown CS tea and cookies. REST Czars The REST Research Exchange Seminars with Tea Czars host a weekly talk from a grad student designed to disseminate information about ongoing research in Brown CS and foster collaboration between disciplines. Info Khan The Info Khan is responsible for maintaining the graduate student web structure. Rubber Chicken Khan The primary responsibility of the Rubber Chicken Khan is to maintain a coop of rubber chickens. A chicken is traditionally awarded to that is, thrown at a PhD candidate who has successfully defended their thesis, following the faculty handshakes and preceding the champagne. The khan is also responsible for assigning the chicken thrower for each thesis defense. The chicken thrower is usually the closest friend of the chicken recipient in Brown CS. Fridge Demon The Fridge Demon is an anonymous position, responsible for the cleanliness of the departments fridges located in CIT 302, 412, 532. Once a month, they must examine the refrigerators and discard any items that need it. DI Administrative Merc The DI Merc assists diversity and inclusion efforts in the graduate student recruitment process. This job involves administrative tasks spreadsheet management, outreach, as well as coordination with the chair of the department and the diversity chair. Ergo Merc The Ergo Merc maintains the departmental ergonomic website as well as a pool of ergonomic keyboards and voice recognition software. New users are taken care of workspace evaluations and injured parties are led through the department and university ropes. In addition, this merc coordinates the Brown RSI-awareness campaign and collects statistics on RSI at Brown CS for reporting to the Facilities Committee. For more information, see the Ergo Merc Details . High Performance Computing HPC Merc The HPC Merc is primarily responsible for fielding questions and providing informationguidance related to the use of the CS departments high-performance computing resources e.g. the in-house Grid or the departments GPU condo on the CCVs Oscar cluster. The position additionally entails communicating and working with the department technical staff regarding potential new features and changes to the existing HPC infrastructure, as well as interfacing with other university computing groups such as CCV for coordinating joint projects. The HPC Merc will also periodically survey the departments current HPC users about their usage patterns and solicit feedback on the state of the HPC infrastructure, and then summarize and present that information to the CS technical staff. Ideally the HPC Merc is someone with knowledge of or interest in learning about modern high-performance computing infrastructure and related technologies. Video Merc The Video Merc collects videos from distinguished lectures, symposiums and any other important talks the department hosts. They will then be in charge of posting them to Vimeo or other flash-based site account. This person will also take pictures at Brown CS events receptions, the Halloween party, and so on and organize them in a photo gallery. This position will require coordination with the Info Khan to link it from the main site. Interview Room Khan archived The Interview Room Khan reserves CIT 522 for students and provides the key so they can access it. Knowledge Khan archived The Knowledge Khan is responsible for the dissemination of exciting Brown CS research to all members of the department. The primary method used is to organize the yearly departmental retreat. Comprehensives Czar archived The job of the Comprehensive Exam Czar, who must be a PhD candidate, is to assist the faculty member in charge of the comprehensive exams to ensure that the exams run smoothly. During the programming exam, the comps czar monitors the process and works with the responsible faculty members to solve any problems that might occur. Calendar Czar archived The Calendar Czar works with AStaff, TStaff, faculty, and grads to keep track of events of interest to the Brown CS community and minimize scheduling conflicts. They collect information on classes, reading groups, lectures, lunches, lab meetings and the like and maintain an up-to-date calendar.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:25+00:00", "headings": ["Information for:", "Graduate Student Job Descriptions"], "word_count": 1407, "token_count_estimate": 1709}}, "https://cs.brown.edu/degrees/why-brown/interdisciplinary/": {"text_content": "Our Interdisciplinary Options Late nights in the graphics lab allowed me to see how CS could connect with other disciplines and Browns honors program allowed me to experiment with my first truly interdisciplinary research project. All of this fed into my approach to CS, which is so beyond interdisciplinary at this point that its hard to even give me a disciplinary label. danah boyd, Microsoft Principal Researcher and Data and Society Founder Brown CS is a diverse community engaged in all aspects of research, teaching, and mentoring. Due to the importance of computational thinking in many different endeavors, we collaborate with almost every department at Brown. Undergraduate Interdisciplinary Options Our joint majors reflect our collaborative orientation, with opportunities to combine CS with four other disciplines Applied Math-CS Computational Biology Math-CS Computer Science-Economics AB Computer Science-Economics ScB We also have strong undergraduate research groups in graphics, neuroscience, and robotics, as well as a long record of involving undergraduates in projects that span disciplinary boundaries. Graduate Interdisciplinary Options Our graduate students often have advisors in two departments, and they have a history of interdisciplinary work, from devising algorithms to improve characterization of genomic mutations in tumors to improving governmental response to natural disasters. Large-scale partnerships like the Brain Science Program made up of more than 70 faculty from ten departments and the Humanity Centered Robotics Initiative faculty, students, and affiliates using robotics to tackle current world problems make it easy for students to customize their education to match their diverse interests.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Our Interdisciplinary Options", "Undergraduate Interdisciplinary Options", "Graduate Interdisciplinary Options"], "word_count": 249, "token_count_estimate": 288}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/": {"text_content": "Concentrating In Computer Science PLEASE NOTE If you started at Brown in or before Fall 2017, youre able to use the old requirements, but we strongly recommend that you use the current requirements, which have been redesigned to serve you better. At this time, requirements for the joint-programs have not changed. The Department of Computer Science offers several A.B. and Sc.B. concentrations a.k.a. majors for undergraduates. The undergraduate program is designed to combine educational breadth in the areas of software, hardware, and theoretical computer science with a deeper understanding of specialized areas such as software system design, programming languages, computer architecture, artificial intelligence, the analysis of algorithms, and the theory of computation. Becoming A CS Concentrator To become a CS concentrator you must fill out the electronic application on ASK . At the time of declaration, you must also complete a program plan or contract indicating which courses you currently plan to take to complete the concentration these can be changed later. For those declaring a pure CS concentration or a CSEconomics joint concentration, fill out the program plan in ASK instructions and FAQ . For those declaring other joint concentrations or using the old concentration requirements, use the paper forms available further down on this page. Make an appointment with your concentration advisor to go over your choices and discuss the programs. All concentrators are required to meet with their concentration advisors at least once a year. This is normally done during a designated four-week period in the middle of the fall semester the dates will be announced several weeks beforehand. Students who dont meet with their advisors during this period are subject to having their computer accounts frozen. If you have any questions and dont already have a CS advisor, contact Tom Doeppner or Kathi Fisler . Concentration Overview CS concentrators must complete an introductory sequence, take intermediate courses that provide a foundation for the upper-level courses, and complete several upper-level courses. Our requirements are built on a collection of pathways, each representing a well defined area within computer science. Concentrators interested in particular areas might choose the courses included in particular pathways. Conversely, concentrators who are unsure of their areas of interest but who have particularly enjoyed certain courses might choose pathways that include these courses. Each pathway specifies a number of core courses, a collection of related courses including 2000-level grad courses, and up to three mandatory intermediate courses. Completing a pathway entails taking at least one core course, another core or related course, and the mandatory intermediate courses. A.B. students must complete one pathway Sc.B. students must complete two pathways. Additional 1000-level or 2000-level courses are required as needed to get to a total of nine courses for the A.B. and fifteen courses for the Sc.B.. In addition, Sc.B. students must complete a capstone course. All CS and joint-CS concentrations, except for Computational Biology, have an optional Professional Track , which primarily supports international students working with CPT visa regulations. Concentration Requirements Please note that you may only use the 2018 requirements if you started at Brown in 2018 or earlier and the 2017 requirements if you started at Brown in 2017 or earlier. Concentration Requirements Current Concentration Requirements 2018 Concentration Requirements 2017 Concentration Contracts Please note that these are only for students using the 2017 Concentration Requirements. The following links are all Adobe Acrobat documents Computer Science A.B. old requirements only, otherwise use ASK Computer Science Sc.B. old requirements only, otherwise use ASK Math-CS Sc.B. Applied Math-CS Sc.B. Computational Biology-Sc.B. Choosing an Advisor Every concentrator will have a concentration advisor, who is normally someone from the list at httpscs.brown.eduwbrdegreesundergradwbrconcentrating-in-csadvisors . While its not mandatory that you do so, we suggest that if there is a particular faculty member who you would like to be your advisor, that you contact them and ask if they are willing most will most definitely be willing. If that person agrees, please email Prof. Doeppner twdbrown.edu to let him know, as he makes the assignments. If you arent sure who you would like to have as your advisor, feel free to leave that field blank in the ASK declaration and we will assign someone for you. Note that for the joint concentrations, if you would prefer an advisor in a particular department, you must request a particular person in that department. If theyre not available, well assign someone else in that department. Related Topics Advanced Placement Earning Honors and Awards Staying a Fifth Year and Combined Masters International Students Internship CPT Application FAQ for Students ASK FAQ for Advisors", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Concentrating In Computer Science", "Becoming A CS Concentrator", "Concentration Overview", "Concentration Requirements", "Concentration Contracts", "Choosing an Advisor", "Related Topics"], "word_count": 760, "token_count_estimate": 954}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements/": {"text_content": "Concentration Requirements 2018 Our requirements are built on a collection of pathways , each representing a well defined area within computer science. Concentrators interested in particular areas might choose the courses included in particular pathways. Conversely, concentrators who are unsure of their areas of interest but who have particularly enjoyed certain courses might choose pathways that include these courses. The total number of courses required for the two concentrations remains the same as they were with the old requirements. There are no changes to the calculus prereq or the intro courses. Intermediate courses are now grouped into three categories. The systems-oriented category remains unchanged, but weve expanded the math-oriented category into two math and fundamentals. The former includes linear algebra, probability and statistics, and multi-variable calculus the latter includes discrete math and theory of computation. AB students must take three courses from at least two of the categories ScB students must take five courses from all three of the categories -- this requirement subsumes the math requirement of the old concentration requirements. Each pathway specifies a number of core courses, a collection of related courses, and up to three mandatory intermediate courses. Completing a pathway entails taking at least one core course, another core or related course, and the mandatory intermediate courses. AB students must complete one pathway ScB students must complete two pathways. Additional 1000-level courses are required as needed to get to nine courses for the AB and fifteen courses for the ScB. The following links state the requirements for each concentration in detail New ScB Concentration Requirements New AB Concentration Requirements Declaring Your Concentration In ASK See our separate page of instructions on how to declare the concentration .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Concentration Requirements (2018)", "Declaring Your Concentration In ASK"], "word_count": 282, "token_count_estimate": 329}}, "https://cs.brown.edu/degrees/undergrad/": {"text_content": "Our Undergraduate Program Our undergrads have flown to Singapore to install software they designed for the Nobel Museum , built an SMS-based commodity exchange to help Ghanaian farmers , and more . They know what its like to hear a professor say, I feel like I can absolutely treat my undergraduate teaching assistant as a peer. This page is for prospective undergrads. Incoming and current students, go here or use the links in the blue bar above. Other schools are dealing with growing interest in CS by capping the number of students who can major in it. Instead of turning applicants away, were putting in place new programs to help first-generation and low-income students. Watch a video of CS majors answering your questions, look at our majors , or apply . Im inspired by the creative and innovative thinking ...faculty mentorship across departments, the strong alum network who work at startups and tech giants alike, design resources at RISD, the Providence tech community, and student organizations like HackBrown and the Entrepreneurship Program are all catalysts for student entrepreneurs. Athyuttam Atty Eleti Im concentrating in Math-CS. Its one of several joint majors that allow students to pursue in-depth study in both CS and another area as well as exploring how the subjects interact. Math-CS has given me a greater degree of flexibility in my course choices it has allowed me to both focus on more theoretical aspects of computer science and to increase my level of mathematical maturity. Eli Rosenthal Doing CS research has been one of the most rewarding aspects of my time at Brown . Its allowed me to make meaningful relationships with my professors and with grad students in the department, and has taught me how to work in a self-directed way on projects I get to define myself...professors are open to mentoring an undergrad, and doing research at Brown also opens up opportunities to work with other universities. Dana Metaxa-Kakavouli Being an undergraduate teaching assistant UTA has been an incredible opportunity for me to grow ...Through my involvement with the UTA program, I have gained incredible mentors professors, head TAs and wonderful friends fellow TAs on several different course staffs. I think the program truly reflects the culture of collaborative learning at the heart of a Brown CS education. Jaclyn Zhong Find out more student groups HackBrown , Department Undergraduate Group , Women in Computer Science , Mosaic , our majors Applied Math-CS, Computational Biology, CS, CS-Economics, and Math-CS, undergrad resources for concentrators and non-concentrators, undergrad research , the UTA program , and other undergrad jobs . We pioneered undergraduate participation in teaching and research before many universities even offered CS courses. Today, no other institution gives you the same opportunity to be part of their intellectual life, make multidisciplinary collaborations, and advance the field. I never want to stop being a Brown Computer Science TA. Mike Frederickson, Technical Director, Pixar My advisor has been a constant anchor, a mentor, a friend...Late nights in the graphics lab allowed me to see how CS could connect with other disciplines and Browns honors program allowed me to experiment with my first truly interdisciplinary research project. danah boyd, Microsoft Principal Researcher and Data and Society Founder", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Our Undergraduate Program"], "word_count": 536, "token_count_estimate": 644}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements-2020/capstone/": {"text_content": "Capstone Courses For The ScB The following courses may be used as capstone courses, but please check with the instructor since what you do for a capstone project in the course might be different from what you would do if you are not using the course as a capstone course. CSCI 1230 with CSCI 1234 CSCI 1260 CSCI 1290 CSCI 1300 CSCI 1320 CSCI 1370 case-by-case basis contact the instructor CSCI 1380 CSCI 1410 CSCI 1420 CSCI 1430 CSCI 1440 CSCI 1470 CSCI 1600 CSCI 1660 with CSCI 1620 CSCI 1670 with CSCI 1690 CSCI 1680 CSCI 1710 formerly CSCI 1950-Y CSCI 1730 CSCI 1760 CSCI 1950-U CSCI 1951-A CSCI 1951-C CSCI 1951-I may be used as part of any pathway CSCI 1951-U CSCI 1952-B CSCI 1970 if topic is in the general area of one of your pathways CSCI 2240 CSCI 2370 case-by-case basis contact the instructor CSCI 2390 CSCI 2420 CSCI 2500-B CSCI 2510 CSCI 2950-T CSCI 2950-V CSCI 2951-I CSCI 2952-K CSCI 2952-N Students pursuing an ScB in a joint degree program, such as MathCS, may do a capstone project within the other department. Please contact elenaquinonezbrown.edu for details. Other courses might be acceptable as capstones please contact the Director of Undergraduate Studies thomasdoeppnerjrbrown.edu for further information. Courses that do NOT provide capstone options CSCI 1460 To register for your capstone course, complete the Google Form that you seniors received in email from Elena Quinonez elenaquinonezbrown.edu . Students are also required to submit a title and abstract by the end of their last undergraduate semester to be posted on the CS website.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Capstone Courses For The ScB"], "word_count": 265, "token_count_estimate": 453}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements/new-concentration-requirements-faq-advisors/": {"text_content": "Concentration Requirements FAQ For Advisors How does the new ASK tool affect existing declarations done in the old requirements It doesnt. Declarations made prior to Jan 19, 2018 are under the old requirements and are not supported by the ASK-based contracts. ASK-based contracts are only available for declarations in the new requirements. How does a current concentrator on the old requirements make changes to their concentration Students declared under the old requirements should be able to continue to use ASK and paper contracts as they did before. ASK internally tracks which requirements were in effect when a declaration was created. What am I looking for when I review a program plan You are looking for the hierarchical boxes to have either green icons or open-red circles with warning triangles Green icons indicate that the requirement is satisfied by the selected courses the shape differs depending on whether the course is completed, in progress, or intended. Open red circles with warning triangles indicate that selected courses need to be checked manually --- they are either not identical to the requirement as formally stated or the requirement allows one of many courses. Intermediate courses in pathways may have green icons and warning triangles. Usually, this would indicate that a student is substituting intermediate courses from the old requirements into the new pathway requirements which is fine while we are in transition. Warning triangles do not propagate upwards through the hierarchy, so if you see a requirement that lacks a green icon, check whether there is a warning triangle on a course within that requirement. If there is no warning triangle, then the student has left some part of the requirement unpopulated. What are we doing for students whose intermediate courses were chosen for the old requirements, and dont satisfy the pathways Have the student declare with the pathway that meets their 1000-level courses. They should drag some intermediate courses into the slots for the pathway even if they dont match the required ones. As long as they satisfy the overall intermediate courses for the new requirements, we will accept the substitution. You can then approve the declaration to formally accept the substitution within ASK. Can I hide the pathway and other requirement options that arent used in a declaration Yes, this is called sifting mode. You can turn it on from the main declaration page. Part of the requirements seem to be missing. For example, a student is doing a pathway but there is no area for intermediate courses. You probably have sifting mode turned on, and the student didnt populate the intermediate courses, so those areas arent showing. Given that intermediate courses are checked in two parts of our requirements, but can only be counted once towards the course total, intermediate courses in pathways show checked by default to students. This will lead some students to overlook this part of the requirement when they first declare. How does an advisor approve a course to get rid of the warning triangle When you approve the declaration, all courses with warning triangles will be marked as approved and the triangles will disappear. How do I override ASK when a student has a unique situation and permission to substitute a non-standard course Have the student populate the requirement with the non-standard course and approve the declaration. Why do some areas say 0-2 credits Our requirements need to count intermediate courses in two places the intermediate courses requirements, and the pathway requirements. The 0-n configurations in the pathways are what let us record the same course two places, while only counting it once in the intermediate courses section. The same issue applies to the ScB capstone course. What do the icons mean Roughly Open red circles mark requirements with missing components Open green circles mark courses in which the student is enrolled but hasnt completed Closed red circles with X inside mark courses for which the student did not get credit Closed red circles with dashes inside mark courses that the student has not taken or has dropped", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Concentration Requirements FAQ For Advisors"], "word_count": 673, "token_count_estimate": 754}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/concentration-requirements-2020/declaring-the-concentration/": {"text_content": "Declaring The Concentration Declarations are made through ASK. The following steps describe the process. There is an FAQ at the bottom of the page. Advisors, your FAQ is here . Understanding The Requirements Before you declare, look at the course requirements. Useful documents include The official requirements in the Brown bulletinFocal Point The requirements pages for CS same info as the bulletin, but formatted differently The CS Concentration Handbook , which lists allowable substitutions, courses from other departments that count towards a CS concentration and other policies for concentrators. Steps To Declaring Here is a video demo of how to declare in ASK . What follows is a textual summary. Log into ASK, go to the Declarations menu, select My Declarations and follow the instructions to create a declaration. Note that the Professional Track option in the drop-downs at the top is intended for international students who wish to do internships under CPT. The track offers no benefits to other students. Once you create the declaration, you need to indicate the courses that you will use to satisfy the concentration requirements the Course Plan, and map those courses onto the requirements the Program Plan. About halfway down the main page for your declared concentration, you will see two buttons, one labeled Course Plan and the other Program Plan, with Edit to the right. Click on Edit. This will put you in a screen that looks like the following partially-completed plan In the left column, add courses that you want to apply to your concentration you can also do this through the Course Plan button on the previous page . Once a course appears in the left column, you can drag it into the boxes for specific concentration requirements in the right column. As you drag in courses, the icons within the requirements area will change to green circles or checkmarks indicating that you have satisfied part of the requirement. Ultimately, you want to see green icons checkmarks or circles for each of the high-level requirements you must fill in the intermediate courses in pathways, even though they appear checked by default . You can find a summary of the icons on the previous declaration overview page to the right of the CourseProgram Plan buttons. In the screenshot, the student has dragged CS15 into a requirement, but not CS32 which explains the different colors in the left column In the screenshot, the student has partly satisfied the introductory courses requirement in the right column CS16 is missing. If the student dragged in CS16, the introductory courses would be marked with a green icon the shape depends on whether the student has finished taking or plans to take the selected courses Check that your declaration is complete. This means Making sure you have populated each requirement area so you have green icons on all of them. If you arent sure which courses or pathways you want, put in something tentative for now. Making sure you have populated the intermediate course areas of the pathways . The pathways will have green icons even without this since the intermediate courses are also listed elsewhere. You can drag the intermediate courses into the pathways even though they are already used in the intermediate course area. Once you believe your declaration is complete, submit it for approval using the button at the bottom of the page. Shortly after submitting, the Director of Undergraduate Studies will match you up with a concentration advisor you may, but do not need to, request a specific advisor on the form before submitting. Your assigned advisor will review your plan with you prior to approving it during which you can discuss and refine tentative selections. Approval does not mean that you are now required to complete the listed courses . You may change the courses and pathways used in your declaration at any time until part way into your last semester. Approval means if you finished the listed courses, you would satisfy the concentration requirements. Students change their minds and revise their declarations all the time. The point of approving something now is to make sure that you understand the concentration requirements and have a tentative plan that you have discussed with an advisor. FAQ About Declaring The answers to many of these pertain to declaring pure CS, as opposed to a joint concentrations. If you have questions that are not answered in this FAQ, contact Professor Fisler. Do I have to identify an advisor before declaring You may identify your own advisor if you wish, or you can let us assign you an advisor. If you dont list a preferred advisor, we will match you up with someone appropriate based on a combination of your interests and the existing advising loads of the faculty. Even if you list a preferred advisor, we may need to assign you to someone else based on how many advisees your requested advisor is able to take on at the time you declare. Professor X agreed to be my advisor, but they arent listed Email Tom as soon as you declare, and we can set that up. If you have an email confirming that your advisor has agreed, forward it as part of your email to Tom. The intermediate courses in the pathways are checked off automatically. So do I need to fill those in Yes. Intermediate courses appear checked off in pathways by default because these courses get formally checked in the intermediate courses section. But your advisor still needs to see the intermediate pathway courses in place in order to review your declaration. Can I drag a course into more than one requirement in the program plan Yes, you will need to do this with those intermediate courses that are used to satisfy pathway requirements. I chose my intermediate courses based on the old requirements, but they dont satisfy my intended pathways under the new requirements. What should I do Declare with pathways that fit your 1000-level courses. If you dont have intermediate courses that match the pathway requirements, drag in the most appropriate intermediate course that you can if you have to use a systems course instead of a math course, or vice versa, thats fine. The substituted course will be flagged with a warning triangle within the program plan. Your advisor can resolve this warning when reviewing and approving your declaration. This is the easiest way to handle most cases of students who land between the old and new requirements. I planned my courses around the old requirements, and I dont see how to fit them into the new requirements. What should I do Students who were enrolled at Brown prior to January 2018 may still graduate under the old requirements. If you feel you need to graduate under the old requirements, populate your course plan, but not the program plan. Then contact Tom or Kathi, who will help move your declaration over to the old requirements. Ive already taken 22, which doesnt seem to fit many pathways. What do I do now You can use one extra intermediate course in place of a 1000-level CS course. Theres a course in another dept that I want to use as a CS 1000-level course. What do I do Check the concentration handbook to see whether we have already made a decision on that course. If the course isnt listed as either approved or rejected, email Tom or Kathi with a link to the syllabus so we can review it. I dragged a course into my program plan but the icon for that section didnt turn green. What happened There are several possibilities 1 Perhaps you put the course in the wrong box. 2 You are substituting a course for the one that is formally in the requirements such as using Math 100 for the Calc Prerequisite. Your advisor will have to check these manually. 3 There are a couple of courses for which the name of the course is slightly different across the two databases used to populate ASK information. The green icons check both course number and title, so these courses dont appear satisfied. Your advisor will inspect these cases manually. Im trying to submit my declaration, and am getting an error that my intermediate courses are not satisfied You have to drag your intermediate courses into two places the general intermediate course requirements, and the intermediate requirements for the individual pathways. If you are getting this error, you probably only populated the intermediate courses in one place or you missed a course when completing one of the two kinds of requirements. The intermediate courses in the pathways will get a green checkmark automatically, even if you dont populate them this is an artifact of having to record them in two places. You still need to drag them in, despite the checkmark. Why do some areas say 0-2 credits Our requirements need to count intermediate courses in two places the intermediate courses requirements, and the pathway requirements. The 0-n configurations in the pathways are what let us record the same course two places, while only counting it once in the intermediate courses section towards your total credits. The same issue applies to the ScB capstone course. I removed an intermediate course from a pathway, and it disappeared from my overall set of intermediate courses as well. What happened The ASK development team is aware of this problem. At the moment, this is how the system behaves, however. What is sifting mode Can I edit my program plan in that mode Sifting mode hides all requirement areas that are not being used in your current declaration. This helps hide all the pathways that you are NOT completing, for example. Unfortunately, a you cant change the sifting mode while you are in Program-Plan edit mode, and b if sifting mode is on, you cant add courses to requirements that you werent already using in other words, sift is fine for reading but interacts poorly with writing. The ASK development team acknowledges that there are issues here that they need to fix. Im considering study abroad. How do I handle that in my declaration AB students may transfer up to two study-abroad courses to the concentration ScB students may transfer up to three. Actual transfers get approved by Tom as Director of Undergraduate Studies. When you fill out your declaration, take your best guess at courses you will take at Brown or transfer from elsewhere you can always update your courses as your study abroad plans take shape. You can add a comment to your declaration about your study-abroad interests. We strongly urge you to review planned course transfers with your advisor andor the Director of Undergraduate Studies before you leave, so that there are no surprises when you seek concentration credit upon you return. I have a question that isnt covered here or in the concentration handbook... Email Tom or Kathi with your question.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Declaring The Concentration", "FAQ About Declaring"], "word_count": 1821, "token_count_estimate": 2050}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/honors/": {"text_content": "Earning Honors Brown awards two kinds of honors. The university awards Magna cum laude based on grades. The Computer Science Department awards Honors in Computer Science. The CS Departments requirements for graduating with honors are as follows Honors candidates must have earned As or S-with-distinction in 23 of the courses used towards the concentration, excluding introductory-sequence courses CS courses numbered below 0200 and the calculus prerequisite unless that course is also used as an intermediate math course in CS requirements. Note that the grade requirement includes courses taken in the final year. Thus, for example, if a students grades drop below this bar in the last year, that student will not graduate with honors. Candidates must have completed 23 of their concentration courses by the start of their last two semesters. Candidates must choose an advisor and submit a 2-to-3 page proposal, approved by the advisor who must be a CS faculty member, to the director of undergraduate studies before the last day to register for classes not the end of shopping period, but two weeks after that in their next-to-last semesters. For May 2024 graduates, that deadline is Oct 3, 2023. The proposal should describe the research question that the student will be working on, how the project fits in either to existing results or larger projects either within the same lab or the research community in general, and what the student hopes the research will achieve could be anything from a new technique, a theorem, a prototype implementation of a new research idea, experimental evidence of something, etc -- your advisor will know whats appropriate for your area No particular format is required for the proposal. It should list the preliminary project title, your name, and your advisors name. Most come in as LaTeX or Google docs saved as PDF. A 3-page progress report must be submitted to the director of undergraduate studies by the end of the first month of the final semester. Also at this time, the student must identify a reader, who should be either a CS faculty member or a faculty member in some other Brown department who has expertise thats relevant to the thesis topic. The progress report restates the research question which may have changed or been refined -- thats fine, just explain why, describes what the student has accomplished to date, and revises the expected outcomes accordingly. No particular format is required. A final draft of the thesis must be submitted to the students committee and the director of undergraduate studies by April 18 for students completing their degrees in May and by December 1 for those completing their degrees in December. Students must submit to a public defense of their theses to be attended by their committees and at least two other CS faculty members. Whether a students thesis is deemed worthy of honors is decided by a combination of the advisor, reader, and faculty present at this defense. Honors candidates should register for CSCI 1970 for both semesters they are working on the thesis. In order to see 1970 on CAB, you have to enable the checkbox to include independent study and research courses. You should then be able to find your advisors section to request the registration override. Any deviation from these rules must be approved by the head of the CS honors program one of the Directors of Undergraduate studies, in consultation with the students advisor. Currently, Professor Kathi Fisler serves as head of the CS honors program. Direct any questions or requests for approval to her. Students in joint concentrations must select one of the two participating departments through which to complete the honors requirements. The honors project must be done following the rules of the selected department, with the primary advisor from that department and the reader from the other joint-concentration department. In these cases, the reader must be identified at the time the student submits the initial proposal as per item 3 above. In the rare case that a student wishes to pursue CS honors working with a research advisor who is not in CS, the student must identify a nominal advisor in CS who will be the advisor of record from the registrars perspective. The nominal advisor would effectively serve as reader. All such cases must be approved by the head of the honors program for CS. By the end of shopping period each fall, we will email all seniors a link to a form to use to inform the department that you are pursuing honors that year. You should only be filling this out if you are in your 7th semester of study,", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Earning Honors"], "word_count": 771, "token_count_estimate": 887}}, "https://cs.brown.edu/degrees/undergrad/concentrating-in-cs/professional.track/": {"text_content": "Professional Track Summer internships and research experiences are nearly essential parts of a CS education, particularly if ones goal is to become a professional computer scientist. They not only give one a chance to gain experience as a practicing computer scientist, but they also provide insights for subsequent courses and project work at Brown. CS interns and undergraduate researchers do work that engages them as computer scientists and have real responsibilities. They learn a lot about the practice of computer science and are better able to make career choices. Students without them are at a disadvantage with respect to their peers when they graduate. If you are an international student with an F-1 visa, you will need to apply for a CPT so that you may do a paid internship with a company in the US. To obtain a CPT, please visit this page and follow the instructions for professional-track students. While we do not give course credit for internships, we officially recognize their importance via the optional Professional Track. The requirements for the professional tracks include all those of the standard tracks, as well as the following Students must complete full-time professional experiences doing work that is related to their concentration programs, totalling 2-6 months, whereby each internship must be at least one month in duration in cases where students choose to do more than one internship experience. Such work is normally done at a company, but may also be at a university under the supervision of a faculty member. On completion of each professional experience or internship, the student must write and upload to ASK a reflective essay about the experience addressing the following prompts, to be approved by the students concentration advisor Which courses were put to use in your summers work Which topics, in particular, were important In retrospect, which courses should you have taken before embarking on your summer experience or internship What are the topics from these courses that would have helped you over the summer if you had been more familiar with them Are there topics you should have been familiar with in preparation for your summer experience or internship, but are not taught at Brown What are these topics What did you learn from the experience that probably could not have been picked up from course work Is the sort of work you did over the summer something you would like to continue doing once you graduate Explain. Would you recommend your summer experience to other Brown students Explain.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Professional Track"], "word_count": 417, "token_count_estimate": 458}}, "https://cs.brown.edu/degrees/undergrad/research/symposium/": {"text_content": "Undergraduate CS Research Symposium For more information, please check out the Meta Undergraduate Research Assistants page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:26+00:00", "headings": ["Information for:", "Undergraduate CS Research Symposium"], "word_count": 16, "token_count_estimate": 20}}, "https://cs.brown.edu/degrees/why-brown/": {"text_content": "Why Study At Brown CS This page is for all prospective students international applicants, please see the additional section below . Our remarkable students conduct cutting-edge research and combine technical strength with a great diversity of backgrounds. Our graduates have an outstanding record of innovation and maintain strong ties with each other. Students work with world-class faculty through coursework, research projects, and theses, and contribute to instruction as teaching assistants. Brown provides excellent resources pleasant office space, quality computing equipment, several specialized labs, and an attractive building close to restaurants and shops. Were conveniently located in Providence, less than an hour from Boston and three hours from New York. Weve been compiling rave reviews of our citys walkability, cultural attractions, and quality of life. If youre coming for a visit, be sure to check out this helpful guide the College Hill, Thayer Street, Wayland Square, and Downtown neighborhoods are all nearby. We have a long tradition of strong industry partnership. Leading organizations actively recruit our graduates, and many of them are members of our Industry Partners Program . Our interdisciplinary options enrich the educational experience, exposing students to novel and fascinating problems. We pride ourselves on being a friendly and welcoming place to a diverse population of students. Brown CS fields teams in several intramural sports and often organizes picnics, games, bike rides, and other activities. International Applicants Our international ambassadors are students from other countries who would love to talk to you about their Brown CS experience. Click the map below, then move your cursor to find an ambassador from your country. Recent Brown CS Graduates Worldwide Our graduates rank high as industry pioneers and in academia as well. Recent graduates have joined the faculty at the following institutions around the world Amherst College Brandeis University Brigham Young University Buena Vista University Carleton College Carnegie Mellon University Davidson College DePaul University ETH Zurich Florida Atlantic University Florida International University George Mason University Iowa State University Johns Hopkins University Koc University Turkey Le Moyne College Longwood University Louisiana State University Mississippi State University Nanyang Technological University Singapore Northwestern University Oakland University Ohio State University Oregon State University Pomona College Purdue University Sapienza University of Rome State University of New York at Albany University of Central Florida University of Houston University of Illinois at Chicago University of Maryland, College Park University of Massachusetts, Amherst University of Massachusetts, Lowell University of Minnesota University of Oxford University of San Francisco University of South Mississippi University of Texas, Austin Virginia Tech Williams College English-Language Courses We know that many of you may not have had the opportunity to fully develop your English language skills. If youre interested in improving them, click here for English-language courses that Brown has designed with you in mind.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Why Study At Brown CS?", "International Applicants"], "word_count": 459, "token_count_estimate": 534}}, "https://cs.brown.edu/events/": {"text_content": "Events Browse Events Lecture Series Distinguished Lecture Series Kanellakis Memorial Lectures Life After Brown Lectures Special Events Computer Science Reunion Events Schedule For The Next Three Months Wednesday, March 13 1200PM, 368, Watson Center for Information Technology CIT Konstantinos Kallas Programmable Software Systems for Correct High-performance Applications Wednesday, March 13 400PM, Rm 302, 164 Angell Street Computational Infrastructures for Consolidating our Knowledge Regarding the Human Genome Wednesday, March 13 400PM, 302, 164 Angell Street Computational Biology Seminar Jie Liu, Ph.D. Wednesday, March 13 500PM - 0600PM, BioMed 291, Eddy Auditorium, 171 Meeting St BioCON Seminar Dr. Melissa Simon Thursday, March 14 1200PM, 368, Watson Center for Information Technology CIT Zachary Ferguson Democratizing Simulation as a Framework for Seamless Analysis and Computational Design Friday, March 15 1200PM, 368, Watson Center for Information Technology CIT Silvia Selln Stochastic Computer Graphics Tuesday, March 19 400PM, 368, Watson Center for Information Technology CIT Navigating Your Career in Tech Wednesday, March 20 1200PM, 368, Watson Center for Information Technology CIT Reto Achermann The Foundation of Performance-aware Resilient Operating Systems Friday, March 22 1200PM, 368, Watson Center for Information Technology CIT Fergus Imrie Transforming medicine and healthcare with machine learning Tuesday, April 2 1200PM, 368, Watson Center for Information Technology CIT Yilun Du Generalizing Beyond the Training Distribution through Compositional Generation Wednesday, April 3 1030AM - 1200PM, 302, 164 Angell Street Thesis Defense Indra Kumar Explainability, fairness, and human evaluation in machine learning From theory to policy and back Wednesday, April 3 1200PM, 368, Watson Center for Information Technology CIT Jacob Schreiber Dissecting the Cell Type-Specific Regulatory Role of Each Nucleotide in the Human Genome Wednesday, April 3 1200PM - 0100PM, True North Classroom 101, Stephen Robert 62 Hall, 280 Brook Street, Providence, RI 02912 Fireside Chat with Rep. Jim Langevin and Gen. Paul Nakasone Friday, April 5 1100AM - 1230PM, 115, Watson Center for Information Technology CIT Thesis Defense Thao Nguyen Human-guided Robot Object Search Friday, April 5 1200PM - 0100PM, 115, MacMillan Hall Horizons Seminar - Alison Marr Wednesday, April 10 1230PM - 0200PM, 101, Watson Center for Information Technology CIT Thesis Defense Yanyan Ren Using Contrasting Cases to Teach Socially Responsible Computing Friday, April 12 1000AM - 1130AM, 241, Watson Center for Information Technology CIT Thesis Defense Pegah Nokhiz Modeling and Simulation of Artificial Societies to Study Precarity and Inequity Friday, April 26 1200PM - 1250PM, 477, Watson Center for Information Technology CIT Aldo Pacchiano BigAI Talk Experiment Planning with Function Approximation", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Events", "Lecture Series", "Special Events", "Events Schedule For The Next Three Months:"], "word_count": 409, "token_count_estimate": 673}}, "https://cs.brown.edu/events/immersionatbrown/": {"text_content": "Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT May 20 and 21, 2015 sponsored by the Office of Brown Universitys 250th Anniversary, the Brown University Center for Computing and Visualization, Brown University Computing and Information Services, and the Brown University Sciences Library the YURT has been developed with funding from NSF We are celebrating the opening of Browns newest virtual reality environment, the YURT YURT Ultimate Reality Theatre, in the context of the many decades of visual study that presaged it. This immersive environment fully engages our visual senses for exploration and discovery in areas as diverse as planetary geology, mathematics, visual art, digital literature, and biology. With head and body-tracking, users control a virtual world shown on a room-sized, 100 million-pixel stereo display that completely surrounds them. You have to experience this unique instrument to truly understand and appreciate it. Join us to learn about the future of virtual reality from some of the fields greatest innovators and to experience the reality for yourself. Please do two things immediately in order to attend E-mail Jesse Polhemus to register. Please note that earlier registrants will be given preference for some events, including demonstrations. Book a hotel room if necessary Hotel Providence 401-861-8000, the Biltmore 401-421-0700, the Wyndham Garden 401-272-5577, or the Marriott 401-272-2400. Schedule 20 WEDNESDAY morning 9am-1pm Attendees are invited to sign up for presentations in both new YURT and the legacy Cave on Wednesday morning, and subsequently on a drop-in basis throughout Thursday. YURT 180 George St at Brook, Cave Granoff Center, Studio 4, N330. 30 minute guided presentations at either site may be booked here . 20 WEDNESDAY afternoon -- all talks are in Granoffs Martino Auditorium 130-2 pm Welcoming remarks and introduction 2-315 Henry Fuchs Keynote The Immersion Renaissance Head-Worn Displays, Projectors, and the YURT 315-4pm Coffee, Tea, snacks available Granoff Center, Foyer 4-515pm Fritz Drury VR Design for Science John Cayley Teaching Literary Arts in an Immersive Audiovisual Environment 530-630pm Reception and YURT Inauguration with Provost Vicki Colvin Please note the venue Brown CIT Building, 3rd Floor Thomas J. Watson Sr. Center for Information Technology 730 pm Symposium dinner for SELECTED participants Venue The Hope Club 21 THURSDAY -- all talks are in Granoffs Martino Auditorium 930am throughout the day Coffee, Tea, PastriesSnacks Granoff Center, Foyer 10-1115am Steven Feiner VR, AR, and the Future of User Interfaces Tom Banchoff 1130-1245pm Jim Head Planetary Immersive VIrtual Reality Transporting Astronauts and Researchers to Planetary Surfaces and Learning to Work Dan Keefe Magical User Interfaces Bringing Interactivity to Immersive Science and Art 1-145pm Pick-up lunch boxes in Granoff center or on your own locally 245-4pm Joe LaViola 3D Spatial User Interfaces Past, Present, and Future from the Virtual to the Real Roderick Coover Hearts and Minds The Interrogations Project 4-430pm Coffee Tea 430-545pm Noah Wardrip-Fruin The Power of Presence with Virtual Art Opportuntity for general discussion. 6-630pm Symposium closing FAQ Where can I find parking How do I find help for my special accessibility needs Parking may be limited, so we recommend carpooling or alternative methods of transportation if possible. You can find more information about parking and accessibility here . Im interested in checking out the Yurt myself. Could you please help Wed be happy to Please e-mail Tom Sgouros .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Visualization and Creativity in Immersive 3D Environments -- from Cave to YURT"], "word_count": 548, "token_count_estimate": 804}}, "https://cs.brown.edu/events/kanellakis/": {"text_content": "The Paris C. Kanellakis Memorial Lecture Series This lecture series honors Paris Kanellakis, a distinguished computer scientist who was an esteemed and beloved member of Brown CS. Paris joined us in 1981 and became a full professor in 1990. His research area was theoretical computer science, with an emphasis on the principles of database systems, logic in computer science, the principles of distributed computing, and combinatorial optimization. Upcoming Lecture Well include information about the 2024 lecture here as soon as its available. Previous Lectures To watch the recording of a lecture or read its abstract, click its title. Date Topic Speaker 2023 Monitoring Health and Diseases Using Radio Signals and Machine Learning Dina Katabi MIT 2022 Balls, Bins and Server Farms Eli Upfal Brown CS 2020 Back to basics the future of Search Sridhar Ramaswamy Neeva, Greylock Partners 2019 Learning from Censored and Dependent Data Constantinos Daskalakis MIT 2018 Algorithms Theory meets Practice Robert E. Tarjan Princeton 2017 Below P vs. NP Conditional Quadratic-Time Hardness for Big Data Problems Piotr Indyk MIT 2016 Professor Donald Knuth Days At Brown A Celebration Of Computer Science Donald Knuth Stanford 2015 The Cryptographic Lens Shafi Goldwasser MIT 2014 Laplacian Matrices of Graphs Algorithms and Applications Daniel Spielman Yale 2013 Bursts, Cascades, and Hot Spots A Glimpse of Some On-Line Social Phenomena at Global Scales Jon Kleinberg Cornell 2012 Differential Privacy Thwarting Big Datas Evil Twin Cynthia Dwork Microsoft 2011 Quantum Computing A Great Science in the Making Andrew Yao Tsinghua University 2010 From Philosophical to Industrial Logics Moshe Vardi Rice University 2009 Safety on the Wild and Wooly World-Wide Web Sandboxing Untrusted JavaScript John C. Mitchell Stanford 2008 A Survey of Some Recent Research at the Border of Game Theory and Theoretical Computer Science Anna Karlin University of Washington 2007 A hardware-design inspired methodology for parallel programming Arvind MIT 2006 Whole Genome Sequencing and Imaging-Based Systems Biology Eugene Myers Howard Hughes Medical Institute 2005 Geiometric Optics, Linear Programming and Congestion in Sensornets Richard Karp UC Berkeley 2004 Hyper-Encryption via Virtual Satellite Michael Rabin Harvard 2003 Reconfigurable Atomic Memory for Dynamic Networks Nancy Lynch MIT- delivered by Alex Shvartsman 2002 Algorithmic Problems in the Internet Christos Papadimitriou UC Berkeley 2001 Progress in System Modeling and Testing Mihalis Yannakakis Avaya Laboratories", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "The Paris C. Kanellakis Memorial Lecture Series"], "word_count": 376, "token_count_estimate": 552}}, "https://cs.brown.edu/events/lifeafterbrown/": {"text_content": "Life After Brown Lecture Series This series features successful alums sharing their perspective on the challenges and opportunities that await Brown CS graduates in the hope that current students can benefit from their experience. Lectures are aimed primarily at undergraduates, but all are welcome to attend. Upcoming Lectures Michael Greenberg Pomona College, 4 PM on April 25 in CIT 368 Previous Lectures Click a lectures title to go its web page. When a recording of a lecture or other items related to it are available, links are shown below the title. Click them to learn more. Date Topic Speaker 11062018 Navigating a Career in HCI Research video recording Meredith Ringel Morris Microsoft Research 03062016 Hidden in Plain Sight Changing the Face of the U.S. STEM Workforce video recording Mary Fernandez MentorNet 11052015 Life After Brown Adam Leventhal Delphix", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Life After Brown Lecture Series", "Upcoming Lectures", "Previous Lectures"], "word_count": 138, "token_count_estimate": 177}}, "https://cs.brown.edu/events/dls/": {"text_content": "Distinguished Lecture Series Launched in 2008, this series features prominent computer scientists from academia and industry addressing topics of broad interest. Distinguished Lectures enrich Browns academic environment by contributing to the education of our students, motivating our undergraduates to get involved in research, and bringing together students, faculty, alums, and industry partners for lively interaction and discussion. Upcoming Distinguished Lectures Our next distinguished lecture will appear here when ready. Previous Distinguished Lectures Click the title of a Distinguished Lecture to learn more about it, including in some cases recordings and other items. Date Topic Speaker 11172019 Collaboration as a Lens for Inclusive Technical Innovation Meredith Ringel Morris Microsoft Research 04182019 Building Machines That Learn And Think Like People Josh Tenenbaum MIT 10032018 AI and Security Lessons, Challenges and Future Directions Dawn Song UC Berkeley 09262018 Hitting the Nail on the Head Interdisciplinary Research in Computer Networking Jennifer Rexford Princeton University 02082018 Rethinking Ubiquitous Computing to Transform Healthcare Elizabeth Mynatt Georgia Tech 11302017 Case Studies from the Real World The Importance of Measurement and Analysis in Building Better Systems Bianca Schroeder University of Toronto 10152015 Personalized Search Potential and Pitfalls Susan Dumais Microsoft 10062015 Accelerating the Discovery of Insights from Data Laura Haas IBM 03052015 Customizing Robots Daniela Rus MIT 02122015 Games, Learning, and the Price of Anarchy Eva Tardos Cornell 12082014 A Surprising Application of Differential Privacy Cynthia Dwork Microsoft 11062014 The Power of Abstraction Barbara Liskov MIT 05012014 Towards Theoretical Models of Natural Inputs Aiming to Bridge the TheoryAI Divide Avrim Blum Carnegie Mellon 03132014 Small, nme, data Deborah Estrin Cornell 02202014 Never-Ending Machine Learning Tom M Mitchell Carnegie Mellon 02062014 Trustworthy Hardened Code Greg Morrisett Harvard 04182013 Reflections on Image-Based Modeling and Rendering Richard Szeliski Microsoft 04112013 Language Translation as Codebreaking Kevin Knight USC 02212013 A Software Crisis Please, sir, may I have some more Abstract David Notkin University of Washington 05052011 CALM Consistency Disorderly Programming in Bloom Joseph Hellerstein Berkeley 11102011 Provenance Everywhere Margo Seltzer Harvard 10012011 Statistics and Computation in the Age of Massive Data Michael Jordan Berkeley 09082011 Algorithms, Graph Theory, and the Solution of Laplacian Linear Equations Daniel Spielman Yale 11182010 Meaning Propagation Fernando Pereira Google 11042010 Computational Cameras Redfining the Image Shree Nayar Columbia 09232010 Strong LP Formulations and Primal-Dual Approximation Algorithms David Shmoys Cornell 04222010 Theory and Applications of an Algorithm for Playing Repeated Games Rob Schapire Princeton 04192010 Computational Thinking Jeannette Wing NSF 04082010 Interdisciplinarity in the Age of Networks Jennifer Tour Chayes Microsoft 03112010 An Evolution of General Purpose Processing Reconfigurable Logic Computing Joel Emer Intel 03042010 Information Integration From Clio to Integration Independence Renee Miller University of Toronto 10292009 Efficiently Learning to Behave Efficiently Michael Littman Rutgers University 10202009 Randomized Shellsort A Simple Oblivious Sorting Michael Goodrich University of California at Irvine 04292009 Cyberspace- Taming the Wild West John Savage Brown 04292009 Probabilistic Models for Complex Systems From Cells to Bodies Daphne Koller Stanford 02262009 Approximation Algorithms Michel Goemans MIT 10162008 Simplicity is Complex John Maeda President of RISD 09252008 Simple Techniques for Eliminating Fatal Errors in Software Systems Martin Rinard MIT", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:27+00:00", "headings": ["Information for:", "Distinguished Lecture Series", "Upcoming Distinguished Lectures", "Previous Distinguished Lectures"], "word_count": 513, "token_count_estimate": 782}}, "https://cs.brown.edu/gcs.html?q=%22amy%20greenwald%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22carsten%20eickhoff%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22eliot%20horowitz%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22james%20tompkin%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22chris%20mascioli%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22seny%20kamara%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22sorin%20istrail%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22suresh%20venkatasubramanian%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22tarik%20moataz%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22theophilus%20benson%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%22ugur%20cetintemel%22": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=%2522sorin%2520istrail%2522": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=Guillaume%20Marceau": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=hal%20triedman": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=Shriram%20Krishnamurthi": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=iris%20bahar": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/gcs.html?q=kathi%20fisler": {"text_content": "Search Results", "metadata": {"last_modified": "2023-05-10T19:49:55+00:00", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "Search Results"], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/giving/uta/": {"text_content": "The Undergraduate Teaching Assistant UTA Endowment Andy van Dam has described Undergraduate Teaching Assistants UTAs as a collaborative troupe spanning generations, making the future happen. Please donate today so they can continue their vital work. Fifty years ago, Brown CS pioneered the idea of computer science UTAs, and if you work in our field, youve either met one or you were one. Serving as a UTA is an opportunity like nothing else at a critical time in a students life, providing them with a higher level of knowledge, self-development, and often with much-needed financial support. When we look at our peers at Brown and see where they are todaywe see Browns undergraduate TA program at workWe believe it is an irreplaceable component to the departments educational leadership and success. Philip Levis Professor of Computer Science and Electrical Engineering, Stanford University, and former UTA Due to growing enrollments over several decades, the UTA program has become far more expensive than it once was. In 2018, Brown CS completed a successful crowdfunded campaign that established a ten-million-dollar endowment to fund our UTAs . Five years later, its clear that much more is needed One in five Brown undergraduates is a CS or joint CS concentrator. We employ more than 325 UTAs each semester. Over 60 of CS concentrators have been a UTA at least once. The administration is making major investments in the expansion of CS and our flagship UTA program. Your gifts will bolster and accelerate our growth. Thats why were creating a two-million-dollar extension to the UTA endowment, and we need your help. Today, you can help Brown CS give the same opportunity that you may have benefited from to someone who wouldnt otherwise have it. Gifts of 50,000 or more provide naming opportunities to support hiring undergraduate teaching assistants. You can also make a smaller gift to a pooled endowment. TAing is about making a course that changed your life just as amazing for the next generation of students. Its about showing a student close to tears how to solve a challenging problem by giving them tools, and changing that students experience from feeling frustrated and lost to feeling inspired and happy and powerful because of CS. Alexandra Schultz Assistant Professor of Classics, Dartmouth, Fulbright scholar, and former UTA Click here to donate or email Nicole Peters Sisson Senior Director of Development, Academic Initiatives with any questions. Thank you", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:28+00:00", "headings": ["Information for:", "The Undergraduate Teaching Assistant (UTA) Endowment"], "word_count": 400, "token_count_estimate": 489}}, "https://cs.brown.edu/news/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown University Master Of Science In Cybersecurity Alum Bill Marino Is A Fulbright Finalist Posted by Jesse Polhemus on March 12, 2024 in Awards The Fulbright Programs 2023-2024 year saw Brown University students and alums earn 36 Fulbright scholarships, the second-highest number in the nation. One of them, Bill Marino, is a recent recipient of Browns Master of Science in Cybersecurity, a fully online degree program that can be completed from anywhere in the world. read more Brown CS PhD Candidate Ji Won Chung Implements A Sleep Regularity Index In A Popular Sleep Tracker Posted by Robayet Hossain on March 7, 2024 Ji Won Chung , a third-year PhD student advised by Jeff Huang , Brown CS faculty member and researcher in human-computer interaction, has been collaborating with the developers of Sleep as Android, a popular sleep tracking app that supports vibration on alarms, anti-snoring measures, and lucid dreaming cues. Ji Wons research focused on writing code to implement a scientifically-evaluated sleep regularity index SRI, which is now being incorporated into the app itself, and is expected to impact the sleep patterns of millions of people worldwide. read more Nora Ayanian Will Present Swarming Drones At SXSW 2024 Posted by Jesse Polhemus on March 5, 2024 Brown Engineering and Computer Science Associate Professor Nora Ayanian will present at the 2024 SXSW Conference, held March 8-12. SXSW provides an opportunity for the global community of digital creatives to encounter cutting-edge ideas, discover new interests, and network with other professionals who share a similar appetite for forward-focused experiences, and the 2050 track where Ayanians presentation falls showcases long-range, big-picture thinking, with topics that range from nanotech breakthroughs and interplanetary expeditions to life-extension research and novel applications of scientific discoveries. read more Brown CS PhD Student Eric Ewing Helps Multi-Robot Research Lift Off At Brown And Beyond Posted by Jesse Polhemus on Feb. 29, 2024 in Socially Responsible Computing Advancing a commitment to accessible robotics education, the Brown CS PhD student is researching how to simultaneously control multiple drones and teaching others how to build and operate them. read more Four Brown CS Students Receive CRA Outstanding Undergraduate Researcher Honors Posted by Jesse Polhemus on Feb. 7, 2024 in Awards Every year, the Computing Research Assiciation CRA recognizes North American students who show phenomenal research potential with their Outstanding Undergraduate Researcher Award, and for 2023-2024, four Brown CS students received honors Megan Frisella Finalist and Anh Truong, Qiuhong Anna Wei, and Carolyn Zech Honorable Mention. read more Maurice Herlihy Gives A Keynote At The International Symposium On Stabilization, Safety, And Security Of Distributed Systems And A Seminar Talk At Stevens Institute Posted by Robayet Hossain on Feb. 6, 2024 On October 4, Maurice Herlihy of Brown CS gave a keynote address at the 25th International Symposium on Stabilization, Safety, and Security of Distributed Systems, focusing on how it is necessary to rethink classical correctness conditions for distributed systems when dealing with cross-blockchain transactions. read more Michael Littmans New Series Of Educational Videos Explores Weird, Wondrous CS Posted by Jesse Polhemus on Feb. 5, 2024 Newcomers to the field of computer science who see it as more than just a ticket to a job at a big tech company have found a kindred spirit in Brown CS faculty member Michael Littman , who has just released Weird Computer Science, a new series of educational videos . read more A Guided Tour Of The Brown CS Digital Archive Posted by Jesse Polhemus on Jan. 24, 2024 The latest cover story from Conduit , the Brown CS annual magazine, is an intimate look at a treasure trove of our departments history. Now in its fifth year, the Brown CS Digital Archive BCSDA is a crowdsourced effort to curate items that have contributed to Brown CS history and preserve them permanently online, where theyll be accessible to all. The vast majority of the BCSDAs more than 400 artifacts photos, graphics, audio, video, and even code have been submitted by alum Paul Anagnostopoulos. In the pages below, Paul takes us behind the scenes, telling the story of developing the read more Brown CS Student Mattie Ji Is A Runner-Up For The Schafer Prize For Excellence In Mathematics By An Undergraduate Woman Posted by Jesse Polhemus on Jan. 19, 2024 in Awards , Diversity Almost twenty-five years ago, the Association for Women in Mathematics established the Alice T. Schafer Mathematics Prize, to be awarded to an undergraduate woman for excellence in mathematics. This year, Brown CS student Mattie Ji, a senior majoring in Mathematics, Applied Mathematics, and Computer Science, was the prizes runner-up. read more Yong Zheng-Xin, Cristina Menghini, And Stephen Bach Earn A Socially Responsible Language Modelling Research SoLaR Best Paper Award Posted by Jesse Polhemus on Jan. 17, 2024 in Socially Responsible Computing , Awards At the recent conference, work Low-Resource Languages Jailbreak GPT-4 from Brown CS PhD student Yong Zheng-Xin, postdoctoral researcher Cristina Menghini of Browns Data Science Institute, and Brown CS faculty member Stephen Bach was selected from 121 submissions to receive the workshops Best Paper Award. read more Page 1 of 85 next", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", ""], "word_count": 864, "token_count_estimate": 1162}}, "https://cs.brown.edu/news/2001/11/21/Kanellakis/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Kanellakis Lecture Series Inaugurated Posted by Amy Tarbox on Nov. 21, 2001 On 29 November 2001, at 400 p.m., the CS Department will hostthe firstannual Paris Kanellakis lecture Dr. Mihalis Yannakakis, of Avaya Laboratories,will speak on Progress in System Modeling and Testing.This lecture series honors Paris Kanellakis, a distinguished computer sciencetheoretician who was an esteemed and beloved member of this department.His death in a December, 1995 airplane accident was a profound loss of whichwe are especially reminded at this time of year.We are therefore all the more delighted now to inaugurate this lecture series in his memory.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Kanellakis Lecture Series Inaugurated"], "word_count": 112, "token_count_estimate": 165}}, "https://cs.brown.edu/news/2002/09/27/Kanellakis/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Kanellakis Lecture Series Inaugurated Posted by Amy Tarbox on Nov. 21, 2001 On 29 November 2001, at 400 p.m., the CS Department will hostthe firstannual Paris Kanellakis lecture Dr. Mihalis Yannakakis, of Avaya Laboratories,will speak on Progress in System Modeling and Testing.This lecture series honors Paris Kanellakis, a distinguished computer sciencetheoretician who was an esteemed and beloved member of this department.His death in a December, 1995 airplane accident was a profound loss of whichwe are especially reminded at this time of year.We are therefore all the more delighted now to inaugurate this lecture series in his memory.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Kanellakis Lecture Series Inaugurated"], "word_count": 112, "token_count_estimate": 165}}, "https://cs.brown.edu/news/2004/05/04/PECASE/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Amy Greenwald Receives PECASE Award Posted by Amy Tarbox on May 4, 2004 Professor Amy Greenwald of this department has just received a prestigious PECASE Presidential Early Career Award for Scientists and Engineers from the National Science Foundation.John H. Marburger III, Science Advisor to the President and Director of the Office of Science and Technology Policy, presented the awards today at a White House ceremony in the Eisenhower Executive Office Building to 20 National Science Foundation NSF supported researchers and 37 other scientists and engineers representing programs sponsored by eight other federal departments and agencies. Amy was recognized for her research on how automated software agents can make decisions in uncertain environments such as online auctions. She recruits many young women into computer science and effectively advises graduates and undergraduates. She also serves an advisor to a summer outreach program for ninth-grade students who gain hands-on computer experience. NSFs nominees for these presidential awards are drawn from junior faculty members who have received grants from NSFs Faculty Early Career Development CAREER program, considered the agencys most important and prestigious awards for new faculty members who show promise as leaders in science and engineering. These scientists have also translated their work into significant education activities. Nearly 400 young faculty members are chosen each year for the CAREER awards, which range from 300,000 to more than 750,000 over five years. The awards support the work and foster growth opportunities of those most likely to become academic leaders. The NSF-supported PECASE recipients represent a little over 5 percent of all CAREER awards made in 2002. Of the 2,900 CAREER awards made since the program began in 1996, only 140 have received presidential recognition. PECASE honorees receive no additional NSF funds beyond their initial CAREER grants, but the presidential recognition carries significant prestige as recipients represent the best among young researchers and educators from the CAREER program.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Amy Greenwald Receives PECASE Award"], "word_count": 328, "token_count_estimate": 403}}, "https://cs.brown.edu/news/2007/04/13/Fellowship/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles PhD student Glencora Borradaile awarded NSERC Postdoctoral Fellowship Posted by Amy Tarbox on April 13, 2007 Ph.D. student Glencora Borradaile has been awarded a National Sciences and Engineering Research Council NSERC Postdoctoral Fellowship. NSERC is the Canadian equivalent of NSF. The fellowship is tenurable at any Canadian institution for two years. Glencoras thesis research concerns designing theoretically efficient algorithms for optimization problems in planar graphs. She has worked with Philip Klein in giving a simple algorithm for finding the maximum st-flow in a directed planar graph. She has given invited talks on this result at The University of Waterloo, NYU, IBM Watson, CMU and Dartmouth. In collaboration with Philip Klein and Claire Mathieu, she has been working on designing polynomial-time approximation schemes for the Steiner tree problem in planar graphs. Both results appeared at the Symposium for Discrete Algorithms SODA in 2006 and 2007, respectively. Glencora will complete her Ph.D. in late 2007. For more information about this award, please see httpwww.nserc.gc.casfe.aspnavsfnavamp lbi3a", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "PhD student Glencora Borradaile awarded NSERC Postdoctoral Fellowship"], "word_count": 178, "token_count_estimate": 263}}, "https://cs.brown.edu/news/2005/03/16/Wriston/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Shriram Krishnamurthi awarded Wriston Fellowship Posted by Amy Tarbox on March 16, 2005 Were delighted to report that Shriram Krishnamurthi has been awarded a Henry Merritt Wriston Fellowship for the next academic year. Brown University gives this award to recognize quoting from the award letter the distinguished contributions that our faculty make to undergraduate education. Receipt of the award entitles the faculty member to one semesters relief from teaching duties it is the award committees hope that by rewarding your commitment to teaching thus far with a Wriston Fellowship, we will be supporting research that will continue to enrich your teaching in the future. Shrirams application for this fellowship cited such successes as his last years CS 190, described in his lively conduit article httpwww.cs.brown.edupublicationsconduitconduitv13n1.pdf . Featuring the design and implementation of a routing system for Browns SafeRIDE shuttle-bus fleet, the course was designed to stress such real-world skills as dealing with incomplete and ambiguous requirements that change over time, using prototype systems to get a better understanding of the requirements, and dealing with administrative structures whose purpose and thrust are at best orthogonal to the goals of a software project. The application also described his extensive research collaborations with undergraduates, which lead to publication at prestigious research conferences, and his TeachScheme Outreach program that trains high-school teachers in new ways of thinking about computer science. Shriram plans to use his Wriston Fellowship to design a new course, provisionally called quotComputer Science for Social Scientistsquot, and write his second textbook, quotProgramming Languages Application and Interpretationquot.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Shriram Krishnamurthi awarded Wriston Fellowship"], "word_count": 270, "token_count_estimate": 354}}, "https://cs.brown.edu/news/2010/10/18/RT/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles BU, Brown and UC Irvine receive 3 million NSF grant Posted by Amy Tarbox on Oct. 18, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Computer scientists from Boston University, Brown University and the University of California, Irvine, will collaborate on a grant from the National Science Foundation NSF in the anticipated amount of 3 million to investigate quottrustworthy interaction in the cloud.quot The cloud refers to Internet-based outsourced computation popularly know as cloud computing, whereby shared resources, software, and information are provided to computers and other devices on demand. As one of the most promising emerging concepts in information technology, outsourced computation is transforming how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. However, despite the relatively fast growth and increased adoption of clouds, aspects related to their security, privacy, and economic value proposition remain largely unanswered and are regarded by some technology experts as impediments to broader acceptance of this approach to computing. quotDeveloping the right mechanisms for the specification and verification of trust-enhancing service-level agreements in the cloud will avert conflicts among cloud market stakeholders,quot says Azer Bestavros, lead principal investigator and professor of computer science at Boston University. quotDoing so will also improve the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society.quot quotAs more and more data is being stored in the cloud, keeping that data private is becoming critical, especially for applications in finance and medicine,quot says Michael Goodrich, principal investigator and Chancellors Professor at the University of California, Irvine. The project supported by the NSF grant will address these concerns by examining the feasibility of extending cloud service-level agreements to cover aspects such as integrity of outsourced services, information leakage control, and fair market pricing. The project also will explore mechanisms that verify trust-enhancing service-level agreements are being followed and develop quottrustworthinessquot guarantees and tradeoffs to cloud customers and system integrators that are both practical and useable. quotWe envision a new generation of trusted cloud computing services where users will be able to verify the integrity of their data stored in the cloud and the correctness of computations performed in the cloud,quot says principal investigator Roberto Tamassia. Tamassia is chair and Plastech Professor of Computer Science at Brown University. The projects co-principal investigators include Leo Reyzin, associate professor, Jonathan Appavoo, assistant professor, and Nikos Triandopoulos, research assistant professor, at BU and Anna Lysyanskaya, associate professor, and Rodrigo Fonseca, assistant professor, at Brown. In exploring these cloud computing-related issues, the team will collaborate with researchers at leading IT industrial labs at IBM, Microsoft, NetApp, RSA the security division of EMC and VMware. The project also will involve BUs Center for Reliable Information Systems and Cyber Security RISCS and the new Massachusetts Green High-Performance Computing Center MGHPCC to examine broader implications and impacts of cloud technology on society. The projects ultimate goal is to define a viable marketplace for cloud computing resources in which users are assured that the services they acquire meet their performance, security, and privacy expectations.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "BU, Brown and UC Irvine receive $3 million NSF grant"], "word_count": 531, "token_count_estimate": 672}}, "https://cs.brown.edu/news/2010/10/18/BenEli/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Ben Raphael and Eli Upfal Receive NSF Grant to Develop Techniques for Analysis of DNA Sequence Variants Posted by Amy Tarbox on Oct. 18, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation NSF awarded a research grant , in the expected amount of 500,000, to Ben Raphael and Eli Upfal to develop robust algorithmic and statistical techniques for the analysis of DNA sequence variants in the context of known and novel gene-gene interactions. These techniques will allow biomedical researchers to identify DNA variants associated with risk for various diseases, including cancer. Algorithms developed in this project will be implemented and released as open-source software for use by the biological and medical community. The project will also support the training of graduate students and undergraduate researchers.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Ben Raphael and Eli Upfal Receive NSF Grant to Develop Techniques for Analysis of DNA Sequence Variants"], "word_count": 155, "token_count_estimate": 182}}, "https://cs.brown.edu/news/2010/11/23/kleinnsf/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Philip Klein, Claire Mathieu and Ph.D. Alum Glencora Borradaile Receive NSF Grant to Develop New Algorithms for Solving Optimization Problems on Planar Networks Posted by Amy Tarbox on Nov. 23, 2010 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation NSF has awarded a research grant , in the expected amount of 800,000, to Philip Klein , Claire Mathieu and Ph.D. alum Glencora Borradaile now Assistant Professor in the School of Electrical Engineering and Computer Science at Oregon State University, to develop new algorithms for solving fundamental optimization problems on planar networks. Many optimization problems in networks are considered computationally difficult some are even difficult to solve approximately. However, problems often become easier when the input network is restricted to be planar, i.e., when it can be drawn on the plane so that no edges cross each other. Such planar instances of optimization problems arise in several application areas, including logistics and route planning in road maps, image processing and computer vision, and VLSI chip design. The team plans to develop algorithms that achieve faster running times or better approximations by exploiting the planarity of the input networks. In addition, in order to address the use of optimization in the discovery of some ground truth, the investigators will develop algorithms not just for the traditional worst-case input model but also for models in which there is an unusually good planted solution for a model of this kind, the investigators expect to find algorithms that produce even more accurate answers. In addition, new algorithms and techniques resulting from this research might enable people to quickly compute better solutions to problems arising in diverse application areas such as computer vision. Further research has the potential to be useful, for example, in the design of networks, the planning of routes in road maps, and the processing of images.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Philip Klein, Claire Mathieu and Ph.D. Alum Glencora Borradaile Receive NSF Grant to Develop New Algorithms for Solving Optimization Problems on Planar Networks"], "word_count": 333, "token_count_estimate": 401}}, "https://cs.brown.edu/news/2011/03/01/bootstrap/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Middle-schoolers are ready, ready, ready for programming adventure Posted by Amy Tarbox on March 1, 2011 Kurt Spindler, right, and Shaopeng Zhang work with Diamon Curry, a student at Gilbert Stuart Middle School, during a lesson on programming. Credit Mike CoheaBrown University By Richard Lewis Community outreach connects Brown CS students to the Providence area. For more articles on how Brown CS students inspire and lead members of the greater Providence community click here . Bootstrap, a nonprofit educational organization, pairs Brown undergraduates with middle-school students in Brown computer classrooms. The kids show up after school to learn how to make animations, video games, and other cool stuff. What theyre actually getting is substantial help with mathematics. Madavin Vongs eyes lit up as the blue rocket spewed a puff of cartoonish smoke and lifted off on her computer screen. Yeah she exclaimed. We did it The 11-year-old Vong was excited because she had mastered the computer and math skills necessary to make the rocket soar. She was doing the programming on the Brown University campus through a class taught by Brown undergraduate students for Providence-area school children. Vong loves video games. Her favorites are ones styled on adventure, fighting, and perhaps in an odd twist for someone so young on time management. Now, through a program run by a nonprofit educational outfit called Bootstrap, she was getting a chance to create her own video game. Basically, I want to see how they make them, said Vong, who is in sixth grade at Gilbert Stuart Middle School. To make characters move is a really cool thing. For about 10 weeks, up to a dozen middle-school students from Providence-area schools ride a bus after school to Brown to fulfill their dreams of creating their own superheroes, villains, monsters, stellar athletes, or super-organized geniuses. The video game, while real, is the hook to expose the children to computer science and to deepen their mathematics skills, according to Shriram Krishnamurthi, associate professor of computer science at Brown and a pivotal backer of the Bootstrap class. Enticing them with a straight-on programming class would be a hindrance, rather than a help, he says. The pitch is, Wouldnt you like to write your own video game said Krishnamurthi, who made Bootstraps video-game software accessible via the Web and has helped with fundraising. For the students who filed into a computer room at the Center for Information Technology for the first class last month, the answer would appear to be yes. These kids, with backgrounds from Cambodia, Haiti and El Salvador, were eager to get started. Their teacher, Brown sophomore Kurt Spindler, urged caution. Were here to make video games, he assured them, but the thing about video games, is theyre complicated. The students soon learn thats the case. They get drilled on x and y coordinates and, in a later class, are introduced to programming code needed to create shapes and animation. They seem vaguely aware of, yet little deterred, by the algebra and computer science as they furiously complete exercises in their workbooks. Thats the goal behind Bootstrap, said Emmanuel Schanzer, a Providence native and the programs creator. While teaching math and computer science classes in Boston-area schools, Schanzer found that his students reacted cooly to algebra and computer programming. So Schanzer, who studied computer science in college and worked for a while at Microsoft, devised a curriculum that effectively masked the fact that his students were tackling heavy math and computer programming. That curriculum led to Bootstrap, now in its fifth year and running after-school classes for urban schoolchildren in Austin, Texas, the Bay Area in California, Boston, New York, and Providence. I had my life plan, Schanzer related. Id make my millions and then go on to teaching. But I realized I wanted to teach full time. Browns involvement with Bootstrap began in spring 2010, with undergraduates teaching the after-school class at the middle schools. The class now takes place at the university, with transportation provided by the Providence After School Alliance. Each semester, about a half-dozen Brown students volunteer to teach, making the instruction for the middle-schoolers more of a hands-on tutorial than an impersonal lecture. Sometimes, the kids are like, Oh, why are we doing this I want to play video games, said Spindler, wearing a black Bootstrap T-shirt with I program my own video games on the front. Other times, they say, Oh my, computer science is so cool. I want to go to college. That is exciting and visceral. Its too early to know whether Vong will attend college, but shes well on her way to creating her own video game and enjoying the ride. We have a long way to go, but Im ready for the adventure, she says during a short break. Ready, ready.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:29+00:00", "headings": ["Information for:", "Brown CS News", "Middle-schoolers are ready, ready, ready for programming adventure"], "word_count": 812, "token_count_estimate": 1017}}, "https://cs.brown.edu/news/2011/01/04/Ben/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Ben Raphael Awarded NSF CAREER Grant Posted by Amy Tarbox on Jan. 4, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Ben Raphael is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The project funded by Bens CAREER grant aims to develop algorithms for new and emerging high-throughput DNA sequencing technologies. These technologies are lowering the cost of DNA sequencing by orders of magnitude, thereby enabling a variety of new biological applications. Ben plans to Develop novel algorithms for assembling complete genome sequences from billions of shorter DNA sequences produced by high-throughput DNA sequencing machines. Design robust algorithms to characterize differences between individual genomes within a species using an available reference genome of the species. Introduce combinatorial algorithms for the study of genome rearrangements in heterogeneous mixtures of DNA sequences. Examples of such mixtures are a community of microbes from an environmental sample, or a collection of cancer cells within a tumor. The proposed research will be integrated with an educational component that includes the development of an undergraduate seminar in personal genomics, a summer research experience in computational biology for high-school students, and the incorporation of a computational biology module into the Artemis summer computing camp for 9th grade girls. The Faculty Early Career Development CAREER Program is a Foundation-wide activity that offers the National Science Foundations most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. Besides his CAREER award, Ben has also received a Sloan Research Fellowship and a Career Award at the Scientific Interface from the Burroughs Wellcome Fund .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Ben Raphael Awarded NSF CAREER Grant"], "word_count": 347, "token_count_estimate": 406}}, "https://cs.brown.edu/news/2011/03/21/Ben/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Ben Raphael Awarded NSF CAREER Grant Posted by Amy Tarbox on Jan. 4, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Ben Raphael is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The project funded by Bens CAREER grant aims to develop algorithms for new and emerging high-throughput DNA sequencing technologies. These technologies are lowering the cost of DNA sequencing by orders of magnitude, thereby enabling a variety of new biological applications. Ben plans to Develop novel algorithms for assembling complete genome sequences from billions of shorter DNA sequences produced by high-throughput DNA sequencing machines. Design robust algorithms to characterize differences between individual genomes within a species using an available reference genome of the species. Introduce combinatorial algorithms for the study of genome rearrangements in heterogeneous mixtures of DNA sequences. Examples of such mixtures are a community of microbes from an environmental sample, or a collection of cancer cells within a tumor. The proposed research will be integrated with an educational component that includes the development of an undergraduate seminar in personal genomics, a summer research experience in computational biology for high-school students, and the incorporation of a computational biology module into the Artemis summer computing camp for 9th grade girls. The Faculty Early Career Development CAREER Program is a Foundation-wide activity that offers the National Science Foundations most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. Besides his CAREER award, Ben has also received a Sloan Research Fellowship and a Career Award at the Scientific Interface from the Burroughs Wellcome Fund .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Ben Raphael Awarded NSF CAREER Grant"], "word_count": 347, "token_count_estimate": 406}}, "https://cs.brown.edu/news/2011/06/01/franco/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown University and National University of Singapore Launch Second Concurrent Degree Program Posted by Amy Tarbox on June 1, 2011 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . Brown University and the National University of Singapore NUS have established a concurrent degree program in computer science. Participants are selected from the top ten percent of NUS computer science concentrators and on completion of the program, will concurrently receive degrees from NUS and Brown a bachelors degree in computer science from NUS and a masters degree in computer science from Brown. This new program follows up the concurrent computational biology degree program , the first concurrent degree launched by Brown and NUS, which awards students a bachelors degree in computational biology from NUS and a masters degree in computer science with a special designation in computational biology from Brown. Franco Preparata , who has been a visiting faculty at NUS for several years, is the main architect of both programs and will provide vision and leadership for them at Brown. We are pleased to expand our educational collaboration with a prestigious world-class institution and we look forward to welcoming to the department the first participants in the program, said Department Chair Roberto Tamassia.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Brown University and National University of Singapore Launch Second Concurrent Degree Program"], "word_count": 245, "token_count_estimate": 282}}, "https://cs.brown.edu/news/2011/06/16/Eli/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Eli Upfal Selected as Chalmers Jubilee Distinguished Visiting Professor Posted by Amy Tarbox on June 22, 2010 Eli Upfal was recently invited to serve as the Chalmers Jubilee Distinguished Visiting Professor for 2010. Chalmers is a Swedish university of technology in which research and teaching are conducted on a broad front within technology, natural science and architecture. The Jubilee Distinguished Visiting Professor Chair was created by the Swedish government when Chalmers university celebrated its 150 year anniversary in 1979. To goal of the visiting chair is bring new skills to the University while strengthening international relations. According to Eli, quotI look forward to working on interesting research problems with Devdatt Dubhashi and his students. There are also exciting opportunities to create new collaborations. Chalmers has been one of the worlds leaders in statistical research and I look forward to collaborating on new ways to integrate statistical concepts and methods in algorithmic research. This is especially useful in applications with large datasets, such as computational biology, web browsing and social networking.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Eli Upfal Selected as Chalmers Jubilee Distinguished Visiting Professor"], "word_count": 185, "token_count_estimate": 238}}, "https://cs.brown.edu/news/2011/07/21/avd/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Sharp Labs Provides Grant to Andy van Dam and his Research Team Posted by Amy Tarbox on July 21, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Sharp Laboratories of America has recently provided a grant and a just released commercial product, a 60 inch touch LCD display, to Andy van Dam and his research team to foster a collaboration in research on touch-enabled user interfaces. Browns LADS application Large Artwork Displayed on the Surface designed to showcase such large format artworks as the enormous Garibaldi Panorama ran without any changes on this Windows 7 supported device. Work is underway to prototype a small-team collaboration scenario to take advantage of the Sharp interactive whiteboard. The scenario uses WorkTop , another application being developed in the group that focuses on the organization of knowledge work and provides an integrated environment for annotating and linking a variety of document types such as text, images, and video with fine-grained, bi-directional hyperlinks. The current version of WorkTop is being enhanced with touch-based gestures, digital ink and character recognition to allow input and manipulation by touch and marker at the white board.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Sharp Labs Provides Grant to Andy van Dam and his Research Team"], "word_count": 213, "token_count_estimate": 254}}, "https://cs.brown.edu/news/2011/09/12/stanugur/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Stan Zdonik and Ugur Cetintemel Receive NSF Grant to Develop Data Management System for Massive Scale Scientific Data Posted by Amy Tarbox on Sept. 12, 2011 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . The National Science Foundation NSF awarded a grant , in the expected amount of 736,987, to Stan Zdonik and Ugur Cetintemel to conduct research towards building a scientific database SciDB, a system designed and optimized to support data-driven scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains. In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to and critical for science provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a general, highly scalable and usable engine. SciDB will thus significantly advance the state-of-the-art in data management in addition to supporting domain scientists in data-driven discovery. This grant is part of a 2.4M Large NSF grant that also funds research teams in University of Washington, MIT, Portland State University and University of Wisconsin-Madison.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Stan Zdonik and Ugur Cetintemel Receive NSF Grant to Develop Data Management System for Massive Scale Scientific Data"], "word_count": 231, "token_count_estimate": 298}}, "https://cs.brown.edu/news/2011/12/22/pascal/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Pascal Van Hentenryck Receives Docteur Honoris Causa from lUniversite de Nantes Posted by Amy Tarbox on Dec. 22, 2011 In addition to advancing the field at a local and national level, Brown CS community members have a global impact on education and research. For more articles on Brown CS around the world click here . The University of Nantes recently presented Pascal Van Hentenryck with the title of Doctor Honoris Causa at the 2011 ceremony of the doctors at the Cit des Congrs de Nantes. In the Universitys 50th year, Pascal was the sole recipient of this prize and the first computer scientist to ever receive it. This is Pascals second doctor honoris causa , the first from the Universit catholique de Louvain in 2008. The ceremony and Pacals talk are available in French on the Universitys website and on YouTube .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Pascal Van Hentenryck Receives Docteur Honoris Causa from l'Universite de Nantes"], "word_count": 157, "token_count_estimate": 213}}, "https://cs.brown.edu/news/2012/02/01/james/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles James Hays Receives NSF CAREER Award Posted by Amy Tarbox on Feb. 1, 2012 James Hays is the latest faculty recipient of an NSF CAREER award, a highly selective grant that the National Science Foundation awards to junior faculty members who are likely to become academic leaders of the future. The research funded by Jamess CAREER grant aims to understand, represent, and enhance scenes at the Internet-scale. James and his team are investigating quotdetail synthesisquot tasks which alleviate camera shake, motion blur, defocus, or low resolution. A key insight behind this research is that Internet scale photo collections and scene matching provide an ideal, context-specific statistical model which can be used to insert convincing texture and object detail. To improve scene matching the team will study attribute-based representations of scenes. Attributes are a powerful intermediate representation for the next generation of big data imaging research. James and his team are also developing a new introductory course for Brown students to explore big data computing across scientific disciplines and are creating an online community for visual computing education to benefit students interested in photography and programming. The Faculty Early Career Development CAREER Program is a Foundation-wide activity that offers the National Science Foundations most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. Such activities should build a firm foundation for a lifetime of leadership in integrating education and research. James received his B.S. in Computer Science from Georgia Institute of Technology in 2003 and completed his PhD in Computer Science at Carnegie Mellon University in 2009, where he was the recipient of a National Science Foundation Graduate Research Fellowship. He joined Brown after serving as a Postdoctoral scholar at MIT.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "James Hays Receives NSF CAREER Award"], "word_count": 320, "token_count_estimate": 377}}, "https://cs.brown.edu/news/2012/08/16/newfac2012/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Michael Littman Returns to Brown with Professor Appointment Tim Kraska and Paul Valiant to Join the Department as Assistant Professors Posted by Amy Tarbox on Aug. 16, 2012 The Department is thrilled to announce the addition of three new faculty members for the 2012-2013 academic year. PhD alum Michael Littman 96 and Paul Valiant will begin teaching in September and Tim Kraska will join the department in January. Michael previously spent many years as the director of the Rutgers Laboratory for Real-Life Reinforcement Learning and served as the department chair from 2009 until June 2012. His expertise includes artificial intelligence and machine learning. Tim will come to Brown after serving as a postdoctoral scholar at the University of California at Berkeley, working in the AMP Lab on Big Data management and hybrid humanmachine database systems. Paul is also a postdoctoral scholar at the University of California at Berkeley in the Theory of Computation group. He received his PhD from MIT and his interests include cryptographic and algorithmic game theory and coding theory. Our three new faculty members will help serving our growing population of graduate and undergraduate students. We are thrilled to have these three exceptionally bright and talented scholars join our department, said Chair Roberto Tamassia. We are all looking forward to welcoming them to Brown in the coming academic year. Michael Littman After earning his PhD from Brown University in 1996, Michael worked as an assistant professor at Duke University, a member of technical staff in ATTs AI Principles Research Department, and was most recently associate professor and chair in the computer science department at Rutgers. He is on the executive council of the American Association for AI, the advisory board of the Journal of AI Research, and serves as an action editor of the Journal of Machine Learning Research. His research in artificial intelligence focuses on designing software systems that improve their behavior with experience. His educational focus is on making academic computer science accessible to the general public. Its a dream come true to be coming back to Brown, said Michael. When I was here as a student, I was very focused on my narrow research area. This time, Im very excited to get to know the undergraduates and to work with faculty both within and outside Computer Science. Its a very exciting time to be a Computer Scientist and I would love to see the whole Brown community benefiting from the fantastic opportunities enabled by our ideas. Tim Kraska Tim received his PhD from the Swiss Federal Institute of Technology Zurich ETH in Switzerland, masters degrees from Westflische Wilhelms-Universitt Mnster in Germany and University of Sydney in Australia and a Bachelor of Science in Information Systems also from Westflische Wilhelms-Universitt Mnster. He received a Swiss National Science Foundation Prospective Researcher Fellowship 2010, a DAAD Scholarship 2006, a University of Sydney Master of Information Technology Scholarship for outstanding achievement 2005, the University of Sydney Siemens Prize 2005, and a VLDB best demo award 2011. Tims current focus is on Big Data management and hybrid human machine data base systems. According to Tim, Browns strong interdisciplinary and friendly environment with its excellent faculty and students make it a truly outstanding university. I am very excited to be joining the CS department and to be part of making it one of the leading places for big data research. Paul Valiant Paul received his PhD from MIT and masters degrees from both MIT and Stanford and a Bachelors degree from Stanford. He was previously a postdoctoral researcher at MIT. Paul received a NSF Mathematical Sciences Postdoctoral Research Fellowship, the Best Student Paper Award at the Theory of Cryptography Conference in 2008 and a National Defense Science and Engineering Graduate Fellowship. His interests include statistics, learning and property testing cryptography auctions and game theory protein folding evolution fluid dynamics and computational approaches to the other sciences. I am very excited to be joining the collaborative and forward-looking community of Browns Computer Science Department, said Paul. Computation has been constantly challenging us to change how we think about the world, and I am particularly intrigued by the new perspectives it offers on deep problems in the other sciences. At Brown I look forward to engaging with students and faculty from many departments and backgrounds to learn how to tackle these challenges.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Michael Littman Returns to Brown with Professor Appointment; Tim Kraska and Paul Valiant to Join the Department as Assistant Professors"], "word_count": 735, "token_count_estimate": 876}}, "https://cs.brown.edu/news/2012/06/25/3DS/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Three Day Startup Successfully Launched at Brown Posted by Amy Tarbox on June 25, 2012 Undergrad Anne Kenyon founded Browns 3 Day Startup 3DS weekend, which was held in early April with the support of the department, Google, 10Gen, and Teespring. The idea of 3 Day Startup is simple start a technology company over the course of three days. Work space was available for an entire weekend, 25 students with a range of backgrounds were selected and top-notch entrepreneurs and investors were onsite to help pick the best ideas for software startups during the Friday brainstorming session. Students then worked to release a minimal prototype by Sunday night, when they gave their product presentations. The goal of 3DS is to build enough momentum among a network of motivated people to sustain a company beyond the weekend. Many students at Brown have cool startup ideas, and all have different skill sets, so they need a way to meet and see each other in action -- working together for three straight days is a perfect way to find those with whom you work well to accomplish something of value, said Anne. Everyone seemed to get a lot out of the weekend, particularly from the mentors who have insight based on years of experience -- they said things I would never have thought of, but make so much sense. Makes us realize how much we have to learn, that business is really non-trivial. 3DS is an academic program designed to teach entrepreneurial skills in an extreme hands-on environment and enable students to start companies. The 3DS program brings together students ranging from freshmen to freshly-minted PhDs, with diverse backgrounds, including computer science, business, engineering, law, design, communications and others. Participants gain experience in cross-disciplinary collaboration, brainstorming and ideation, and group productivity, including ad-hoc leadership and decision-making under severe time constraints. 3DS is way more than a hackathon and we were more than coders. We went out and collected customer feedback as we rapidly assembled and programmed our live demo. We had to quickly fix complaints and adopt suggestions. Everything was in flux I had never experienced anything like it, said attendee Ryan McVerry. In addition to Anne, David Borcsok, Gabi Lewis and T. Luke Sherwin all of Brown, helped to organize the event. Mentors included CS alums Spiros Eliopoulos Co-Founder, CTO Tracelytics and Keith Dreibelbis Google.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:30+00:00", "headings": ["Information for:", "Brown CS News", "Three Day Startup Successfully Launched at Brown"], "word_count": 408, "token_count_estimate": 519}}, "https://cs.brown.edu/news/2013/06/07/michael-littman-honored-2013-aaai-classic-paper-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Michael Littman Honored With 2013 AAAI Classic Paper Award Posted by Angel Murakami on June 7, 2013 The Association for the Advancement of ArtificialIntelligence AAAI has selected the 1994 paper Acting Optimally in Partially ObservableStochastic Domains by Anthony R. Cassandra, Leslie Pack Kaelbling, and Michael Littman ,then a Brown CS graduate student, for a 2013 AAAI Classic Paper Award. Thisaward was established in 1999 to honor authors of papers deemed mostinfluential from a specific conference year. This years award recognizespapers from the Twelfth National Conference on Artificial Intelligence thattook place in 1994 in Seattle, Washington. Back in 1994, we were fascinated by the idea that an agentcan make optimal decisions in spite of not knowing all the facts, statedMichael Littman. The math wasoriginally developed in the operations research community, but we found that itwas a perfect fit for the kinds of problems AI people are interested inaddressing. These days, the notion ofpartial observability is a standard part of the AI vernacular. In academia a classic paper is one that changes thedirection of the field, typically because it identifies a sweet spota placewhere one can accomplish a lot without incurring overwhelming complexity. This paper is a classic classicpaper, added Professor Eugene Charniak. Michael Littman", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Michael Littman Honored With 2013 AAAI Classic Paper Award"], "word_count": 218, "token_count_estimate": 307}}, "https://cs.brown.edu/news/2012/10/03/BigData/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown awarded 1.5M for new Big Data tools Posted by Amy Tarbox on Oct. 3, 2012 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Eli Upfal, Fabio Vandin, and Ben Raphael, from left, are developing Big Data analytical tools that make sense of large datasets and eliminate the noise of data errors. Credit Mike CoheaBrown University. By Kevin Stacey As datasets expand and new generations of faster computers arrive, users urgently require more powerful algorithms to make sense of Big Data. Brown computer scientists have received a 1.5-million award from the National Science Foundation and the National Institutes of Health to conduct research on new analytical tools for Big Data. Computer scientists from Brown University have been awarded 1.5 million to develop new computer algorithms and statistical methods to analyze large, complex datasets. Funding for the project comes from a joint initiative of the National Science Foundation and the National Institutes of Health aimed at supporting fundamental research on Big Data. Eli Upfal , professor of computer science, will lead the research with fellow computer science professors Ben Raphael and Fabio Vandin . Browns funding allotment is the second largest of the eight grants awarded under the program this year, according to the official NSFNIH announcement. Upfal and his colleagues will test their new methods on genomics data. Nowhere are the challenges of Big Data more evident than in genomics. As techniques for sequencing genes have become faster and cheaper, researchers have compiled mountains of new data. The trick now is trying to make sense of it all picking out significant trends and ignoring all the unimportant noise that inevitably accumulates in large datasets. These datasets have all the good and bad properties of Big Data, Upfal said. Theyre big, noisy, and require very complicated statistical analysis to obtain useful information. One of the aims of this project is to develop better computational tools to isolate genetic mutations that drive cancer by comparing gene sequences of healthy tissue to those of cancerous tissue. The problem is that not every mutation found in cancerous cells is important. There could be thousands of mutations in each cell that dont actually contribute to cancer growth. Theyre simply insignificant, random mutations. An effective computer algorithm will be able to identify with statistical certainty the mutations that actually matter, keeping doctors from chasing millions of red herrings. But thats not the only problem Upfal and his team will try to address. Theres also the fact that the lab tools used to sequence genes sometimes record information inaccurately. The error rate varies between sequencing techniques but its significant, and analytical tools need to deal with that problem as well. One of the thrusts of the Brown project is finding algorithms that address these problems in a way that can be verified statistically. The output of traditional machine learning algorithms, Upfal said, is generally not confirmed in an objective way. Take search engines as an example. If the search algorithm consistently returns the kinds of results users are looking for, theyll keep using it and the algorithm will be deemed successful. But that evaluation is subjective and largely unquantifiable. In scientific applications, you need something that can be analyzed rigorously, Upfal said. We need to know the confidence level of the outcome. So a key aspect of this project will be combining traditional machine learning algorithms with the most rigorous of statistical methods. Daunting as the obstacles may be, Upfal and his colleagues have already had success in addressing them. Last year they developed an algorithm called HotNet that helps to isolate clusters of mutated genes that can cause cancer. Theyre hoping to build on that success with this new grant. Ultimately, Upfal said, the team hopes to develop new tools that can be broadly applied not only to genomics data but also to other Big Data problems like the analysis of large-scale social networks.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Brown awarded $1.5M for new Big Data tools"], "word_count": 673, "token_count_estimate": 792}}, "https://cs.brown.edu/news/2014/03/14/iman-hajirasouliha-receives-nserc-fellowship/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Iman Hajirasouliha Receives NSERC Fellowship Posted by Jesse Polhemus on March 14, 2014 Postdoctoral Research Associate Iman Hajirasouliha of Brown Universitys Computer Science Department and the Center for Computational Molecular Biology CCMB has just received a Postdoctoral Fellowship from the Natural Sciences and Engineering Research Council of Canada NSERC for his proposal Algorithms for constructing ancestral history of deep-sequenced tumors on cancer heterogeneity. Iman is the second member of BrownCS to receive the fellowship, joining Glencora Borradaile, who received hers in 2007. Its very exciting and gratifying, he says. I knew that this fellowship is competitive, and I was thrilled that my proposal was accepted. It shows the importance of computational methods to help combat a very complex disease. Iman goes on to explain that we find ourselves at a pivotal moment in cancer research. Only in recent years have scientists discovered that mutations thought of collectively by the general public for example, breast cancer or lung cancer actually vary considerably from person to person. Perhaps even more interestingly, heterogeneous mutations can exist across a single tumor. The goal here and now, Iman says, is to characterize that heterogeneity. The Postdoctoral Fellowships Program, which is in the amount of 40,000 per year for two years, offers an attractive opportunity to continue that effort. It was created to support researchers of promise at a crucial moment in their careers, with the goal of creating a pool of Canadians with top-quality research and scientific skills to supply the Canadian government, industry, and higher education system. NSERC Postdoctoral Fellowships are extremely competitive, and only a few are awarded each year to Canadians working at institutions in other countries. This fellowship is well-deserved, says Ben Raphael, Associate Professor of BrownCS and Director of the CCMB, who has supervised Imans recent work. Hes one of the star PhDs in his research area, and Im equally proud of his abilities as a mentor and collaborator. Iman returns the compliment with a broad smile. Im really grateful to Ben and the colleagues of mine that have made this opportunity possible. Thank you all.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Iman Hajirasouliha Receives NSERC Fellowship"], "word_count": 361, "token_count_estimate": 463}}, "https://cs.brown.edu/news/2013/06/18/phd-student-jeff-rasley-receives-nsf-graduate-research-fellowship/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Ph.D. Student Jeff Rasley Receives NSF Graduate Research Fellowship Posted by Angel Murakami on June 18, 2013 Computer Science PhD graduate student Jeff Rasley has received a National Science Foundation Graduate Research Fellowship, a prestigious and highly competitive program. Jeff is broadly interested in networks, distributed systems, and security. His current research is on network profiling of big data workloads, which aims to better understand the interaction and performance of data center networks and big data computing frameworks such as Hadoop. He is advised by Rodrigo Fonseca . Jeff joins our other PhD students who have been recently supported by NSF Graduate Fellowships Connor Gramazio, Michael Hughes, Dae Il Kim, Mark Leiserson, and Layla Oesper.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Ph.D. Student Jeff Rasley Receives NSF Graduate Research Fellowship"], "word_count": 130, "token_count_estimate": 168}}, "https://cs.brown.edu/news/2014/04/01/erik-sudderth-wins-nsf-career-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Erik Sudderth Wins NSF CAREER Award Posted by Jesse Polhemus on April 1, 2014 AssistantProfessor Erik Sudderth of Brown Universitys Computer Science Department has just won a National Science Foundation CAREER Award for his work onBayesian nonparametric learning for large-scale structure discovery. Itsaccompanied by a grant in the expected amount of more than 509,000. He joinsmultiple previous Brown CS faculty winners, including most recently James Hays , Ben Raphael ,and ChadJenkins . CAREER Awards are the most prestigious awards given by theNational Science Foundation NSF in support of outstanding junior facultyteacher-scholars who excel at research, education, and integration of the twowithin the context of an organizational mission. Themotivations for Sudderths research start with very large datasets, which couldinclude anything from the videos available on YouTube to the complete corpus of New York Times articles. Parametric statistical learning algorithms workby tuning model parameters to match a user-specified list of properties, orstatistics, of the data. When these algorithms are used to analyzeimages and video, for instance, humans are required to laboriously collectexamples of objects of interest for example, people, cars, and buildings.This puts real limits on what can be learned from even very big datasets,Erik explains, because the models structure has to be manually specified byexperts. Anonparametric model, however, allows its structure and complexity to bedetermined from the data itself, so it can grow naturally as the data grows.This allows for algorithms that are capable of unsupervised learning, andbecause less manual supervision is needed, such methods are muchmore broadly applicable. The real-world applications for models ofthis kind are almost limitless helping computers analyze photographs to differentiateobjects from their surroundings, or allowing robots to determine humancognitive states based on facial expressions, or finding communities withinsocial networks by analyzing patterns of collaboration. Eriksinnovative research is highly regarded in both computer science andstatistics, comments BrownCS Department Chair Roberto Tamassia . Theprestigious NSF CAREER award is one more indication that Erik is a leader inthe important field of Bayesian nonparametric statistical methods. Iflaypeople find the mathematical and computational methods underlying this worka bit daunting, Sudderth already has their needs in mind. Were very eager,he says, to put useful tools into the hands of people who dont yet know whatnonparametric methods can provide. The five-year term of the grant lets us takea long-term perspective and address the full data analysis process, from modelsto algorithms to usable software. In addition to supporting research, the CAREERgrant funds a three-pronged outreach and education plan that includes 1an accessible Python software package to allow for easier data analysis, 2interdisciplinary research projects involving undergraduate students withtraining in other sciences or the humanities, and 3 two week-long summerschools on Bayesian nonparametrics to be held at Browns Institute for Computational andExperimental Research in Mathematics ICERM. Sudderthscolleagues are eager to see the project begin. Erik does excellent work on allaspects of Bayesian nonparametric models, says Professor MichaelLittman , from devising new mathematical structures, to applying them tointeresting problems in text and vision processing, to developing fasteralgorithms that handle larger and more complex problems, to providing toolkitsso others can leverage these advances in their own work. Im delighted that theNSF recognized his contributions and promise with a prestigious CAREER award. Thisis a big honor, Erik concludes. This award is about making interdisciplinarylinks. Its vital for computer scientists to understand how our code andalgorithms are challenged by complicated, messy datasets, and its equallyimportant for those in other fields to see how computer science can be used tohelp understand their data. Im extremely excited.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Erik Sudderth Wins NSF CAREER Award"], "word_count": 591, "token_count_estimate": 797}}, "https://cs.brown.edu/news/2014/05/29/browncs-celebrates-35-years/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles BrownCS Celebrates 35 Years Posted by Jesse Polhemus on May 29, 2014 by Kevin Stacey Science News Officer, Physical Sciences As the Brown community came together to celebrate Commencement in the Universitys 250th year, computer science alumni reunited this weekend to celebrate another anniversary. This year marks the 35th year of Browns Department of Computer Science , which was founded in 1979. Much has changed in computer science in those 35 years. The department started with one general-purpose computer a lone Digital VAX-11780. It was joined shortly thereafter, in 1981, by another of the same model. The two were affectionately dubbed Nancy and Sluggo after the cartoon characters. Nancy, which now resides as a museum piece on the third floor of Browns Center for Information Technology Building, boasted a whopping 512 kilobytes of memory and 67 megabytes of disk space. It was state-of-the-art at the time, but today, an iPhone 5 has about 18,000 times more computing power. In the years that followed, things ramped up quickly. We wrote a proposal to the National Science Foundation for an infrastructure grant to provide funding to purchase computers for the department for both research and teaching, said John Savage, the An Wang Professor of Computer Science and one of the departments founders. By the fall of 1983, we had the first electronic classroom populated with powerful workstations. Today, the department boasts several labs filled with computers for student use, and a cluster consisting of 180 different computers and 1,800 central processing units for intensive research. What hasnt changed in those 35 years is the departments commitment to groundbreaking research and graduate education, coupled with an undergraduate experience that is second to none. Thats a tradition Im very proud of, said Andries van Dam, the Thomas J. Watson Jr. University Professor of Technology and Education, professor of computer science, and the departments first chair. Early years While the department was formed in 1979, the story of computer science at Brown goes back more than a decade earlier. In 1965, van Dam, who was awarded the second Ph.D. ever in the burgeoning field of computer science, joined the faculty in the Division of Applied Mathematics. Two years later, Savage joined the faculty in what was then the Division of Engineering. Along with Peter Wegner, also in Applied Mathematics, the trio formed the core of what would become Browns program in computer science. Making the leap from program to department met with some early resistance, van Dam says. Starting a Department of Computer Science in an age where people appreciate the discipline on one hand but dont think of it on equal terms as they do their own discipline on the other, has been a bit of a rough ride at times, he said. But Im pleased to report that overall Brown has treated us well. These days the University truly values the contributions computer science can make. One of the founding principles of the department was articulated in a mission statement developed very early. The faculty chose a theme for the department balancing theory and practice. We asked the question What distinguishes us from other institutions Savage said. There was Cornell, which was very theoretical. The faculty was dominated by people with mathematical backgrounds. One of the other leading departments was Carnegie Mellon, and they were primarily experimentally oriented. So we looked at our interests and found we had some people interested in the theoretical side of the house and others in the more applied side of the house. So we chose that theme for that reason. Research in the early days of the department was very much focused on building the foundations of a discipline in its infancy. Brown faculty made crucial contributions in those early years. Van Dam worked with his students on the earliest hypertext systems, precursors to modern webpages with hyperlinks. He was also a pioneer in the field of computer graphics. He was co-author of the textbook Computer Graphics Principles and Practice , considered to be the Bible of computer graphics. His research and books are widely recognized to have been influential in creating computer-aided design systems and modern animated films. Having invited him to the premiere of the blockbuster Toy Story , Steve Jobs presented van Dam with a book on the making of the film that included the inscription, You made it so. Savage made crucial theoretical contributions to the coding and decoding of information for storage and transmission. He showed that these processes were intimately related to the size and depth of the circuits on which they are computed. He wrote the first book on this topic, known as circuit complexity, which is now a cornerstone of theoretical computer science. Peter Wegner did seminal work on the theory and practice of programming languages. He pioneered object-oriented programming, a paradigm shift that led to modern computer languages like C , Java, Python and others. Thanks to John, Andy, and Peter, Brown became internationally known for computer science research in the 60s and 70s, well before the CS department was founded, said Roberto Tamassia, the Plastech Professor of Computer Science and current department chair. Founded on undergraduate education While pioneering research helped to put the department on the map, a priority was placed on undergraduate instruction from the beginning. You can look at the development of computer science and see that Brown was essentially unique in those early days in that we taught computer science not just at the graduate level but also at the undergraduate level, van Dam said. I was told by the top schools in computer science at the time that it was wrong to teach undergraduates computer science. They felt computer science should be a specialized graduate school-only discipline, and those departments didnt really take undergraduates seriously until the late 90s in some cases. So Brown was a full 30 years ahead of other institutions in terms of offering degrees in undergraduate computer science. That meant taking conscious steps to make sure that top faculty balanced their research and teaching responsibilities. It is very much part of our departmental culture that everybody teaches at every level, van Dam said. Despite the fact that weve become rather larger than we ever anticipated, Brown has preserved a sense that undergraduates matter as much as graduate students. That meant limiting, to some extent, the number of graduate students each professor would take on. One of the many foundational issues we tackled was what kind of department we wanted to be. Do we want to be big, or do we want to be in the Brown tradition of small is beautiful van Dam said. We tried to settle how many Ph.D. students we wanted to have with classic math or computer science humor. We bounded the number between e Eulers constant and Pi. So on average, each professor should have between 2.7 and 3.14 graduate students. Countless students, both graduate and undergraduate, have gone on to successful careers both in academia and industry. Van Dam counts at least seven graduates who have gone on to chair computer science departments around the country, including powerhouse departments at MIT and the University of WashingtonSeattle. Others have taken top executive positions at companies like Intel, Microsoft, and Google. Today, that commitment to undergraduate education is buttressed by a program that puts undergraduate teaching assistants in all the lower-level classes. Tamassia refers to the undergraduate teaching assistants program as the departments flagship program. For every undergraduate course, Brown aims to provide one undergraduate TA for every 10 students. The TAs hold extensive office hours to tutor fellow students, while helping professors in the creative endeavor of developing new assignments and projects. The TAs develop leadership and communication skills while gaining a deeper understanding of the material, Tamassia said. This system has been copied at other institutions. It has worked extremely well. The Future is Bright Initiatives like the undergraduate TA program have helped the department manage a tremendous growth in enrollment. In the last six years, the enrollment in undergraduate computer science courses has tripled and computer science has become the second-largest declared concentration on campus. This year, a record number of degrees were awarded to 114 undergraduate computer science concentrators and 59 masters and Ph.D. students. Increasing interest in computer science on the part of students is a global phenomenon, Tamassia said. The most important reason is that computer science is becoming pervasive in society, in business, in science, and in the way people interact. There are more and more exciting careers opening up for our graduates. Theres a need for computer scientists in all other sectors of the economy. The department has 26 highly decorated tenured and tenure-track faculty . Research in the department has taken on a decidedly outward-facing character, Savage says, with researchers forming new partnerships across campus and across disciplines. A burgeoning robotics group is working to expand the use of robots in healthcare, education, industry, and elsewhere. Browns Center for Computational Biology is bringing the power of computers to problems in the life sciences, including the development of algorithms to help unravel the genetic underpinnings of cancer. The artificial intelligence group continues to develop strategies to help machines better solve problems and interact with people. The graphics, visualization, and interaction group continues a long tradition of creating new ways for people to leverage the power of computers through novel human-computer interfaces, immersive virtual reality, pen computing, behavioral modeling, and internet-scale image analysis. The data systems group is addressing the big data challenges faced by the industry, sciences, and engineering fields by developing highly scalable and usable data management and analytics software. Other faculty are involved in foundational hardware and software systems research ranging from computer architecture to computer networks, distributed computing, and programming environments. Finally, a number of faculty are attacking the grand challenge of securing cyberspace in an increasingly digital world with a broad approach that includes cryptographic foundations, programming languages, cloud computing, and Internet governance. A list of research areas pursued by faculty in the department is available online . Above all, the department has maintained its standing as one of the top computer science programs in the country. Possibly the most distinguishing feature of the department is that we compete with departments that are much larger in size, Tamassia said. We have truly outstanding faculty members. Our people are at the top of the field.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "BrownCS Celebrates 35 Years"], "word_count": 1747, "token_count_estimate": 2063}}, "https://cs.brown.edu/news/2014/09/26/chad-jenkins-and-his-team-help-develop-nasa-software/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Chad Jenkins And His Team Help Develop NASA Software Posted by Jesse Polhemus on Sept. 26, 2014 by Kevin Stacey Science News Officer, Physical Sciences Brown CS students continue to distinguish themselves at hackathons nationwide. To read more on this topic, click here . A group of computer scientists from Brown were at the Johnson Space Center in Houston recently for a week-long marathon of intensive coding to build new software for the Robonaut 2 and other NASA robots. The coding marathon, known in the computer science vernacular as a hackathon, was a partnership between NASA, Brown, and the University of TexasAustin. The work was part of a NASA grant awarded recently to Chad Jenkins, associate professor of computer science and engineering at Brown. Jenkins lab builds user interfaces that can control robots of all kinds with an off-the-shelf web browser. The system can be adapted for even the most complex robots, and NASA wants Jenkins and his team to adapt the interface for the humanoid robot, Robonaut 2 R2. As it is now, R2 can be controlled only from computers with specialized software that can communicate with R2s operating system. The interface Jenkins and his team are developing creates a software bridge that enables a web browser to communicate with that operating system. That means all of the R2s complex capabilities could be accessed from virtually any computer or even from tablets. The goal of the hackathon was to lay the groundwork for the project. Jenkins was joined at the hackathon by research scientist John Raiti, undergraduate student Matt Wong, and David Lu, a researcher from Washington University working with Jenkinss lab. Before the hackathon started we only had a first pass of a web interface, Raiti said. But by the end we were able to demonstrate through simulation a working interface for control of the Robonaut 2. By simulation, Raiti is referring to a virtual version of R2 that runs on a computer server. Operating the real thing comes later. There are currently two R2s, one aboard the International Space Station and one operating at the Johnson Space Center. The earthbound version is used to test code and do safety checks for the orbiting version. The new web interface will enable the R2 on earth to be controlled from a Web connection anywhere. Astronauts could control the orbiting R2 with nothing more than a tablet. Matt Wong, a rising senior and computer science concentrator, relished the chance work on the project and make the trip to Johnson Space Center. His work on the project this summer was supported by Browns Karen T. Romer Undergraduate Teaching and Research Awards program. The hackathon also gave me an opportunity to meet more people involved with robotics, as we worked alongside several NASA employees as well as a group from UTAustin, Wong said. It was a really rewarding experience. He and his fellow hackers churned out thousands of lines of code during the week. The group was pleased with what they were able to accomplish. Most of the work I did at the hackathon revolved around setting up the basic structure to enable communication between our browser-based front-end and the back-end server on which robot code actually runs, Wong said. We made good progress at the hackathon, but theres still a good amount of work to be done before the web interface is fully functional. Wong said he looks forward to continuing his work on the project when school starts again. For Jenkins, the R2 project is part of a broader effort to make robots more accessible to more people. His lab has already designed web interfaces that can control the PR2 household assistance robot, quadricopter drones, and other devices. The idea is that we want to be able to make robots available to everybody in the world through the Internet, using the web browser, Jenkins said. This is our way of getting robots out of the lab and into the world.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Chad Jenkins And His Team Help Develop NASA Software"], "word_count": 675, "token_count_estimate": 808}}, "https://cs.brown.edu/news/2014/11/11/philip-klein-wins-nsf-grant-optimization-planar-graphs-and-beyond/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Philip Klein Wins NSF Grant For Optimization In Planar Graphs And Beyond Posted by Jesse Polhemus on Nov. 11, 2014 Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Kleins recent project Fast and accurate optimization in planar graphs and beyond has won a grant in the expected amount of 1.2M from the National Science Foundation NSF, shared with Professor Jeff G. Erickson of the University of Illinois at Urbana-Champaign. Kleins research involves discovering and analyzing algorithms for optimization problems in graphs, problems such as traveling salesman , shortest paths , network design , clustering , graph decomposition , and facility location . The grant supports work aimed at discovering algorithms that are designed specifically for planar graphs---graphs that can be drawn on a plane so that no edges cross. When the input graph is required to be a planar graph, we can achieve faster running times and more accurate approximations than we know how to achieve in general. Road maps are nearly planar, so planar-graph algorithms are applicable to problems in logistics and planning in road maps. Grids are planar, so some problems in image processing can be addressed using planar-graph algorithms.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Philip Klein Wins NSF Grant For Optimization In Planar Graphs And Beyond"], "word_count": 217, "token_count_estimate": 265}}, "https://cs.brown.edu/news/2015/03/17/jeff-huang-wins-nsf-crii-grant-and-salomon-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Jeff Huang Wins NSF CRII Grant And Salomon Award Posted by Jesse Polhemus on March 17, 2015 in Awards Brown CS community members continue to win noteworthy grants and awards. To read more articles click here . Less than two years after his arrival at Brown University s Computer Science Department , Assistant Professor Jeff Huang has received a Richard B. Salomon Faculty Research Award from Browns Office of the Vice-President for Research as well as a National Science Foundation NSF Computer and Information Science and Engineering CISE Research Initiation Initiative CRII grant. CRII is a new program aimed at encouraging research independence among scientists in their first academic position, and Jeff is its first grant recipient at Brown CS. The Salomon Award, given annually, was established to support excellence in scholarly work by providing funding for selected faculty research projects of exceptional merit with preference given to junior faculty who are in the process of building their research portfolio. Jeff joins multiple previous Brown CS winners, including Stefanie Tellex , Rodrigo Fonseca , and Ugur Cetintemel . This research is about democratizing eye tracking, Jeff explains. Its extraordinarily useful in applications ranging from human-computer interaction studies to medical research, but the tracking devices are highly specialized, can cost tens of thousands of dollars, and are difficult to calibrate and use. Thats restricted their availability to mostly on-site labs. On the other hand, he says, many of us have one of the low-end webcams that are widely available around the world. I intend to provide one of the first opportunities for turning them into tools fit for professional study. This can be done by using user interactions to continuously calibrate the eye tracker during regular activity. Jeffs earlier research reveals that when a user clicks on a web page, they first look where they intend to click, and that the eye is likely to be two to four characters to the right of the last typed character on the screen. Webcam images during these user interactions can be collected by the website to use as cues for what the users pupil looks like when that user interacts with a particular location. Future observations of the pupil can be matched to past instances with similar-looking pupils as the eye tracking system collects mapping of pupil features to eye-gaze locations on the page, allowing a model to infer the eye-gaze location even when the user is not interacting. Collaborating with Jeff is an exceptional experience, says PhD candidate Alexandra Papoutsaki , one of his collaborators. He has a diverse background and can bring together concepts from different domains. As part of designing our first eye-tracking algorithm, were working with Professor James Hays and his Masters student, Patsorn Sangkloy . Its a challenging problem, Patsorn says, especially when peoples eyes can be so different. I think weve made good progress, and I cant wait to see where eye-tracking could lead to. I believe its going to play an important role in the development of future technology, says Alexandra. Eye-tracking is far more inclusive than touch or click interactions and can even be used by people with motor impairments. Once it reaches a stable phase, I think that well be surprised by the unexpected uses that appear. This is special because it frees eye tracking from the confines of the lab, Jeff says. Sharing my work and source code will set this technique loose so it can be used in a broad range of applications. With no need to install additional software, eye tracking can go anywhere. Think of the possible output everything from new types of online games to superior website navigation for the impaired to improved search engine results could become part of the natural Web experience of everyday users.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Jeff Huang Wins NSF CRII Grant And Salomon Award"], "word_count": 643, "token_count_estimate": 752}}, "https://cs.brown.edu/news/2015/05/07/nobel-laureates-scholars-discuss-computation-future-their-fields/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Nobel Laureates, Scholars To Discuss Computation In The Future Of Their Fields At May 12-15 Symposium Posted by Jesse Polhemus on May 7, 2015 by Kevin Stacey Science News Officer, Physical Sciences A group of scholars including three Nobel laureates will gather at Brown for a week-long series of talks on the future of their fields and honoring the legacy of computer pioneer and scientific polymath John von Neumann. The Brown University 250th Anniversary Symposium The Next 250 Years, May 12-15, 2015, will feature talks in economics, physics, computer science, and brain science. PROVIDENCE, R.I. Brown University John von Neumann was without doubt one of the 20th centurys greatest minds. He is considered to be one of the founders of digital computing, pioneered game theory as a model of decision-making, and made critical contributions in the fields of physics, applied mathematics, and engineering. Next week, renowned scholars including three Nobel laureates and a Turing Prize winner will give lectures at Brown in economics, physics, computer science, and brain science. Speakers will reflect on what the future may hold for their disciplines, while emphasizing von Neumanns vision of computation as a scientific lens. Fourteen von Neumann lectures will be given over four days, May 12-15, 2015. Each days session will include a sweat box session an intensive question-and-answer forum with some of the days speakers. Von Neumann was dedicated to the idea that we should tackle the hardest problems, working in symbiosis on the most abstract and most practical aspects of the problem in an intra-math, inter-sciences, cross-cultures, interdisciplinary approach, said Sorin Istrail, the Julie Nguyen Brown Professor of Computational and Mathematical Sciences. Von Neumanns seminal research is organically aligned with Browns research mission across departments, inspiring us as we focus on the next generation of research problems. The weeks talks are free, open to the public, and will be held in Browns Center for Information Technology. The lectures will be webcast live . Speakers will include Kenneth Arrow, winner of the 1972 Nobel Prize in Economics Leon Cooper, Brown professor and winner of the 1972 Nobel Prize in Physics Frank Wilczek, winner of the 2004 Nobel Prize in Physics Leslie Valiant, winner of the 2010 ACM Turing Award and Freeman Dyson, physicist and mathematician, reflecting on his experience as a colleague of von Neumanns at the Institute for Advanced Study. The full schedule of 14 lectures, with information about the speakers, is available online . The symposium was organized by Brown professors Cooper physics, Istrail computer science, Stuart Geman applied mathematics, and Roberto Serrano economics. Each considers von Neumann a hero and has tried to incorporate his vision into research and teaching. This is the second von Neumann symposium to be held at Brown. The prior event, the kick-off the John von Neumann Distinguished Lecture Series, was held at Brown in 2010 . The event is co-sponsored by Browns Office of the President, Office of the Provost, Office of the Vice President for Research, Office of Browns 250th Anniversary, Department of Computer Science, Department of Economics, Department of Neuroscience, Department of Physics, Center for Computational Biology, and Department of Biostatistics. It is hosted by the Department of Computer Science.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:31+00:00", "headings": ["Information for:", "Brown CS News", "Nobel Laureates, Scholars To Discuss Computation In The Future Of Their Fields At May 12-15 Symposium"], "word_count": 544, "token_count_estimate": 715}}, "https://cs.brown.edu/news/2015/05/11/visualization-and-creativity-immersive-3d-environments-cave-yurt-may-20-21-2015/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Visualization And Creativity In Immersive 3D Environments -- From Cave To YURT May 20-21, 2015 Posted by Jesse Polhemus on May 11, 2015 sponsored by the Office of Brown Universitys 250th Anniversary, the Brown University Center for Computing and Visualization, Brown University Computing and Information Services, and the Brown University Sciences Library the YURT has been developed with funding from NSF For more CS News and CS Blog articles about the Yurt, please click here . We are celebrating the opening of Browns newest virtual reality environment, the YURT YURT Ultimate Reality Theatre, in the context of the many decades of visual study that presaged it. This immersive environment fully engages our visual senses for exploration and discovery in areas as diverse as planetary geology, mathematics, visual art, digital literature, and biology. With head and body-tracking, users control a virtual world shown on a room-sized, 100 million-pixel stereo display that completely surrounds them. You have to experience this unique instrument to truly understand and appreciate it. Join us to learn about the future of virtual reality from some of the fields greatest innovators and to experience the reality for yourself. Please do two things immediately in order to attend E-mail Jesse C. Polhemus to register. Please note that some events have already reached maximum attendance. Book a hotel room if necessary Hotel Providence 401-861-8000, the Biltmore 401-421-0700, the Wyndham Garden 401-272-5577, or the Marriott 401-272-2400. Agenda All talks will be in Martinos Auditorium, Granoff Center, with other locations indicated below. Wednesday, May 20 9am-1pm Attendees will be invited to sign up for presentations in both new YURT and the legacy Cave on Wednesday morning, and subsequently on a drop-in basis throughout Thursday with priority given to those registered for the symposium, and any free spaces then offered to the Brown community at large. YURT 180 George St at Brook Cave Granoff Center, Studio 4, N330 Guided presentations from 9am to 1pm at both sites will last 45 minutes 130-2 pm Welcoming remarks and introduction 215-330 pm Keynote by Henry Fuchs 330-4 pm Coffee, tea, snacks available Granoff Center, Foyer 4-515 pm Fritz Drury and John Cayley Teaching in Immersive Audiovisual Environments VR Design for Science and Cave Writing 530-630 pm Reception and YURT Inauguration with Provost Vicki Colvin Please note the venue Brown CIT Building, 3rd Floor, Thomas J. Watson Sr. Center for Information Technology 730 pm Symposium dinner for selected participants Please note the venue The Hope Club Thursday, May 21 930 am and throughout the day coffee, tea, pastries, and snacks Granoff Center, Foyer 10-1115 am Steven Feiner and Tom Banchoff 1130-1245 pm Jim Head 1-145 pm Pick up lunch boxes in Granoff Center or on your own locally 245-4 pm Joe LaViola 3D User Interfaces in Virtual Environments Past, Present, and Future and Roderick Coover 4-430 pm Coffee and tea 430-545 pm Noah Wardrip-Fruin The Power of Presence with Virtual Art and Dan Keefe Magical User Interfaces Bringing Interactivity to Immersive Science and Art 6-630pm Symposium closing FAQ Where can I find parking How do I find help for my special accessibility needs Parking may be limited, so we recommend carpooling or alternative methods of transportation if possible. You can find more information about parking and accessibility here . I have another question. Could you please help Wed be happy to Please e-mail or call 401-863-7600.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Visualization And Creativity In Immersive 3D Environments -- From Cave To YURT: May 20-21, 2015"], "word_count": 574, "token_count_estimate": 809}}, "https://cs.brown.edu/news/2015/05/15/michael-littman-wins-ifaamas-influential-paper-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Michael Littman Wins IFAAMAS Influential Paper Award Posted by Jesse Polhemus on May 15, 2015 in Awards Professor Michael Littman of Brown University s Department of Computer Science has just won the International Foundation for Autonomous Agents and Multi-Agent Systems IFAAMASs Influential Paper Award for work Markov games as a framework for multi-agent reinforcement learning originally published at the Proceedings of the Eleventh International Conference on Machine Learning ICML in 1994. The award was established by IFAAMAS in 2006 to recognize publications that have made seminal contributions to the field. Such papers represent the best and most influential work in the area of autonomous agents and multi-agent systems. These papers might, therefore, have proved a key result, led to the development of a new sub-field, demonstrated a significant new application or system, or simply presented a new way of thinking about a topic that has proved influential. This award, following shortly after his 2013 AAAI Classic Paper Award, is another example of the continued recognition of Michaels insight, influence, and distinguished contributions to the field. Congratulations", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Michael Littman Wins IFAAMAS Influential Paper Award"], "word_count": 191, "token_count_estimate": 245}}, "https://cs.brown.edu/news/2015/05/18/celebrate-andy-50-years-cs-brown/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Celebrate With Andy 50 Years Of CS At Brown Posted by Jesse Polhemus on May 18, 2015 As the department approaches its silver anniversary, Brown CS is making a comprehensive effort to document our early history online and in print. Our themes are the intellectual daring of our academic home, the making of things never before imagined, and the spirit of community thats guided the entire effort. Throughout, our storytellers will be the faculty and alumni whose examples go before us. This article is the first in that series. Andy would like to mention that in the writing of this piece, he remembered many other stories and many other key contributors that we were unable to include due to space limitations. The semicentennial festivities known as Celebrate With Andy , to be held on May 22, mark three golden anniversaries for the Brown CS family fifty years of the UTA program, undergraduate involvement in research, and Andy van Dam at Brown. A thousand words dont suffice to tell the history of those three institutions, but one picture from our archives evokes something of their spirit. Believed to be taken at Commencement 1977, it shows van Dam and five others Heather Claflin 77, Peter Relson 77, Douglas Dixon 77, the late David Notkin 77, and Henri Bulterman 71 77 ScM , some in regalia and some not. Laughter and conversation are passing diagonally across the scene, and just for a moment, neither in the center of the composition nor at the Golden Mean, Andy has turned to the camera very casually Look at the great people weve got here Its time for a toast. Romulus and Remus are fables Brown CS doesnt require a founding myth because the true history of these three institutions is compelling enough. This article, however, will give only an abbreviated version of that story and tell just a fraction of the anecdotes. Wed rather you join us in person or via livestream on May 22. Instead, in preparation for all the fun of Celebrate With Andy , lets take a few moments now to go back in time to reflect, enjoy, and celebrate. A Random Sequence The story of CS at Brown begins, humbly enough, in a bathroom. In 1962, Andys wife, Debbie, was teaching high school French, and one of her National Education Association magazines had ended up as his bathroom reading material. I read an article, he remembers, about teaching students at Bronx High School of Science to program and thought, Thats ridiculous Im in grad school, just learning to do that But it kept bugging me, and I figured that it wasnt quantum physics, that they could certainly learn logical thinking. So in 1962 he began a summer program of his own, showing Philadelphia area high school students and their teachers how to program, and even managed to obtain his first NSF grant, to support this novel project. Running this course is how I fell in love with teaching, van Dam says, noting that the program continued on after his tenure. Alumni of the pioneering effort include Elliot Perlman, a prominent local ophthalmologist who today counts Andy and Tom Doeppner among his clients our own Steve Reiss was a later graduate. I was teaching programming, Andy says, but in my own first course in grad school, I didnt actually get to use a computer because Penns sole computer was too scarce a resource. We wrote machine code on paper and had our programs hand-corrected, but at least I got to see the mainframe He describes as pseudo-religious the experience of standing not just in the the machine room of UNIVAC 1, but inside its main memory, a little room consisting of a thousand words of memory implemented with mercury-filled acoustic delay lines. My arrival at Brown is based on a nearly random sequence of happenstance events, says Andy. Reading the magazine article was the second one. The first was an unplanned conversation that got me into computer science to begin with. I was a hard-core electronics engineer, with an offer from Bell Labs to go design transistor circuits. But I went to grad school to learn more about the field, and my officemate mentioned that there was a new course on computers We both have electives, so how about this new Computers and Automata course Up until that point, Id only worked on analog computers, not digital ones, and I fell in love and switched my field. Over the years, and even now, as I interview new TAs, hundreds of people have shared similar experiences with me taking a CS class at random, falling in love, and realizing for the first time what they want to do with their professional lives. Its many peoples story, not just mine. The third random event was the one that brought Andy to Brown. Reading that magazine, he says, led to teaching, and teaching led to a phone call three years later from a graduate of the summer program, James Castellan, who was then a student in Applied Math at Brown. Castellan called Andy after van Dam had all but accepted his first academic job elsewhere, asking if Andy knew that they were recruiting a CS person in what students called Apple Math at the time. I dont know anything about Brown or Applied Math, Andy replied, adding that hed essentially already made his decision. Jim persisted, saying that Brown was the perfect place because of its emphasis on undergraduate teaching. I spent one day here, Andy says, and knew it was the right place because of their early history using computers in Applied Math and Engineering and especially because of the undergraduate emphasis. The clincher, he adds, was when the Chairman of Applied Mathematics excused himself in the middle of Andys candidate interview to go teach a first-year course. Thinking Of Themselves As Computer Scientists Understanding the genesis of undergraduate teaching assistants and undergraduate research is impossible without seeing the context of specialization and the departments formation. Future articles will address this issue in depth, and be narrated by others, but these new roles for undergraduates were were born in what van Dam calls those workaholic, all-consuming, frantic early days. For some time, Andy says, there had already been LISP and FORTRAN programming courses at Brown, but I was brought to Brown to create a formal computer science track within the Division of Applied Mathematics. Applied Math didnt see CS as something self-standing, but by the late 60s, after John Savage and Peter Wegner and several others came to Brown, undergraduates began thinking of themselves as computer scientists your degree would say Applied Mathematics on it, but effectively, you were a computer scientist. Andy, John, and Peter initially proposed a Center for Computer Science, but --amazing in retrospect-- the Universitys response to the proposal was negative, and so the three colleagues drafted a two-division program uniting CS-oriented faculty and courses from Applied Math and Engineering. In essence, it was a trial department, followed by the official establishment of the Brown CS Department. Andy was the Program Director and reported to both Division Chairs in the final year of three, John served as Acting Director in his absence until Andy returned from his sabbatical at CERN and the University of Geneva in the summer of 1979 to become Chair of the new Department. When the time came to start a computer science degree program at all three levels undergraduate, Masters, and PhD, competing universities were anything but amenable to the idea of undergraduate CS education. Heres the thing, van Dam explains. Even if we didnt call it that, Brown almost exclusively pioneered the idea of an undergraduate CS program, which our competitors said was premature specialization -- they thought students should wait to specialize in CS at the few grad schools that offered programs at that time. The genesis of undergraduate participation in teaching and research has to be contextualized by the fact that in 1965, teaching computer science as a degree program, not just a few programming courses, to undergrads at all was novel. Teaching these various topics in computer science that were being taught at the graduate level elsewhere to undergraduates, even beginning undergraduates, worked at Brown because of the high quality of the students who were willing to be part of this total immersion style of learning. Offering teaching and research assistant opportunities to undergrads, he says, was even more unusual, indeed was viewed with everything from skepticism to outright hostility. Hardly anyone said, What a fantastic idea Everyone was used to four years of preparation as an undergraduate, then n years of graduate work before you could contribute to a science. But were different. CS was and is young, experimental, and open for undergrads to contribute. And undergraduate participation in research in all fields has become commonplace, especially in the last decade. Born Of Necessity The UTA Program In 1965, a single, intense full-year course could cover much of the breadth, if not the depth, of the systems-oriented portion of the discipline, not including theory, AI, numerical analysis, and a few other topics. Andy insisted that students couldnt learn to be good programmers by solving small toy problems they had to write significantly-sized programs, each taking multiple weeks. Not just checking for the right answer but giving useful feedback on structure, style, and efficiency required careful reading and one-on-one help with concepts and debugging. In a class with forty students, it was impossible for one graduate TA and a professor to provide this level of attention, no matter how little sleep they were getting, so van Dam asked for help from students who had taken a prior programming course. In that first cohort, he remembers Bill Adcock Dan Bergeron, who also subsequently got his PhD with Andy and became Chairman of the CS Department at UNH and went with him and a group of six other of Andys students for his first sabbatical in 1971 at the University of Nijmegen in Andys country of origin and Dennis Ruggles, among others. The undergraduate teaching assistants, Andy explains, though they were initially called graders, didnt just grade programs -- they not only provided one-on-one help to students but also became active participants in course design and in subsequent years read research papers and brought new ideas into the curriculum. In fact, they did everything graduate TAs did, becoming producers and not just consumers of education. We kept modifying the course as we went along, but the one constant was the highly-appreciated UTA system. Few people appreciate it more than Ed Lazowska 72, who will lead the first Stone Age panel for Celebrate With Andy . He says, Im a faculty member precisely because of the UTA program. I went to grad school because Andy told me to. In some way, everything I do professionally today is due to him. To provide feedback for the course, students wrote detailed, multi-page evaluations, something that was almost unheard of in 1965. As Bob Munck recalls, Also after every class, the graders would sit around on the floor of Andys office later my office and critique the lecture and him. Id never seen anything like it. On his commute home from work, Andy would listen to tape recordings of his lectures, filling the empty minutes with self-critiques Boy, was that a clumsy explanation Get rid of the ums and the you knows. Presentation skills are still something that van Dam is keenly interested in. Todays equivalent of you know is like, which I try to stamp out in all students who work with me. Ive given up on awesome. An interesting aspect of the UTA program is that the system has essentially never been challenged by students due to the built-in checks and balances. By having rotating TAs and detailed rubrics, Andy says, you create fairness. Its a system thats at least as fair as having a single faculty member grading. Besides, a single faculty member, even assisted by a few graduate TAs, cant begin to read that many programs at the required level of detail, and students recognize that. Part of the checks and balances is that faculty members are responsible for assigning the final grades, and I personally review all borderline grades, hoping to find evidence for promotion to the next grade bin. Originally something made up as they went along, the UTA program matured over a period of decades. Iteration and gradual regularization brought cross-course norms and standards that are used today by almost all Brown CS courses. In my opinion, says Andy, We have the most systemic TA program, and theres a well-defined appeal system in place to address any grading errors. In some classes, van Dam explains, even PhD students are in a course with undergraduate TAs, but it works for a particular topic, in a particular course, the younger student knows more. He drops his voice an octave to imitate a disbelieving critic. Undergrads grading grad students How can that work His own warm bark of a laugh is flung out with the response Just fine -- in fifty years, Ive never had a complaint from a grad student They respect competence as much as I do. Fearless, Ambitious Undergraduate Research After undergraduates had successfully assisted with teaching, the logical next step was assisting with research the logical choice of accommodation for a research team was a shared room. If these conclusions seem obvious, listen to Andys description of what happened Applied Math had never seen anything like it The biggest room in the building as this nerve center, six hundred square feet for me and an admin and four or five student researchers, going in and out at all hours of the night. They saw us as these unwashed hippie kids, loud adolescents -- how could they possibly do research We occupied the entire basement, too, says Ed, dozens of desks, cheek-to-jowl. What really drove the Applied Math faculty crazy is that we were constantly running from the basement to the third floor. We had weekly project meetings in Andys office, lined with bookshelves and filing cabinets surrounding the desks, where several dozen students would cram in, with no room to breathe. The schleps, as we called them, Andy continues, were a group of more than a dozen undergraduates apprenticing in the group who contributed in every capacity, from getting lunch to reading research papers and explaining them to me to see if they were usable in class. They worked with a few Masters and PhD students, including the late Charles Strauss, Dan Bergeron, and Jim Michener, among others. The bullpen was noisily chaotic, but we were young, and kids have powers of concentration that adults dont. The best part was the selective eavesdropping and peripheral conversations, learning by accident from the people around you. My graphics group still works that way we strongly encourage everyone to be in the graphics lab together multiple nights per week. Resulting in at least five geek-geek marriages, notes Bob Munck, crediting the fact that women were fully equal contributors in Andys group from the beginning. These were the days in which the IBM 360 Model 50, which started with 256KB of memory and no disks and was upgraded to 512KB and a disk array, served the entire university. Normally, users keypunched their programs on decks of IBM cards and submitted jobs that were processed in batches, many hours later. Andys group, doing graphics research on their IBM 2250 display courtesy of an IBM research grant, were allowed small chunks of time during third shift to debug their programs, where an occasional crash that brought down the mainframe was reluctantly tolerated by the operators. Stories of how Andy and company were at times dilatory with food and candy wrapper disposal, how they allowed dogs and therefore, without putting too fine a point on it, the things dogs do into the machine room, and how they bought far more Girl Scout cookies than were strictly necessary from Big Grace, the head operator, are better left for Celebrate With Andy . At the time, these quarter-of-a-million-dollar displays in 1967 dollars close to two million in todays money were rare indeed, and letting undergraduates have access to them was even rarer. With Browns acquisition of the 36067, Andys group became one of the earliest users of virtual memory and virtual machine-based time-sharing. Among the many firsts, Andy explains, Bob Munck and other students built time-sharing systems to run in a partition of the OS on the 36050. Even before his graduation, Bob took the highly unusual step of teaching portions of my courses, on assembly language and other systems topics. Steve Carmody was another student in my first course in 1965, and is still associated with CIS at Brown. He was a leader in the group project to design and implement the first hypertext system on commercial equipment in 1967, the Hypertext Editing System HES. HES was co-designed with Ted Nelson, coiner of the term hypertext. HES was followed by FRESS File Retrieval and Editing System, which was an active project for more than a decade, starting in 1968. Many undergraduates contributed to its design and implementation, including the late Bob Wallace, who was one of the seven original founders of Microsoft and the inventor of shareware with his utility, PC-Write. As part of the LSD Language for Systems Development project to define a systems programming language and create an optimizing compiler for it, led by Dan Bergeron as a PhD student, Andy recalls the thrill of having exclusive access to some highly sought-after IBM software. We were using a proprietary systems dialect of the standard language, PLI, called PLS, he says. It was never used by anyone else outside the company, and even years later, Id get calls from people within IBM, wondering if I could tell them about this mysterious language that theyd heard about but werent able to get a hold of. We were also among the very first to do simple distributed computing by attaching graphics mini-computers to a mainframe. The late George Stabler and Rick Harrington, Andy adds, a PhD student and undergraduate, respectively, designed, implemented, and published the first remote procedure call RPC protocol to allow code modules on the graphics satellite and code modules on the mainframe to call each other, and even to let code migrate to do load balancing from one to the other, at least a decade before other organizations reinvented the idea of RPC. To make our microprogrammed multiprocessor graphics satellite even more real-time, undergraduate Hal Webber designed and built the first high-performance, microprogrammable 3D and 4D homogeneous coordinate transformation engine, SIMALE, now part of our Computer Museum. PhD student Jack Stankovic, who became the Department Chair at UVA, and I ran the first workshops on distributed computing in the 1970s. The whole idea about being a research assistant, says Ed Lazowska, was that Andy asked us to figure out how to do things that hadnt been done before. It was the first time that someone had treated me as an intellectual peer and showed confidence that I could do the tasks that adults could do. The whole group was remarkable, and Andy and Charles had an extraordinary impact on me. They totally captured my imagination. Even the briefest look at Strausss research gives a powerful sense of the time. For the first time, his work with a light pen and specially-designed stereoscope that fused left and right images on a split screen allowed the user to navigate a live, 3D stereo representation of the layout of pipes in an oil refinery, helping identify potential interference between pipes. For the computer user of today, the world in which mainframes rented for tens of thousands of dollars per month is scarcely thinkable. Looking that many decades into the past, we might be impressed to find graphics of any kind, even 2D. Yet in this case, 2D wasnt sufficient, and neither was static 3D Brown had to pioneer not just 3D graphics but interactive 3D stereo motion graphics to provide the functionality required. Working with Professor Tom Banchoff of the Math Department, Charles was the first to provide real-time manipulation and visualization of Mbius strips and 4D geometry hypercubes and hyper tori. Banchoff-Straus Productions continued for decades and produced impactful movies of manipulations of 4D geometry, which were greatly aided by Hal Webbers SIMALE. Up until this point, computers were used almost entirely for crunching numbers, and computers with graphics were for oil companies and car and airplane manufacturers, says Ed, whose Brown independent concentration was titled Non-Numerical Computer Science. With HES and FRESS, we were working with text Not just text, but WYSIWYG hypertext. It wasnt until that point, says Ed, that you could actually put the word personal in front of the word computer, although our PC was a multi-million dollar mainframe. Thats all Andy. Andy shrugs. We were just fearless, we had ambitious ideas, didnt really know what was possible and what was not. I had all those smart and highly motivated kids available, so we took wild, crazy ideas and ran with them. Creative Expression Whats the common link between undergraduate teaching assistants and undergraduate researchers Creating knowledge, says Ed, not absorbing knowledge. Creativity. Teaching and research both need this in spades. Janete Perez 06, who will lead the third Machine Age panel at Celebrate With Andy , says, I wanted to be a UTA like high schoolers want to be on the varsity football team...To add to a class, make it more fun, be part of it all...Andy finds the kids that are really excited, not just the straight-A students. He teaches you to work hard and be disciplined, but really to be creative. Interestingly, van Dams thoughts move in a similar line when asked about the theme of his lifes work From the time I saw Sutherlands mind-blowing Sketchpad movie in 64, Ive loved human-computer interaction and the visual I really value creative expression in various media. Watching the Sketchpad movie, he says, was another random event that changed my life forever. At the time, computing was done by entering programs and data via punch cards or teletype tape. Programs were run in batches and dealt with numeric data. Sutherland showed the world interactivity, humans working with computers in real-time, and he showed us communicating through drawing and manipulating images directly. It was beyond revolutionary, and like the other random events, it ended up completely determining my career. When advisees come to me obsessed with making a commitment to one research area, I tell them to relax Youre going to experience ideas thatll change your point of view. Be open, experiment, try different things. Youll change your mind a half-dozen times. It was true then and its a hundred times more true now. But back then or now, what could be a taller order than trying to foster creativity After hundreds of thousands of years of human history, our understanding of our creative powers is still incomplete. But lets try. Ed shares a visual from the height of the late 60s hippie era that well return to later driving in a Volkswagen bus in mid-winter to northern Virginia, where the group programmed a special version of FRESS for a 3-lettered federal agency while locked in a Faraday cage and monitored by armed guards when they went to the bathroom. There was no working heater in the bus of course, adds Steve Carmody, so for the entire trip people took turns sitting atop a multi-platter disk, trying to keep it warmer than the frigid air inside the bus. Now lets try to press Andy again for the secret of bringing out peoples creativity. Asked for heroes of the recent past, he divides them into those outside his field Einstein, Feynman, Gandhi, King, Mandela and those inside Engelbart, Turing, von Neumann, Maurice Wilkes. Douglas Engelbart was just amazing, but he unfortunately never had the direct impact he should have had...he had trouble explaining his vision, and sadly is only remembered for inventing the mouse, probably the least important of his huge number of inventions in the oNLine System, NLS, from which so many of our modern ideas of word- and idea-processors derive. Hearing that, anyone who has known van Dam for five minutes is going to think the same thing Andy doesnt have a problem explaining or sharing his vision . Whether it was inspiring Janete and her peer UTAs to create elaborate skits for CS15 class with classically-trained musicians playing instruments, or getting a bunch of tie-dyed rebels to bring peace and love into the fortress of unsmiling agents, Andy van Dam fosters creativity through personal connection. Students relate to him, Janete says. More than fifty years younger, they relate to him because he relates to who they are. Andy believes in the power of young students, adds Ed. He taught me that impact and excellence are a multidimensional quantity...we cant hire or admit people or motivate them to do great work through just one lens. When we ask Andy about a common theme for both undergraduate teaching assistants and researchers, theres a long pause. The idea that you can do serious work before the PhD is almost unique to CS, he says. We did it fifty years ago, and its true to a fare-thee-well today...its about skilled and creative analysis and synthesis I try to create a productive, challenging but nurturing environment for creatives to make things that are, to use the Jobs phrase, insanely great . Responsibility, Then And Now Norm Meyrowitz 81, who will lead the second Iron Age panel at Celebrate With Andy , also believes that giving responsibility to young students was and is key. We were seventeen, eighteen, nineteen, creating all the assignments for an entire class. I was a junior, writing a windows manager program, a twenty-year-old with other twenty-year-olds presenting our research to the NSF. Did this seem strange at the time It just felt like something we were supposed to do Norm replies. Remember, the only PC then was the Apple II there were no mice, no graphics, no hypertext in general use. There were thousands of areas that nobody had started researching yet, so it was exciting. So Andy, Bill Shipp then Vice-Provost of Computing and a professor of biology, and I --at the ripe old age of 23-- raised 17 million dollars to put hundreds of graphical workstations on campus. The workstation effort led to the development of the Intermedia hypermedia system --which looked like the Web and worked on a LAN in 1985-- by me along with many of Andys former students. Andy gave us incredible responsibility as undergrads, and that bred confidence in future endeavors. Their confidence was clearly justified the third extant HTML message ever created, by Tim Berners-Lee for his own research team, was about Intermedia. Responsibility and confidence are both in full view at a January, 2015 meeting of Andys group in the CIT Library. Students and researchers sit at a long table with their laptops, tablets, and smartphones their mentor is leaning back in a chair, dressed in familiar sweater-over-the-shoulders style with arms crossed. His laptop a ThinkPad touch tablet is closed, and his smartphone only emerges for a momentary calendar check. The batch inputter is going pretty well, says a student. Andys eyes narrow a little as he grins. Did I hear pretty well or very well in there Were working on the user interface, but we havent caught the edge cases yet. Well be done by end of day, then test. No more guesswork, says Andy on another feature. We may have to take over these transactions ourselves. The atmosphere in the room is immediately recognizable to anyone who has worked in a production environment, in the technology sector, or in any setting where efficiency matters. The students are obstacle-oriented, focused, going back and forth seamlessly. Andy lets them converse, answering each others questions and asking for clarification when necessary. The sophistication of the students could be envied by professionals twice their age, and its mirrored in the vocabulary that van Dam uses in his comments bona fides , rubric , interregnum , kibbitz . Later, hell credit this to growing up surrounded by people who use language well and not being a native speaker of English, but the fact remains this is the way that someone addresses responsible peers, not children. For the hearer, confidence follows naturally. After an impromptu test of a new feature on an Android tablet works better than expected, the table explodes in cheers Yay...Wow...Show that again See you next week, Andy says at the end. Same bat time, same bat station. Getting It Done Fifty years later, Ed says, every generation tells the same stories. Andy always said that were here to make the future happen, Norm adds. Research is a byproduct of having a vision of the future and sharing it through teaching, instilling it in generation after generation. Research is just those people making the vision happen, getting it done...As teaching assistants or researchers, everyone from first-years to PhD students, Andy had us think of ourselves as a collaborative troupe spanning the generations. Every day, we put on a show and did our best. After you leave Brown, the troupe still exists for you in the community, the camaraderie. Celebrate With Andy is only one night, but it carries a thank-you that doesnt end to Andy and everybody else for our past half-century. The troupe goes on, making the future happen.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Celebrate With Andy: 50 Years Of CS At Brown"], "word_count": 4948, "token_count_estimate": 6042}}, "https://cs.brown.edu/news/2015/05/22/brown-cs-launches-undergraduate-teaching-assistant-endowment/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown CS Launches A 10,000,000 Fundraising Campaign For An Undergraduate Teaching Assistant Endowment Posted by Jesse Polhemus on May 22, 2015 Brown University s Department of Computer Science Brown CS today announces the start of a fundraising campaign to build a 10,000,000 endowment for its Undergraduate Teaching Assistant UTA program. The campaigns web site, with testimonials from former UTAs such as Mike Fredrickson of Pixar and Philip Levis of Stanford University, is at httpscs.brown.edugiving . Announced by President Christina Paxson, Provost Vicki Leigh Colvin, and Department Chair Ugur Cetintemel, the endowment will be a landmark investment in a key element of the Brown CS educational mission. UTAs contribute to all aspects of instruction and play a mentoring role thats vital to the quality of coursework, the educational experience of their peers, and their own personal growth. One in nine Brown undergraduates is a CS or joint CS concentrator and one in seven took a CS course this year Brown CS employs almost 200 UTAs each semester, with some courses requiring over 30 assistants At last count, over 60 of CS concentrators have been a UTA at least once Until last year, the Brown CS UTA budget hadnt changed since 2006, while enrollment grew 273. Our UTA program, says Ugur Cetintemel, is the most distinctive of its kind. It creates a highly interactive and social learning environment that helps students master the technical material by teaching it, while allowing them to develop important interpersonal skills such as communication, team work and leadership. Its the combination of these ingredients, which are often absent from the standard diet of undergraduates, that prepare them remarkably well for whatever they choose to pursue in their future careers. We would like to continue to offer this opportunity for generations to come. There is also a real need now for an expanded UTA program due to the exploding interest in CS courses. This endowment will be a permanent source to secure the health and future of this unique program. Its one of the best investments we can make in the education of our students, many of whom graduate to become leaders and innovators in information technology and other fields. Brown CS is looking forward to an exciting campaign that will permanently benefit our students and any industries, disciplines, and communities where they contribute. Please send any questions to donatecs.brown.edu .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Brown CS Launches A $10,000,000 Fundraising Campaign For An Undergraduate Teaching Assistant Endowment"], "word_count": 408, "token_count_estimate": 517}}, "https://cs.brown.edu/news/2015/06/01/watch-video-celebrate-andy-50-years-cs-brown/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Watch Video From Celebrate With Andy 50 Years Of CS At Brown Posted by Jesse Polhemus on June 1, 2015 On Friday, May 22, 2015, the Brown CS family gathered in Pizzitola Sports Center to celebrate three golden anniversaries the Undergraduate Teaching Assistant program, undergraduate participation in research, and Andy van Dam at Brown. The tributes and reminiscences were insightful, heartfelt, eloquent, and often extremely funny. You can watch a full video of the formal program here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Watch Video From Celebrate With Andy: 50 Years Of CS At Brown"], "word_count": 93, "token_count_estimate": 128}}, "https://cs.brown.edu/news/2015/09/30/brown-cs-introductory-course-enrollment-sets-records/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown CS Introductory Course Enrollment Sets Records Posted by Jesse Polhemus on Sept. 30, 2015 To read more stories about the Brown CS departments increasing enrollment click here . Enrollment in Brown Computer Sciences core introductory courses is continuing to accelerate year after year In the past year alone, CS 015 Introduction to Object-Oriented Programming and Computer Science has seen 20 growth, arriving at a record-setting 391 students. At this time four years ago, CS 017 CS An Integrated Introduction had 154 students enrolled. Currently, its 214, an increase of more than 38. Final enrollment of CS 019 Accelerated Introduction to Computer Science has more than doubled over the past four years, rising from 27 to 60 students. What can we derive from these statistics Among other conclusions, the parallel growth of all three courses suggests that Brown CS has successfully answered growing interest in our field by establishing multiple entrances that allow for varied definitions of computer science and its many uses.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "Brown CS Introductory Course Enrollment Sets Records"], "word_count": 178, "token_count_estimate": 217}}, "https://cs.brown.edu/news/2015/06/22/dazzling-boston-globe-attends-yurts-launch-and-inaugural-symposium/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Dazzling The Boston Globe Attends The Yurts Launch And Inaugural Symposium Posted by Jesse Polhemus on June 22, 2015 For more CS News and CS Blog articles about the Yurt, please click here . The June 20, 2015 edition of the Boston Globe includes a front-page story on Brown University s new fully immersive 3D virtual reality environment, the Yurt. Reporting from the symposium that marked the Yurts launch, Amanda Katz describes the rise of VR as a medium, the Yurts remarkable technical achievements, and the hope of its creators, led by Professor David Laidlaw of Brown Computer Science , to accelerate science and discover new uses for cutting-edge virtual reality. The entire article is available here .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:32+00:00", "headings": ["Information for:", "Brown CS News", "\"Dazzling\": The Boston Globe Attends The Yurt's Launch And Inaugural Symposium"], "word_count": 133, "token_count_estimate": 175}}, "https://cs.brown.edu/news/2015/09/30/enrollment-soars-1-5-students-taking-brown-cs-course/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Enrollment Soars 1 In 5 Students Is Taking A Brown CS Course Posted by Jesse Polhemus on Sept. 30, 2015 To read more stories about the Brown CS departments increasing enrollment click here . As enrollment in Brown CS courses continues to accelerate, a few statistics help give a sense of the tremendous year-on-year growth One in six Brown undergraduates took a CS course last year. This year, its one in five. Not only have total enrollments increased by 990 students in the past four years, more than 40 of that growth was in the last year alone. Individual courses also show remarkable expansion CS 33 formerly CS 31 has increased from 128 to 286 students in four years, more than doubling its enrollment CS 15 has grown by more than 20 just in the past year, reaching a record-setting 391 students. CS 1300 had 52 students two years ago, then 160 students last year. This year, it has 293.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Enrollment Soars: 1 In 5 Students Is Taking A Brown CS Course"], "word_count": 175, "token_count_estimate": 221}}, "https://cs.brown.edu/news/2015/10/07/mace-roelke-and-fonseca-win-best-paper-award-sosp-2015/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015 Posted by Jesse Polhemus on Oct. 7, 2015 in Awards Brown University Computer Science Brown CS PhD Candidate Jonathan Mace , Ryan Roelke 15 now at Vertica, and Brown CS Assistant Professor Rodrigo Fonseca have just received one of three Best Paper Awards at the 25th Association for Computing Machinery ACM Symposium on Operating Systems Principles SOSP 2015, currently being held in Monterey, California. SOSP is often considered the leading forum for researchers and developers of computer operating systems, and their research compared favorably with more than two dozen entries selected from over 300 global submissions, covering a wide range of theory and practice. Jonathan, Ryan, and Rodrigos work Pivot Tracing Dynamic Causal Monitoring for Distributed Systems addresses the challenge of monitoring and troubleshooting distributing systems with a monitoring framework that combines techniques from both the dynamic instrumentation and causal tracing literature. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, alter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. The result is a dynamic and extensible solution that enables cross-tier analysis between inter-operating applications with low execution overhead. This is the first framework we are aware of, Rodrigo says, that allows you to ask questions about a system as it runs, while causally combining metrics across its distributed components.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Mace, Roelke, And Fonseca Win A Best Paper Award At SOSP 2015"], "word_count": 261, "token_count_estimate": 328}}, "https://cs.brown.edu/news/2015/10/13/erik-sudderth-and-collaborators-advance-seismic-monitoring-and-nuclear-non-proliferation-earning-top-prize-bayesian-analysis/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Erik Sudderth And Collaborators Advance Seismic Monitoring And Nuclear Non-Proliferation, Earning A Top Prize In Bayesian Analysis Posted by Jesse Polhemus on Oct. 13, 2015 in Awards Few things are less abstract than an earthquake or more important than nuclear non-proliferation, and one of the top awards in Bayesian analysis highlights how complex statistical models can be used to solve problems that go far beyond theory. The International Society for Bayesian Analysis ISBA, which sponsors leading journals and conferences presents the Mitchell Prize in annual recognition of an outstanding paper that uses Bayesian analysis to solve an important applied problem. This year, Professor Erik Sudderth of Brown University s Computer Science Department and his collaborators Professor Stuart Russell of University of California, Berkeley and Nimar S. Arora of Bayesian Logic, Inc. and BetaZi have received the award for their research in seismic monitoring. Their work NET-VISA Network Processing Vertically Integrated Seismic Analysis , which was also highlighted Global Seismic Monitoring A Bayesian Approach at the Twenty-Fifth Conference on Artificial Intelligence AAAI-11, involves automated processing of multiple seismic signals, a central problem in both geophysics and nuclear treaty verification. Around the globe, Erik explains, one of the most important mechanisms for nuclear non-proliferation is the global sensor network that identifies seismic events and their locations. As part of the Comprehensive Nuclear Test Ban Treaty, its a key tool to ensure that nuclear weapons arent being tested. Unfortunately, identifying true seismic events at a global scale is a complex task. Our Bayesian seismic monitoring system rigorously models geophysical uncertainty to avoid missed events. In the end, we reduce them by 60 compared to a highly advanced baseline system, and we even find events missed by expert human analysts. As worldwide interest in mitigating the risks of nuclear proliferation grows, improving the accuracy of seismic signal processing becomes more urgent every day. Were tremendously proud to use statistical machine learning to contribute to an area of global importance.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Erik Sudderth And Collaborators Advance Seismic Monitoring And Nuclear Non-Proliferation, Earning A Top Prize In Bayesian Analysis"], "word_count": 340, "token_count_estimate": 420}}, "https://cs.brown.edu/news/2015/11/06/touch-art-gallery-tag-continues-global-expansion-nobel-museumnobel-mediamicrosoft-collaboration/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Touch Art Gallery TAG Expands Worldwide With A Nobel MuseumNobel Media Collaboration Posted by Jesse Polhemus on Nov. 6, 2015 Brown University s Department of Computer Science Brown CS today announces a major milestone for the Touch Art Gallery TAG project, one of the most visible recent successes of the departments undergraduate research program. Working under the direction of Professor Andy van Dam , a group of entirely undergraduate researchers in the Graphics Lab has demonstrated the power of technology to enhance research and learning with two state-of-the-art museum experiences that focus on Alfred Nobels final Will and the 900 Nobel laureates to date. The experiences, a collaboration between Brown University, the Nobel Museum, and Nobel Media, use a uniquely compelling form of interaction to give new life to documents that hold a significant place in human history. They debut in Singapore on November 7 during the two-day Future of Learning Nobel Media Conference at Nanyang Technological University, but enthusiastic news coverage has already begun, with Channel NewsAsia devoting a television news segment to these ideas that changed the world. TAG is sponsored by Microsoft, and the experiences are hosted on two 82-inch Microsoft touch displays, a 55-inch touch display, and six smaller Surface touch tablets. Theyll be housed at the ArtScience Museum in Singapore for the next three months, where theyre projected to be seen by thousands of visitors. Afterward, the experiences will be incorporated into a larger traveling exhibit by the Nobel Museum. From the start of the project, students in their earliest years of higher education have made contributions that rival the efforts of far more experienced peers in the technology sector. Both experiences were tested by some fifty undergraduate students at Brown, many of them from van Dams introductory Java programming class. The testing sessions provided valuable feedback on user interaction with the experiences, and many design decisions were fine-tuned after the user studies. The current TAG team leader, Trent Green, traveled to Singapore to oversee the exhibits installation, interacting with multiple Nobel laureates while still a sophmore. The first of the experiences focuses on Alfred Nobels final Will, in which he set aside part of his fortune to fund annual prizes for the top global researchers and practitioners in the fields of physics, chemistry, literature, physiology and medicine, and peace. It uses a digital scan of the hand-written Will as its anchor, using key words and phrases in the document to tell the story of Nobels life as an inventor and industrialist as well as the establishment of the Nobel Foundation after his death. From the Will interface, visitors can link to related collections of high-resolution images, which can be explored in depth via pan and pinch-zoom gestures that are familiar to any smart phone user. They can also watch interactive tours, which combine audio narration as well as panning and zooming images. Unlike traditional videos, the tours can be paused at any time to allow touch interaction with the visual elements on screen. For many of the images, additional information is also provided to viewers via a sidebar. The second experience focuses on the 900 laureates who have won Nobel Prizes since the first award ceremony in 1901, the most recent of whom were announced this October and will be honored this December. Images of the laureates are displayed in a grid on screen and can be filtered via combined queries over prize category, gender, and decade filters and also searched by name or other metadata fields such as country of origin. Touching a laureates image launches a pop-up with more information about the contributions that led to their Nobel Prize recognition. Its been exciting for us to work on a project that will have such high visibility, says Lucy van Kleunen, the previous undergraduate TAG team leader. Designing large display touch exhibits has also been an instructive research experience in user interface and experience design for a large screen form-factor.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Touch Art Gallery (TAG) Expands Worldwide With A Nobel Museum/Nobel Media Collaboration"], "word_count": 672, "token_count_estimate": 791}}, "https://cs.brown.edu/news/2015/12/11/stefanie-tellex-and-john-oberlins-award-winning-video-earns-brown-cs-new-baxter-robot/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Stefanie Tellex And John Oberlins Award-Winning Video Earns Brown CS A New Baxter Robot Posted by Jesse Polhemus on Dec. 11, 2015 by Kevin Stacey Science News Officer, Physical Sciences Brown University s Humans to Robots Lab is about to get a new robot, thanks to Stefanie Tellexs video-making skills. Tellex, assistant professor of computer science and the labs principal investigator, entered the Rethink Robotics Video Challenge. The Boston-based company asked users of its Baxter robot to submit videos showing Baxter solving real-world problems, whether in research, manufacturing, or education. Tellex took first place with a little help from the band ACDC and graduate student John Oberlin for her video about teaching Baxter to manipulate objects from experience. The grand prize A spanking new Baxter the labs third is on its way from Rethink. On a factory floor, robots do a great job of picking up and manipulating objects that theyve been programmed to handle. However, picking up objects that theyve never encountered before can be a big problem for even the most sophisticated robots. Tellex has developed an algorithm that enables Baxter to learn how to pick up new objects by repeatedly trying and often failing to do so. Over time, the robot learns how best to pick up the object, and can do so successfully on future attempts. At night or on weekends, Baxters are just sitting there in labs doing nothing, Tellex said. If we could get all 300 research Baxters working on this during what would normally be down time, we could reach our goal of a million objects in only about 11 days.Tellex is hoping to recruit other researchers who use Baxters users to scan objects as well. Shes calls it the Million Object Challenge . Tellexs work has been the subject of recent stories on National Public Radio and in MIT Technology Review .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Stefanie Tellex And John Oberlin's Award-Winning Video Earns Brown CS A New Baxter Robot"], "word_count": 325, "token_count_estimate": 401}}, "https://cs.brown.edu/news/2015/12/15/brown-cs-announces-10000-randy-f-pausch-82-computer-science-undergraduate-summer-research-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown CS Announces The 10,000 Randy F. Pausch 82 Computer Science Undergraduate Summer Research Award Posted by Jesse Polhemus on Dec. 15, 2015 Brown University s Department of Computer Science Brown CS is glad to announce a significant milestone in the continued growth of our undergraduate research program. A generous gift from Peter Norvig 78 has established the Randy F. Pausch 82 Computer Science Undergraduate Summer Research Award, which provides 10,000 annually to support an undergraduate engaged in an intensive faculty-student summer research partnership at Brown CS. Norvig, now a Director of Research at Google and a thought leader in the areas of artificial intelligence, natural language processing, information retrieval, and software engineering, was drawn to Brown as an undergraduate by the open curriculum and his interests in computer science and linguistics, which he studied in high school. Computer science seemed much simpler then, he says. We went slower, and we had the advantage of being able to cover the entire field. But if you wanted a piece of software, you usually had to write it yourself. His gift honors the life and work of Randy F. Pausch 82, a renowned expert in computer science, human-computer interaction, and design who died of complications from pancreatic cancer in 2008 and whose Last Lecture has been widely praised. I didnt know Randy when I was at Brown, Peter says, but we met afterward and corresponded for many years. His story is inspiring, and this is an opportunity to remember him. Norvig sees this award as a multiplier that will amplify the value of his gift and extend it through time. Im interested in students with a wide range of personalities and interests, he says, and in putting students and faculty together. In the past, we had to build all our own tools, and we didnt have time to combine computer science with other fields. Now, there are so many opportunities to do so. I think its a wise choice you invest in things that you think will do good, and educating a student allows them to help add to the things that youre already trying to accomplish. This is a prestigious award, says Department Chair Ugur etintemel, Its the first of its kind, and we hope it inspires many others. Its going to fund one of our exceptional students whose work reflects the high standards and values for which Randy was recognized. Were truly grateful to Peter for honoring Randys life and accomplishments by creating this lasting research opportunity for our best and brightest. To apply, no later than February 15, 2016, students should email Associate Professor Research and Vice Chair Tom Doeppner either A a copy of their summer UTRA application or B a two-page description of their proposed research and a letter of support from the Brown CS faculty member they intend to work with. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Brown CS Announces The $10,000 Randy F. Pausch '82 Computer Science Undergraduate Summer Research Award"], "word_count": 509, "token_count_estimate": 615}}, "https://cs.brown.edu/news/2016/03/07/bootstrap-plays-key-role-cs4ri-expansion-cs-education-rhode-island/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Bootstrap Plays A Key Role In CS4RI Expansion Of CS Education In Rhode Island Posted by Jesse Polhemus on March 7, 2016 Bootstrap is a computer science literacy curriculum used by 10,000 students in 17 states and five countries whose founders include two Brown CS faculty members, Kathi Fisler adjunct and Shriram Krishnamurthi . Starting today, its playing a key role in the new Computer Science for Rhode Island CS4RI effort, which brings together a coalition of partners to offer low or no-cost options for K-12 schools to expand CS education. Bootstrap is excited to partner with Governor Raimondos team to enrich math and computing education for students across Rhode Island, says Shriram. The CS4RI initiative will get students computing creatively and thriving mathematically so that they graduate high school prepared with skills that matter. CS4RI is among the most comprehensive statewide computer science initiatives in the country, and it takes a coalition approach by combining national leadership with homegrown talent to reduce barriers to providing quality computer science education and professional development. Its goal is to have CS taught in every public school in Rhode Island by December, 2017. Brown is proud, says President Christina Paxson, to be a part of a project that positions Rhode Island as a leader in efforts to bring computer science education to students statewide. The Bootstrap curriculum, developed in part by Brown faculty, teaches essential skills that can propel students toward fields with significant opportunities in tomorrows world. Its exciting that Bootstrap will be part of this initiative, which is so important for our state, and I thank Governor Raimondo and her team for their work.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Bootstrap Plays A Key Role In CS4RI Expansion Of CS Education In Rhode Island"], "word_count": 288, "token_count_estimate": 357}}, "https://cs.brown.edu/news/2018/06/06/shriram-krishnamurthi-wins-sigsoft-influential-educator-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Shriram Krishnamurthi Wins The SIGSOFT Influential Educator Award Posted by Jesse Polhemus on June 6, 2018 in Awards Click the links that follow for more news items about awards won by Brown CS faculty and Shriram Krishnamurthi . Professor Shriram Krishnamurthi of Brown University s Department of Computer Science Brown CS has just received the SIGSOFT Influential Educator Award. Presented annually, its given to an educator or educators who have made significant contributions to, and impact on, the field of software engineering through accomplishments as teachers, mentors, researchers in education or learning, authors, andor policy makers. In particular, the award committee noted Shrirams contributions to the advancement of the research and practice of software engineering. The award is international recognition of continued strength in education at Brown CS, and it follows recent awards for three faculty members and one PhD student that highlight campus-wide recognition of the Departments teaching excellence. It comes less than halfway into a busy year in which Shriram has already given keynote addresses at Programming 2018 and elsewhere , written a cover story for Communications of the ACM , and been appointed to co-lead the CACM Research Highlights Editorial Board . With this win, he joins Brown alum Barbara Ryder and the late David Notkin, a Brown CS alum, who won the prestigious award in 2015 and 2012, respectively. The full list of winners dating back to 2009 is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Shriram Krishnamurthi Wins The SIGSOFT Influential Educator Award"], "word_count": 270, "token_count_estimate": 347}}, "https://cs.brown.edu/news/2018/08/02/tellexs-outreach-inspires-high-school-student-study-robotics-then-teach/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Tellexs Outreach Inspires A High School Student To Study CS, Then Teach Posted by Jesse Polhemus on Aug. 2, 2018 Click the link that follows for more news about Brown CS outreach and Stefanie Tellex . These are kids who would never have seen a real robotics lab otherwise, says Annalisa Marchessault, Pre-Engineering Instructor at Providence Career and Technical Academy PCTA, one of New Englands premier technical high schools. Many of them dont even realize the magnitude of what Stefanie has done for them. Shes talking about Professor Stefanie Tellex of Brown University s Department of Computer Science Brown CS, whose four-year outreach effort with the schools students has produced some inspiring results. Jose Toribio, one of the programs alums, is not only studying robotics but helping teach it to the next generation of students. Now almost a decade old, Providence Career and Technical Academy allows students to choose a particular area of technology and then pursue their studies with a mix of internships and classwork. Computer science has always been a popular subject, and four years ago, Annalisas predecessor approached Stefanie with a request that Tellex share her robotics work with PCTA students in the Engineering program. The response was surprising along with giving a talk, Tellex invited students to come and work with drones and robots in her Humans To Robots lab during the summer. What makes Stefanie amazing is that shes so approachable, Annalisa says. She reaches out, she wants everyone to learn, and nothing could have been better than giving our kids an opportunity to learn like this locally, working alongside Brown students. Jose Toribio was part of Stefanies second cohort. For someone with a lifelong interest in computers, the Humans To Robots lab was filled with exciting possibilities. He says, I liked how open the program was. If I came up with an idea, everyone was ready to think about how it could be achieved. Jose mentions that giving public demonstrations of drones hed built with fellow students was one of the things he enjoyed most. One of his demos was recently seen by Richard M. Locke, Browns Provost. At one of them, he remembers, I met someone from Google who was from Providence, someone just like us. It was really exciting to feel that connection to her. Maybe part of the excitement was because Jose was beginning to think about being a role model himself. After completing his second summer with Stefanies lab, he ran the program for the five juniors and seniors who joined the following year, and accepted Annalisas offer to serve as PCTAs Robotics Coach. This summer, he taught a high school course as part of SummerBrown and mentored two high school students doing paid internships with Stefanies lab. Its wonderful to see Joses eagerness to share knowledge, Stefanie says. Hes the sort of person that when he first came into the lab, he immediately started showing another high school student how to solder. PCTA students have been a strong asset in hardware design and creating documentation for the course for the high school level. Im excited to continue working with them as our project grows Now studying computer science at Rhode Island College, Jose says that its a chance to revisit the important high school years that passed by so quickly Its incredible to see the next generation of students doing what I did. I love being able to share my experience and show them different ways to look at an experiment. When he graduates, hes hoping to move to a bigger city and continue his engineering work, particularly in the area of robotic vision. I just want to thank Stefanie and Annalisa, Jose says. Without them, I might be programming, but Id never have had this chance to work up close with robots. Annalisa expects that there are big things in store for him. Two of the most amazing things about this program, she says, are Jose and Stefanie themselves. For kids in Joses position, seeing how he wanted to go and learn, then come back and volunteer, is the coolest thing. Hes someone like them, so they feel comfortable, and they see that everything hes done is attainable for them. And Stefanie doesnt have to do what she does, but she always makes the time. Thanks to her, these kids have seen possibilities for their lives that theyd never known about. For more information, click the link that follows to contact Brown CS Communication Outre ach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:33+00:00", "headings": ["Information for:", "Brown CS News", "Tellex's Outreach Inspires A High School Student To Study CS, Then Teach"], "word_count": 768, "token_count_estimate": 928}}, "https://cs.brown.edu/news/2018/09/14/andy-van-dam-has-been-named-siggraph-academy-contributions-computer-graphics/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Andy Van Dam Has Been Named To The SIGGRAPH Academy For Contributions To Computer Graphics Posted by Rujul Singh on Sept. 14, 2018 in Awards Click the links that follow for more news about Andy van Dam and recent awards won by Brown CS faculty members SIGGRAPH, a special interest group for the Association for Computing Machinery, is one of the worlds largest communities of researchers, artists, developers, and filmmakers dedicated to the advancement of computer graphics and interactive techniques. Their Awards Committee has recently announced that Professor Andy van Dam of Brown Universitys Department of Computer Science Brown CS has been named to the ACM SIGGRAPH Academy, an honorary group of individuals known for contributions to the field of computer graphics as well as impact through research directives and innovations. Its a great honor to be in the first class of inductees into the SIGGRAPH Academy. When in 1967 I co-founded SICGRAPH, the precursor to SIGGRAPH, computer graphics wasnt even recognized as a specialty within the then new field of CS, and now SIGGRAPH is the dominant Special Interest Group in ACM, running the largest annual conference. And the Visual Computing Group in our department has six faculty and a senior lecturer, as many people as founded our department in 1979, he says. Already recognized by the ACM as a pioneer in the field of graphics previously winning the ACM Karl V. Karlstrom Outstanding Educator Award, and the ACM SIGGRAPH Steven A. Coons Award, Andy continues to innovate in the computer graphics realm. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Andy Van Dam Has Been Named To The SIGGRAPH Academy For Contributions To Computer Graphics"], "word_count": 287, "token_count_estimate": 345}}, "https://cs.brown.edu/news/2018/10/05/michael-littman-receives-browns-presidential-faculty-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Michael Littman Receives Browns Presidential Faculty Award Posted by Jesse Polhemus on Oct. 5, 2018 in Awards Click the link that follows for more news about Michael Littman and recent awards won by Brown CS faculty . Out of more than 700 faculty members, two are chosen each year for Brown University s Presidential Faculty Award, and this semester, President Christina Paxson selected Professor Michael Littman of the Department of Computer Science Brown CS. Established in 2013, the Presidential Faculty Award recognizes members of Browns distinguished faculty who are conducting especially important and innovative scholarship. Michael is the first Brown CS recipient of the award, and it comes only months after he received the Philip J. Bray Award for Excellence in Teaching in the Physical Sciences . Prior winners of the Presidential Faculty Award include Bonnie Honig Professor of Modern Culture and Media and Professor of Political Science, Jill Pipher Elisha Benjamin Andrews Professor of Mathematics and Founding Director of the Institute for Computational and Experimental Research in Mathematics, and David Berson Sidney A. Fox and Dorothea Doctors Fox Professor of Ophthalmology and Visual Sciences. Michael will receive a research stipend of 5,000 and give a Presidential Faculty Lecture to provide an opportunity for faculty members in other disciplines to learn about his work. A list of previous winners is available here . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Michael Littman Receives Brown's Presidential Faculty Award"], "word_count": 257, "token_count_estimate": 311}}, "https://cs.brown.edu/news/2019/01/18/nakul-gopalan-eric-rosen-daniel-ullman-david-whitney-win-hyundai-visionary-challenge/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyundai Visionary Challenge Posted by Rujul Singh on Jan. 18, 2019 in Awards Click the link that follows for more news items about our students competing at hackathons and other events. The Hyundai Visionary Challenge is a competition to ignite learning, exploration, and development in the realm of smart mobility. Its meant to accelerate research innovations in smart mobility that drive the creation of sustainable cities across the globe, and awards teams across a broad spectrum of categories. Encompassing biology-inspired mobility, digital phenotyping, and man-machine partnership, these categories all aim to inspire new ways of thinking to impact the world. This year, Brown CS PhD students Nakul Gopalan, Eric Rosen, and David Whitney along with Brown CLPS PhD student Daniel Ullman whose team was advised by Stefanie Tellex have won the annual award for their proposal, Improving Man-Machine Partnership using Mixed Reality Social Feedback from Robots. I really enjoyed being able to talk about and explore the applications of our work in the business world, explains David as he describes the groups project, and I saw the potential for VR to be truly transformative for society. In essence, the teams goal was to increase the efficiency of communication between robots and human workers in the workplace. As it stands, robots are very unsafe to human coworkers. Humans cant predict the future actions of automated robots, which vastly reduces robot effectiveness on the job. The idea to solve this issue is to have workers in warehouses wear augmented reality headsets to see the future actions of moving robots in real time, minimizing collisions and significantly improving workplace output. This tool would foster interaction between humans and machines, making for a much safer work environment. It may sound futuristic, but the team has set high goals for this project, and plans to continue working and refining this man-machine partnership idea in the upcoming years. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Nakul Gopalan, Eric Rosen, Daniel Ullman, And David Whitney Win The Hyundai Visionary Challenge"], "word_count": 355, "token_count_estimate": 431}}, "https://cs.brown.edu/news/2019/02/28/evan-cater-wins-randy-f-pausch-computer-science-undergraduate-summer-research-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Evan Cater Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award Posted by Jesse Polhemus on Feb. 28, 2019 in Awards Click the links that follow for more news items about Michael Littman , Peter Norvig , and the Randy F. Pausch 82 Computer Science Undergraduate Summer Research Award . The Randy F. Pausch 82 Computer Science Undergraduate Summer Research Award , given this year to Evan Cater to support his work with Brown CS Professor Michael Littman , recognizes strong achievement from young students and offers them the opportunity to partner with faculty and advance work that began in the undergraduate research program. A generous gift from Peter Norvig 78 a Director of Research at Google and a thought leader in the areas of artificial intelligence, natural language processing, information retrieval, and software engineering established the award, which provides 10,000 annually to support an undergraduate engaged in an intensive faculty-student summer research partnership. The gift honors the life and work of Randy F. Pausch 82, a renowned expert in computer science, human-computer interaction, and design who died of complications from pancreatic cancer in 2008. His story is inspiring, Peter says, and this is an opportunity to remember him. Evan explains that he began collaborating with Michael as a first-year student, working alongside a Masters student on Variational Autoencoders with Deep Q-Networks, a type of reinforcement learning RL algorithm. We couldnt get the idea working, he says, and the project fizzled out, but it piqued my interest in both RL and Variational Inference. Ive revisited these ideas in conjunction over the past couple of years, and this proposal and research project will hopefully synthesize my thoughts on the subject. And what might that look like First, some background. Any time we have robotics or computer programs interacting with the real world, Evan says, there exists a lot of uncertainty. When deploying a program that, for example, modulates the power grid, or a self-driving bus that carts children to school, a lot is at stake. Storms can impede driving, hard drives can fail, car accidents happen, and programs can seg-fault. When faced with uncertainty, we want to make sure our Artificial Intelligence can make decisions. The agents interact with the world over time, so we can formalize this problem as learning good policies or actions over time, under uncertainty. To construct agents that operate under uncertainty, he says, its necessary to categorize uncertainties. For example, epistemic uncertainty is created by a lack of data, whereas aleatoric uncertainty is the result of random changes in the environment. My work, Evan says, is a research study on a unified view of uncertainty in Deep Reinforcement Learning. First, well provide a taxonomy and vocabulary to describe the various uncertainties used in reinforcement learning. Next, well compare and contrast different contemporary papers, clearly distinguishing the types of uncertainty each paper considers and how the papers interact. The study will also provide some theoretical comparisons between the types of uncertainty. Finally, well use the study to inform the design of a new set of algorithms based on the insights ascertained. My hypothesis is that techniques from Variational Inference can be used as a unifying tool for the competing techniques. With the summer only months away, Evan tells us that he cant wait to explore, read, and tinker Im ecstatic and really thankful to all the students and professors that got me here. I remember being a first-year student sitting in on Michaels lab meetings and catching every tenth word. Flustered, a couple of seniors and PhD students took me under their wings and pointed me in the right direction. I owe everything to those student mentors and Michael for nurturing me as a researcher. Michael has been helpful and understanding, supportive during the rough weeks, and he sparks creativity in all of his students. I often look forward to our exploratory debates and deep dives into what is really going on. Evans eagerness and excitement is exactly what Peter Norvig is looking for. He sees this award as a multiplier that will amplify the value of his gift and extend it through time. In the past, he says, we had to build all our own tools, and we didnt have time to combine computer science with other fields. Now, there are so many opportunities to do so. I think its a wise choice you invest in things that you think will do good, and educating a student allows them to help add to the things that youre already trying to accomplish. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Evan Cater Wins The Randy F. Pausch Computer Science Undergraduate Summer Research Award"], "word_count": 791, "token_count_estimate": 961}}, "https://cs.brown.edu/news/2019/03/06/rhode-island-robot-block-party-returns-april-13/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Rhode Island Robot Block Party Returns On April 13 Posted by Jesse Polhemus on March 6, 2019 in Diversity The robots return Rhode Island Robot Block Party will take place on Saturday, April 13, 2019, from 12-4 PM at the WaterFire Arts Center 475 Valley Street. The event, an expo founded by the Rhode Island Students of the Future in partnership with Brown University s Humanity Centered Robotics Initiative and Brown CS , highlights the innovation of our states robotic community. Bringing together industry, universities, community organizations, and K-12 schools, its open to the public and includes numerous pieces of robotic equipment that range from ocean exploration devices to animatronic toys. It was a Rhode Island Monthly Editors Choice Best of Award winner in 2015. Recent exhibitors included University Exhibits and Demonstrations RISD students demonstrated the rover they built for the NASA Human Exploration Rover Challenge. The Brown Robotics Lab demonstrated cloud robotics technologies and quadrotor and telepresence robots. Brown University Planetary Geosciences and NASA Solar System Exploration Virtual Institute SSERVI. The SSERVI Evolution and Environment of Exploration Destinations SEEED team is hosted by Brown University and MIT. NASA and international space probes are exploring all the planets of the solar system and will reach Pluto this summer. Come see pictures of Mars from the sophisticated Curiosity rover, and share close-up images of the surface of a comet. Meet scientists from Brown University who are exploring the planets and satellites of the Solar System and learn of their discoveries and future plans for human and robotic exploration Human 2 Robots Lab demonstrated the pick and place capabilities of the Baxter industrial robot, created by Rethink Robotics. The Laboratory for Engineering ManMachine Systems Computer Vision LEMS displayed their Blindfind project. The Brown IEEE Robotics Olympiad Micromouse competition held their annual competition at the Robot Block Party. University of Rhode Island Graduate School of Oceanography displayed the autonomous kayak and Lagrangian floats used to explore shallow coastal waters. The URI RoboBoat team and the Robotics Laboratory for Complex Underwater Environments R-CUE teamed up to display the URI Autonomous Surface Vehicle a pair of flying robots at least two underwater robots and a variety of soft robotics prototypes use for underwater grasping and manipulation. Roger Williams University School of Engineering, Computing and Construction Management demonstrated a student built, human scale mobile robot allowing for virtual telepresence. Salve Regina University School of Business Studies and Technology displayed student technology projects. New England Institute of Technology had a demonstration of robotics, quad-copters, and support products. Manufacturing and Community Organizations Hasbro demonstrated their animatronic toy line, FurReal Friends. igus, inc displayed their movement machine and iglide and echain products. The Rhode Island Computer Museum presented Robots on the Run an activity that explains basic circuits and programmable electronics in hobby robots. FabNewport demonstrated ArtBots that create original works of art. IEEE Providence Section demonstrated their role in the robotics industry and professional development of engineers. The Providence Childrens Museum provided the Rigamajig play area which encourages hands on exploration of mechanical design concepts. BLT Robotics displayed a Robotic Vertical Hydroponic Farm. Members of Makes book publishing team joined the Robot Block Party to show off projects from some of our recent and soon-to-be-published books. They had hands-on interactive projects you can play with from our upcoming Getting Started with littleBits book, some 3d-printed-in-place objects, and some Raspberry Pi demos. AS220 Labs showed a new line of electronics kits and some drawing machines from the Lab. Robotix Learning Solutions demonstrated their affordable robot that helps teach kids 4-18 years how to code in an easy and interactive way. Student Exhibits Coventry Alan Shawn Feinstein Middle School students built a robotic claw that can pick up a ball and a Chain Reaction Machine. East Greenwich Our Lady Of Mercy School had over 30 students building autonomous parade floats and interactive robotics projects. The students range from age 6-12. East Providence Martin Middle School had middle school students building autonomous parade floats and interactive projects. MiddletownNewport Newport Community School brought students who built autonomous parade floats. All Saints STEAM Academy students displayed their Arduino robots and several other interactive projects. Their Jr. FIRST LEGO League team demonstrated their Think Tank project. The Aquidneck Island 4-H club runs robotics programs for kids aged 9-18. AIR Strike 78, their FIRST Robotics team demonstrated their award-winning robot. Narragansett The Pier School exhibited classroom robotics projects. Providence Providence Career and Tech Academy demonstrated engineering and robotics projects completed by their engineering students. Wheeler School exhibited projects built by lower and middle school students. FRC 2780 Robotics Team, based at Wheeler School, demonstrated their FIRST Robotics Robot. Lincoln School demonstrated Tetrix robots built by the Robotics I II classes, plus a demonstration of our FIRST Tech Challenge bot with field elements from the 2015 FTC game, Cascade Effect. Mount Pleasant High School demonstrated their student robotics projects. Nathan Bishop Middle School demonstrated their student robotics projects. The College Crusade is a community-based robotics teams, composed of Cranston Providence youth. They demonstrated a rover. Riverside Riverside Middle School students buildt autonomous parade floats, and interactive projects. Gordon School students worked on interactive robotics projects and a Chain Reaction Machine. Warren Kickemuit Middle School built a chain reaction machine. West Warwick 21st Century Community Learning Center, YMCA at John Deering Middle School featured students demonstrating autonomous parade floats.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Rhode Island Robot Block Party Returns On April 13"], "word_count": 907, "token_count_estimate": 1132}}, "https://cs.brown.edu/news/2019/04/18/george-konidaris-wins-nsf-career-award-autonomous-robotic-learning/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles George Konidaris Wins An NSF CAREER Award For Autonomous Robotic Learning Posted by Jesse Polhemus on April 18, 2019 Click the links that follow for more news about George Konidaris , other Brown CS NSF CAREER Award winners , and other recent awards won by our faculty . Robotics is no longer primarily a hardware problem, but largely one of software, says Professor George Konidaris of Brown CS . We already have highly physically capable robots, but our ability to program them is still quite limited. Ideally, wed like to be able to give the robot a what goal e.g. the light should be switched on, and have the robot figure the how part of the problem out itself. But were a long way from that, and a major reason why is that we dont know how to get away from the plethora of tiny low-level details a robot has to deal with every pixel, and every motor signal to the kinds of high-level planning at which humans excel. Konidariss recent work has been focused on the theoretical foundations of the problem of abstraction, and last year he published a paper that introduced a new theoretical framework for helping robots learn to reason abstractly. That work felt like a great step, says George, but it wasnt yet really practical, because the robot must learn every aspect of every new task from scratch. Earlier this month, George won a National Science Foundation NSF CAREER Award that will help him tackle that challenge by applying his new theoretical framework to the problem of designing robots that view the world in an object-centric way they will learn to manipulate objects, build abstract internal representations of those objects, and reuse these representations to generalize across similar objects. His aim is to build the foundation for a new family of algorithms that will enable robots to reason and plan in complex scenarios in the real world by getting the most mileage out of the learning theyve already done. CAREER Awards are given in support of outstanding junior faculty teacher-scholars who excel at research, education, and integration of the two within the context of an organizational mission, and George joins multiple previous Brown CS winners of the award, including most recently Theophilus Benson , Stefanie Tellex , Jeff Huang , and Rodrigo Fonseca . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "George Konidaris Wins An NSF CAREER Award For Autonomous Robotic Learning"], "word_count": 422, "token_count_estimate": 491}}, "https://cs.brown.edu/news/2019/05/20/david-abel-wins-presidential-award-excellence-teaching/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles David Abel Wins A Presidential Award For Excellence In Teaching Posted by Rujul Singh on May 20, 2019 in Awards Click the links that follow for more news items about David Abel , other winners of the Presidential Award , and other awards won by our students. PhD candidate David Abel of Brown CS , who just recently proposed his thesis and expects to graduate with a PhD in Computer Science and a Masters in Philosophy next spring, has been recognized for an accomplishment beyond his achievements in research. Chosen out of hundreds of graduate students with teaching appointments, Dave was one of only four to win the Presidential Award for Excellence in Teaching. The award, given annually at the University Awards ceremony, recognizes outstanding pedagogical achievement. Its criteria span from teaching that influences and inspires students to learn to development of curriculum and resources that promote student learning. Dave began his teaching journey in 2014 as a TA for Stefanie Tellex, teaching CS 1410 an undergraduate Artificial Intelligence class. After being nominated as a great TA by the students in the class, he became a TA for CS 8 A First Byte of Computer Science, an introductory computer science class for non-majors taught by Professor Michael Littman with enrollment of 109 students. During his semester of teaching the course, Dave was consistently praised by his students, with many citing his energy, availability, and thoughtfulness as being key to fostering an environment for intellectual curiosity. Dave was instrumental in implementing an optional python unit in the class that gave students the opportunity to learn a language used widely in industry. As a testament to his teaching abilities, a full 98.5 of respondents rated the class as effective or very effective when Michael took a sabbatical and Dave ran the class on his own. Not limited to the classroom, Dave has been involved in a variety of activities that may very well have had an even greater impact on the Brown community. Along with fellow CS PhD students Nediyana Daskalova and Amariah Becker, Dave has been heavily involved in designing and running peer mentorship program in the department. His initiative pairs up post-candidacy PhD students with first year PhD students, ensuring that new students have proper guidance regarding finding research, working with their advisor, and establishing work-life balance. Keeping with the spirit of mentorship, Dave has been a primary research advisor for several Brown undergraduates as well. Over the past few years, he has co-authored 11 papers with many undergraduate students, guiding them through the research process. Dave has clearly shown himself to be a remarkable teacher, both in and outside the classroom. As he finishes up his graduate studies, its evident that his work has made a personal impact on the many dozens of students with whom he has worked. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse Polhemus.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "David Abel Wins A Presidential Award For Excellence In Teaching"], "word_count": 502, "token_count_estimate": 593}}, "https://cs.brown.edu/news/2019/06/17/michael-littman-has-been-named-acm-fellow/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Michael Littman Has Been Named An ACM Fellow Posted by Jesse Polhemus on June 17, 2019 in Awards Click the links that follow for more news about Michael Littman and other Brown CS ACM Fellows . In a ceremony on June 15, 2019, the Association for Computing Machinery ACM, the worlds largest educational and professional computing society, elevated Professor Michael Littman of Brown CS to the rank of Fellow, the organizations highest membership grade, for contributions to the design and analysis of sequential decision-making algorithms in artificial intelligence. The ACM Fellows Program, initiated in 1993, celebrates the exceptional contributions of leading members of the computing field, and Michael joins a distinguished list of colleagues to whom the ACM and its members look for guidance and leadership in computing and information technology. It was an honor to be selected as a Fellow, Michael says, and I really enjoyed the ceremony and hearing about all the remarkable achievements of the big award winners. Computing is such an exciting field right now and getting to see so many important figures in the field in one place was a total trip. Michael earned his doctorate from Brown CS in 1996 and has been a member of the faculty since 2012. Currently co-directing Brown s Humanity-Centered Robotics Initiative , he works mainly in reinforcement learning, but has done research in machine learning, game theory, computer networking, partially observable Markov decision process solving, computer solving of analogy problems, and other areas. Hes earned multiple awards for teaching and research and has served on the editorial boards for The J ournal of Machine Learning Research and The J ournal of Artificial Intelligence Research . He served as General Chair of the International Conference on Machine Learning and Program Chair of the Association for the Advancement of Artificial Intelligence AAAI Conference in 2013. Hes also an AAAI Fellow and Co-Chair of the upcoming Reinforcement Learning and Decision Making Conference, to be held in 2019 in Montreal. Michael is the eighth ACM Fellow among current Brown CS faculty. Others include Maurice Herlihy , Philip Klein , Franco Preparata , John Savage , Roberto Tamassia , Eli Upfal , Andy van Dam , and Stan Zdonik . For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:34+00:00", "headings": ["Information for:", "Brown CS News", "Michael Littman Has Been Named An ACM Fellow"], "word_count": 401, "token_count_estimate": 489}}, "https://cs.brown.edu/news/2019/06/18/brown-cs-undergraduate-atsunobu-kotani-teaches-robots-handwriting-and-drawing/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing Posted by Jesse Polhemus on June 18, 2019 by Kevin Stacey Science News Writer, Physical Sciences Click the links that follow for more news about Stefanie Tellex and other accomplishments by Brown CS students . An algorithm developed by Brown University computer scientists enables robots to put pen to paper, writing words using stroke patterns similar to human handwriting. Its a step, the researchers say, toward robots that are able to communicate more fluently with human co-workers and collaborators. Just by looking at a target image of a word or sketch, the robot can reproduce each stroke as one continuous action, said Atsunobu Kotani, an undergraduate student at Brown who led the algorithms development. That makes it hard for people to distinguish if it was written by the robot or actually written by a human. The algorithm makes use of deep learning networks that analyze images of handwritten words or sketches and can deduce the likely series of pen strokes that created them. The robot can then reproduce the words or sketches using the pen strokes it learned. In a paper presented at the International Conference on Robotics and Automation in May, the researchers demonstrated a robot that was able to write hello in ten languages that employ different character sets. The robot was also able to reproduce rough sketches, including one of the Mona Lisa. Stefanie Tellex , an assistant professor of computer science at Brown and Kotanis advisor, says that what makes this work unique is the ability of the robot to learn stroke order from scratch. A lot of the existing work in this area requires the robot to have information about the stroke order in advance, Tellex said. If you wanted the robot to write something, somebody would have to program the stroke orders each time. With what Atsu has done, you can draw whatever you want and the robot can reproduce it. It doesnt always do the perfect stroke order, but it gets pretty close. Another remarkable aspect of the work, Tellex says, is how the algorithm was able to generalize its ability to reproduce strokes. Kotani trained his deep learning algorithm using a set of Japanese characters, and showed that it could reproduce the characters and the strokes that created them with around 93 percent accuracy. But much to the researchers surprise, the algorithm wound up being able to reproduce very different character types it had never seen before English print and cursive, for example. We would have been happy if it had only learned the Japanese characters, Tellex said. But once it started working on English, we were amazed. Then we decided to see how far we could take it. Tellex and Kotani asked everyone who works in Tellexs Humans to Robots lab to write hello in their native languages, which included Greek, Hindi, Urdu, Chinese and Yiddish among others. The robot was able to reproduce them all with reasonable stroke accuracy. I feel like theres something really beautiful about the robot writing in so many different languages, Tellex said. I thought that was really cool. But the systems masterwork may be its copy of Kotanis Mona Lisa sketch. He drew his sketch on a dry erase board in Tellexs lab, and then allowed the robot to copy it fairly faithfully on the same board just below Kotanis original. It was early morning that our robot finally drew the Mona Lisa on the whiteboard, Kotani said. When I came back to the lab, everybody was standing around the whiteboard looking at the Mona Lisa and asking me if the robot drew this. They couldnt believe it. It was a big moment for Kotani because it was the moment that our robot defined whats beyond mere printing. An ink jet printer can recreate an image, but it does so with a print head that goes back in forth building the image line by line. But this was the robot creating an image with human-like strokes, which to Kotani is something much more humane and expressive. Key to making the system work, Kotani says, is that the algorithm uses two distinct models of the image its trying to reproduce. Using a global model that considers the image as a whole, the algorithm identifies a likely starting point for making the first stroke. Once that stroke has begun, the algorithm zooms in, looking at the image pixel by pixel to determine where that stroke should go and how long it should be. When it reaches the end of the stroke, the algorithm again calls the global model to determine where the next stroke should start, then its back to the zoomed-in model. This process is repeated until the image is complete. Both Kotani and Tellex say the work is a step toward better communication between people and robots. Ultimately, they envision robots that can leave Post-it Notes, take dictation or sketch diagrams for their human coworkers and collaborators. I want a robot to be able to do everything a person can do, Tellex said. Im particularly interested in a robot that can use language. Writing is a way that people use language, so we thought we should try this. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "Brown CS Undergraduate Atsunobu Kotani Teaches Robots Handwriting And Drawing"], "word_count": 907, "token_count_estimate": 1062}}, "https://cs.brown.edu/news/2020/11/18/new-brown-cs-program-researching-socially-responsible-ai-students-hugs/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles A New Brown CS Program Researching Socially-Responsible AI With Students From HUGs Posted by Jesse Polhemus on Nov. 18, 2020 in Socially Responsible Computing , Diversity Click the links that follow for more news about diversity and inclusion at Brown CS , our Socially Responsible Computing program , Amy Greenwald , Jeff Huang , Daniel Ritchie , or James Tompkin . At Brown CS and around the globe, interest in AI and related topics is soaring. CSCI 1470 Deep Learning , only a few years old, today has an enrollment of over 350 students, the departments second largest. But as computer scientists hope to expand the field to historically underrepresented groups HUGs, students from demographics that have born the brunt of algorithmic bias and deepfakes may be understandably hesitant to take part. A new program aims to change that. Thanks to an exploreCSR award from Google, Professors Amy Greenwald , Jeff Huang , Daniel Ritchie , and James Tompkin are launching a program for college students from HUGs in CS that will expose them to socially-responsible ways that AI can be used to realize creative visions . Working virtually at first due to the COVID-19 pandemic, students from around the country will become research associates, paired with Brown graduate student mentors where possible, from similar HUGs to conduct individualized research experiences, each culminating in a substantial artifact. In short, its a behind-the-scenes look at how CS research operates, normalized and without pretentions, that students can use as a building block for future careers. Brown is uniquely qualified for this kind of experience, says Daniel, not only due to our diversity and inclusion programs and our efforts to integrate socially responsible computing across our entire curriculum , but because were the headquarters of the Leadership Alliance. Its a nationwide consortium of higher educational institutions dedicated to training and mentoring a diverse population of students to take up research leadership positions in academia, industry, and government. CS faculty have mentored visiting students as part of Leadership Alliance programs in the past, and well be collaborating with them on this effort and other upcoming outreach initiatives to coordinate professional networking and other opportunities for participating students. Thanks to the departments strong AI and visual computing groups, research topics are many and varied, including creative deepfake detection, mimicking high-end photography, structured image editing, adversarial shape generation, 3D augmented reality sketching, and building AI to play games. Opportunities for projects include literature reviews, replication studies, research apprenticeships, and independent research projects. Although activities will be conducted virtually, the program will culminate in an in-person visit to campus, centered around a symposium in which students present their findings alongside Brown undergrads. Im excited to see how this virtual research associate approach goes, says Daniel. Its really different from the typical outreach approach of bringing students in for a short workshop that lasts maybe for a long weekend. Im hopeful that having a longer timeline, where students get to really experience a research culture over the span of a semester, can have a more lasting impact on attracting students to CS research careers. And well still bring students to campus at the end of this experience, for them to meet with their mentors and collaborators and present their research alongside Brown undergrads, as their research peers. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "A New Brown CS Program: Researching Socially-Responsible AI With Students From HUGs"], "word_count": 583, "token_count_estimate": 706}}, "https://cs.brown.edu/news/2021/07/09/leonhard-spiegelberg-wins-facebook-fellowship/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Leonhard Spiegelberg Wins A Facebook Fellowship Posted by Livia Gimenes on July 9, 2021 in Awards Click here to find out more about other recent accomplishments by Brown CS students . Brown CS PhD student Leonhard Spiegelberg has received a Facebook Fellowship for his research on systems for big data analytics. His paper Tuplex Data Science in Python at Native Code Speed was also published at the ACM Special Interest Group on Management of Data conference. The Facebook Fellowship provides awards to outstanding PhD candidates currently conducting research in the fields of computer vision, programming languages, computational social science, databases, and more. This year, 26 candidates were selected out of 2,163 applicants to receive tuition and fees paid as well as a stipend of 42,000. Leonhards research focuses on building more efficient and productive ways of processing large amounts of data. As a data scientist, you want to focus on the data and the data questions, not on debugging, tuning, and fixing the tools you need to answer them, Leonhard says. Hence, I asked myself whether there isnt a better way to have the high productivity of a high-level language like Python without having to sacrifice performance when scaling out to large datasets. At Brown, Leonhard worked in the systems and database groups , advised by Brown CS Professor Malte Schwarzkopf. Leonhard is the lead developer of Tuplex , a new framework that facilitates the processing of large datasets. Data science is part of nearly every business today, and Leonhards research makes data scientists more productive and energy-efficient by compiling Python code to highly efficient machine code. Pulling this off required a rare combination of skills Leonhard wrote Tuplex, a Python compiler and a parallel execution framework similar to the popular Apache Spark, completely from scratch, says Malte. He is amazingly quick and efficient at turning ideas into code, and has been a fantastic mentor to several undergraduate students who are working on the project. Im delighted that Facebook chose Leonhard for this prestigious fellowship and therefore supports his research going forward. Leonhard joins Brown CS alum Jonathan Mace as the second Brown CS recipient of the fellowship. For more information, click the link that follows to contact Brown CS Communications Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "Leonhard Spiegelberg Wins A Facebook Fellowship"], "word_count": 392, "token_count_estimate": 473}}, "https://cs.brown.edu/news/2021/08/09/wrenn-nelson-and-krishnamurthi-win-programming-editors-choice-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Wrenn, Nelson, And Krishnamurthi Win The Programming Editors Choice Award Posted by Jesse Polhemus on Aug. 9, 2021 in Awards Click the links that follow for more news about Shriram Krishnamurthi , Tim Nelson , Jack Wrenn , and other recent accomplishments by Brown CS faculty and students . New research Using Relational Problems to Teach Property-Based Testing by Brown CS PhD student Jack Wrenn and Professors Tim Nelson and Shriram Krishnamurthi has recently won the annual Editors Choice Award for Volume 5 of The Art, Science, and Engineering of Programming , popularly known as Programming . I think this paper, writes editor Professor Jeremy Gibbons of Oxford University, clearly epitomises the spirit of the journal not just elegant technical work, but also a careful discussion of how properly to evaluate it. In their work, the authors discuss the use of relational problems those for which an input may admit multiple valid outputs to motivate the use of property-based testing PBT libraries. In addition to describing problems that theyve developed for use, they introduce a simple method to evaluate the accuracy of student specifications and demonstrate that students can do quite well at PBT for these problems. Recent days have brought two other honors for Shriram he received an Outstanding Reviewer Award for stellar service on Programming s Standing Review Committee and a Distinguished Reviewer Award for the International Conference on Software Engineering ICSE 2021. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "Wrenn, Nelson, And Krishnamurthi Win The <Programming> Editors' Choice Award"], "word_count": 269, "token_count_estimate": 340}}, "https://cs.brown.edu/news/2021/12/17/brown-cs-student-sreshtaa-rajesh-wins-cadence-women-technology-scholarship/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Brown CS Student Sreshtaa Rajesh Wins A Cadence Women In Technology Scholarship Posted by Jesse Polhemus on Dec. 17, 2021 in Awards , Diversity Click the link that follows for more news about other recent accomplishments by Brown CS students . Each year, Cadence, a computational software company focusing on tools for electronic design automation, awards its Women in Technology Scholarship to support and celebrate young women who are starting their careers. Recently, Brown CS student Sreshtaa Rajesh was declared one of the winners, earning a 5,000 stipend. Your impressive academic achievements, professor recommendations, and drive to shape the future of technology set you apart from the many talented women we considered, writes Academic Network Program Manager Mallory Clemons of Cadence. We are excited for what the future holds for you and the impact you will make in technology. Sreshtaas letters of recommendation were written by Brown CS Professors R. Iris Bahar , who worked with her on a summer research project, and Shriram Krishnamurthi , her CS advisor, with whom shes taken courses and for whom she served as Head Teaching Assistant. Iris explains that Sreshtaas work with her was broadly applicable to artificial intelligence planning in domains where there is uncertainty, such as partial occlusion or inaccurate sensor readings. These types of problems can be represented by frameworks known as PartiallyObservable Markov Decision Processes POMDPs. A POMDP features a set of possible states that the agent could be in, as well as a probability distribution over the set, known as the belief state. Sampling from the belief state informs the agent what state it is most likely in, given all the previous observations it has gotten from the environment. Each time the agent takes an action, it receives a new observation which it then uses to update this belief state and inform future actions. There are several algorithms that exist to solve POMDPs one such is PartiallyObservable Monte Carlo Planning POMCP. At each step in the process, the algorithm runs many random lookahead simulations to determine the best action to take next. The challenge for using this algorithm is that in order to achieve a high reward result, a large number of simulations are required, making the process extremely computationally expensive for large domain realworld problems. Sreshtaa worked closely with one of Iriss PhD students to parallelize the most expensive part of POMCP building the lookahead search tree and running the simulations. Oftentimes, Iris writes in her recommendation letter, when I assign undergraduate students to work with my graduate students, they just follow specific directions given to them. In Sreshtaas case, she was very proactive in offering suggestions, testing out new ideas, and helping implement and debug the parallel algorithm. Specifically, she developed different reward functions for selecting the best action, translated nave implementations of the code to one using pthreads, explored the use of hashmaps to improve code efficiency, and wrote a plotting script to parse the output of our algorithm. In the end, with the parallelized version, we were able to cut down the runtime of the original POMCP algorithm by almost 50. For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "Brown CS Student Sreshtaa Rajesh Wins A Cadence Women In Technology Scholarship"], "word_count": 552, "token_count_estimate": 685}}, "https://cs.brown.edu/news/2022/05/17/zachary-espiritu-wins-norman-k-meyrowitz-81-award/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles Zachary Espiritu Wins The Norman K. Meyrowitz 81 Award Posted by Jesse Polhemus on May 17, 2022 in Awards Click the links that follow for more news about Zachary Espiritu , Norm Meyrowitz , and other recent accomplishments by our students . Brown University s Department of Computer Science has just announced that Zachary Espiritu, a Brown CS student, SPOC Systems Programmer, Operator, and Consultant, and one of the four Meta-TAs who coordinate the Undergraduate Teaching Assistant program , has just won the Norman K. Meyrowitz 81 Award. Named for an alum known for his contributions to the department, the award recognizes exceptionally meritorious service to Brown CS and is accompanied by a cash prize of five hundred dollars. Zach was a super-competent UTA, HTA, and MTA, says Brown CS Professor Tom Doeppner , Vice Chair and Director of Undergraduate Studies. He excelled in research, particularly in cybersecurity, but was also sought out for his research skill in other areas. He took time off from school to undergo cancer treatment, which he pulled through to the relief of everyone. Norm Meyrowitz feels similarly. Ive worked with Zach over the past year, he says, and I can certify that he has done amazingly at a job way more complicated than the one done by the person after whom the award is named. For more information, click the link that follows to contact Brown CS Communication Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "Zachary Espiritu Wins The Norman K. Meyrowitz '81 Award"], "word_count": 255, "token_count_estimate": 328}}, "https://cs.brown.edu/news/2022/06/06/rldm-2022-brings-over-500-reinforcement-learning-researchers-brown/": {"text_content": "Brown CS News Categories Awards 186 articles Socially Responsible Computing 43 articles Diversity 29 articles RLDM 2022 Brings Over 500 Reinforcement Learning Researchers To Brown Posted by Jesse Polhemus on June 6, 2022 Click the links that follow for more news about George Konidaris , Michael Littman , and other recent accomplishments by our faculty. This week, Brown University hosts the Multi-disciplinary Conference on Reinforcement Learning and Decision Making RLDM, bringing over 500 of the fields thought leaders to Providence and demonstrating Browns continued status as one of the worlds leading centers for reinforcement learning RL research and study. Attendees will include the fields founders, Andy Barto and Rich Sutton, and many others who have made seminal contributions, including Peter Dayan, who in 2017 received a Brain Prize for identifying how RL principles explain the workings of the dopamine system in the brain and its implications for human decision-making and its disorders. The RL field has been incredibly influential for developing new principles of brain function, says Professor Michael Frank. This conference is a fertile ground by which research communities with shared goals in understanding natural and artificial intelligence can augment each other and catalyze new discoveries. Were thrilled to host it at Brown. RLDM is an interdisciplinary conference, hosting two families of RL researchers who often work in parallel those studying computational reinforcement-learning algorithms, and those who use reinforcement learning as a model of decision-making in the brain and reciprocally develop new RL algorithms to better capture the mechanisms by which the brain solves RL problems, and to inspire developments in AI. Brown is home to some of the fields leading researchers in both families, the former at Brown CS Professors Amy Greenwald, George Konidaris, Michael Littman, and Stefanie Tellex and the latter at the Carney Institute for Brain Science and its Center for Computational Brain Science Professors Wael Asaad, David Badre, Theresa Desrochers, Oriel FeldmanHall, Michael Frank, Matthew R. Nassar, Frederike Petzschner, and Amitai Shenhav. The conference features invited talks from speakers on both sides of the artificialnatural divide, including Browns own Professor Stefanie Tellex from the CS side and Professors Oriel FeldmanHall and Frederike Petzschner from the natural side. Professor Arif Hamid of the University of Minnesota, former postdoctoral trainee with Professors Michael Frank and Christopher Moore of the Carney Institute, will also present a revised understanding of the dopamine system with implications for RL based on work they did at Brown. Other speakers are listed here . The main meeting will be single-track, consisting of a mixture of invited and contributed talks, tutorials, and poster sessions. For those unable to attend, all invited and contributed talks will be recorded and made public within a few days after the talks. Professor Michael Littman of Brown CS is General Co-Chair of the event, along with New York Universitys Professor Catherine Hartley. The two served as program chairs for the 2019 conference. This years Program Chairs are Professor Roshan Cools of Radboud University Nijmegen and Peter Stone of University of Texas at Austin. Local Chairs are Professor Michael Frank, Director of the Carney Center for Computational Brain Science and Professor of Cognitive, Linguistic, and Psychological Sciences CLPS, and Professor George Konidaris of Brown CS. The Social Chair is Professor Amitai Shenhav of CLPS. Sponsors include the Carney Institute for Brain Science, Sony AI, Microsoft, DeepMind, the Vector Institute, and Google. Reinforcement learning is at the very core of the entire Artificial Intelligence enterprise, says Professor George Konidaris of Brown CS, because its the only machine learning paradigm that focuses on how an agents interaction with the world can help it achieve its goals. Its incredibly exciting to have RL researchers from all over the world including my home country of South Africa converging on Brown, which in the last decade or so has become a world center for RL research. He added, Its going to be great to see everyone again For more information, click the link that follows to contact Brown CS Communication and Outreach Specialist Jesse C. Polhemus .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:35+00:00", "headings": ["Information for:", "Brown CS News", "RLDM 2022 Brings Over 500 Reinforcement Learning Researchers To Brown"], "word_count": 672, "token_count_estimate": 858}}, "https://cs.brown.edu/people/avandam/": {"text_content": "Andries van Dam Thomas J. Watson, Jr. University Professor of Technology and Education and Professor of Computer Science Brown University, Box 1910, Providence, RI 02912 phone 401 863-7640, fax 401 863-7657 email avdcs.brown.edu Andries van Dam Andy has been on Browns faculty since 1965, and was one of the Computer Science Departments co-founders and its first Chairman, from 1979 to 1985. He was a Principal Investigator and was the Director from 1996-1998 in the NSF Science and Technology Center for Graphics and Visualization , a research consortium including Brown, Caltech, Cornell, North Carolina Chapel Hill, and the University of Utah. He served as Browns first Vice President for Research from 2002-2006. Professor van Dam received his B.S. degree with Honors in Engineering Sciences from Swarthmore College in 1960 and his M.S. and Ph.D. from the University of Pennsylvania in 1963 and 1966, respectively. Recent Events Celebrating CHM 2021 Fellow Andy van Dam Andy van Dam has devoted his lifes work to revolutionizing how people and ideas connect through computers, how people and computers connect through interactive graphics, how scholars connect through digital humanities education, and how technology and society can connect in ways that are good for humanity. AREC Distinguished Lectures Series Andy van Dam Reflections on Hypertext, the Online World, and Societal Impact Computer graphics legend, Andries Andy van Dam is co-designer of HES and FRESS, the first and second hypertext systems allowing information to connect through hyperlinks. Crucial to the development of modern markup and browsing technology, van Dams work influenced how we use the web today. He founded the computer science department at Brown University and served as its first chair from 1979-1985. A pioneer in his field, he co-authored Computer Graphics Principles and Practice, a textbook that defined computer graphics that remains the classic standard introduction into the field. Credited with founding SICGRAPH, van Dams distinguished career includes receiving the ACM Karl V. Karlstrom Outstanding Educator Award, the SIGGRAPH Steven A. Coons Award for Outstanding Creative Contributions to Computer Graphics, the IEEE Centennial Medal, and honorary doctorates from Darmstadt Technical University, Swarthmore College, the University of Waterloo, and ETH Zurich. ACM Hypertext 2019 Andy van Dam Keynote Reflections on a Half-Century of Hypertext Is It Time to Declare Victory and Go Home Or Hypertext The Web wasnt the Beginningand the Web isnt the End - Norm Meyrowitz CSCI 1951V HypertextHypermediaThe Web Was Not the Beginning and the Web Is Not the End CSCI1951-V, HypertextHypermedia The Web Was Not the Beginning and the Web Is Not the End, looks at hypertext systems that came before and after the World Wide Web as a basis for discussing what next generation hypertext systems could look like. Students will be doing writing assignments, reading, annotating, and writing technical papers, participating in in-class brainstorming sessions, discussing materials in a roundtable format, and developing software prototypes with Javascript and the state-of-the-art MERN MongoDB, Express, React and Node.js stack. Students will learn not only about hypertext, but will use that knowledge to develop full-stack applications using modern technologies and high-level software architectures as they prototype systems of the future. The course will be capped at 35 students to facilitate participation and discussion. Research His research has concerned computer graphics, hypermedia systems, post-WIMP user interfaces, including pen-centric computing, and educational software. He has been working for over four decades on systems for creating and reading electronic books with interactive illustrations for use in teaching and research. Publications The completely rewritten third edition of the widely used reference book Computer Graphics Principles and Practice , co-authored with John F. Hughes, Morgan McGuire, David Sklar, James D. Foley, Steven K. Feiner, and Kurt Akeley, was released at ACM SIGGRAPH 2013 and is available from Amazon. Prof. Hughes wrote a description of the extensive changes and additions in the new version on the CS Blog New Edition of Computer Graphics Principles and Practice Earlier editions include Fundamentals of Interactive Computer Graphics, co-authored with J.D. Foley, was published by Addison-Wesley in 1982 the expanded successor, Computer Graphics Principles and Practice, co-authored with J.D. Foley, S.K. Feiner, and J.F. Hughes, was published in June of 1990. An undergraduate version, by the same four authors and D. Phillips, Introduction to Computer Graphics, was published in 1993. Pascal on the Macintosh - a Graphical Approach, co-authored with David Niguidula, was published by Addison-Wesley in 1987. Object-Oriented Programming in Pascal, A Graphical Approach, co-authored with D. Brookshire Conner, and David Niguidula was published in April, 1995. Frontiers of Human-Centered Computing, OnLine Communities and Virtual Environments, with Rae Earnshaw, Richard Guedj, and John Vince Eds was published in February 2001, and Object-Oriented Programming in Java A Graphical Approach, co-authored with Kathryn E. Sanders was published by Addison-Wesley in 2005. van Dam has authored or coauthored over 100 papers, which are listed in his Curriculum Vitae . Courses CS123 - Introduction to Computer Graphics lectures are available for downloading in PDF format. CS15 - Introduction to Object-Oriented Programming and Computer Science lectures are available for downloading in PDF format. Awards Among his awards are the Society for Information Displays SpecialRecognition Award 1974, the IEEE Centennial Medal 1984, theNational Computer Graphics Associations Academic Award 1990, theACM SIGGRAPH Steven A. Coons Award 1991, the L. Herbert BallouUniversity Professor Chair 1992, the ACM Karl V. Karlstrom Outstanding Educator Award 1994, the Thomas J. Watson, Jr.University Professor of Technology and Education Chair 1995, the IEEE James H. Mulligan, Jr. Education Medal 1999, and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education 2000. In 1994 he became an IEEE Fellow and an ACM Fellow.He received an honorary Ph.D. from Darmstadt Technical University in Germany 1995, an honorary Ph.D. from SwarthmoreCollege 1996, an honorary Ph.D. from the Faculty of Mathematics, University of Waterloo 2007, and an honorary Ph.D. from the Department of Computer Science, ETH Zurich 2008. In 1996 he was inducted into the National Academy of Engineering, in 2000 he became a Fellow of the American Academy of Arts and Sciences, in 2002 he received the CRA Distinguished Service award and the Brown University Sheridan Teaching award, and in 2004 was elected a fellow of the American Association for the Advancement of Science. Professional Activities In 1967, Professor van Dam co-founded ACM SIGGRAPH and from 1985 through 1987 was Chairman of the Computing Research Association. He has been Associate Editor of the ACM Transactions on Graphics 1981-1986, Editorial Board Member of Computers and Graphics, Pergamon Press 1983 -1994, Advisory Editor, Journal of Visual Languages and Computing, Academic Press 1989-1998, and Editorial Board Member of the IEEE Transactions on Visualization and Computer Graphics, 1994-1998. From 1991 - 2006 he served on the Microsoft Research Technical Advisory Board MSR TAB. Hobbies grandchildren, eating well, and outdoor sports--especially sea-kayaking, scuba-diving, mountain biking, skiing and backpacking. Andy -- Switzerland -- August 2016 CS15 , CS123 gfxwwwcs.brown.edu", "metadata": {"last_modified": "2021-09-25T03:34:48+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Andries van Dam"], "word_count": 1136, "token_count_estimate": 1636}}, "https://cs.brown.edu/people/alysyans/": {"text_content": "Anna Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Brown University Box 1910 Providence, RI 02912 401 863-7600 anna at cs.brown.edu Homepage Brief bio Contact info Research Teaching Tweets Welcome to my homepage I am James A. and Julie N. Brown Professor of Computer Science at the Computer Sciencedepartment at Brown University . My research area is Cryptography. Of particular importance in myresearch are privacy-enhancing technologies that allow individuals togo about their daily online lives without disclosing unnecessarypersonal data. I am most proud of my work on anonymous credentials andelectronic cash. I am also interested in more broad and foundationalcryptographic questions. If you are a prospective Ph.D. student interested in Cryptography, I encourage you to apply to the Brown CS department . Current Ph.D. students Leah Rosenbloom, Scott Griffy, Victor Youdom Kemmoe Past Ph.D. students Mira Belenkiy Melissa Chase Alptekin Kp . Feng-Hao Liu Foteini Baldimtsi Elizabeth Crites Apoorvaa Deshpande Megumi Ando This semester Spring 2024, I am teaching CSCI1040 The Basics of Cryptographic Systems .In the Fall, I will be on Sabbatical.", "metadata": {"last_modified": "2024-03-06T14:55:33+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": [], "word_count": 176, "token_count_estimate": 265}}, "https://cs.brown.edu/people/bcz/": {"text_content": "Intra-Mural Football Champs, 2001", "metadata": {"last_modified": "2022-02-02T20:40:30+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": [], "word_count": 4, "token_count_estimate": 11}}, "https://cs.brown.edu/people/bjm/bio/": {"text_content": "Home Teaching Research Creative Visual Effects Images Animations DrawingsPaintings Interests Publications Bio Contact Info Links Biography Barbara Meier is an animator and teaches computer animation at Brown University in Providence, Rhode Island. Her research interests include non-photorealistic rendering and creating tools for artists that build on artists preferred working methods. In her art work, she designs new visual styles of animation that combine traditional and computer techniques. Previously, Meier created visual effects for feature films in Hollywood at Pacific Data Images, Cinesite, and Hammerhead Productions, and developed a painterly rendering technique for Fantasia 2000 at Walt Disney Feature Animation. She received BA and MS degrees in Computer Science from Brown and studied animation and illustration at the Rhode Island School of Design, Art Center College of Design, and the Museum School in Boston. Meier lives in Barrington, Rhode Island with her husband and two sons.", "metadata": {"last_modified": "2012-03-28T00:20:15+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["Biography"], "word_count": 145, "token_count_estimate": 180}}, "https://cs.brown.edu/people/bnacar/": {"text_content": "Benjamin Ewing Nacar Brown University 2012 Sc. B. Computer Science also finished a concentration in Classics CS31 TA Fall 2010 Sunlab Consultant Fall 2011-Spring 2012 CS146 Head TA Spring 2012 Tstaff, Systems Programmer 2015-2022 Musical projects Ben Nacars Home Page YouTube channel insearchofthemuses Other Ben Nacars Other Stuff Contact benjaminnacar at alumni dot brown dot edu bnacar at cs dot brown dot edu ben at bennacar dot com CS Home People", "metadata": {"last_modified": "2022-06-01T01:14:06+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["Benjamin Ewing Nacar", "Musical projects", "Other", "Contact"], "word_count": 71, "token_count_estimate": 117}}, "https://raphael-group.github.io/research/": {"text_content": "Research Teaching Publications Software Projects AncesTree Binary Tree Partition CHISEL CNT-ILP CNT-MD CoMEt Dendrix GASV GASVPro Gremlin HATCHet HotNet HotNet2 MAGI MASCoTE MoDL Multi-Dendrix MultiBreak-SV NAIBR NBC PASTRI PREGO RAIG SPRUCE Survival Analysis TADtree THetATHetA2 WExT People News research We develop algorithms and mathematical models to address biological problems. Major areas of interest include computational cancer genomics, human structural variation, and comparative genomics. The motivation for many of our current projects derives from the tremendous advances in DNA sequencing technology over the past few years. Next-generation DNA sequencing machines have lowered the cost of DNA sequencing by orders of magnitude, and enabled a variety of new applications such as personal genome sequencing and cancer genome sequencing. Computational Cancer Genomics We develop algorithms to study somatic mutations that drive cancer progression. Specific areas of interest include Identification of genome rearrangements including translocations, inversions, deletions, and duplications in cancer genomes. We designed the RAIG and NBC algorithms to detect recurrent and independent copy number aberrations. Reconstruction of highly scrambled cancer genomes and the mechanisms that produce them. We introduced the PREGO algorithm to combine rearrangement breakpoints and copy number data in cancer genomes.Study of changes in gene structure and regulation that result from these rearrangements. Cancer Genome Evolution. Cancer is a microevolutionary process in a population of cells that reproduce via cell division and acquire new mutations. Extracting information about the process of tumor evolution from bulk sequencing data containing mixtures of cells demands novel computational approaches. We developed several algorithms to study intra-tumor heterogeneity and tumor evolution including THetA , rec-BTP , and AncesTree . Network and pathway-based analysis of somatic mutations. We designed the HotNet and HotNet2 algorithms for de novo identification of mutated subnetworks in large-scale protein-protein interaction networks using somatic mutation data from multiple cancer patients. De novo identification of combinations of mutually exclusive mutations. Early cancer sequencing studies demonstrated that in many cases somatic mutation of a single gene in a pathway e.g. a pathway controlling cell growth is sufficient to perturb this pathway. This implies that when examining somatic mutations from many patients, mutations in the same pathway will exhibit a pattern of mutual exclusivity. We designed Dendrix , Multi-Dendrix and CoMEt algorithms for de novo identification of one or more sets of mutually exclusive mutations. Comparative Genomics We study the role of structural variation genome rearrangements, segmental duplications, and repeats in evolution and human genetics. Sequencing Structural Variants We are developing scalable and robust algorithms to identify structural variants in individual genomes and to compare structural variants across individuals using various second and third generation DNA sequencing technologies. We introduced Geometric Analysis of Structural Variants GASV a geometric method that explicitly computes the information that each measurement reveals about the boundaries breakpoints of a structural variant and quantifies the uncertainty associated with this measurement. We are designing algorithms to maximize the effectiveness of emerging single-molecule sequencing technologies for detecting and assembling complex structural variants and for de novo genome assembly. In particular, we designed the MultiBreak-SV algorithm for long-read and strobe read sequencing data from Pacific Biosciences . Other Research We have also worked on a number of other areas in computational biology. Examples include Visualization and collaborative annotation of genomics data OBrien et al. 2010, Leiserson et al. 2015 Chromatin organization Weinreb and Raphael 2015. Proteomics Nguyen et al. 2009, Ritz et al. 2009, Metagenomic studies of protein family diversity Yooseph et al. 2006 Multiple sequence alignment with block rearrangements Raphael, et al. 2004 Motif finding Raphael, Liu and Varghese, 2004 See the publications page for further details. Raphael Research Group 2014-2017 Princeton University Department of Computer Science", "metadata": {"last_modified": "2024-02-29T22:47:17+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["research", "Computational Cancer Genomics", "Comparative Genomics", "Sequencing Structural Variants", "Other Research"], "word_count": 604, "token_count_estimate": 819}}, "https://cs.brown.edu/people/apapouts/faculty_dataset.html": {"text_content": "Dataset of 2200 faculty in 50 top US Computer Science Graduate Programs Alexandra Papoutsaki, Hua Guo, Danae Metaxa-Kakavouli, Connor Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang Brown University, Providence, RI, USA Any questions or comments should be sent to alexpapcs.brown.edu The Dataset We provide the first free dataset of all professors in 50 top US Computer Science Graduate Programs. We believe that we offer a valuable resource to the academic community and to anyone who is interested in the shape of the Computer Science in the most competitive institutes of the US. You can download the database from here if you want to explore the data. To avoid conflicts you can only download and comment on the spreadsheet. You do not need to be signed in with a Google account. How to fix an incorrect entry If you find any errors, you can right-click the cell you want to fix and add a comment . We will double-check your correction and we will accept your change accordingly. How to insert a new professor If you cannot find a professor you can right-click and add a comment in one of the empty lines in the bottom of the spreadsheet. Try to insert as many of the required fields as possible. How to use this dataset Here is a list of suggestions Look up faculty in a particular area when applying to grad schools Track Alumni Chose what field to study Look at what is the breakdown of research areas per department Disclaimer We do not make any guarantee on the quality of the data. As you can read below, we used crowdsourcing techniques to create this database. We expect about 80 of our data to be correct.We need your help to fix any errors that are still left. Did you know Here are some interesting facts we found when analysed the data. Last version of dataset that was used was downloaded on Wednesday, October 22th, 2014 0853 PMEDT . Largest fields of research These are the fields of research according to their popularity. Field of Research Number of Professors Algorithms Theory 296 Networks Communications 168 Artificial Intelligence 151 Hardware Architecture 142 Bioinformatics Computational Biology 131 Security Privacy 130 Human-Computer Interaction 129 Graphics 118 Distributed Parallel Computing 101 Machine Learning Pattern Recognition 99 Programming Languages 98 Computer Vision 95 Scientific Computing 89 Software Engineering 83 Databases 80 Operating Systems 71 Natural Language Speech 58 Computer Education 49 Real-Time Embedded Systems 35 Data Mining 32 Multimedia 16 Information Retrieval 6 World Wide Web 5 Where do most professors get their bachelors from These are the universities with at least 10 BSc alumns that provide the largest number of BSc among the professors in 50 top universities. Bachelors University Number of Professors Massachusetts Institute of Technology - USA 117 Harvard University - USA 66 Cornell University - USA 46 University of California - Berkeley - USA 43 Indian Institute of Technology - Madras - India 37 Tsinghua University - Beijing - China 33 Indian Institute of Technology - Kanpur - India 32 Stanford University - USA 32 Princeton University - USA 32 Carnegie Mellon University - USA 31 Brown University - USA 29 Yale University - USA 25 Indian Institute of Technology - Bombay - India 24 Rice University - USA 23 University of Michigan - USA 21 Georgia Institute of Technology - USA 20 California Institute of Technology - USA 19 Indian Institute of Technology - Delhi - India 19 University of Illinois at Urbana-Champaign - USA 18 University of Science and Technology of China - China 18 Duke University - USA 17 Indian Institute of Technology - Kharagpur - India 16 Peking University - Beijing - China 16 University of California - Los Angeles - USA 15 National Taiwan University - Taipei - Taiwan 15 Columbia University - USA 14 University of Toronto - Canada 14 Pennsylvania State University - USA 14 University of Texas - Austin - USA 13 Technion-Israel Institute of Technology - Israel 13 National Technical University of Athens - Greece 13 Purdue University - USA 12 University of Wisconsin - Madison - USA 12 Hebrew University of Jerusalem - Israel 12 Polytechnic University of Bucharest - Romania 11 Dartmouth College - USA 11 Birla Institute of Technology and Science - Pilani - India 10 Where do most professors get their doctorate degree from These are the universities with at least 10 PhD alumns that provide the largest number of PhD among the professors in 50 top universities. 10 universities account for 50 of all PhDs students that become faculty in 50 top universities Doctorate University Number of Professors Massachusetts Institute of Technology - USA 251 University of California - Berkeley - USA 181 Stanford University - USA 146 Carnegie Mellon University - USA 121 University of Illinois at Urbana-Champaign - USA 82 Cornell University - USA 68 Princeton University - USA 66 University of Washington - USA 63 Georgia Institute of Technology - USA 54 Harvard University - USA 51 University of Texas - Austin - USA 50 University of Wisconsin - Madison - USA 45 University of Pennsylvania - USA 40 University of Maryland - College Park - USA 39 University of California - Los Angeles - USA 34 University of Michigan - USA 34 California Institute of Technology - USA 32 Columbia University - USA 31 University of Toronto - Canada 27 Purdue University - USA 26 University of Southern California - USA 26 University of North Carolina - Chapel Hill - USA 25 Yale University - USA 24 University of Massachusetts - Amherst - USA 24 Brown University - USA 23 University of California - San Diego - USA 22 University of Minnesota - Twin Cities - USA 22 State University of New York - Stony Brook - USA 22 New York University - USA 21 Rice University - USA 21 Pennsylvania State University - USA 20 University of Rochester - USA 18 University of Utah - USA 18 University of Virginia - USA 16 Ohio State University - USA 16 University of California - Irvine - USA 15 University of Chicago - USA 15 Hebrew University of Jerusalem - Israel 13 University of Colorado Boulder - USA 12 Johns Hopkins University - USA 12 Duke University - USA 12 Rutgers - State University of New Jersey - New Brunswick - USA 10 University of California - Santa Barbara - USA 10 Computer Science Department Sizes In order to interpret correctly the above data you would need to know the size of each department. University Size in faculty Carnegie Mellon University 131 Georgia Institute of Technology 93 Massachusetts Institute of Technology 80 University of California - Irvine 61 University of Maryland - College Park 60 University of Michigan 59 Northwestern University 59 University of California - San Diego 57 University of Illinois at Urbana-Champaign 57 University of California - Berkeley 54 University of Southern California 54 Duke University 52 Stanford University 52 University of Washington 49 Columbia University 48 Purdue University 48 North Carolina State University 47 University of Utah 45 Texas AM University 42 University of Florida 40 University of California - Los Angeles 40 Virginia Polytechnic Institute and State University 39 University of Colorado Boulder 39 Rutgers - State University of New Jersey - New Brunswick 39 Ohio State University 38 University of Wisconsin - Madison 38 University of Texas - Austin 38 New York University 37 University of Massachusetts - Amherst 37 State University of New York - Stony Brook 36 Cornell University 36 University of Minnesota - Twin Cities 34 Pennsylvania State University 33 University of California - Santa Barbara 32 Princeton University 32 University of North Carolina - Chapel Hill 31 University of California - Davis 31 University of Pennsylvania 31 Brown University 30 University of Chicago 29 Johns Hopkins University 29 Rensselaer Polytechnic Institute 29 Harvard University 25 University of Virginia 23 Arizona State University 23 Washington University - St. Louis 21 University of Rochester 20 Yale University 20 University of Pittsburgh 20 Rice University 20 Boston University 19 University of Arizona 18 California Institute of Technology 15 Dartmouth College 12 New hires since 2009 by University University Number of hires since 2009 Carnegie Mellon University 24 Georgia Institute of Technology 19 University of Michigan 17 University of Colorado Boulder 15 Ohio State University 14 University of Washington 12 University of Southern California 12 Stanford University 12 Columbia University 11 University of Chicago 10 State University of New York - Stony Brook 10 Johns Hopkins University 10 Massachusetts Institute of Technology 10 University of Utah 10 Cornell University 10 Rutgers - State University of New Jersey - New Brunswick 10 University of Illinois at Urbana-Champaign 10 University of Florida 9 New York University 9 Duke University 9 Brown University 9 University of California - Berkeley 8 University of North Carolina - Chapel Hill 8 Texas AM University 8 University of California - Santa Barbara 8 University of Maryland - College Park 8 University of Wisconsin - Madison 7 North Carolina State University 7 University of Massachusetts - Amherst 7 University of California - San Diego 7 University of Texas - Austin 7 University of Pennsylvania 7 Northwestern University 7 Harvard University 6 Princeton University 6 Dartmouth College 5 Purdue University 5 Virginia Polytechnic Institute and State University 5 Pennsylvania State University 5 Rensselaer Polytechnic Institute 5 Washington University - St. Louis 5 University of California - Irvine 5 University of Rochester 4 University of Virginia 4 University of Minnesota - Twin Cities 4 University of California - Los Angeles 4 California Institute of Technology 4 Rice University 4 Boston University 3 Arizona State University 2 Yale University 2 University of Pittsburgh 2 University of Arizona 1 New hires since 2009 by Field of Research Field of Research Number of hires since 2009 Algorithms Theory 61 Human-Computer Interaction 34 Machine Learning Pattern Recognition 32 Artificial Intelligence 30 Bioinformatics Computational Biology 29 Security Privacy 28 Networks Communications 27 Computer Vision 23 Distributed Parallel Computing 21 Graphics 18 Hardware Architecture 17 Software Engineering 15 Databases 15 Programming Languages 13 Natural Language Speech 11 Scientific Computing 11 Data Mining 10 Computer Education 9 Operating Systems 9 Real-Time Embedded Systems 8 Multimedia 1 The Paper A paper titled Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters has been accepted at HCOMP 2015. Supplemental Analysis by Prof. Jeff Huang Professor Jeff Huang has released a detailed analysis that accompanies this dataset on his website. He reports Composition of Computer Science Departments, Hiring Trends of Universities, andEducational Background of Professors. You can find his analysis here . Ranking based on the Number of Papers in Theory Professor Mohammad Taghi Hajiaghayi and his student Saeed Seddighin of University of Maryland, along with researchers from MIT created a revised ranking of CS Departments based on our dataset and the number of papers in Theory. They intend to release a ranking for other CS areas soon. You can find their ranking here . Visual Exploration of Data PhD student M. Adil Yalcin of University of Maryland incorporated our dataset in keshif . You can perform various queries and see the results in an accessible GUI. Behind the scenes This dataset is the outcome of a seminar course on Human-Computer Interaction taught by Professor Jeff Huang in the Department of Computer Science of Brown University , during the academic semester of Spring 2014. As part of an assignment , 19 students were given 30 each and were asked to come up with different strategies that would allow them to employ workers on Amazon Mechanical Turk, in order to collect a full record of all professors in 5 top Computer Science Graduate Programs. Our goal was to create a full record of all Computer Science professors in 50 top Graduate Programs, according to the popular ranking of US News .For now, we restrict the professors to only Full, Associate, or Assistant. Lecturers, Researchers, Teaching faculty are not allowed momentarily. We also only allow professors of the 50 provided universities.In the future we wish to expand this database to fully reflect the status of each Computer Science department. For each professor we require 10 pieces of information Name Full Name University The name of the university they teach JoinYear When they joined that department of Computer Science as faculty Rank One of Full, Associate, Assistant Subfield Main field of research. One of the 20 fields reported by Microsoft Academic Bachelors University they acquired their BSc degree from Masters University they acquired their MSc degree from Doctorate University they acquired their PhD degree from PostDoc University or Company they did their post-doctoral training Sources at least one link to the source that contains the above information Since we ended up with 2 instances of each department we managed to increase the accuracy of the database by merging them into a single dataset. Special Thanks This work would not be possible without the hard work of 19 exceptional students. We would like to thank Suliman Alsowelim, Ali Erman Celen, Eda Celen, Connor Gramazio, Hua Guo, Scott Houde, Chris Johnson-Roberson, Danae Metaxa-Kakavouli, Amia Oberai, Alexandra Papoutsaki, Jeff Rasley, Jiangnan Shangguan, Erica Silverstein, Chris Tanner, Guan Wang, Wenting Xie, Fan Yang, Charles Yeh, and Zhe Zhao. Special thanks also to Lucas Kang for curating the dataset over the summer of 2014. And of course thanks to all of you, anonymous or not, contributors.", "metadata": {"last_modified": "2015-08-11T15:35:55+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["Dataset of 2200 faculty in 50 top US Computer Science Graduate Programs", "The Dataset", "Did you know?", "The Paper", "Supplemental Analysis by Prof. Jeff Huang", "Ranking based on the Number of Papers in Theory", "Visual Exploration of Data", "Behind the scenes", "Special Thanks"], "word_count": 2233, "token_count_estimate": 2784}}, "https://cs.brown.edu/people/dhl/": {"text_content": "David H. Laidlaw Computer Science Brown University Visualization Research Lab lab research pages Research Interests Caltech graphics group Beckman Institute Biology division web pages Some of the projects I am directing and participating in are alsodescribed in the scientific visualization pages of the Brown Graphics Group. Check out the VR Wiki that my cs1951t class has been building. My CV lists publications, teaching,service, funding, and has links to papers. List of allpublications at DPLP , and at PubMed diffusion MRI data Questions, comments, suggestions E-mail me dhlcs.brown.edu Office CIT 521 Snail mail Box 1910, Computer Science Department Brown University Providence, RI 02912 Packages Computer Science Dept 115 Waterman St 4th floor Providence, RI 02906 401-863-7600 voice 401-863-7657 fax For students If you are in CS, See my tips for advisees page", "metadata": {"last_modified": "2022-03-20T18:20:35+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["", "David H. Laidlaw", "Visualization Research Lab", "Research Interests", "For students"], "word_count": 131, "token_count_estimate": 191}}, "https://cs.brown.edu/people/dc65/": {"text_content": "Do Kook DK Choe Hi, I am DK. I am interested in Natural Langauge Processing and Deep Learning. I am a member of Descartes headed by Ray Kurzweil at Google. While interning in 2015 with Yun-hsuan Sung and Brian Strope , I built a prototype of a Natural Language Understanding NLU system, which now serves Allo , Smart Reply and other products. Now I work on improving the NLU system and exploring its new applications. I developed a state-of-the-art parser and received my PhD from Brown University under the supervision of Eugene Charniak . In the summer of 2014, I was an intern at IBM Research working on parsing with David McClosky and Jennifer Chu-Carroll . During my undergrad at NYU, I did research with David Sontag on MAP inference. Contact me at dokookchoegmail.com . Publications EMNLP, November 2016 Parsing as Language Modeling Do Kook Choe, Eugene Charniak EMNLP, September 2015 Syntactic Parse Fusion Do Kook Choe, David McClosky, Eugene Charniak ACL, July 2015 Parsing Paraphrases with Joint Inference extended version Do Kook Choe, David McClosky ACL, July 2015 Sparse, Contextually Informed Models for Irony Detection Exploiting User Communities, Entities and Sentiment Byron C. Wallace, Do Kook Choe, Eugene Charniak ACL, June 2014 Humans Require Context to Infer Ironic Intent so Computers Probably do, too Byron C. Wallace, Do Kook Choe, Laura Kertz, Eugene Charniak EMNLP, October 2013 Naive Bayes Word Sense Induction Do Kook Choe, Eugene Charniak UAI, August 2012 Efficiently Searching for Frustrated Cycles in MAP Inference David Sontag, Do Kook Choe, Yitao Li", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "word_count": 256, "token_count_estimate": 410}}, "https://cs.brown.edu/people/eupfal/home.htm": {"text_content": "Home Biography Publications Research Teaching Editorial Consulting Brown University P.O. Box 1910 Providence, RI 02912 USA Voice 401-863-7645 Fax 401-863-7657 Mail elics.brown.edu Im the Rush C. Hawkins professor of computer science at Brown University, during 2002 -2007 I was also the department chair. Before coming to Brown in 1998 I was a researcher and project manager at the IBM Almaden Research Center in California, and a professor at the Weizmann Institute in Israel. I received an undergraduate degree in mathematics and statistics and a doctorate degree in computer science from the Hebrew University in Jerusalem, Israel. My research focuses on the design and analysis of algorithms. In particular Im interested in randomized algorithms and probabilistic analysis of algorithms. Applications range from combinatorial and stochastic optimization to routing and communication networks, computational biology, and computational finance. Visit our Research Group Page My Erdos number is 2, and I am a mathematical descendant of Eli Shamir, Jacques Hadamard 4th generation, Simeon Denis Poisson 8th generation and Pierre-Simon Laplace 9th generation. . Designed by Ahmed Idrissi", "metadata": {"last_modified": "2021-06-03T15:40:48+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": [], "word_count": 173, "token_count_estimate": 246}}, "https://cs.brown.edu/people/epavlick/": {"text_content": "Research current Teaching Data Contact Ellie Pavlick I am an Assistant Professor of Computer Science and Linguistics at Brown University , and a Research Scientist at Google Deepmind . I lead the Language Understanding and Representation LUNAR Lab, which seeks to understand how language works and to build computational models which can understand language the way that humans do. My labs projects focus on language broadly construed, and often includes the study of capacities more general than language, including conceptual representations, reasoning, learning, and generalization. We are interested in understanding how humans acheive these things, how computational models especially large language models and similar types of black box AI systems achieve these things, and what insights can be gained from comparing the two. We often collaborate with researchers outside of computer science, including cognitive science, neuroscience, and philosophy. For more information on my current research priorities, please visit the LUNAR Lab page . My Google Scholar page is probably the best place to see what my students, collaborators, and I have been up to most recently.", "metadata": {"last_modified": "2023-11-13T18:46:38+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["Ellie Pavlick"], "word_count": 176, "token_count_estimate": 204}}, "https://cs.brown.edu/people/echarnia/": {"text_content": "Eugene Charniak eccs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7636 voice 401-863-7657 fax Finger me. Index Books Recent Publications Biographical Material CS 241 Natural Language Processing at Brown Software Books Statistical Language Learning , Cambridge MIT Press1993 Introduction to ArtificialIntelligence with Drew McDermott, Reading MA Addison-Wesley 1985 Artificial Intelligence Programming now in a second edition with Chris Riesbeck, Drew McDermott, andJames Meehan, Hillsdale NJ Lawrence Erlbaum Associates 1980, 1987 Computational Semantics , withYorick Wilks, Amsterdam North-Holland 1976 Publications in Statistical Language Processing Parsing and Speech Immediate-Head Parsing for Language Models Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics2001An abstract and gzipped postscript version areavailable. Edit Detection and Parsing for TranscribedSpeech with Mark Johnson.Proceedings of the 2nd Meeting of the North American Chapter of theAssociation for Computational Linguistics, pp 118-126 2001An abstract and gzipped postscript version areavailable. Lexical Semantics and Anaphora Unsupervised learning of name structure fromcoreference data Proceedings of the 2nd Meeting of the North American Chapter of theAssociation for Computational Linguistics, pp 48-54 2001An abstract and gzippedpostscript version are available. Finding parts in very large corpora with Matthew Berland, Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pp 57-64 1999An abstract and postscript version areavailable. A statistical approach to anaphora resolution ,with Niyu Ge and John Hale,Proceedings of the Sixth Workshop on Very Large Corpora1998.An abstract and postscript version areavailable. Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction ,with Brian Roark,Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics1998An abstract anda postscript version are available. Efficient Parsing Edge-based best-first chart parsing ,with Sharon Goldwater and Mark Johnson,Proceedings of the Sixth Workshop on Very Large Corpora 1998An abstract and postscript version areavailable. New figures of merit for best-first probabilistic chart parsing , with Sharon Caraballo Computational Linguistics , 1998.A postscript version is available. Statistical Parsing A Maximum-Entropy-Inspired Parser Proceedings of NAACL-2000An abstract and postscript version are available. Statistical techniques for natural language parsing AI Magazine. 1997.An abstract and postscript version are available. Statistical parsing with a context-free grammar and word statistics ,Proceedings of the Fourteenth National Conference on Artificial IntelligenceAAAI PressMIT Press, Menlo Park 1997.An abstract and postscript version are available. Tree-bank grammars ,Technical Report CS-96-02,Department of Computer Science, Brown University 1996.An abstract and postscript version are available. A statistical syntactic disambiguation program and what it learns , withMurat Ersan, TR CS-95-29 Brown University, Department of Computer Science 1996. In Symbolic, Connectionist, and Statistical Approaches to Learning for Natural Language Processing ,S. Wermter, E. Riloff, and G. Scheler Eds.,New York Springer 1996.An abstract and postscript version are available. Part-of-Speach Tagging Taggers for parsers , withGlenn Carroll, John Adcock, Antony Cassandra, Yoshihiko Gotoh,Jeremy Katz, Michael Littman, and John McCann,Artificial Intelligence forthcoming.An abstract and postscript version are available.The techreport version is also available. Equations for part-of-speech tagging , withCurtis Hendrickson, Neil Jacobson, and Mike Perkowitz,Proceedings of the Eleventh National Conference on Artificial Intelligence,Menlo Park AAAI PressMIT Press 1993 784-789.An abstract and postscript version are available. Software nlparser To inspire research into parsing, I thought it might be interestingto publicize a list of sentences on which my parser performspoorly. Look here. Biographical Material Eugene Charniak is Professor of ComputerScience . and Cognitive Scienceat Brown University.He received an A.B. degree in Physics from University ofChicago and a Ph.D. from M.I.T. in Computer Science. He haspublished four books Computational Semantics , withYorick Wilks 1976 Artificial Intelligence Programming now in a second edition with Chris Riesbeck, Drew McDermott, andJames Meehan 1980, 1987 Introduction to ArtificialIntelligence with Drew McDermott 1985 and StatisticalLanguage Learning 1993. He is a Fellow of the AmericanAssociation of Artificial Intelligence and was previously a Councilorof the organization. His research has always been in the area oflanguage understanding or technologies which relate to it, such asknowledge representation, reasoning under uncertainty, and learning.Over the last few years he has been interested in statisticaltechniques for language understanding. His research in this area hasincluded work in the subareas of part-of-speech tagging,probabilistic context-free grammar induction, and, more recently,syntactic disambiguation through word statistics, efficient syntacticparsing, and lexical resource acquisition through statistical means.", "metadata": {"last_modified": "2003-09-02T20:10:40+00:00", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["", "", "", "", "", "", "", "", ""], "word_count": 685, "token_count_estimate": 1135}}, "https://cs.brown.edu/people/eupfal/": {"text_content": "Home Biography Publications Research Teaching Editorial Consulting Brown University P.O. Box 1910 Providence, RI 02912 USA Voice 401-863-7645 Fax 401-863-7657 Mail elics.brown.edu Im the Rush C. Hawkins professor of computer science at Brown University, during 2002 -2007 I was also the department chair. Before coming to Brown in 1998 I was a researcher and project manager at the IBM Almaden Research Center in California, and a professor at the Weizmann Institute in Israel. I received an undergraduate degree in mathematics and statistics and a doctorate degree in computer science from the Hebrew University in Jerusalem, Israel. My research focuses on the design and analysis of algorithms. In particular Im interested in randomized algorithms and probabilistic analysis of algorithms. Applications range from combinatorial and stochastic optimization to routing and communication networks, computational biology, and computational finance. Visit our Research Group Page My Erdos number is 2, and I am a mathematical descendant of Eli Shamir, Jacques Hadamard 4th generation, Simeon Denis Poisson 8th generation and Pierre-Simon Laplace 9th generation. . Designed by Ahmed Idrissi", "metadata": {"last_modified": "2021-06-03T15:40:48+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 173, "token_count_estimate": 246}}, "http://www.cs.pomona.edu/~apapoutsaki/": {"text_content": "About Publications Teaching Miscellaneous Alexandra Papoutsaki sheherhers alexandra.papoutsakipomona.edu I am an Associate Professor in Computer Science at Pomona College .I received my PhD fromthe Department of Computer Science at Brown University , under the guidance of Prof. Jeff Huang .I completed my masters at Brown while working with Prof. Benjamin Raphael and hold a B.Sc. from Athens University of Economics and Business . My research focuses on Human-Computer Interaction and in particular on the methodology ofeye tracking.For a long time, my goal has been to democratize eye tracking by using webcams instead ofrelying on specialized equipment.Recently, I have started looking on the effect of gaze sharing on remote collaborations, aline of research that is supported by NSF .I am also interested in health informatics and crowdsourcing and I used to work oncomputational biology. Curriculum Vitae Publications Cross-Language Music Recommendation Exploration Stefanos Stoikos, David Kauchak, Douglas Turnbull, Alexandra Papoutsaki ICMR 2023 Webcam-based eye tracking to detectmind wandering and comprehension errors Stephen Hutt, Aaron Wong, Alexandra Papoutsaki , Ryan S. Baker, Joshua I. Gold,Caitlin Mills Behavior Research Methods, 2023. ReadabilityResearch An Interdisciplinary Approach Sofie Beier, Sam Berlow, Esat Boucaud, Zoya Bylinskii, Tianyuan Cai, Jenae Cohn, KathyCrowley, Stephanie L Day, Tilman Dingler, Jonathan Dobres, Jennifer Healey, Rajiv Jain,Marjorie Jordan, Bernard Kerr, Qisheng Li, Dave B Miller, Susanne Nobles, AlexandraPapoutsaki , Jing Qian, Tina Rezvanian, Shelley Rodrigo, Ben D Sawyer, Shannon MSheppard, Bram Stein, Rick Treitman, Jen Vanek, Shaun Wallace, Benjamin Wolfe Foundations and Trends in Human-Computer Interaction, 2022, 164, 214-324. Designing Flexible Longitudinal RegimensSupporting Clinician Planning for Discontinuation of Psychiatric Drugs Eunkyung Jo, Myeonghan Ryu, Georgia Kenderova, Samuel So, Bryan Shapiro, AlexandraPapoutsaki , Daniel A. Epstein CHI 2022352 first round 12.5 acceptance rate Theelephant in the room attention to salient scene features increases with comedicexpertise Ori Amir, Konrad J. Utterback, Justin Lee, Kevin S. Lee, Suehyun Kwon, Dave M.Carroll, Alexandra Papoutsaki Cognitive Processing, 2022, 10.1007s10339-022-01079-0 Understanding Delivery ofCollectively Built Protocols in an Online Health Community for Discontinuation ofPsychiatric Drugs Alexandra Papoutsaki , Samuel So, Georgia Kenderova, Bryan Shapiro, Daniel A.Epstein PACM Human-Computer Interaction 5CSCW2 420 2021 Case Studies on the Motivation andPerformance of Contributors Who Verify and Maintain In-Flux Tabular Datasets Shaun Wallace, Alexandra Papoutsaki , Neilly H. Tan, Hua Guo, Jeff Huang PACM Human-Computer Interaction 5CSCW2 448 2021 Effects of Shared Gaze on Audio- VersusText-Based RemoteCollaborations Grete Helena Ktt, Teerapaun Taprasert, Jay Rodolitz, Bernardo Moyza, Samuel So,Georgia Kenderova, Alexandra Papoutsaki PACM Human-Computer Interaction 4CSCW2 136 2020 Eye-Write Gaze Sharing for CollaborativeWriting Grete Helena Ktt, Kevin Lee, Ethan Hardacre, Alexandra Papoutsaki CHI 2019497 24 acceptance rate The Eye of the Typer A Benchmark and Analysisof Gaze Behavior during Typing Alexandra Papoutsaki , Aaron Gokaslan, James Tompkin, Yuze He, Jeff Huang ETRA 201816 34 acceptance rate Dataset Remotion A Motion-Based Capture andReplay Platform of Mobile Device Interaction for RemoteUsability Testing Jing Qian, Arielle Chapin, Alexandra Papoutsaki , Fumeng Yang, Klaas Nelissen,Jeff Huang ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2018 22, 77 Website Lessons Learned from Two Cohorts ofPersonal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki , Diane Schulze, HanSha, Jeff Huang ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2017 13 46 SearchGazer Scalable Webcam EyeTracking for Remote Studies of Web Search Alexandra Papoutsaki , James Laskey, Jeff Huang CHIIR 2017 42 acceptance rate, Best Paper Finalist Website Software WebGazer Scalable Webcam Eye TrackingUsing User Interactions Alexandra Papoutsaki , Patsorn Sangkloy, James Laskey, Nediyana Daskalova, JeffHuang, James Hays IJCAI 2016 25 acceptance rate Website Software Crowdsourcing from Scratch APragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki , Hua Guo, Danae Metaxa-Kakavouli, Connor Gramazio, JeffRasley, Wenting Xie, Guan Wang, Jeff Huang HCOMP 2015 30 acceptance rate, Best Paper Finalist Website Analysis Data Scalable Webcam Eye Tracking by Learningfrom User Interactions Alexandra Papoutsaki CHI 2015 Extended Abstracts Genome-Wide SurvivalAnalysis of Somatic Mutations in Cancer Mark D.M. Leiserson, Fabio Vandin, Hsin-Ta Wu, Jason R. Dobson, Jonathan V. Eldridge,Jacob L. Thomas, Alexandra Papoutsaki , Younhun Kim, Beifang Niu, Michael McLellan,Michael S. Lawrence, Abel Gonzalez-Perez, David Tamborero, Yuwei Cheng, Gregory A. Ryslik,Nuria Lopez-Bigas, Gad Getz, Li Ding, Benjamins J. Raphael Nature Genetics, 2015 472 106-114 Website Software AccurateComputation of Survival Statistics in Genome-Wide Studies Fabio Vandin, Alexandra Papoutsaki , Benjamin Raphael, Eli Upfal PLoS Computational Biology, 2015 115 e1004071 Genome-WideSurvival Analysis of Somatic Mutations in Cancer Fabio Vandin, Alexandra Papoutsaki , Benjamin Raphael, Eli Upfal RECOMB 2013 19.2 acceptance rate, Best Paper Award Website Denotes undergraduate student at the time of writing. Teaching Experience CS 051-A Intro to Computer Science with Topics in AI Spring 2019 , Spring 2022 , Spring 2023 Instructor , Department of Computer Science - Pomona College CS 062 Data Structures and Advanced Programming Fall 2017 , Spring 2018 , Fall 2018 , Spring 2019, Fall 2019 , Spring 2020 , Fall 2021 , Fall 2023 Instructor , Department of Computer Science - Pomona College CS 124 User Interfaces and User Experience Fall 2017,Spring 2018,Spring 2019,Fall 2021 Instructor , Department of Computer Science - Pomona College CS 190 Computer Science Senior Seminar Fall 2018, Fall 2019 , Fall 2023 Instructor , Department of Computer Science - Pomona College CS 188 Computer Science Colloquium 2019-2020 Instructor , Department of Computer Science - Pomona College CS1950N Topics in 2D Games Fall 2016 Instructor , Department of Computer Science - Brown University FinalProjects CS0931 Introduction to Computation for the Humanities and Social Sciences Fall 2015 Instructor , Department of Computer Science - Brown University Seminar in Human Computer Interaction Spring 2015 and Spring 2014 Teaching Assistant , Department of Computer Science - Brown University Instructor Prof. Jeff Huang Brown Computer Sciencewithout Borders Spring 2012 and Spring 2013 Teaching Assistant , Department of Computer Science - Brown University Alexandra Papoutsaki Design HTML5 UP .", "metadata": {"last_modified": "2024-01-09T04:56:22+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Publications", "Teaching Experience"], "word_count": 950, "token_count_estimate": 1675}}, "https://cs.brown.edu/people/faculty/bjm.html": {"text_content": "Barbara J. Meier Distinguished Senior Lecturer in Computer Science Office CIT 401 Phone 401-863-7604 Email barbarameier brown.edu Assistant Dawn T Reed Research Areas Graphics and Visualization Teaching Fall 2024 CSCI1250 Introduction to Computer Animation Spring 2025 not teaching Home Page I teach introductory and intermediate computer animation. In the intro course, students learn the steps of the animation production pipeline including storyscript writing, planning, modeling, shading, lighting, animating, and compositing. They use commercial software to complete exercises and a short finished animation. In the intermediate course, students learn the technical workflows for character modeling, rigging, animating, shading, and lighting in more depth. My research is in computer graphics techniques. My focus is creating and using tools for artists. Past work includes WYSIWYG NPR, or What you see is what you get non-photorealistic rendering. In this prototype system, artists draw directly on 3d models to create stylized silhouettes, shading, and decal designs. I also worked on the Accessible Color Project to make color easier to use in graphics programs for both novices and experts. Some of this work resulted in Interactive Color Palette Tools. I am interested in figuring out ways that artists, especially animators, can use computers in conjunction with their current skills to alleviate some of the tedium of creating scores of images as well as to explore new looks and techniques. In addition, I work on personal animated films and have an oil painting practice.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:36+00:00", "headings": ["Information for:", "Barbara J. Meier"], "word_count": 237, "token_count_estimate": 313}}, "https://cs.brown.edu/people/faculty/amy/": {"text_content": "Amy R Greenwald Professor of Computer Science Office CIT 383 Phone 401-863-7678 Email amy cs.brown.edu Assistant Lori Agresti Research Areas Artificial Intelligence, Multi-Agent Systems, Reinforcement Learning, Algorithmic Game Theory Teaching Fall 2024 not teaching Spring 2025 CSCI1440 Algorithmic Game Theory CSCI2440 Advanced Algorithmic Game Theory Publications by Amy R Greenwald Home Page In our increasingly networked world, fewer and fewer decisions can be made in isolation. Consequently, AI agents artificially intelligent, programmed decision-makers must cooperate, compete, and trade with other agents, both human and artificial. This trend drives Amy Greenwalds twin research goals first, the effort to design and implement AI agents that interact effectively in multiagent environments second, the effort to understand, explain, and accurately predict the dynamics of such interactions. In pursuing these goals, Prof. Greenwald draws from theoretical and practical sources, including a variety of disciplines such as AI, decision theory, game theory, and economics.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Amy R Greenwald"], "word_count": 148, "token_count_estimate": 206}}, "https://cs.brown.edu/people/eg29/": {"text_content": "Esha Ghosh Contact esha underscore ghosh at brown dot edu I am a Ph.D candidate at Brown University working with Professor Roberto Tamassia . I am interested in applied cryptography and computer security. My current research addresses the security and privacy of cloud storage and cloud applications with work on authenticated data structures, verifiable computation, efficient and zero-knowledge verification of queries on outsourced data, and data integrity protocols. My other interests include algorithms and data structures. My research is supported in part by the U.S. National Science Foundation and by the Paris C. Kanellakis Fellowship at Brown University. I was supported by Coline M. Makepeace Fellowship for the academic year 2012-13. Before joining Brown as a grad student, I completed my MS by research at the Theory group at IIT Madras in India under the guidance of Professor C. Pandu Rangan . My masters thesis was on Hamiltonicity and Longest Path Problem on Special Classes of Graphs.During my masters, I interned at the Distributed Systems group at Siemens Research under the mentorship of Mr. Subhas K. Ghosh and I worked on Independent Spanning Trees problem on Optical Transpose Interconnect System. After finishing my masters, I was a Project Associate in the Fixed Parameter Algorithms group at IMSc , India between December 2011 and July 2012 and I was mentored by Dr. Saket Saurabh. Internships I am interning with the Cloud Storage and Security group at IBM Research Zurich from June - December 2016. I spent the summer of 2015 interning in the Constructive Security group at Microsoft Research Cambridge. Recent Work in Security and Privacy Hash First, Argue Later Adaptive Verifiable Computations on Outsourced Data Dario Fiore, Cedric Fournet, Esha Ghosh, Markulf Kohlweiss, Olga Ohrimenko and Bryan Parno In CCS 2016 Authenticated Range Closest Point Queries in Zero-Knowledge Esha Ghosh, Olga Ohrimenko and Roberto TamassiaIn PETS 2016 Zero-Knowledge Accumulators and Set Operations Esha Ghosh, Olga Ohrimenko, Dimitrios Papadopoulos, Roberto Tamassia and Nikos TriandopoulosTo appear ASIACRYPT 2016 Fully-Dynamic Verifiable Zero-Knowledge Order Queries for Network Data Esha Ghosh, Michael T. Goodrich, Olga Ohrimenko and Roberto Tamassia In SCN 2016 Verifiable Order Queries and Order Statistics on a List in Zero-Knowledge Esha Ghosh, Olga Ohrimenko and Roberto Tamassia In ACNS 2015 This work won the Best Student Paper award at ACNS and was covered in Brown CS news . Posters and Talks I gave talks on Efficient Zero-Knowledge Authenticated Data Structures at Microsoft Research, Redmond hosted by Dr. Melissa Chase in March 2016 and at University of Maryland hosted by Prof. Jonathan Katz in November 2015. Zero-Knowledge Authenticated Order Queries and Applications Esha Ghosh, Michael T. Goodrich, Olga Ohrimenko and Roberto TamassiaIn IEEE Symposium on Security and Privacy 2015 and In New England Security Day 2015 I gave invited talks at R. C. Bose Centre for Cryptology and Security, ISI Kolkata , India and IIIT Delhi , India in December 2014 and gave a short talk at CRYPTO 2014 rump session. Work in Graph Algorithms Faster Parameterized Algorithms for Deletion to Split Graphs. Extended version Esha Ghosh, Sudeshna Kolay, Mrinal Kumar, Pranabendu Misra, Fahad Panolan, Ashutosh Rai, and M.S. Ramanujan In Algorithmica April 2015, Volume 71, Issue 4 Faster Parameterized Algorithms for Deletion to Split Graphs. Esha Ghosh, Sudeshna Kolay, Mrinal Kumar, Pranabendu Misra, Fahad Panolan, Ashutosh Rai, and M.S. Ramanujan In SWAT 2012 On Fault Tolerance and Hamiltonicity of Optical Transpose Interconnection System of Non-Hamiltonian Base Graphs Esha Ghosh, Subhas K. Ghosh, and C. Pandu Rangan A Polynomial Time Algorithm for Longest Paths in Biconvex Graphs Esha Ghosh, N. S. Narayanaswamy, and C. Pandu Rangan In WALCOM 2011 Other I TA-ed for Professor Anna Lysyanskaya in Fall 2014 for the course Models of Computation . During my MS at IIT Madras, I had TA-ed for Advanced Topics in Formal Languages and Automata I have been the external reviewer for Cryptology and Network Security CANS 2016, Public Key Cryptography PKC, 2016, ACM Conference on Computer and Communications Security CCS, 2014 and 2016 and Workshop on Privacy in the Electronic Society WPES 2014.", "metadata": {"last_modified": "2016-09-05T20:46:09+00:00", "scraped_at": "2024-03-13T22:15:37+00:00", "headings": ["Esha Ghosh"], "word_count": 669, "token_count_estimate": 1037}}, "https://cs.brown.edu/people/faculty/alysyans/": {"text_content": "Anna A Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Office CIT 501 Phone 401-863-7605 Email alysyans cs.brown.edu Assistant Lori Agresti Research Areas Security and Cryptography Teaching Fall 2024 not teaching Spring 2025 CSCI1040 The Basics of Cryptographic Systems Publications by Anna A Lysyanskaya Home Page Anna Lysyanskayas primary research area is cryptography, the study of protecting communication and computation against malicious users. The fundamental problems in this area are secure communication, authentication of data, pseudorandomness, and secure multi-party computation. Prof. Lysyanskaya wrote her Ph.D. thesis on digital signature schemes and their applications in protocols. Her thesis explores the uses of digital signature schemes in cryptographic protocols, as well as proposes several signature schemes especially suitable for use in protocols. Cryptography in general, and signature schemes in particular, depends on computational assumptions. A proof that a scheme is unbreakable amounts to showing that solving a certain computational problem is infeasible in any reasonable time. Unconditional proofs of infeasibility of problems relevant to cryptography are not known, and they would imply that P is different from NP. Therefore, in cryptography we have to settle for assumptions that certain tasks are infeasible. Prof. Lysyanskaya is interested in such issues as efficient and provably secure cryptographic protocols, minimal complexity assumptions for achieving security in various settings, and secure distributed computation.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:37+00:00", "headings": ["Information for:", "Anna A Lysyanskaya"], "word_count": 220, "token_count_estimate": 305}}, "https://cs.brown.edu/people/faculty/avandam/": {"text_content": "Andries van Dam Thomas J. Watson Jr. University Professor of Technology and Education, Professor of Computer Science Office CIT 465 Phone 401-863-7640 Email avandam cs.brown.edu Assistant Lisa Manekofsky Research Areas Graphics and Visualization Teaching Fall 2024 CSCI0150 Introduction to Object-Oriented Programming and Computer Science Spring 2025 not teaching Publications by Andries van Dam Home Page Tell us a little about your background educational, professional, personal, etc. I am originally from the Netherlands but immigrated with my parents in 1952. Originally trained as an electronic engineer at Swarthmore College and then University of Pennsylvania for graduate school, I switched to computer science after taking my first course and falling in love with the material. I got the second Ph.D. explicitly in CS in the US, in 1966 in Penns brand new CS degree program, and came to Brown in 1965 because of its emphasis on undergraduate teaching. I was founding chairman of the Department in 1979. What do you focus on in your research Any recent advances My main interest is in interactive computer graphics, as reflected by my first technical paper Computer-Driven Displays and their Use in Man-Machine Interaction 1966. The Brown Graphics Group is the longest continuously running graphics research group in the world, and CS123, Introduction to Computer Graphics, is similarly the longest-running graphics course. For nearly two decades Ive been most interested in post-WIMP UIs, including Virtual Reality and pen- and touch-computing. What do you like teaching classes about I love teaching beginners, whether in programmingCS or in graphics. Getting students hooked and often changing their lives is a source of great satisfaction. How did you become interested in computer science Taking an elective in the brand-new area of digital computers and programming, to get some relief from the normal math-intensive EE courses What is your favorite thing about Brown The unending stream of great undergraduates who fall in love with the subject as I did, and have great enthusiasm and work ethic. The undergraduate TA and RA programs I started in 1965 are a continuing source of pleasure for me, and have led to nearly 40 students that I worked with over the decades to become academics, the achievement I am most proud of. Any hobbies or passions Outdoor activities mountain and road biking, skiing, sea-kayaking, scuba-diving, backpacking, my three grandkids, eating and drinking well.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:37+00:00", "headings": ["Information for:", "Andries van Dam"], "word_count": 389, "token_count_estimate": 499}}, "https://cs.brown.edu/people/faculty/dhl/": {"text_content": "David H. Laidlaw Professor of Computer Science Office CIT 521 Phone 401-863-7647 Email dhl cs.brown.edu Assistant Dawn T Reed Research Areas Human-Computer Interaction, Graphics and Visualization, Computational Biology, Data Science, Design Teaching Fall 2024 CSCI2370 Interdisciplinary Scientific Visualization Spring 2025 not teaching Publications by David H. Laidlaw Home Page David Laidlaw is interested in visualization and modeling applications of computer graphics and computer science to other scientific disciplines. Applications give a real-world direction to computational research and are also compelling because they can provide concrete answers to questions about how our world works. He is working with researchers in, for example, archaeology, developmental neurobiology, medical imaging, orthopaedics, art, cognitive science, remote sensing, and fluid mechanics to develop new computational applications and to understand their strengths and weaknesses. Some applications he is particularly interested in are visualization of multivalued multidimensional imaging data, comparisons of virtual and nonvirtual environments for scientific tasks, and applications of art and perception to visualization.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:37+00:00", "headings": ["Information for:", "David H. Laidlaw"], "word_count": 158, "token_count_estimate": 215}}, "https://cs.brown.edu/people/faculty/eupfal/": {"text_content": "Eli Upfal Rush C. Hawkins Professor of Computer Science Office CIT 319 Phone 401-863-7645 Email eupfal cs.brown.edu Primary Research Areas Theory, Algorithms and Theory, Randomized Algorithms and Probabilistic Analysis, Machine Learning, Data Science Secondary Research Areas Artificial Intelligence, Computational Biology, Deep Learning, Security Teaching Fall 2024 not teaching Spring 2025 CSCI1550 Probabilistic Methods in Computer Science Publications by Eli Upfal Home Page Eli Upfals general research area is theory of computation trying to apply rigorous mathematical tools to the design and analysis of computer algorithms. He is particularly interested in applications of probability theory and combinatorics to this area. Randomness comes up in two aspects of the study of algorithms randomized algorithms and probabilistic analysis of algorithms. Randomized algorithms are algorithms that make random choices during their execution. In many cases the randomized algorithms are more efficient, simpler and easier to program than their deterministic counterparts. Probabilistic analysis of algorithms attempt to characterize the average-case performance of algorithms on typical inputs. This issue is important in computation problems for which there are no efficient solutions for all possible inputs. Recent work includes Developing probabilistic techniques for studying the long-term behavior of dynamic computer processes such as communication, load balancing, cashing, and paging a novel combinatorial design improving the design of sequencing by hybridization SBH microchips and stochastic analysis of commodity trading strategies.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:38+00:00", "headings": ["Information for:", "Eli Upfal"], "word_count": 222, "token_count_estimate": 287}}, "https://cs.brown.edu/people/faculty/mlittman.html": {"text_content": "Michael L. Littman University Professor of Computer Science Office CIT 301 Phone 401-863-7634 Email mlittman cs.brown.edu Assistant Lori Agresti Primary Research Areas Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics Secondary Research Areas Algorithmic Fairness Publications by Michael L. Littman Home Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:38+00:00", "headings": ["Information for:", "Michael L. Littman"], "word_count": 41, "token_count_estimate": 67}}, "https://cs.brown.edu/people/faculty/fprepara/": {"text_content": "Franco Preparata An Wang Professor Emeritus of Computer Science Phone 401-863-7649 Email fprepara cs.brown.edu Research Areas Algorithms and Theory, Computational Biology Publications by Franco Preparata Home Page Following early research in switching and coding, culminating in the discovery of the nonlinear Preparata codes, for the past three decades the focus of Franco Preparatas research has been the design and analysis of algorithms in their most general connotation. With the remarkable evolution of computer technology, his research interests have been correspondingly evolving. He has been deeply interested in fundamental algorithms and data structures, VLSI computation and layout, and parallel algorithms. Perhaps the most enduring interest has been computational geometry, a spin-off of algorithmic research aimed at the systematic investigation of methods for the most efficient solution of geometric problems. Geometric problems are ubiquitous in human activities. Sporadic, and frequently inefficient, computer solutions had been proposed before, but in the mid-1970s computational geometry emerged as a self-standing discipline targeted at this important area. The goal of computational geometry is to analyze the combinatorial structure of specific problems as the underpinning of efficient algorithms for their solution. The field burgeoned, and in the mid-1980s Prof. Preparata wrote a textbook on the subject that helped establish it in the instructional arena. Today an enormous body of geometric algorithms is known and this knowledge is increasingly indispensable in several applied areas such as geographic information systems, computer graphics, and computer-aided design and manufacturing. Within the last area, Prof. Preparata has also contributed to computational metrology the assessment of the geometric quality of manufactured parts. As another example of computer science interacting with other fields, today his main research focus is computational biology also called bioalgorithmics, an emerging discipline that entails the development and use of mathematical and computer science techniques to solve problems in molecular biology. Since the discovery of the structure of DNA about 50 years ago and the digital underpinning of molecular biology, huge amounts of data have been generated in this field, making it necessary to resort to sophisticated computer science techniques for their analysis.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:38+00:00", "headings": ["Information for:", "Franco Preparata"], "word_count": 343, "token_count_estimate": 433}}, "https://emanuelzgraggen.com/": {"text_content": "Emanuel Zgraggen Co-founder and CEO at Einblick. Former Postdoctoral Associate at MITs CSAIL Database Group where I worked with Tim Kraska My research interests include HCI, InfoVis and Data Science and Im currently working on interactive tools for visual data exploration and analysis. I got my Ph.D. from at Brown University where I was advised by Andy van Dam. Einblick - Startup I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, aquired by Databricks in 2024. I was a co-founder and CEO of Einblick. Einblick was a next-generation, AI-native, multi-modal data notebook to build workflows and data apps. Founded in 2019, a classtext-zinc-500 transition underline hovertext-zinc-900 hrefhttpswww.databricks.comblogwelcome-data-intelligence-platform-databricks-einblickaquired by Databricks in 2024.a Overview Video Natural Language Video Interactive Data Science Northstar is an interactive data science plattform that combines data exploration with automated machine learning. Northstar is an interactive data science plattform that combines data exploration with automated machine learning. SIGMOD DEEM Paper Video Progressive Visualizations We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations. We investigated how progressive visualizations affect users in exploratory data analysis scenarios. Through a controlled experiment, we compared progressive visualizations to blocking and instantaneous visualizations. TCVG 2017 Paper Summary Video Visual Regular Expressions squeries pronounced Squeries is a visual query interface for creating queries on sequences series of data based on regular expressions. squeries pronounced Squeries is a visual query interface for creating queries on sequences series of data based on regular expressions. CHI 2015 Paper Summary Video Interactive Data Exploration PanoramicData is a hybrid pen and touch system for visual data exploration. PanoramicData is a hybrid pen and touch system for visual data exploration. Infovis 2014 Paper Video Handwritten Spreadsheets Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink. Tableur is a spreadsheet-like pen- and touch-based system that revolves around handwriting recognition - all data is represented as digital ink. CHI 2016 LBW Paper Video Multiple Comparisons Problem The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise. The goal of visualizations is to facilitate data-driven insight discovery. But what if the insights are spurious Features or patterns in visualizations can be perceived as relevant insights, even though they arise from noise. CHI 2018 Paper Summary Video Progressive Sequence Mining ProSecCo is an algorithm for progressive mining of frequent sequences it processes the dataset in blocks and outputs a high-quality approximation. ProSecCo is an algorithm for progressive mining of frequent sequences it processes the dataset in blocks and outputs a high-quality approximation. ICDM 2018 Paper Interactive Analytics Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation. Vizdom is an interactive visual analytics system that scales to large datasets through progressive computation. VLDB Demo 2015 Paper Health Video Election Video Emanuel Zgraggen. All rights reserved.", "metadata": {"last_modified": "2024-02-01T14:40:44+00:00", "scraped_at": "2024-03-13T22:15:38+00:00", "headings": ["Emanuel Zgraggen"], "word_count": 523, "token_count_estimate": 720}}, "https://cs.brown.edu/people/faculty/": {"text_content": "Faculty Research Areas Profile Tags Reset Filters 3D Photography 3D Scanning Algorithmic Fairness Algorithmic Game Theory Algorithms and Theory Artificial Intelligence Computational Biology Computational Geosciences Computer Architecture Computer Systems Computer Vision Computing Education Data Science Database Systems Deep Learning Design Digital Geometry Processing Distributed Systems Formal Methods Geometric Modeling Graphics and Visualization Human-Computer Interaction Machine Learning Multi-Agent Systems Natural Language Processing Networking Programming Languages Randomized Algorithms and Probabilistic Analysis Reinforcement Learning Robotics Security Security Policy Security and Cryptography Signal Processing Software Engineering Theory Virtual Reality Lecturer-Stream Tenure-Stream Primary No Match found Nora Ayanian Associate Professor of Computer Science and Engineering Office CIT 449 Robotics Artificial Intelligence, Multi-Agent Systems Fall 2024 not teaching Spring 2025 CSCI1952-Z Profile Home Page Stephen Bach Assistant Professor of Computer Science Office CIT 335 Machine Learning, Artificial Intelligence, Data Science Fall 2024 not teaching Spring 2025 CSCI1420 Profile Home Page Ugur Cetintemel Khosrowshahi University Professor of Computer Science Office CIT 437 Data Science, Database Systems, Distributed Systems Fall 2024 CSCI1270 Spring 2025 CSCI2270 Profile Home Page Yu Cheng Assistant Professor of Computer Science Office CIT 413 Algorithms and Theory, Machine Learning Fall 2024 CSCI2952-Q Spring 2025 CSCI1952-Q Profile Home Page Nicholas A DeMarinis Lecturer in Computer Science Office CIT 317 Fall 2024 CSCI0200 , CSCI1680 Spring 2025 CSCI0300 , CSCI1310 , CSCI1620 , CSCI1660 , CSCI2660 Profile Lorenzo De Stefani Lecturer in Computer Science Office CIT 435 Algorithms and Theory Machine Learning, Randomized Algorithms and Probabilistic Analysis Fall 2024 CSCI1010 , CSCI1570 Spring 2025 CSCI1951-A Profile Home Page Thomas W Doeppner Associate Professor of Computer Science Research, Vice Chair of Computer Science Office CIT 405 Computer Systems Fall 2024 CSCI0081 , CSCI0082 , CSCI0330 , CSCI1330 Spring 2025 CSCI0081 , CSCI0082 , CSCI1670 , CSCI1690 , CSCI2670 Profile Home Page Timothy H Edgar Professor of the Practice of Computer Science Security Policy Fall 2024 CSCI1805 , CSCI1860 Spring 2025 CSCI1952-X , CSCI2952-S Profile Kathi Fisler Professor of Computer Science Research Office CIT 309 Computing Education, Programming Languages, Formal Methods Fall 2024 not teaching Spring 2025 CSCI0200 Profile Home Page Amy R Greenwald Professor of Computer Science Office CIT 383 Artificial Intelligence, Multi-Agent Systems, Reinforcement Learning, Algorithmic Game Theory Fall 2024 not teaching Spring 2025 CSCI1440 , CSCI2440 Profile Home Page Maurice P Herlihy An Wang Professor of Computer Science Office CIT 341 Distributed Systems Fall 2024 CSCI1760 Spring 2025 CSCI1951-L Profile Home Page Ellis Hershkowitz Assistant Professor of Computer Science Office CIT 507 Algorithms and Theory Profile Home Page Jeff Huang Associate Professor of Computer Science, Associate Chair of Computer Science Office CIT 245 Human-Computer Interaction, Design, Data Science Profile Home Page John F Hughes Professor of Computer Science, Associate Chair of Computer Science Office CIT 365 Graphics and Visualization Fall 2024 CSCI0170 Spring 2025 not teaching Profile Home Page Deborah Hurley Professor of the Practice of Computer Science Fall 2024 CSCI1870 Spring 2025 CSCI2002 Profile Home Page Sorin Istrail James A. Julie N. Brown Professor of Computational and Mathematical Sciences Office CIT 523 Algorithms and Theory, Computational Biology Fall 2024 CSCI1810 , CSCI2810 Spring 2025 CSCI1820 , CSCI2820 Profile Home Page Vasileios Kemerlis Assistant Professor of Computer Science Office CIT 505 Security, Computer Systems Software Engineering Fall 2024 CSCI1650 Spring 2025 CSCI2951-U Profile Home Page Philip Klein Professor of Computer Science Office CIT 503 Algorithms and Theory Fall 2024 not teaching Spring 2025 CSCI0500 , CSCI2500-B Profile Home Page George D Konidaris Associate Professor of Computer Science Office CIT 447 Artificial Intelligence, Machine Learning, Robotics Fall 2024 not teaching Spring 2025 CSCI2951-X Profile Home Page Shriram Krishnamurthi Professor of Computer Science Office CIT 377 Programming Languages, Computing Education, Networking, Security and Cryptography, Software Engineering, Formal Methods, Human-Computer Interaction Fall 2024 CSCI0190 , CSCI1730 Spring 2025 not teaching Profile Home Page David H. Laidlaw Professor of Computer Science Office CIT 521 Human-Computer Interaction, Graphics and Visualization, Computational Biology, Data Science, Design Fall 2024 CSCI2370 Spring 2025 not teaching Profile Home Page Robert Y. Lewis Lecturer in Computer Science Office CIT 433 Formal Methods, Programming Languages Theory, Computing Education Fall 2024 CSCI1260 Spring 2025 CSCI0220 Profile Home Page Michael L. Littman University Professor of Computer Science Office CIT 301 Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics Algorithmic Fairness Profile Home Page Anna A Lysyanskaya James A. and Julie N. Brown Professor of Computer Science Office CIT 501 Security and Cryptography Fall 2024 not teaching Spring 2025 CSCI1040 Profile Home Page Barbara J. Meier Distinguished Senior Lecturer in Computer Science Office CIT 401 Graphics and Visualization Fall 2024 CSCI1250 Spring 2025 not teaching Profile Home Page Peihan Miao Assistant Professor of Computer Science Office CIT 511 Security and Cryptography, Theory Fall 2024 CSCI1510 Spring 2025 CSCI1515 Profile Home Page Tim Nelson Lecturer in Computer Science Office CIT 355 Computing Education, Software Engineering, Formal Methods Algorithms and Theory, Networking, Programming Languages Fall 2024 CSCI0112 , CSCI0320 , CSCI1340 Spring 2025 CSCI0320 , CSCI1340 , CSCI1710 Profile Home Page Julia Netter Adjunct Assistant Professor of the Practice of Computer Science Office Arnold Lab 309 Fall 2024 not teaching Spring 2025 CSCI1952-B Profile Home Page Bernardo Palazzi Adjunct Professor of the Practice of Computer Science Security and Cryptography Fall 2024 not teaching Spring 2025 CSCI1660 , CSCI1880 , CSCI2660 Profile Home Page Ellie Pavlick Manning Assistant Professor of Computer Science, Assistant Professor of Linguistics Office CIT 333 Artificial Intelligence, Machine Learning, Data Science, Natural Language Processing Fall 2024 CSCI1460 Spring 2025 not teaching Profile Home Page Steven P Reiss Professor of Computer Science Office CIT 403 Software Engineering, Design, Formal Methods, Graphics and Visualization, Human-Computer Interaction, Security and Cryptography Fall 2024 CSCI2340 Spring 2025 CSCI2340 Profile Home Page Daniel C Ritchie Eliot Horowitz Assistant Professor of Computer Science Office CIT 445 Graphics and Visualization, Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision Fall 2024 CSCI1230 , CSCI1234 , CSCI2230 Spring 2025 CSCI1950-U , CSCI2240 Profile Home Page Malte Schwarzkopf Assistant Professor of Computer Science Office CIT 525 Computer Systems, Distributed Systems Database Systems Fall 2024 not teaching Spring 2025 CSCI0300 , CSCI1310 Profile Home Page Ritambhara Singh Assistant Professor of Computer Science Office BOB 313 Machine Learning, Deep Learning, Computational Biology Fall 2024 not teaching Spring 2025 CSCI1470 , CSCI2470 Profile Home Page Srinath Sridhar Assistant Professor of Computer Science Office CIT 407 Computer Vision, Machine Learning, Deep Learning, Artificial Intelligence, Robotics Human-Computer Interaction Fall 2024 CSCI1430 Spring 2025 CSCI1430 , CSCI2952-O Profile Home Page Chen Sun Assistant Professor of Computer Science Office CIT 379 Computer Vision, Artificial Intelligence, Machine Learning, Deep Learning Fall 2024 not teaching Spring 2025 CSCI2952-N Profile Home Page Roberto Tamassia James A. and Julie N. Brown Professor of Computer Science, Chair of Computer Science Office CIT 473 Security and Cryptography, Algorithms and Theory, Data Science Fall 2024 CSCI2951-E Spring 2025 not teaching Profile Home Page Stefanie A Tellex Associate Professor of Computer Science, Associate Professor of Engineering Office CIT 375 Artificial Intelligence, Machine Learning, Robotics Profile Home Page James H Tompkin John E. Savage Assistant Professor of Computer Science Office CIT 547 Graphics and Visualization, Computer Vision, Human-Computer Interaction Fall 2024 CSCI1290 , CSCI1950-N , CSCI2951-I Spring 2025 not teaching Profile Home Page Eli Upfal Rush C. Hawkins Professor of Computer Science Office CIT 319 Theory, Algorithms and Theory, Randomized Algorithms and Probabilistic Analysis, Machine Learning, Data Science Artificial Intelligence, Computational Biology, Deep Learning, Security Fall 2024 not teaching Spring 2025 CSCI1550 Profile Home Page Andries van Dam Thomas J. Watson Jr. University Professor of Technology and Education, Professor of Computer Science Office CIT 465 Graphics and Visualization Fall 2024 CSCI0150 Spring 2025 not teaching Profile Home Page Nikos Vasilakis Assistant Professor of Computer Science Office CIT 555 Computer Systems, Distributed Systems, Security, Programming Languages Fall 2024 not teaching Spring 2025 CSCI1380 Profile Home Page Suresh Venkatasubramanian Professor of Data Science and Computer Science Algorithmic Fairness Algorithms and Theory, Machine Learning Fall 2024 not teaching Spring 2025 CSCI1951-Z Profile Ernesto Zaldivar Associate Professor of the Practice of Computer Science Security, Security Policy, Human-Computer Interaction Fall 2024 CSCI1360 Spring 2025 CSCI1800 Profile Stanley B Zdonik Professor of Computer Science Office CIT 363 Database Systems, Distributed Systems Fall 2024 not teaching Spring 2025 CSCI2270 Profile Home Page Milda Zizyte Lecturer in Computer Science Office CIT 429 Formal Methods, Robotics, Software Engineering, Computing Education Fall 2024 CSCI0111 , CSCI1600 Spring 2025 CSCI0111 , CSCI1952-Y Profile Affiliated On Campus No Match found Karianne Bergen Assistant Professor of Earth, Environmental, and Planetary Sciences and Data Science, Assistant Professor of Computer Science Data Science, Machine Learning, Computational Geosciences, Signal Processing Profile Home Page Roger B Blumberg Visiting Scholar in Computer Science Office 113 MacMillan Profile Home Page Adam Blumenthal Visiting Scientist in Computer Science Office CIT 408 Virtual Reality, Human-Computer Interaction, Design, Natural Language Processing Profile Home Page Vanessa Cho Adjunct Professor of Practice of Computer Science Profile Pedro F Felzenszwalb Professor of Engineering Artificial Intelligence, Machine Learning, Algorithms and Theory, Computer Vision, Data Science Profile Home Page Ian Gonsher Assistant Professor of the Practice of Engineering Robotics, Design Profile Serdar Kadioglu Adjunct Associate Professor of Computer Science Algorithms and Theory, Artificial Intelligence, Machine Learning, Data Science Fall 2024 not teaching Spring 2025 CSCI2951-O Profile Home Page Ronald Parr Visiting Professor of Computer Science Fall 2024 not teaching Spring 2025 CSCI2951-F Profile Sohini Ramachandran Director of the Data Science Institute, Hermon C. Bumpus Professor of Biology, Professor of Computer Science Computational Biology, Data Science, Machine Learning Profile Home Page Sherief Reda Professor of Engineering, Professor of Computer Science Computer Systems, Computer Architecture, Deep Learning Profile Home Page Thomas R Serre Thomas J. Watson, Sr. Professor of Science Profile Donald L Stanford Adjunct Professor of the Practice of Computer Science Office CIT 223 Security and Cryptography, Human-Computer Interaction, Computer Architecture Fall 2024 CSCI0020 Spring 2025 not teaching Profile Home Page Gabriel Taubin Professor of Engineering, Professor of Computer Science 3D Scanning, 3D Photography, Digital Geometry Processing, Geometric Modeling, Graphics and Visualization, Computer Vision Profile Home Page Alan M Usas Adjunct Professor of the Practice of Computer Science Computing Education, Security and Cryptography, Computer Systems Profile Affiliated Off Campus No Match found R. Iris Bahar Professor Emerita of Engineering, Professor Emerita of Computer Science, Adjunct Professor of Engineering Computer Architecture, Computer Systems, Robotics Profile Home Page Carsten Binnig Visiting Scientist in Computer Science Database Systems Profile Home Page Thomas L Dean Professor Emeritus of Computer Science Artificial Intelligence, Computational Biology, Computer Vision, Deep Learning, Human-Computer Interaction, Machine Learning, Natural Language Processing, Reinforcement Learning, Robotics Profile Home Page Seny F Kamara Visiting Associate Professor of Computer Science Security and Cryptography Profile Home Page Joseph J Laviola Visiting Scholar in Computer Science Human-Computer Interaction, Graphics and Visualization, Robotics Profile Norm Meyrowitz Former Adjunct Professor of the Practice of Computer Science. Visiting Scholar. Software Engineering Human-Computer Interaction Profile Home Page Franco Preparata An Wang Professor Emeritus of Computer Science Algorithms and Theory, Computational Biology Profile Home Page Matteo Riondato Visiting Scientist in Computer Science Data Science Randomized Algorithms and Probabilistic Analysis Profile Home Page John E Savage An Wang Professor Emeritus of Computer Science Security Policy Theory Profile Home Page Tom Sgouros Research Associate in Computer Science Algorithmic Fairness, Software Engineering Data Science Profile Home Page Post Docs No Match found Alper Ahmetoglu Postdoctoral Research Associate in Computer Science Office CIT 303 Artificial Intelligence, Robotics, Deep Learning Profile Home Page Gianluca Brero Postdoctoral Research Associate in Data Science Profile Will Crichton Postdoctoral Research Associate in Computer Science Profile Gayathri Garimella Postdoctoral Research Associate in Computer Science Profile David Paulius Postdoctoral Research Associate in Computer Science Office CIT 303 Robotics, Artificial Intelligence Natural Language Processing Profile Home Page Jake Russin Postdoctoral Research Associate in Computer Science Profile", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:38+00:00", "headings": ["Information for:", "Faculty", "Primary", "Affiliated On Campus", "Affiliated Off Campus", "Post Docs"], "word_count": 1939, "token_count_estimate": 2941}}, "https://cs.brown.edu/people/faculty/mph.html": {"text_content": "Maurice P Herlihy An Wang Professor of Computer Science Office CIT 341 Phone 401-863-7646 Email mph cs.brown.edu Research Areas Distributed Systems Teaching Fall 2024 CSCI1760 Multiprocessor Synchronization Spring 2025 CSCI1951-L Blockchains Cryptocurrencies Publications by Maurice P Herlihy Home Page Tell us a little about your background educational, professional, personal, etc. I have an A.B. from Harvard in Math, and a Ph.D. from MIT in CS. I have worked, in one role or another, in four research labs Xerox PARC, DEC CRL, Microsoft Cambridge UK, and Sun Labs New England. I have taught at CMU and Brown. What do you focus on in your research Any recent advances The shift to multicore architectures changes everything. Multiprocessors and concurrency, once an exotic subculture, has become mainstream. What do you like teaching classes about Things that excite me. How did you become interested in computer science When I graduated, I knew nothing about CS, but I needed a job. I was hired to write FORTRAN programs for minimum wage, and one thing led to another. What is your favorite thing about Brown The enthusiasm of the students. Any hobbies or passions Tango, birding.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Maurice P Herlihy"], "word_count": 190, "token_count_estimate": 264}}, "https://cs.brown.edu/people/faculty/jsavage/": {"text_content": "John E Savage An Wang Professor Emeritus of Computer Science Phone 401-863-7642 Email johnsavage brown.edu Assistant Lori Agresti Primary Research Areas Security Policy Secondary Research Areas Theory Publications by John E Savage Home Page Tell us a little about your background educational, professional, personal, etc. I was educated as a coding, communication, and information theorist at MIT but became a theoretical computer scientist in order to understand why decoders for error correcting codes were so much bigger than encoders. The result was a series of papers and a book Complexity of Computing, 1976 that demonstrated that the size and depth of a circuit are key measures of the computational complexity of the function that is computed by the circuit. Circuit complexity is now a principal topic in theoretical computer science. After completing my PhD at MIT, I worked for Bell Laboratories in New Jersey. Within three years I was off to Brown as an engineering faculty member. In the early 1970s it became apparent to Andy van Dam and Peter Wegner, who were in Applied Math, and me that we should pool our resources and form the Program in Computer Science. By the late 1970s we saw that we needed to have departmental status if we were going to obtain the resources needed to ensure that Brown could take advantage of this new, exploding research area called computer science. Starting a new department was a challenge to all of us. Some of us had to serve as chair. Andy was our first chair and I was the second, serving from 1985 to 1991. Recruiting a high quality faculty was our first priority, which we did very successfully and continue to do today. Outside of Computer Science but within Brown I have served on many faculty committees and as chair of many key committees. At the professional level I have served on several editorial boards and committees as well as a member of the visiting committee for the MIT Department of Electrical Engineering and Computer Science, my undergraduate and graduate department, which was a great deal of fun. On the personal side, my wife and I have four children all of whom graduated from Brown and are leading interesting and happy lives. We have traveled with them on sabbatical leaves to the Netherlands, France, and England. What do you focus on in your research Any recent advances I am now very actively involved in cybersecurity from both a policy and technology point of view. This is an interest that I developed as a result of spending the 2009-2010 academic year in the U.S. Department of State as a Jefferson Science Fellow. Over the last decade I have also done research and published on computational nanotechnology, the IO efficiency of multicore chips, and coded computation. The latter involves adding redundancy to data so that if errors occur during a computation, they can be corrected. What do you like teaching classes about I like to teach computer sciencecourses that involve models of computation and related analysis. Im a big believer in developing good models from which one can derive important limitations on computation through analysis. My last book, Models of Computation, published in 1998, deals with this topic. I also like to teach courses that involve both policy and technology in cybersecurity. This is an area whose importance has risen rapidly recently due to the globalization of the Internet and the fact that our software, hardware and networks were not designed with security in mind. How did you become interested in computer science As explained above, I became a computer scientist by accident in order to understand why decoders for error correcting codes, as seen in practice, were so much more complex than the encoders that added redundancy to messages. What is your favorite thing about Brown I very much like the atmosphere at Brown. Faculty, students and staff are generally happy being here. They are all nice, pleasant and intelligent people. Its fun to be around them. Any hobbies or passions I enjoy exploring ideas. Cybersecurity is my current focus. I also read extensively in science and foreign policy and have many friends who are scientists with whom I exchange ideas. At one time, I did the same with friends in economics.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "John E Savage"], "word_count": 710, "token_count_estimate": 822}}, "https://cs.brown.edu/people/faculty/mlittman/": {"text_content": "Michael L. Littman University Professor of Computer Science Office CIT 301 Phone 401-863-7634 Email mlittman cs.brown.edu Assistant Lori Agresti Primary Research Areas Artificial Intelligence, Machine Learning, Reinforcement Learning, Robotics Secondary Research Areas Algorithmic Fairness Publications by Michael L. Littman Home Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Michael L. Littman"], "word_count": 41, "token_count_estimate": 67}}, "https://cs.brown.edu/people/faculty/jeffh/": {"text_content": "Jeff Huang Associate Professor of Computer Science, Associate Chair of Computer Science Office CIT 245 Phone 401-863-5808 Email jeffhuang brown.edu Assistant Dawn T Reed Research Areas Human-Computer Interaction, Design, Data Science Publications by Jeff Huang Home Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Jeff Huang"], "word_count": 37, "token_count_estimate": 53}}, "https://cs.brown.edu/people/faculty/sbz.html": {"text_content": "Stanley B Zdonik Professor of Computer Science Office CIT 363 Phone 401-863-7648 Email sbz cs.brown.edu Assistant Lori Agresti Research Areas Database Systems, Distributed Systems Teaching Fall 2024 not teaching Spring 2025 CSCI2270 Topics in Database Management Publications by Stanley B Zdonik Home Page Stan Zdoniks research interests include database systems, object-oriented databases, query processing, data dissemination, mobile computing and stream processing.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Stanley B Zdonik"], "word_count": 61, "token_count_estimate": 95}}, "https://cs.brown.edu/people/faculty/sbach/": {"text_content": "Stephen Bach Assistant Professor of Computer Science Office CIT 335 Email sbach cs.brown.edu Research Areas Machine Learning, Artificial Intelligence, Data Science Teaching Fall 2024 not teaching Spring 2025 CSCI1420 Machine Learning Home Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Stephen Bach"], "word_count": 33, "token_count_estimate": 47}}, "https://cs.brown.edu/people/faculty/rtamassi/": {"text_content": "Roberto Tamassia James A. and Julie N. Brown Professor of Computer Science, Chair of Computer Science Office CIT 473 Phone 401-863-7600 Email robertotamassia brown.edu Assistant Kate Correia Research Areas Security and Cryptography, Algorithms and Theory, Data Science Teaching Fall 2024 CSCI2951-E Topics in Computer System Security Spring 2025 not teaching Publications by Roberto Tamassia Home Page Contact Information Alternate email robertotamassiabrown.edu My assistant Kate Correia katherinecorreiabrown.edu QA with Roberto Tell us a little about your background educational, professional, personal, etc. I am originally from Italy. Franco Preparata was my doctoral advisor at the University of Illinois at Urbana-Champaign. After completing my PhD in 1988, I joined Brown, where I am currently James A. and Julie N. Brown Professor of Computer Science and Chair of the Department of Computer Science. What do you focus on in your research Any recent advances My primary research area is computer security and applied cryptography. Recent work includes methods and system prototypes for searchable encryption. I am also interested in design and analysis of algorithms, graph drawing, geometric computing, data management, and information visualization. What do you like teaching classes about I like teaching classes that cover both theory and practical implementations. In 2005, I developed a course on computer systems security that can be taken by students as early as the second year. How did you become interested in computer science As an undergraduate at the University of Rome, I was an electrical engineering concentrator. What got me interested in computer science was a course on programming and data structures taught by Carlo Batini, who eventually became my first academic mentor. What is your favorite thing about Brown The synergism between excellence in research and in teaching. Any hobbies or passions I am interested in classical music and finance. I enjoy stand-up paddleboarding, ocean kayaking, and cross-country skiing.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Roberto Tamassia"], "word_count": 304, "token_count_estimate": 397}}, "https://cs.brown.edu/people/faculty/twd.html": {"text_content": "Thomas W Doeppner Associate Professor of Computer Science Research, Vice Chair of Computer Science Office CIT 405 Phone 401-863-7633 Email twd cs.brown.edu Research Areas Computer Systems Teaching Fall 2024 CSCI0081 TA Apprenticeship Full Credit CSCI0082 TA Apprenticeship Half Credit CSCI0330 Introduction to Computer Systems CSCI1330 Computer Systems Masters students only Spring 2025 CSCI0081 TA Apprenticeship Full Credit CSCI0082 TA Apprenticeship Half Credit CSCI1670 Operating Systems CSCI1690 Operating Systems Laboratory CSCI2670 Operating Systems Home Page Thomas Doeppner is interested in operating systems and everything related to them. He wrote one of the first threads packages for Unix and has dabbled in threads and concurrency ever since. With the help of a number of top undergraduate students, he worked on tools for measuring and analyzing performance of concurrent programs, particularly on shared-memory multiprocessors. He also designed and implemented an object-oriented threads package for C, using ideas borrowed from Suns Spring operating system. More recently, he worked with wireless devices and mobile computers, building an infrastructure for sharing information in settings such as lectures, seminars, and face-to-face meetings. He is currently interested in the area of operating system support for security. He is investigating means for running arbitrary programs without fear of the consequences. In the distant past he did work in proving the correct of parallel programs and published papers in STOC, POPL, and PODC.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Thomas W Doeppner"], "word_count": 223, "token_count_estimate": 306}}, "https://cs.brown.edu/people/gdk/index.html": {"text_content": "George Konidaris Director Intelligent Robot Lab Associate Professor Department of Computer Science Brown University, Providence RI gdkcs.brown.edu Home IRL Research Teaching Publications Software CV Welcome to my home page. Im an Associate Professor of Computer Science and director ofthe Intelligent Robot Lab at Brown , which forms part of bigAI Brown Integrative, General AI . My group and I conduct research driven by the overarching scientific goal of understanding the fundamental computational processes that generateintelligence, and using them to design a generally-intelligent robot. I am also the co-founder of two technology startups.I co-founded, and serve as the Chief Roboticist of, Realtime Robotics , a startup based on our research on robot motion planning , and that aims to make robotic automation simpler, better, and faster. I also co-founded Lelapa AI , a commercial AI research lab focused on technology by and for Africans, and based in Johannesburg, South Africa. If youre considering applying to the PhD program at Brown to study in my lab, please see this page . Research My research aims tobuild intelligent, autonomous, general-purpose robots that are generally capable in a wide variety of tasksand environments. I focus on understanding how todesign agents that learn abstraction hierarchies that enable fast, goal-oriented planning.I develop andapply techniques from machine learning, reinforcement learning, optimal control and planningto construct well-grounded hierarchies that result in fast planning for common cases,andare robust to uncertainty atevery level of control. I believe that it will take advances in all of these areas, and additionally advances in how to integrate these areas,to solve the AI problem. This recent lecture covers the high-level vision underlying most of my work You can also find an approachable and short view of my approach to building generally intelligent agentsin the following review paper G.D. Konidaris. On TheNecessity of Abstraction . Current Opinion in Behavioral Sciences 29Special Issue on Artificial Intelligence,pages 1-7, October 2019. My invited talk at CoRL 2019 in Osaka summarizes my labs technical work at that point Finally, this journal article is a good indicator of my interests - it combines ideas fromhierarchical reinforcement learning, probabilistic machine learning, task-level planning, and roboticsto create a robot that autonomously learns an abstract symbolic model of an environment and then uses it to plan G.D. Konidaris, L.P. Kaelbling, and T. Lozano-Perez. From Skills to Symbols Learning Symbolic Representationsfor Abstract High-Level Planning . Journal of Artificial IntelligenceResearch 61, pages 215-289, January 2018. Of course, the video is a lot more accessible Other than that, here are a few sample project pages Constructing High-Level Symbolic Representations for Planning . Autonomous Robot Skill Acquisition . Planning for the Decentralized Control of Multi-Robot Teams . Robot Motion Planning on a Chip . The Fourier Basis . Teaching I am currently teaching CSCI 2951X Reintegrating AI Spring 2024 I have previously taught the following classes at Brown CSCI 2951X Reintegrating AI Spring 2023 CSCI 1410 Artificial Intelligence Fall 2022 CSCI 2951X Reintegrating AI Fall 2021 CSCI 1410 Artificial Intelligence Fall 2021 CSCI 2951X Reintegrating AI Spring 2021 CSCI 2951X Reintegrating AI Spring 2020 CSCI 1410 Artificial Intelligence Fall 2019 CSCI 2951X Reintegrating AI Spring 2018 CSCI 1410 Artificial Intelligence Fall 2018 CSCI 1410 Artificial Intelligence Fall 2017 CSCI 1410 Artificial Intelligence Spring 2017 I taught the following classes when I was at Duke CPS 590.2 Hierarchical Robot Learning and Planning Fall 2014 CPS 270 Introduction to Artificial Intelligence Spring 2015 CPS 590 Decision Making for Robots and Autonomous Systems Fall 2015 CPS 270 Introduction to Artificial Intelligence Spring 2016", "metadata": {"last_modified": "2024-03-11T15:07:41+00:00", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Research", "Teaching"], "word_count": 583, "token_count_estimate": 814}}, "https://cs.brown.edu/people/faculty/twd/": {"text_content": "Thomas W Doeppner Associate Professor of Computer Science Research, Vice Chair of Computer Science Office CIT 405 Phone 401-863-7633 Email twd cs.brown.edu Research Areas Computer Systems Teaching Fall 2024 CSCI0081 TA Apprenticeship Full Credit CSCI0082 TA Apprenticeship Half Credit CSCI0330 Introduction to Computer Systems CSCI1330 Computer Systems Masters students only Spring 2025 CSCI0081 TA Apprenticeship Full Credit CSCI0082 TA Apprenticeship Half Credit CSCI1670 Operating Systems CSCI1690 Operating Systems Laboratory CSCI2670 Operating Systems Home Page Thomas Doeppner is interested in operating systems and everything related to them. He wrote one of the first threads packages for Unix and has dabbled in threads and concurrency ever since. With the help of a number of top undergraduate students, he worked on tools for measuring and analyzing performance of concurrent programs, particularly on shared-memory multiprocessors. He also designed and implemented an object-oriented threads package for C, using ideas borrowed from Suns Spring operating system. More recently, he worked with wireless devices and mobile computers, building an infrastructure for sharing information in settings such as lectures, seminars, and face-to-face meetings. He is currently interested in the area of operating system support for security. He is investigating means for running arbitrary programs without fear of the consequences. In the distant past he did work in proving the correct of parallel programs and published papers in STOC, POPL, and PODC.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Information for:", "Thomas W Doeppner"], "word_count": 223, "token_count_estimate": 306}}, "https://cs.brown.edu/people/fprepara/": {"text_content": "Franco P. Preparata An Wang Professor of Computer Science francocs.brown.edu AddressPhoneFax Department of Computer Science Center for Geometric Computing Brown University Biographical Sketch nbsp Recent papers nbsp Teaching nbsp Computational Biology nbsp The 101 Forum", "metadata": {"last_modified": "2004-02-02T19:17:13+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 35, "token_count_estimate": 52}}, "https://cs.brown.edu/people/gdk/": {"text_content": "George Konidaris Director Intelligent Robot Lab Associate Professor Department of Computer Science Brown University, Providence RI gdkcs.brown.edu Home IRL Research Teaching Publications Software CV Welcome to my home page. Im an Associate Professor of Computer Science and director ofthe Intelligent Robot Lab at Brown , which forms part of bigAI Brown Integrative, General AI . My group and I conduct research driven by the overarching scientific goal of understanding the fundamental computational processes that generateintelligence, and using them to design a generally-intelligent robot. I am also the co-founder of two technology startups.I co-founded, and serve as the Chief Roboticist of, Realtime Robotics , a startup based on our research on robot motion planning , and that aims to make robotic automation simpler, better, and faster. I also co-founded Lelapa AI , a commercial AI research lab focused on technology by and for Africans, and based in Johannesburg, South Africa. If youre considering applying to the PhD program at Brown to study in my lab, please see this page . Research My research aims tobuild intelligent, autonomous, general-purpose robots that are generally capable in a wide variety of tasksand environments. I focus on understanding how todesign agents that learn abstraction hierarchies that enable fast, goal-oriented planning.I develop andapply techniques from machine learning, reinforcement learning, optimal control and planningto construct well-grounded hierarchies that result in fast planning for common cases,andare robust to uncertainty atevery level of control. I believe that it will take advances in all of these areas, and additionally advances in how to integrate these areas,to solve the AI problem. This recent lecture covers the high-level vision underlying most of my work You can also find an approachable and short view of my approach to building generally intelligent agentsin the following review paper G.D. Konidaris. On TheNecessity of Abstraction . Current Opinion in Behavioral Sciences 29Special Issue on Artificial Intelligence,pages 1-7, October 2019. My invited talk at CoRL 2019 in Osaka summarizes my labs technical work at that point Finally, this journal article is a good indicator of my interests - it combines ideas fromhierarchical reinforcement learning, probabilistic machine learning, task-level planning, and roboticsto create a robot that autonomously learns an abstract symbolic model of an environment and then uses it to plan G.D. Konidaris, L.P. Kaelbling, and T. Lozano-Perez. From Skills to Symbols Learning Symbolic Representationsfor Abstract High-Level Planning . Journal of Artificial IntelligenceResearch 61, pages 215-289, January 2018. Of course, the video is a lot more accessible Other than that, here are a few sample project pages Constructing High-Level Symbolic Representations for Planning . Autonomous Robot Skill Acquisition . Planning for the Decentralized Control of Multi-Robot Teams . Robot Motion Planning on a Chip . The Fourier Basis . Teaching I am currently teaching CSCI 2951X Reintegrating AI Spring 2024 I have previously taught the following classes at Brown CSCI 2951X Reintegrating AI Spring 2023 CSCI 1410 Artificial Intelligence Fall 2022 CSCI 2951X Reintegrating AI Fall 2021 CSCI 1410 Artificial Intelligence Fall 2021 CSCI 2951X Reintegrating AI Spring 2021 CSCI 2951X Reintegrating AI Spring 2020 CSCI 1410 Artificial Intelligence Fall 2019 CSCI 2951X Reintegrating AI Spring 2018 CSCI 1410 Artificial Intelligence Fall 2018 CSCI 1410 Artificial Intelligence Fall 2017 CSCI 1410 Artificial Intelligence Spring 2017 I taught the following classes when I was at Duke CPS 590.2 Hierarchical Robot Learning and Planning Fall 2014 CPS 270 Introduction to Artificial Intelligence Spring 2015 CPS 590 Decision Making for Robots and Autonomous Systems Fall 2015 CPS 270 Introduction to Artificial Intelligence Spring 2016", "metadata": {"last_modified": "2024-03-11T15:07:41+00:00", "scraped_at": "2024-03-13T22:15:39+00:00", "headings": ["Research", "Teaching"], "word_count": 583, "token_count_estimate": 814}}, "https://cs.brown.edu/people/irisbahar/index.html": {"text_content": "Research current Students Teaching Publications Contact News and Upcoming Travel 932020 PhD student Yanqi Jasmine Liu presented her work at FPL . 462020 Undergrad student Casey Nelson wins Randy F. Pausch summer research award. R. Iris Bahar I am a Professor of Computer Science and Engineering at Brown University . I hold a joint appointment in the School of Engineering and Department of Computer Science . My research interests lie broadly in the areas of computer system design and electronic design automation. In particular, my research focuses on energy-efficient and reliable computing, from the system level to device level. Past research topics have included modelling thermal noise effects in nanoscale circuits, design of noise- and error-immune circuits, approximate computing from systems to circuits, and memory synchronization techniques for multiprocessor systems. Most recently, my research interests have led me to explore applications for near-data processing and design of robust machine learning techniques for robot scene perception. More information about my research, teaching, and service can be found on my Brown University research page. Below is a brief overview of a few of my recent research projects. Concurrent Near-Data Processing Architectures Recent advances in memory architectures have provoked renewed interest in near-data-processing NDP as way to alleviate the memory wall problem. An NDP architecture places logic circuits, such as simple processors, in close proximity to memory. This is distinct from processing-in-memory PIM where logic computation is effectively integrated into the memory cellsarrays. More - Robust and Computationally-Efficient Scene Perception Technological advancements have led to a proliferation of robots using machine learning systems to assist humans in a wide range of tasks. However, we are still far from accurate, reliable, and resource-efficient operations of these systems. More - Modeling of Fundamental Noise Effects in Nanoscale Circuits Near-threshold and sub-threshold voltage designs have been identified as possible solutions to overcome the limitations introduced by energy consumption in modern VLSI circuits. However, aggressive voltage and gate length scaling will reduce the reliability of logic circuits due to the increasing impact of noise and variability effects. More - Managing Microarchitecture Timing Violations with Hardware Transactional Memory Scaling of semiconductor devices has enabled higher levels of integration and performance improvements at the price of making devices more susceptible to the effects of static and dynamic variability. Adding safety margins guardbands on the operating frequency or supply voltage prevents timing errors but has a negative impact on performance and energy consumption. More -", "metadata": {"last_modified": "2020-09-28T17:50:38+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["R. Iris Bahar"], "word_count": 405, "token_count_estimate": 487}}, "https://cs.brown.edu/people/gsatas/": {"text_content": "Gryte Satas gsatas at cs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7600 CS Home Page", "metadata": {"last_modified": "2014-09-29T14:40:31+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Gryte Satas"], "word_count": 19, "token_count_estimate": 38}}, "https://cs.brown.edu/people/hg12/": {"text_content": "Hua Guo huag at cs dot brown dot edu 553 CIT Box 1910, Computer Science Department Brown University Providence, RI 02912 About Me In 2015 - 2016, I am a fifth year PhD student in Computer Science Department in Brown University. I work in the Visualization Research Lab , and my advisor is Professor David Laidlaw . Before starting my study at Brown, I received my B.S. degree in Computer Science and Mathematics from Hong Kong University of Science and Technology. Research My research centers on human-centered design and evaluation of visual analytics tools to support scientific reasoning. No matter what computational methods we apply to extract, transform, and summarize information, information needs to be processed by human users at the end to be converted into knowledge and decisions, and visual analytics applications need to help human process information more effectively. Therefore, my research aims to inform the design of visual analysis tools by studying how users perceive, interact with, and ultimately make sense of the visualized data. I have been collaborating with experts outside Computer Science, primarily brain scientists, to distill visualization research problems from their needs while developing tools that can help them in their work. Publications Papers A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights IEEE VAST , 2015 Hua Guo , Steven R. Gomez, Caroline Ziemkiewicz, and David H. Laidlaw Representing Uncertainty in Graph Edges An Evaluation of Paired Visual Variables IEEE Transactions on Visualization and Computer Graphics , 2015 Hua Guo , Jeff Huang, and David H. Laidlaw Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters HCOMP , 2015 Alexandra Papoutsaki, Hua Guo , Danae Metaxa, Jeff Rasley, Jeff Huang An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics IEEE VAST , 2014 Steven R. Gomez, Hua Guo , Caroline Ziemkiewicz, and David H. Laidlaw Different Strokes for Different Folks Visual Presentation Design Between Disciplines IEEE InfoVis , 2012 Steven R. Gomez, Radu Jianu, Caroline Ziemkiewicz, Hua Guo , and David H. Laidlaw Extended Abstracts and Posters Visualization to Facilitate Structured Exploration of Published Findings in Rat Brain Connectivity IEEE InfoVis Poster session , 2013 Hua Guo , Steven R. Gomez, Mark J. Schnitzer, David H. Laidlaw Toward a visual interface for brain connectivity analysis ACM CHI Poster session , 2013 Hua Guo , Arthur Yidi, Steven R. Gomez, Mark J. Schnitzer, David Badre, David H. Laidlaw Incorporating GOMS analysis into the design of an EEG data visual analysis tool IEEE InfoVis Poster session , 2012 Hua Guo , Diem Tran, and David H. Laidlaw", "metadata": {"last_modified": "2015-10-19T14:10:18+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Hua Guo", "About Me", "Research", "Publications"], "word_count": 434, "token_count_estimate": 616}}, "https://cs.brown.edu/people/faculty/stellex/": {"text_content": "Stefanie A Tellex Associate Professor of Computer Science, Associate Professor of Engineering Office CIT 375 Phone 401-863-6898 Email stellex cs.brown.edu Assistant Suzanne M Alden Research Areas Artificial Intelligence, Machine Learning, Robotics Home Page", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Information for:", "Stefanie A Tellex"], "word_count": 33, "token_count_estimate": 52}}, "https://cs.brown.edu/people/jhughes/home.htm": {"text_content": "John Hughes Professor of Computer Science Current Activities Research Projects Office Hours For Fall 2012 Mondays, 100 - 200 PM, and by email appointment Biography, CV, and Contact Courses CS 224 - Interactive Computer Graphics, Spring 2010 CS 16 - Introduction to Algorithms and Data Structures, Spring 2010", "metadata": {"last_modified": "2014-07-15T20:52:00+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": [], "word_count": 48, "token_count_estimate": 64}}, "https://cs.brown.edu/people/jhughes/": {"text_content": "John Hughes Professor of Computer Science Current Activities Research Projects Office Hours For Fall 2012 Mondays, 100 - 200 PM, and by email appointment Biography, CV, and Contact Courses CS 224 - Interactive Computer Graphics, Spring 2010 CS 16 - Introduction to Algorithms and Data Structures, Spring 2010", "metadata": {"last_modified": "2014-07-15T20:52:00+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 48, "token_count_estimate": 64}}, "https://cs.brown.edu/people/jsavage/blockchain.html": {"text_content": "Blockchain Technologies and Cryptocurrencies Prof. John E. Savage Brown University Brown University Courses CS 2952 A Blockchains and Cryptocurrencies Lecture 13 of CSCI 1800, Cybersecurity and International Relations Observations about the Internet and Cryptocurrencies Motto of the Internet Engineering Community We reject kings, presidents and voting. We believe in rough consensus and running code. Appears in A Cloudy Crystal Ball Visions of the Future, by David Clark, 24th Internet Engineering Task Force, 1992 A Declaration of the Independence of Cyberspace by John Perry Barlow, February 8, 1996 A Declaration of the Dependence of Cyberspace by Moshe Y. Vardi, Communications of the ACM, Vol. 61 No. 3, Page 9, 2018 CryptoCurrency Facts Opinions about Blockchain Technologies Just Another Day for Bitcoin a 25 Plunge Digital currency down 48 from December high amid growing regulatory scrutiny by Mike Bird and Gregor STuart Hunter, The Wall Street Journal, January 16, 2018 Blockchains Broken Promises by Nouriel Roubini, Project Syndicate, January 26, 2018 The Blockchain Pipe Dream by Nouriel Roubini and Preston Byrne, Project Syndicate, March 5, 2018 Why Blockchain Will Survive, Even If Bitcoin Doesnt Latest blockchain applications could bring overdue change to critical, if unsexy, functions in shipping, real estate and ... diamonds by Christopher Mims, The Wall Street Journal, March 11, 2018 Blockchain is not only crappy technology but a bad vision for the future by Kai Stinchcombe, Medium, April 5, 2018 Projects based on the elimination of trust have failed to capture customers interest because trust is actually so damn valuable. The Blockchain Movement is Underway. What Should CEOs Know , FTI Journal, May 2018 187 THINGS THE BLOCKCHAIN IS SUPPOSED TO FIX , by Eric Griffin, Wired, May 25, 2018 Alternatives to Blockchain by Jimmy Song, Medium, May 23, 2018 Monetary Policy in the Digital Age Crypto assets may one day reduce demand for central bank money by Dong He, International Monetary Fund, June 2018 This article analyzes the consequences of replacing a fiat currency with a cryptocurrency. Top banker batters Bitcoin for sucky scalability, security Australias Reserve Bank sees no need for national cryptocurrencies, for now by Simon Sharwood, The Register, June 27 2018 Tony Richard, head of payments policy at Australias Reserve Bank, highlights the scaling problems associated with the Bitcoin currency. This Years Blockchain Craze Mirrors the Early Days of the Internet by Iris Zhao, The Council on Foreign Relations, December 20, 2018 Remember Bitcoin Some Investors Might Want to Forget by Nellie Bowles, The New York Times, December 27, 2018 Raising Money in the Crypto World Has Gotten a Lot Harder The market for initial coin offerings, which boomed last year, has ground to a halt by Paul Vigna, The Wall Street Journal, March 31, 2019 Amid Bitcoin Uncertainty, the Smart Money Knows That Crypto Is Not Ready by Nathaniel Popper, The New York Times, April 2, 2019 Introduction to Bitcoins The Crypto-Currency Bitcoin and its mysterious inventor by Joshua Davis, The New Yorker, October 10, 2011 The author provides an introduction to bitcoin and describes his attempt to identify its author, Satoshi Nakamoto. How Bitcoin Works Under the Hood , CuriousInventor, YouTube, January 31, 2017 A transcript of the video is available here . This 2224 minute video provides a technical introduction to bitcoin, the worlds first cryptocurrency. It defines bitcoin transfers and explains how bitcoin ownership is certified, how transfers occur using a decentralized public blockchain, and the role of miners who collect transfers, solve a hard computational problem to obtain a proof of work, and form a block and append it to the blockchain. It also explains the verification process that each miner does to verify the ownership of bitcoin and the work of other miners, thereby realizing a system of trust without invoking a trusted centralized broker. The State of the Ethereum Network After months of intense attention on blockchain technology and the Ethereum blockchain, we pull together statistics from across the network to provide a snapshot of Ethereum today, its past, and its roadmap ahead , Consensus, June 1, 2018 Blockchain Technologies Introduction to Blockchains What is blockchain The most disruptive tech in years by LucasMearian, Computerworld, January 18,2018 This article provides a high-level textual description of blockchains. What is Blockchain , Centre for International Governance Innovation, YouTube, January 4, 2018 This 626 minute video provides a quick overview of the operation ofblockchains and their importance. Blockchains How They Work and Why Theyll Change the World byMorgen E. Peck, IEEE Spectrum, September 28, 2017 This article provides more depth than the video and introduces the conceptof smart contracts . Blockchain by Margaret Rouse, TechTarget, SearchCIO.com, July 26, 2017 SPECIAL REPORT BLOCKCHAIN WORLD , IEEE Spectrum, September 28, 2017 This is a collection of 11 articles on blockchain technology. Decentralized Blockchain-Based Electronic Marketplaces by Hemang Subramanian, Communications of the ACM, January 2018A video providing an overview of blockchains is available here . MITs Blockchain Site Maurice Herlihys Site for CSCI 2952-A Understanding The DAO Attack by David Siegel, Coindesk, June 25, 2016 Realizing Policy Goals through Blockchain Technology , Centre for International Governance Innovation, July 6, 2017 SPECIAL REPORT BLOCKCHAIN WORLD , IEEE Spectrum Wall Street Firms to Move Trillions to Blockchains in 2018 by AmyNordrum, IEEE Spectrum, September 29,, 2017 Do You Need a Blockchain by Morgen E. Peck, IEEE Spectrum,September 29, 2017Money pp 239-278, September 1, 2016 50 Examples of How Blockchains are Taking Over the World by MatteoGianpietro Zago, Medium, May 30, 2018 DealBook , The New York Times, June 27,2018 Demystifying the Blockchain by Andrew Ross Sorkin, The New YorkTimes, June 27, 2018 Confused About Blockchains Heres What You Need to Know by Nathaniel Popper, The New York Times, June 27, 2018 Industries, Looking for Efficiency, Turn to Blockchains by Laura Shin, The New York Times, June 27,2018 The People Leading the Blockchain Revolution by Nathaniel Popper, The New York Times, June 27, 2018 A Guide to the World of Blockchain by Nathaniel Popper and Guilbert Gates, The New York Times, June 27, 2018 Scaling Issues Ensuring Network Scalibility How to Fight Blockchain Bloat byAndrew Wagner, BitcoinMagazine, November 6, 2014 What is the Lightning Network and how can it help Bitcoin scale by Elizabeth Stark, coincenter, September 15, 2016 Blockchains dont scale. Not today, at least. But theres hope. by Preethi Kasireddy, Hackernoon, August 23, 2017 Bitcoin Hasnt Replaced Cash, but Investors Dont Care by Nathaniel Popper, December 6, 2017 This article states that Bitcoin can handle about 5 transactions persecond whereas Visa is able to handle about 25,000 transactions per second. Plasma Scalable Autonomous Smart Contracts by Joseph Poon and Vitalik Buterin, Working Draft, August 11, 2017 Bitcoin Lightning Network 7 Things You Should Know by LukasSchor, Medium, January 10, 2018 The State of Scaling Ethereum A concise overview of the challenges and solutions to scaling the Ethereum Network , Consensy, April 24, 2018 Ethereums Casper and Sharding New Design by Michael K. Spencer, Medium, June 16, 2018 Blockchain phase 2 Will it scale by Lucas Mearian, Computerworld, August 15, 2018 As blockchain grows in popularity, so does the conundrum of how to scale it while maintaining or boosting performance so it can compete with todays transaction networks. Mutable Blockchains Accentures Blockchain Redaction Solution by Martha Bennett, Accenture, April 2017 Redactable Blockchain or Rewriting History in Bitcoin andFriends by Giuseppe Ateniese, Bernardo Magri, Daniele Venturi and Ewerton Andrade, The International Association for Cryptologic Research, May 11, 2017 Consensus Algorithms Proof of Stake FAQ , by Moshe Simantov, GitHub, 2018 Casper the Friendly Gadget by Buterin and Griffith Incentives in Casper the Friendly Gadget by Vitalik Buterin, Ethereum, August 27, 2017 Decentralization in Bitcoin and Ethereum Networks by Gencer, Basu, Eyal, Renesse, and Sirer, Cornell University, January 11, 2018 When IoT met blockchain by Frederic Paul, Networkworld, January 26, 2018 A Concurrent Perspective on Smart Contracts by Ilya Sergey and Aquinas Hobor, arXiv.org, February 17, 2017 IBM sees blockchain as ready for government use by Lucas Mearian, Computerworld, February 14, 2018 The Eureka Moment That Made Bitcoin Possible A key insight for the technology came to a physicist almost three decades ago at a Friendlys restaurant in New Jersey by Amy Whitaker, May 25, 2018 Scaling Nakamoto Consensus to Thousands of Transactions per Second by Chenxing Li, Peilun Li, Dong Zhou, Wei Xu, Fan Long, and Andrew Chi-Chih Yao, arXiv1805.03870, August 31, 2019 Solida A Blockchain Protocol Based on Reconfigurable Byzantine Consensus by Ittai Abraham, Dahlia Malkhi, Kartik Nayak, Ling Ren, and Alexander Spiegelman, arXiv 1612.02916, November 18, 2017 Ethereum Plans to Cut Its Absurd Energy Consumption by 99 Percent by Peter Fairley, IEEE Spectrum, January 2, 2019 Cryptocurrency Vulnerabilities BatchOverflow Exploit Creates Trillions of Ethereum Tokens, Major Exchanges Halt ERC20 Deposits by Sam Town, Cryptoslate, April 25, 2018 Majority Is Not Enough Bitcoin Mining Is Vulnerable by Ittay Eyal and Emin Gn Sirer, CACM, July 2018 Problems with Smart Contracts The Curious Case of 184 Billion Bitcoin by Bruno, January 14, 2018 The author explains how a failure to check for integer overflow in the Bitcoin softwareallowed two units of about 184 million bitcoin to be created and sent toaccounts in 2010 until corrected. Blockchains from a Distributed Computing Perspective by MauriceHerlihy, Brown University, January 16, 2018 This article is a tutorial on the basic notions and mechanismsunderlying blockchains, colored by the perspective that much of theblockchain world is a disguised, sometimes distorted, mirror-imageof the distributed computing world. Maurice also explains how a failureto understand this lead to the theft of about 50 Million from theDecentralized Autonomous Organization DAO in 2016 by exploiting poorlydesigned smart contracts. An Overview of Cryptocurrency Consensus Algorithms by Phil Glazer,HackerNoon, March 14, 2018 This Yale Technology Could Fix Blockchains Security Issues and Make It a Lot More Viable , Office of Cooperative Research, Yale University,2018 A team at Yale has developed technology to simplify verification of thecorrectness of smart contracts. When smart contracts are embedded inblockchains, they are permanent. If they contain errors, misuse ofblockchain data can occur. The only way to fix this is to execute a hardfork, which requires rebuilding the blockchain from the point of the error. Databases for Blockchains Concerto A High Concurrency Key-Value Store with Integrity by Arvind Arasu, Ken Eguro, Raghav Kaushik, Donald Kossmann,Pingfan Meng, Vineet Pandey, and Ravi Ramamurthy, Procs.2017 ACM International Conference on Management of Data SIGMOD, Pages 251-266 Available Blockchain Implementations Hyperledger Consortium , a product of the Linux Foundation. See this article . Microsoft wants to make blockchain networks enterprise-ready with its new Coco Framework by Frederic Lardinois, TechCrunch, August 10, 2017 Announcing the Coco Framework for enterprise blockchain networks , Mark Russinovich, CTO, Microsoft Azure, August 10, 2017 Corda , a distributed ledger technology. Corda is an open source blockchain project designed for business from the start. Only Corda allows you to build interoperable blockchain networks that transact in strict privacy. Cordas smart contract technology allows businesses to transact directly, with value. Quorum by J. P. Morgan Quorum is an enterprise-ready distributed ledger and smart contract platform. The Bitcoin Mining Process Bitcoin Reward Halving Countdown In one chart, heres how much it costs to mine bitcoin in your state , by Ryan Vlastelica, MarketWatch, December 18, 2017 A Short Guide to Blockchain Consensus Protocols by Amy Castor, coindesk, March 4, 2017 What Is Cryptocurrency How It Works, History Bitcoin Alternatives by Brian Martucci, Money Crashers Crypto Mining ETH Not Worth Starting by Tyler, Medium, May 25, 2018 Cryptocurrencies Bitcoin A Peer-to-Peer Electronic Cash System by Satoshi Nakamoto, published on the cryptography mailing list metzdowd.com. 100 Cryptocurrencies Described in Four Words or Less , by Nate Murray, TechCrunch, November 19, 2017 Want to really understand how bitcoin works Heres a gentle primer by Timothy B. Lee, Ars Technica, December 15, 2017 Five myths about bitcoin by Joseph Bonneau and Steven Goldfeder, The Washington Post, December 15, 2017 Bitcoins Academic Pedigree by Arvind Narayanan, Jeremy Clark, Communications of the ACM, Vol. 60 No. 12, Pages 36-45, December 2017 Algorand Scaling Byzantine Agreements for Cryptocurrencies by Yossi Gilad, Rotem Hemo, Silvio Micali, Georgios Vlachos, and Nickolai Zeldovich, SOSP 2017 Algorand provides a new way to create distributed ledgers that avoids important problems that arise with traditional blockchains. A 3946 minute video of a talk given at Berkeley by Silvio Micali explains the basic concepts is available here . A longer and more complete 11246 video produced by the ACM is available here . Merrill Lynch Bars Trading of Bitcoin Fund, Futures Firm has already denied clients access to the bitcoin futures markets by Lisa Beilfuss, The Wall Street Journal, January 3, 2018 Russia and Venezuelas Plan to Sidestep Sanctions Virtual Currencies by Nathaniel Popper, Oleg Matsnev and Ana Vanessa Herrero, The New York Times, January 3, 2018 Rise of Bitcoin Competitor Ripple Creates Wealth to Rival Zuckerberg by Nathaniel Popper, The New York Times, January 4, 2018 SEC warns cryptocurrency investors of rampant illegal trading by Sylvan Lane, The Hill, January 4, 2018 Ripple Steals Bitcoins Thunder, Surges 1,135 in a Month by Paul Vigna, The Wall Street Journal, January 5, 2018 Initial Coin Offerings and Cryptocurrencies Will be a Priority for FINRA in 2018 by Linn Foster Freedman, Robison Cole, January 11, 2018 MoneyGram Signs Deal to Work With Currency Startup Ripple Money-transfer company will run a pilot program testing XRP, a digital currency by Paul Vigna and Peter Rudegeair, The Wall Street Journal, January 11, 2018 Beyond the Bitcoin Bubble Yes, its driven by greed but the mania for cryptocurrency could wind up building something much more important than wealth. by Steven Johnson, The New York Times, January 16, 2018 New Cyberattack on Cryptocurrency Investors Came From North Korea, Report Says by Jonathan Cheng, The Wall Street Journal, January 17, 2018 Credit Card Companies Dont Want You to Buy Bitcoin With Plastic by AnnaMaria Andriotis and Paul Vigna, The Wall Street Journal, January 25, 2018 Cryptocurrency botnets are rendering some companies unable to operate by Dan Goodin, ArsTechnica, February 2, 2018 Bitcoins Plunge Weighs on Coin Offerings by Paul Vigna, The Wall Street Journal, February 7, 2018 A 232 Million Cryptocurrency Fight Comes to a Close Tezos team can move forward after nonprofit foundation chief who was locked in a battle for control of funds steps down by Paul Vigna, The Wall Street Journal, February 22, 2018 What Bitcoin Rout Sales of New Digital Tokens Are Still Soaring by Paul Vigna, The Wall Street Journal, February 22, 2018 Bitcoins Underlying Incentives by Yonatan Sompolinsky, Aviv Zohar Communications of the ACM, Vol. 61 No. 3, Pages 46-53, 2018 Bitcoin Price , Business Insider Bitcoin DiamondSuper BitcoinBitCore What You Need To Know by Jimmy Song, Medium, January 3, 2018 Top Cryptocurrency Primer Guide in Bite Sized Notes by Michael Spencer, Medium, May 27, 2018 Bitcoin Drop Sparks Broad Cryptocurrency Selloff by Paul Vigna, The Wall Street Journal, June 22, 2018 Crypto Pioneer David Chaum Says Hes Built a Better Bitcoin A new platform, called Elixxir, promises to improve on bitcoins speed by processing thousands of transactions a second by Paul Vigna, The Wall Street Journal, September 19, 2019 Cryptocurrency Exchanges Cryptocompare This site lists the current price in various currencies of 1994 cryptocurrencies. Bitcoin Plunges as South Korea Crafts Cryptocurrency Crackdown South Korea is preparing a bill to ban the trading of cryptocurrencies on exchanges by Eun-Young Jeong and Gregor Stuart Hunter, The Wall Street Journal, January 11, 2018 This weeks Bitcoin crash was all about fraud and regulation by Simon Chandler, The Verge, January 18, 2018 The Programmer at the Center of a 100 Billion Crypto Storm by Paul Vigna and Jim Oberman, The Wall Street Journal, January 23, 2018 Whats Bitcoin Worth A New Plan to Bring Discipline to Crypto Prices by Alexander Osipovich, The Wall Street Journal, January 19, 2018 Financial regulators subpoena major bitcoin exchange by Ali Breland, The Hill, January 30, 2018 Cryptocurrency Firm Coinbase in Talks to Become SEC-Regulated Brokerage by Dave Michaels, The Wall Street Journal, April 6, 2018 Other Countries Forge Ahead on Crypto Regulations by Laura Shin, The New York Times, June 27, 2018 Bots Are Manipulating Price of Bitcoin in Wild West of Crypto Abusive softrware runs largely unchecked on crypto exchanges, prompting regulatory concern by Paul Vigna and Alexander Osipovich, The Wall Street Journal, October 2, 2018 Initial Coin Offerings HoweyCoins PRE-ICO SALE IS LIVE The SEC Has an Opportunity You Wont Want to Miss Act Now , U.S. Securities and Exchange Commission The SEC has created a website advertisiting a fake initial coin offering ICO. Cryptocurrency ICO Stats 2018 , CoinSchedule The Failure Rate of ICOs is Skyrocketing in 2018 by Michael K. Spencer, Medium, August 9, 2018 Cryptocurrency Scandals A Painful Lesson For The Ethereum Community by Frances Coppola, Forbes, July 21, 2016 Bitcoin 64m in cryptocurrency stolen in sophisticated hack, exchange says by Samuel Gibbs, The Guardian, December 7, 2017 Japanese Cryptocurrency Exchange Coincheck to Pay Back Customers by Peter Landers, The Wall Street Journal, January 27, 2018 Bitcoin wallets vulnerable to security hacks , University of Ediburgh Cryptocurrency botnets are rendering some companies unable to operate by Dan Goodin, ArsTechnica, February 2, 2018 BitGrail cryptocurrency exchange loses 170 million in Nano tokens ... the checks for whether you had a sufficient balance to withdraw were only implemented as client-side JavaScript Cryptocurrency Worth 170 Million Missing From Italian Exchange BitGrail says it lost about 17 million tokens of Nano by Paul Vigna, The Wall Street Journal, February 10, 2018 Inside the Worlds Bigggest Cryptocurrency Hack and How the Scammers Pulled it Off by Rob Wile, Money, January 29, 2018 Feds charge former bitcoin exchange with fraud by Ali Breland, The Hill, February 21, 2018 Crypto Wallet Vs. Address Believe it or not, theres a difference by Kenny Li, Hackernoon, May 22, 2018 About 1.2 billion in cryptocurrency stolen since 2017 by Gertrude Chavez-Dreyfuss, Reuters, May 24, 2018 Policing Cryptocurrencies Has Become a Game of Whack-a-Mole for Regulators by Peter J. Henning, The New York Times, May 31, 2018 Making Bitcoin Legal by Ross Anderson, Ilia Shumailov and Mansoor Ahmed, Cambridge University Computer Laboratory, 2018 The authors identify existing law that can be applied to making bitcoin legal. Bitcoin Falls Sharply After Another Cryptocurrency Exchange Is Hacked The largest cryptocurrency has lost more than half its value this year by Steven Russolillo, The Wall Street Journal, June 10, 2018 Bitcoins Price Was Artificially Inflated, Fueling Skyrocketing Value, Researchers Say by Nathaniel Popper, The New York Times, March 30, 2018 A concentrated campaign of price manipulation may have accounted for at least half of the increase in the price of Bitcoin and other big cryptocurrencies last year. Major cryptocurrency exchange Bithumb halts trading after more than 31 million hack by Brian Murphy, The Washington Post, June 19, 2018 Inside the Crypto Worlds Biggest Scandal by Gideon Lewis-Kraus, Wired, June 19, 2018 A Fifth of All Bitcoin Is Missing. These Crypto Hunters Can Help by Elliott Krause, The Wall Street Journal, July 5, 2018 Cryptocurrencys Criminal Revolution by Tyler Eliot Bettilyon, Medium, July 12, 2018 Cryptocurrency Exchanges Are Getting Hacked Because Its Easy Regulatory gaps and insufficient levels of defense have made some exchanges simple to breach by Steven Russolillo and Eun-Young Jeong, The Wall Street Journal, July 16, 2018 Traders Are Talking Up Cryptocurrencies, Then Dumping Them, Costing Other Millions Pump groups fuel millions in trading activity, with price rises followed by quick falls by Shane Shifflett and Paul Vigna, The Wall Street Journal, August 5, 2018 The Big Blockchain Lie by Nouriel Roubini, Project Syndicate, Octobr 15, 2018 ICO Firms Paid Themselves 24 Billion Absent of Accountability or Much Effort by Shaurya Malwa, CRYPTOSLATE, January 18, 2019 A Blockchain Bandit is Guessing Private Keys and Scoring Millions by Andy Greenberg, WIRED, April 23, 2019 A new cryptocurrency mining malware uses leaked NSA exploits to spread across enterprise networks by Zack Whittaker, TechCrunch, April 25, 2019 Blockchain and Cryptocurrency Governance BitLicense Regulatory Framework , New York State Russia and Venezuelas Plan to Sidestep Sanctions Virtual Currencies by Nathaniel Popper, Oleg Matsnev and Ana Vanessa Herrero, The New York Times, January 3, 2018 U.S. Sanctions Weapon Is Under Threat, but Not From Bitcoin by Keith Johnson and Elias Groll, Foreign Policy, January 24, 2018 Bitcoins real story isnt the rampant speculation, but its untold potential by Steve Forbes, The Hill, January 18, 2018 Cryptocurrencies Are Top of Mind for G20 Finance Ministers Anonymity and borderless transactions create a perfect climate for money laundering by Samantha St. Amand, Centre for International Governance Innovation, February 20, 2018 Women in Cryptocurrencies Push Back Against Blockchain Bros by Nellie Bowles, The New York Times, February 25, 2018 G20 leaders to hold fire on cryptocurrencies amid discord sources by Francesco Canepa, Reuters, March 19, 2018 Bitcoin Could Become Illegal Almost Everywhere, After Shocking Discovery in The Blockchain Theres something hidden inside it. by Peter Dockrill, Science Alert, March 22, 2018 Venture Capitalists Seek Safe Harbor for Virtual Currencies by Nathaniel Popper, The New York Times, April 19, 2018 A Former Top Wall Street Regulator Turns to the Blockchain by Nathaniel Popper, The New York Times, April 22, 2018 The Crypto Crime Wave Is Here From stickups and drug deals to white-collar scams, cryptocurrency-related crime is soaring and law enforcement is scrambling to keep up by Corinne Ramey, The Wall Street Journal, April 26, 2018 Blockchain Will Be Theirs, Russian Spy Boasted at Conference by Nathaniel Popper, April 29, 2018 Cryptocurrency Regulation Update May 2018 by Phil Glazer, Hackernoon, May 1, 2018 Recent Trends in Virtual Currency Regulation, Enforcement, and Litigation by Sharon Brown-Hruska and Trevor Wagener, NERA, May 21, 2018 Regulatory uncertainty could stymy blockchain adoption Even as companies seek to integrate the distributed ledger technology into their business models, uncertainty about the regulatory landscape is seen as a major stumbling block. By Lucas Mearian, Computerworld, June 7, 2018 Decentralized Blockchain Governance by Daniel Larimer, Medium, June 20, 2018 State of Cryptocurrencies Summer 2018 by Adam Tach, Hackernoon, June 23, 2018 Cryptocurrency Regulation Update June 2018 by Phil Glazer, Hackernoon, June 12, 2018 COINBASE DOUBLES DOWN ON THE FUTURE OF DIGITAL IDENTITY by Gregory Barber, Wired, August 15, 2018 Energy Consumption The Hard Math Behind Bitcoins Global Warming Problem by Adams Rogers, Wired, December 15, 2017 There Is Nothing Virtual About Bitcoins Energy Appetite by Nathaniel Popper, The New York Times, January 21, 2018 Bitcoins alarming carbon footprint , Spyros Fonteinis, Nature, Vol. 554, February 8, 2018 Cryptocurrency mining in Iceland is using so much energy, the electricity may run out by Rick Noack, The Washington Post, February 13, 2018 Bitcoin Mania Triggers Miner Influx to Rural Washington by Alison Sider, The Wall Street Journal, February 11, 2018 Salon to use readers computers to mine cryptocurrency by Julia Manchester, The Hill, February 13, 2018 Salon Is Asking Readers to Mine Cryptocurrency if They Dont Want to See Ads by AAron Mark, Slate, February 13, 2018 Is Bitcoin a Waste of Electricity, or Something Worse by Binyamin Appelbaum, The New York Times, February 28,2018 Cryptocurrency mining is neither wasteful nor uneconomic by Stuart Wimbush, Nature, March 21, 2018 Why its time to stop mining cryptocurrency and look to the future of blockchain The time has come to stop mining cryptocurrencies. , by Alex Stand, Medium, April 3, 2018 Iceland Takes Hard Look at Tech Boom Sparked by Its Cheap, Bountiful Power by Zeke Turner, The Wall Street Journal, April 19, 2018 By 2030, data centers and all internet-related activity, from streaming video to analyzing financial data to storing software, photos and emails, could use more electricity than all of China did in 2018. Deconstructing the Blockchain to Approach Physical Limits by Vivek Bagaria, Sreeram Kannan, David Tse, Giulia Fanti, and Pramod Viswanath, axXiv1810.08092, October 18, 2018 Ethereum Plans to Cut Its Absurd Energy Consumption by 99 Percent by Peter Fairley, IEEE Spectrum, January 2, 2019 Commercial Offerings IBM and Stellar Are Launching Blockchain Banking Across Multiple Countries by Jeff John Roberts, Fortune, October 16, 2017 An overview of Stellar is given here . A comparison of Stellar with other blockchains is available here . And a detailed explanation of Stellar is given here . Need help on blockchain These are the top three experts How IBM, Microsoft and Accenture have made themselves consultants of choice by Finbarr Toesland, The Times of London,, November 16 2017 Google Is Working on Its Own Blockchain-Related Technology by Olga Kharif and Mark Bergen, Bloomberg Technology, March 2,1 2018 Twitter is joining Facebook and Google in banning cryptocurrency advertisements The ban isnt yet official, but should be soon. by Kurt Wagner, recode, March 19, 2018 Google to Ban Ads for Cryptocurrencies New policy follows Facebooks lead, takes effect in June by Lara OReilly and Douglas MacMillan, The Wall Street Journal, March 13, 2018 Goldman Sachs to Open a Bitcoin Trading Operation by Nathaniel Popper, The New York Times, May 2, 2018 IBM partners Stronghold for new digital stable coin by Gertrude Chavez-Dreyfuss, Reuters, July 17, 2018 Blockchain Efforts Move Beyond the Hype This is Happening Now by Matthew Leising, Bloomberg, July 19, 2018 Cryptocurrency Startups Combine as Wall Street Blockchain Effort Falters by Paul Vigna, The Wall Street Journal, September 10, 2018 Advice on Blockchains Blockchain How this technology could impact the CFO Blockchain reaction Tech plans for critical mass Blockchain the hype, the opportunity and what you should do by Angus Champion de Crespigny, Ernst Young LLP, 2016 NISTIR 8202 Draft Blockchain Technology Overview by Dylan Yaga NIST, Peter Mell NIST, Nik Roby G2, Karen Scarfone Scarfone Cybersecurity, NIST Interledger Currency Exchanges Interledger How to Interconnect All Blockchains and Value Networks by Evan Schwartz and Vanessa Pestritto, Medium, October 3, 2018 Curated List of Publications by Philippe Camacho Papers on Bitcoins, Blockchains, and Smart Contracts Miscellaneous What is the Privacy Coin Matrix by Michael Spencer, Medium, May 21, 2018 News Reports Ethereum is Not Secure and its Delayed its Upgrade again by Michael K. Spencer, Medium, January 16, 2019 John Savage", "metadata": {"last_modified": "2019-05-20T17:47:18+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Blockchain Technologies and Cryptocurrencies", "Prof. John E. Savage", "Brown University", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "word_count": 4319, "token_count_estimate": 6507}}, "https://cs.brown.edu/people/jsavage/deterrence.html": {"text_content": "Cyber Deterrence Prof. John E. Savage Brown University Deterrence Methods Cyberdeterrence and Cyberwar by Martin Libicki, Rand, 2009 Deception, Disinformation, and Strategic Communications How One Interagency Group Made a Major Difference by Fletcher Schoen and Christopher J. Lamb, Institute for National Strategic Studies, Strategic Perspective, No. 11, National Defense University, June 2012 Toward Theory for Dissuasion or Deterrence by Denial Using Simple Cognitive Models of the Adversary to Inform Strategy by Paul K. Davis, RAND NSRD WR-1027, January 2014 This Working Paper grew out a conference paper presented at the Munk School of the University of Toronto, October 18-20, 2013. The conference, Deterrence by Denial Theory, Practice, and Empiricism, was co-organized by the Munk School of Global Affairs and the Center for Security Studies, ETH Zurich. How the United States Can Win the Cyberwar of the Future Cold War-era deterrence theory wont cut it anymore. by P.W. Singer, Foreign Policy, December 18, 2015 There is perhaps no national security problem more 21st century in both its definition and form than cybersecurity. And yet to solve it, the ready solution in nearly every U.S. national security conversation today is that tried and true 20th-century framework of deterrence. Cyber-Deterrence by Kim Taipale, Boston Global Forum, December 12, 2016 Raising the Consequences of Hacking American Companies Why the United States Needs an Explicit Cyber Deterrence Policy for the Private Sector by David A. Simons, CSIS, October 2017 Deterrence and Dissuasion in Cyberspace by Joseph S. Nye Jr., International Security, Vol. 41, No. 3, Winter 20162017 Deterring Cyberattacks How to Reduce Vulnerability by Susan Hennessy, Foreign Affairs, NovemberDecember 2017 Botched CIA Communications System Helped Blow Cover of Chinese AgentsThe number of informants executed in the debacle is higher thaninitially thought. by Zach Dorfman, Foreign Policy, August 15, 2018 Revealed Pentagon Push to Hack Nuke Missiles Before They Launch A former U.S. official calls the 2017 Pentagon policy document an exercise to legally justify a potential attack on a North Korean missile on the launchpad. From the article The Pentagon has embraced a controversial policy of destroying enemy nuclear missiles before they launch, an internal policy document from May 2017 shows. Itb bs an effort that appears to include executing cyberattacks against missile control systems or components. The Pentagon document Declaratory Policy,Concept of Operations and Employment Guidelines for Left-of-LaunchCapability is cited in the news article. Is Deterrence Possible by Timothy M. McKenzie, Colonel USAF, Air University, January 2017 Hacking Back Hacking Back Without Cracking Up by Jeremy Rabkin, Ariel Rabkin, Aegis Paper Series No.1606, Hoover Institution, June 28, 2016 The authors examine the risks and rewards of hacking back and conclude that it is worth conducting experiments to determine its effectiveness. It also refers to some interesting sources. The Digital Vigilantes Who Hack Back American companies that fall victim to data breaches want to retaliate against the culprits. But can they do so without breaking the law by Nicholas Schmidle, The New Yorker, May 7, 2018 This article provides an excellent introduction to hacking back. It cites CFAA, provides analogies for hacking back such as use of dye packs by banks, and discusses nascent effortsB to legalize some types of hackback, which some call vigilantism. It also highlights the difficulty of attributing hackers, calls attention to escalation dominance, and notes that hackers do make serious personal threats against those hacking back. Several experts warn that hacking back can be very dangerous and could lead to cyberwar. Assessment of Deterrence Strategies Not The Cyber Deterrence the United States Wants by Jason Healey, Council on Foreign Relations, June 11, 2018 What War Games Tell Us About the Use of Cyber Weapons in a Crisis by Jacquelyn G. Schneider, The Council on Foreign Relations, June 21,2018 The Limits of Deterrence Theory in Cyberspace by Mariarosaria Taddeo, Philos. Technol. 2018 31 339. I ... argue that ... applicability of deterrence to cyberspace is limited and that these limits are not trivial. Cyber Offense On the Theft and Reuse of Advanced Offensive Cyber Weapons by Gil Baram, Defense One, June 19, 2018 Symantec warns of China-based espionage campaign targeting satellites by Olivia Beavers, The Hill, June 20, 2018 Trump, Seeking to Relax Rules on U.S. Cyberattacks, Reverses Obama Directive Administration has faced pressure to show that it is taking seriously national-security cyberthreats by Dustin Volz, The Wall Street Journal, August 15, 2018 Legality of Cyber Operations US DoD Laws of War Manual Updated December 2016 Page 1012 of Chapter XVI applies these laws to Cyber Operations. Section 16.1.2.1 Examples of Cyber Operations on page 1012 refers to the pre-emplacement of capabilities or weapons . Ex-NSA Hackers Worry China And Russia Will Try to Arrest Them The US government has been indicting foreign government hackers, and American government hackers are worried China and Russia might start doing the same to them. by Lorenzo Franceschi-Bicchierai, Motherboard, December 1, 2017 Guide to Cyberspace Operations The Cyber Security Forum Initiative The Joint Force Commanders Guide to Cyberspace Operations by Brett T. Williams, USAF John Savage", "metadata": {"last_modified": "2020-08-21T00:41:14+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Cyber Deterrence", "Prof. John E. Savage", "Brown University", "", "", "", "", "", "", "", "", "", "", "", "", ""], "word_count": 831, "token_count_estimate": 1205}}, "https://cs.brown.edu/people/jbazik/": {"text_content": "These are for me Slashdot Debian News Debian Bits Debian Micronews RIPTA 1 Providence Weather This is my home page. I also have a more formal profile page on our website. Long ago I wrote xmx , an X protocol multiplexor. I do lots of Django programming lately. Visit my neighborhood . Test .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["This is my home page."], "word_count": 54, "token_count_estimate": 67}}, "https://cs.brown.edu/people/jrasley/": {"text_content": "Jeff Rasley Email jeffra cs brown edu Twitter jeffra45 Office 339 CIT 115 Waterman Street Computer Science Department Brown University Providence, RI 02912 Update 2018-05 I have accepted a Research SDE position at Microsoft. I am a Ph.D. candidate advised by Rodrigo Fonseca , primarily interested in distributed systems, networks, and security. I am supported by the NSF Graduate Research Fellowship Program . I completed my undergrad at the University of Washington where I studied computer science. During my time at UW I primarily worked with Justin Cappos on topics related to sandbox security and API Write-Once-Run-Anywhere verification. I also worked on the GENI supported peer-to-peer testbed called Seattle . More details can be found in my CV . News 2017-08 Our work with MSR on application-aware resource scheduling in the context of hyperparameter exploration in deep learning systems was accepted to Middleware 2017 2017-03 I will again be spending the summer at Microsoft Research in Redmond working with Yuxiong He , Minjia Zhang , and Wenhan Wang in the Deep Learning Optimizations team continuing our work on application-aware resource scheduling. 2016-02 I will be spending the summer at Microsoft Research in Redmond working with Yuxiong He , Olatunji Ruwase , and Trishul Chilimbi on topics related to building an application-aware resource scheduler for distributed deep neural network frameworks. 2016-02 Presenting a poster on queue manangement for cluster schedulers at NSDI 16 . 2016-01 Our work with Microsoft CISL and MSR on queue management for cluster schedulers was accepted to EuroSys 2016 2015-10 Giving a talk on queue management in cluster schedulers at the 2nd annual New England Networking and Systems Day . 2015-10 Thanks to the generosity of the NSF and SwitchOn I will be attending the SwitchOn Workshop in So Paulo which aims to foster collaborations between the U.S. and Brazil. 2015-09 I was elected as Faculty-Graduate Liaison FGL in my department 2015-02 Thanks to ACM SIGCOMM and others for a travel grant to attend the 5th PhD School on Traffic Monitoring and Analysis in Barcelona. 2015-01 I will be spending the summer as a Microsoft Research Intern at the Cloud and Information Services Lab CISL in Mountain View, CA. I will be working with Konstantinos Karanasos , Sriram Rao , and Srikanth Kandula on some interesting topics related to scheduling in large shared compute clusters. 2015-02 Thanks to ACM SIGCOMM and others for a travel grant to attend the 5th PhD School on Traffic Monitoring and Analysis in Barcelona. 2015-01 I will be spending the summer as a Microsoft Research Intern at the Cloud and Information Services Lab CISL in Mountain View, CA. I will be working with Konstantinos Karanasos , Sriram Rao , and Srikanth Kandula on some interesting topics related to scheduling in large shared compute clusters. 2014-12 As part of CS Education Week , I will be again visiting Nathan Bishop Middle School to help students with an Hour of Code. 2014-11 I will be a graduate TA for Distributed Computer Systems taught by Tom Doeppner and Rodrigo Fonseca in the Spring 15 semester. 2014-11 Giving an invited talk at UBC about our low-latency network monitoring work. Plus attending IMC 14 via a generous travel grant. 2014-10 Presenting a poster on low-latency network monitoring at the first annual New England Networking and Systems Day at the Hariri Institute at Boston University. 2014-04 Our work on low-latency network monitoring will be appearing at SIGCOMM 14 2014-04 Presenting a poster on low-latency network monitoring at NSDI 14 via a generous travel grant from USENIX. 2014-03 Poster judge at NEUCS 14 . 2014-03 I will be spending the summer at VMware in the NSX i.e., Nicira group. 2014-02 I will be presenting our paper Low-latency Network Monitoring via Oversubscribed Port Mirroring at the Open Networking Summits Research Track. 2013-12 Visiting Nathan Bishop Middle School to help students with an Hour of Code . 2013-09 Attending IMC 13 via a generous travel grant by the NSF. 2013-06 NSF Graduate Research Fellowship Awardee 2013, Brown blog post 2013-04 Poster judge at NEUCS 13 . Sadly, the event was canceled. 2013-03 I will be at IBM Research in Austin working with Colin Dixon and Eric Rozner this summer. More... Publications, Posters, etc. Accelerating Large Scale Deep Learning Inference through DeepCPU at Microsoft Minjia Zhang, Samyam Rajbandari, Wenhan Wang, Elton Zheng, Olatunji Ruwase, Jeff Rasley, Jason Li, Junhua Wang, and Yuxiong He. To appear at the 2019 USENIX Conference on Operational Machine Learning OpML 19 . Santa Clara, CA, 2019 HyperDrive Exploring Hyperparameters with POP Scheduling Jeff Rasley, Yuxiong He, Feng Yan, Olatunji Ruwase, Rodrigo Fonseca. In proceedings of the ACMIFIPUSENIX Middleware 2017 . Las Vegas, NV, 2017 pdf Efficient Queue Management for Cluster Scheduling Jeff Rasley, Konstantinos Karanasos, Srikanth Kandula, Rodrigo Fonseca, Milan Vojnovic, Sriram Rao. In proceedings of the 2016 European Conference on Computer Systems EuroSys 16 . London, UK, 2016 pdf Poster at the 13th USENIX Symposium on Networked Systems Design and Implementation NSDI 2016 . Santa Clara, CA, 2016 Detecting Latent Cross-Platform API Violations Jeff Rasley, Eleni Gessiou, Tony Ohmann, Yuriy Brun, Shriram Krishnamurthi, Justin Cappos. In proceedings of the IEEE International Symposium on Software Reliability Engineering ISSRE 2015 pdf Runtime Verification of Portable Programming Interfaces Jeff Rasley. Undergraduate Honors Thesis . Computer Science and Engineering, University of Washington, June 2011 Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki, Hua Guo, Danae Metaxa-Kakavouli, Connor C. Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang. In proceedings of the AAAI Conference on Human Computation and Crowdsourcing HCOMP 2015. Best Paper Award Runner Up site , pdf Planck Millisecond-scale Monitoring and Control for Commodity Networks Jeff Rasley, Brent Stephens, Colin Dixon, Eric Rozner, Wes Felter, Kanak Agarwal, John Carter, Rodrigo Fonseca. In proceedings of the 2014 ACM Conference on SIGCOMM . Chicago, IL, 2014 pdf slides Poster at the 11th USENIX Symposium on Networked Systems Design and Implementation NSDI 2014 . Seattle, WA, 2014 poster Talk at the 2014 Open Networking Summit Research Track. Santa Clara, CA, March 2014 pdf slides Talk at the 2015 Open Networking User Group Research Track. Columbia University, New York, NY, May 2015 Seattle The Internet as a Testbed. Jeff Rasley, Monzur Muhammad, Alex Hanson, Sebastian Morgan, Alan Loh, Justin Cappos. Poster at the 8th USENIX Symposium on Networked Systems Design and Implementation NSDI 2011 . Boston, MA, 2011 Retaining Sandbox Containment Despite Bugs in Privileged Memory-Safe Code Justin Cappos, Armon Dadgar, Jeff Rasley, Justin Samuel, Ivan Beschastnikh, Cosmin Barsan, Arvind Krishnamurthy, and Thomas Anderson. The 17th ACM Conference on Computer and Communications Security CCS 2010 . Chicago, IL, 2010 pdf", "metadata": {"last_modified": "2019-03-19T22:34:06+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Jeff Rasley", "News", "Publications, Posters, etc."], "word_count": 1103, "token_count_estimate": 1708}}, "https://cs.brown.edu/people/jsavage/pubs.html": {"text_content": "Department of Computer Science Brown University Recent Research Publications by John E. Savage Derek S. Reverson and John E. Savage, Cybersecurity Convergence Digital Human and National Security , Orbis, Vol. 64, No. 4, 2020, p. 555-570. Ryan Maness, Derek S. Reveron, John Savage, and Alan Cytryn, Creating a Safe and Prosperous Cyberspace The Path to Ise-Shima Cybersecurity Norms , The Bridge, August 2, 2017. Allan Cytryn, Nazli Choucri, Michael Dukakis, Ryan C. Maness, Tuan Nguyen, Derek Reveron, John E. Savage and David Silbersweig, Keynote Address for 2016 Cybersecurity Day , Boston Global Forum, December 12, 2016. Allan Cytryn and John E. Savage, Action Plan to Block Cyberattacks in Vietnam , a Report Produced by the Boston Global Forum for the Government of Vietnam, August 2016. Greg Austin, Bruce McConnell, and Jan Neutze with contributions from Shen Yi and John Savage, Promoting International Cyber Norms A New Advocacy Forum , EastWest Institute, Breakthrough Group Report on Promoting Measures of Restraint in Cyber Armaments, by December 2015. John E. Savage and Bruce McConnell, Exploring Multi-Stakeholder Internet Governance , EastWest Institute, January 20, 2015. Desh Ranjan, John E. Savage, and Mohammad Zubair, Upper and Lower IO Bounds for Pebbling r-Pyramids , Journal of Discrete Algorithms, Vol. 14, pp. 2-12, 2012. Melissa Hathaway, and John E. Savage, Stewardship of Cyberspace Duties for Internet Service Providers , CyberDialogue2012, Munk School of Global Affairs, University of Toronto, March 2012. Desh Ranjan, John E. Savage and Mohammad Zubair, Upper and Lower Bounds for Pebbling r Pyramids , Journal of Discrete Algorithms, published online December 7, 2011. Les Bloom and John E. Savage, On Cyber Peace , Issue Brief, Atlantic Council, August 2011. Desh Ranjan, John E. Savage and Mohammad Zubair, Strong IO Lower Bounds for Binomial and FFT Computation Graph , Procs. COCOON, August 2011. Desh Ranjan, John E. Savage and Mohammad Zubair, Upper and Lower IO Bounds for Pebbling r-Pyramids , Procs. IWOCA 2010, July 2010 London. Eric Rachlin and John E. Savage, Stochastic Nanoscale Addressing for Logic , Procs. NANOARCH 2010, June 2010 Anaheim, CA. John E. Savage and Mohammad Zubair, Cache-Optimal Algorithms for Option Pricing , ACM Transactions on Mathematical Software, Vol. 17, No. 1, pp. 1-30 2010. John E. Savage and Mohammad Zubair, Evaluating Multicore Algorithms on the Unified Memory Model , Scientific Programming, Vol. 17, Issue 4, pp. 295-308 2009. John E. Savage and Mohammad Zubair, A Unified Model for Multicore Architectures, Procs. 1st Int. Forum on Next-Generation MulticoreManycore Technologies, Nov. 24-25, 2008 Cairo, Egypt. Eric Rachlin and John E. Savage, Nanowire Addressing with Randomized-Contact Decoders ,Theoretical Computer Science, Vol. 408, Issues 2-3, pp. 241-261, October, 2008. Eric Rachlin and John E. Savage, A Framework for Coded Computation 1 ,Procs. IEEE International Symposium on Information Theory, pp. 2342-2346, July 6-11, 2008. Jennifer Long and John E. Savage, Modeling and Analysis of a Membrane-Based Randomized-Contact Decoder ,Procs. NSTI-Nanotech 2008, Vol. 3, pp. 80-83, June 1-5, 2008. Eric Rachlin and John E. Savage, Analysis of a Mask-Based Decoder ,IEEE Transactions on Computers, February 2008. Eric Rachlin and John E. Savage, Radial Addressing of Nanowires ,ACM J. Emerging Technologies in Computing Systems, Vol. 2, No. 2, pp. 129-154, April 2006. Eric Rachlin and John E. Savage, Nanowire Addressingwith Randomized-Contact Decoders ,Procs. IEEEACM Int. Conf. on Computer-Aided Design ICCAD, 2006. Benjamin Gojman, Eric Rachlin, and John E. Savage, Evaluation of Design Strategies for Stochastically Assembled Nanoarray Memories ,ACM J. on Emerging Technologies in Computing Systems, Vol. 1, No. 2, pp. 73-108, July 2005. Eric Rachlin, John E. Savage, and Benjamin Gojman, Analysis of a Mask-Based Decoder ,Proceedings of the IEEE Computer Society Annl. Symp. on VLSI,A. Smailagic and N. Ranganathan Eds., May 11-12, 2005, pp. 6-13. Lee-Ad Gottlieb, John E. Savage, and Arkady Yerukhimovich, Efficient Data Storage in Large Nanoarrays ,Theory of Computing Systems, Vol. 38, pp. 503-536, 2005. Benjamin Gojman, Eric Rachlin, and John E. Savage, Decoding of Stochastically Assembled Nanoarrays Proceedings of the 2004 Int. Symp. on VLSI,February 19-20, 2004. Andr DeHon describing work with Charles M. Lieber, Patrick Lincoln, and John E. Savage, Sub-lithographic Semiconductor Computing Systems ,HotChips 15 HotChips-15, August 17--19, 2003. Andr DeHon, Patrick Lincoln, and John E. Savage, Stochastic Assembly of Sublithographic Nanoscale Interfaces IEEE Transactions in Nanotechnology , Vol. 2, No. 3,pp. 165-174, 2003. P. Fischer, F.P. Preparata, and J.E. Savage, Generalized Scans and Solution of Tridiagonal Systems , Theoretical Computer Science, 255, pp. 423-436 2001 J.E. Savage, A.L. Selman, and C. Smith History and Contributions of Theoretical Computer Science , Advances in Computers , Vol. 55, pp. 171-183, 2001. J.G. Castanos and J.E. Savage, Repartitioning Unstructured Adaptive Meshes , Procs. 2000 Int. Parallel andDistributed Proc. Symp. IPDPS00 , Cancun, Mexico, pp. 823-832, May 1-5, 2000. J.G. Castanos and J.E. Savage, ParallelRefinement of Unstructured Meshes , Procs. IASTEDConference on Paralleland Distributed Computing and Systems PDCS99 , Nov. 3-6, 1999. J.G. Castanos and J.E. Savage, PARED aFramework for the Adaptive Solution of PDEs , Procs. Eighth IEEEInt. Symp. High Performance Distributed Computing HPDC99, August 3-6,1999. J.G. Castanos and J.E. Savage, The DynamicAdaptation of Parallel Mesh-Based Computation , Procs. of the Eighth SIAMConf. on Parallel Processing for Scientific Computation, March 14-17,1997.pp.169-180 March 1995. J.E. Savage Extending the Hong- Kung Model to Memory Hierarchies , in Computing and Combinatorics, e.d. Ding-Zhu Du and Ming Li, pp.270-281, Lecture Notes in Computer Science, Springer Verlag, vol. 9591995. J.E. Savage, A Model for Multi-GrainedParallelism , Procs. 6th Annl. ACM Symp. on Parallel Algorithms andArchitectures, pp. 330-335, Cape May, NJ June 27-29, 1994. J.E. Savage and M.G. Wloka, Parallelism in Graph Partitioning , Journal of Parallel and Distributed Computing, 13, pp. 257-272 November 1991. The PARED Distributed FEM System CLICK HERE mpegplay Professional Reports Authored and Co-Authored by John E. Savage Condon, Edelsbrunner, Emerson, Fortnow, Haber, Karp, Leivant, Lipton, Lynch,Parberry, Papadimitriou, Rabin, Rosenberg, Royer, Savage, Selman, Smith,Tardos, and Vitter, Challenges for Theory ofComputing Report of an NSF-Sponsored Workshop on Research in TheoreticalComputer Science SIGACT News, June 1999. Condon, Fich, Frederickson, Goldberg, Johnson, Loui, Mahaney, Raghavan,Savage, Selman, and Shmoys, StrategicDirections in Research in Theory of Computing , by Loui et al, ACMComputing Surveys, December 1996. J.E. Savage, Theoretical Computer Science inTransition PDF , A Report Prepared for the ACM Strategic Directions Workshop, June 1996. Brown Faculty Bulletin Articles J.E. Savage, The Growth of Brown Since 1955 , Brown Faculty Bulletin , 1996. J.E. Savage, Budgetary Priorities for Brown , Brown Faculty Bulletin ,Volume XII, Number 2, April 1999. J.E. Savage, The Role of Tenure in Higher Education , Brown Faculty Bulletin , Volume X, Number 2 May, 1998 J.E. Savage, Strategic Directions Task Force Reports An Evaluation , Brown Faculty Bulletin , Volume X, Number 1 November, 1997. John Savage", "metadata": {"last_modified": "2022-12-12T19:50:09+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Department of Computer Science", "Brown University", "Recent Research Publications by John E. Savage", "The PARED Distributed FEM System", "Professional Reports Authored and Co-Authored by John E. Savage", "Brown Faculty Bulletin Articles"], "word_count": 1103, "token_count_estimate": 2116}}, "https://cs.brown.edu/people/lbsun/deblur2013/deblur2013iccp.html": {"text_content": "Edge-based Blur Kernel Estimation Using Patch Priors Libin Sun 1 Sunghyun Cho 2 Jue Wang 2 James Hays 1 1 Brown University 2 Adobe Research Abstract Blind image deconvolution, i.e., estimating a blur kernelk and a latent image x from an input blurred image y, is aseverely ill-posed problem. In this paper we introduce a newpatch-based strategy for kernel estimation in blind deconvolution.Our approach estimates a trusted subset of x byimposing a patch prior specifically tailored towards modelingthe appearance of image edge and corner primitives.To choose proper patch priors we examine both statisticalpriors learned from a natural image dataset and a simplepatch prior from synthetic structures. Based on the patchpriors, we iteratively recover the partial latent image x andthe blur kernel k. A comprehensive evaluation shows thatour approach achieves state-of-the-art results for uniformlyblurred images. Paper patchdebluriccp2013.pdf , 11MB Supplementary Materials 1. Mathematical Derivations 2. Additional Results Slides SUNpatchdeblurICCP2013.zip Citation Libin Sun, Sunghyun Cho, Jue Wang, James Hays. Edge-based Blur Kernel Estimation Using Patch Priors.Proceedings of the IEEE International Conference on Computational Photography ICCP, 2013. Bibtex inproceedingspatchdebluriccp2013, author Libin Sun and Sunghyun Cho and Jue Wang and James Hays, title Edge-based Blur Kernel Estimation Using Patch Priors, booktitle Proc. IEEE International Conference on Computational Photography, year 2013 MatLab Code Available upon request, please contact Libin Sun lbsun at cs.brown.edu. Test Set our synthetic test set blurred 1 noise 80 images x 8 kernels 640 images, 240MB Full Results all results 80 images x 8 kernels x 7 methods, with cropped ground truth images and kernels, 1.3GB All evaluations are done using the center portion of the images, discarding 50 pixels from each border. PSNR, SSIM and error ratios are computed based on best alignment. Note few of the methods failed to produce output on some of the test images due to their code crashing, hence less than 640 output images are included for these methods. reference images 80 images x 8 kernels 640 images, 243MB Deblurred using groundtruth kernels and Zorans EPLL-GMM ICCV 2011 for the final non-blind deconvolution step. This is considered the performance upper bound when computing error ratios. Sample Results Quantitative Evaluation Results on test set 32 images from Levin et al 2011 Results on our test set 640 images", "metadata": {"last_modified": "2014-10-20T16:59:09+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Edge-based Blur Kernel Estimation Using Patch Priors", "Abstract", "Paper", "Supplementary Materials", "Slides", "MatLab Code", "Test Set", "Full Results", "Sample Results", "", "", "", "Quantitative Evaluation"], "word_count": 372, "token_count_estimate": 560}}, "https://jeffhuang.com/": {"text_content": "Jeff Huang Brown University homejeffhuang.com Home Research Students CV HCIBrown 245 CIT 115 Waterman Street Providence RI 02912 401-863-5808 homejeffhuang.com Office Hours Tues 2-3pm Drop in only, no appointments Until May 7 in 2024, except Mar 26 Im an Associate Professor and Associate Chair of Computer Science at Brown University. My research is in Human-Computer Interaction, where my research is building personalized systems based on user behavior data. These systems are applied to attention, mobile, user experience, and health. I am primarily funded by the NSF, NIH, and ARO, and have received the NSF CAREER award, Facebook Fellowship, and ARO Young Investigator Award. My Ph.D. is in Information Science from the University of Washington in Seattle, and my masters and undergraduate degrees are in Computer Science from the University of Illinois at Urbana-Champaign UIUC. Before joining Brown, I analyzed search behavior at Microsoft Research, Google, Yahoo, and Bing and co-founded World Blender, a Techstars-backed startup that made geolocation mobile games. Brown University students interested in joining my group should review our active projects and read about the expectations . Ph.D. applicants please read the Student FAQ . Teaching User Interfaces Fall 2013 , Fall 2014 , Fall 2015 , Fall 2016 , Fall 2017 , Fall 2018 , Fall 2019 , Fall 2020 , Fall 2022 HCI Seminar Spring 2014 , Spring 2015 , Spring 2018 , Spring 2020 , Spring 2023 Livestreaming Reimagined Spring 2021 Computer Science Research Methods Spring 2019 Personal Informatics Seminar Spring 2016 Information Retrieval Fall 2010 University of Washington Computer Science Open Data Data analysis about professors, rankings, best papers, and stipends CS Faculty Composition and Hiring Trends source Drafty CS Professors Bias in Computer Science Rankings source CS Open Rankings Who Wins CS Best Paper Awards source Best Paper Awards in Computer Science Verified Computer Science Ph.D. Stipends contribute The Endlessness of Publishing Behind the scenes the struggle for each paper to get published This page is designed to last , a manifesto for preserving content on the web Illustrative notes for obsessing over publishing aesthetics On Long-Term Self-Tracking My productivity app is a never-ending .txt file The Coronavirus pandemic has changed our sleep behavior Extracting data from tracking devices by going to the cloud Papers from my Research Group Negotiating Dyadic Interactions through the Lens of Augmented Reality Glasses Ji Won Chung, Jenny Fu, Zachary Deocadiz-Smith, Malte Jung, Jeff Huang DIS 2023 filtered.ink Creating Dynamic Illustrations with SVG Filters Tongyu Zhou, Connie Liu, Joshua Yang, Jeff Huang CHI 2023 website Together but not together Evaluating Typing Indicators for Interaction-Rich Communication Zainab Iftikhar, Yumeng Ma, Jeff Huang CHI 2023 FocalPoint Adaptive Direct Manipulation for Selecting Small 3D Virtual Objects Jiaju Ma, Jing Qian, Tongyu Zhou, Jeff Huang IMWUT 2023 Bridging the Social Distance Offline to Online Social Support during the COVID-19 Pandemic Gabriela Hoefer, Talie Massachi, Neil G Xu, Nicole Nugent, Jeff Huang CSCW 2022 The UX Factor Using Comparative Peer Review to Evaluate Designs through User Preferences Sarah Bawabe, Laura Wilson, Tongyu Zhou, Ezra Marks, Jeff Huang CSCW 2021 Honorable Mention Award, Impact Recognition Award website Case Studies on the Motivation and Performance of Contributors Who Verify and Maintain In-Flux Tabular Datasets Shaun Wallace, Alexandra Papoutsaki, Neilly H. Tan, Hua Guo, Jeff Huang CSCW 2021 Portalware Exploring Free-Hand AR Drawing with a Dual-Display Smartphone-Wearable Paradigm Jing Qian, Tongyu Zhou, Meredith Young-Ng, Jiaju Ma, Angel Cheung, Xiangyu Li, Ian Gonsher, Jeff Huang DIS 2021 Self-E Smartphone-Supported Guidance for Customizable Self-Experimentation Nediyana Daskalova, Eindra Kyi, Kevin Ouyang, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, Jeff Huang CHI 2021 website Sochiatrist Signals of Affect in Messaging Data Talie Massachi, Grant Fong, Varun Mathur, Sachin Pendse, Gabriela Hoefer, Jessica Fu, Chong Wang, Nikita Ramoji, Nicole Nugent, Megan Ranney, Daniel Dickstein, Michael Armey, Ellie Pavlick, Jeff Huang CSCW 2020 website Sketchy Drawing Inspiration from the Crowd Shaun Wallace, Brendan Le, Luis Leiva, Aman Haq, Ari Kintisch, Gabrielle Bufrem, Linda Chang, Jeff Huang CSCW 2020 website SleepBandits Guided Flexible Self-Experiments for Sleep Nediyana Daskalova, Jina Yoon, Yibing Wang, Cintia Araujo, Guillermo Beltran, Nicole Nugent, John McGeary, Joseph Jay Williams, Jeff Huang CHI 2020 website Portal-ble Intuitive Free-Hand Manipulation in Unbounded Smartphone-based Augmented Reality Jing Qian, Jiaju Ma, Xiangyu Li, Benjamin Attal, Haoming Lai, James Tompkin, John Hughes, Jeff Huang UIST 2019 website Rewind Automatically Reconstructing Everyday Memories with First-Person Perspectives Neille-Ann Tan, Han Sha, Eda Celen, Phucanh Tran, Kelly Wang, Gifford Cheung, Philip Hinch, Jeff Huang IMWUT 2018 Remotion A Motion-Based Capture and Replay Platform of Mobile Device Interaction for Remote Usability Testing Jing Qian, Arielle Chapin, Alexandra Papoutsaki, Fumeng Yang, Klaas Nelissen, Jeff Huang IMWUT 2018 website The Eye of the Typer A Benchmark and Analysis of Gaze Behavior during Typing Alexandra Papoutsaki, Aaron Gokaslan, James Tompkin, Yuze He, Jeff Huang ETRA 2018 website Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Han Sha, Jeff Huang IMWUT 2017 Drafty Enlisting Users to be Editors who Maintain Structured Data Shaun Wallace, Lucy van Kleunen, Marianne Aubin-Le Quere, Abraham Peterkin, Yirui Huang, Jeff Huang HCOMP 2017 website SearchGazer Webcam Eye Tracking for Remote Studies of Web Search Alexandra Papoutsaki, James Laskey, Jeff Huang CHIIR 2017 Best Paper Finalist website Master Maker Understanding Gaming Skill through Practice and Habit from Gameplay Behavior Jeff Huang, Eddie Yan, Gifford Leung, Nachiappan Nagappan, Thomas Zimmermann topiCS Topics in Cognitive Science, 92, 2017 SleepCoacher A Personalized Automated Self-Experimentation System for Sleep Recommendations Nediyana Daskalova, Dana Metaxa, Adrienne Tran, Nicole Nugent, Julie Boergers, John McGeary, Jeff Huang UIST 2016 website WebGazer Scalable Webcam Eye Tracking Using User Interactions Alexandra Papoutsaki, Patsorn Sangkloy, James Laskey, Nediyana Daskalova, Jeff Huang, James Hays IJCAI 2016 website Crowdsourcing from Scratch A Pragmatic Experiment in Data Collection by Novice Requesters Alexandra Papoutsaki, Hua Guo, Dana Metaxa, Connor Gramazio, Jeff Rasley, Wenting Xie, Guan Wang, Jeff Huang HCOMP 2015 Best Paper Finalist Masters of Control Behavioral Patterns of Simultaneous Unit Group Manipulation in StarCraft 2 Eddie Yan, Jeff Huang, Gifford Cheung CHI 2015 Papers Led by Collaborators Epigraphics Message-Driven Infographics Authoring Tongyu Zhou, Jeff Huang, Gromit Chan CHI 2024 Understanding the Needs of Enterprise Users in Collaborative Python Notebooks Catherine Li, Talie Massachi, Jordan Eschler, Jeff Huang CHI 2023 case study Increased sleep duration and delayed sleep timing during the COVID-19 pandemic Robin K. Yuan, Kirsi-Marja Zitting, Liyaan Maskati, Jeff Huang Scientific Reports, 1210937, 2022 website Personalized Font Recommendations Combining ML and Typographic Guidelines to Optimize Readability Tianyuan Cai, Shaun Wallace, Tina Rezvanian, Jonathan Dobres, Bernard Kerr, Samuel Berlow, Jeff Huang, Ben D. Sawyer, Zoya Bylinskii DIS 2022 Days with and without self-injurious thoughts and behaviors Impact of childhood maltreatment on adolescent online social networking Lauren R. Grocott, Anneliese Mair, Janine N. Galione, Michael F. Armey, Jeff Huang, Nicole R. Nugent Journal of Adolescence, 945, 2022 Dually Noted Layout-Aware Annotations with Smartphone Augmented Reality Jing Qian, Qi Sun, Curtis Wigington, Han L. Han, Tong Sun, Jennifer Healey, James Tompkin, Jeff Huang CHI 2022 Towards Individuated Reading Experiences Different Fonts Increase Reading Speed for Different Individuals Shaun Wallace, Zoya Bylinskii, Jonathan Dobres, Bernard Kerr, Sam Berlow, Rick Treitman, Nirmal Kumawat, Kathleen Arpin, Dave B. Miller, Jeff Huang, Ben D. Sawyer TOCHI Transactions on Computer-Human Interaction, 294, 2022 Scalable Scalable Vector Graphics Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering Michail Schwab, David Saffo, Nicholas Bond, Shash Sinha, Cody Dunne, Jeff Huang, James Tompkin, Michelle Borkin TVCG Transactions on Visualization and Computer Graphics, 289, 2022 website Evaluating Pan and Zoom Timelines and Sliders Michail Schwab, Sicheng Hao, Olga Vitek, James Tompkin, Jeff Huang, Michelle Borkin CHI 2019 website EasyPZ.js Interaction Binding For Pan and Zoom Visualizations Michail Schwab, James Tompkin, Jeff Huang, Michelle Borkin VIS 2019 short paper website Investigating the Effectiveness of Cohort-Based Sleep Recommendations Nediyana Daskalova, Bongshin Lee, Jeff Huang, Chester Ni, Jessica Lundin IMWUT 2018 SEEDE Simultaneous Execution and Editing in a Development Environment Steven Reiss, Qi Xin, Jeff Huang ASE 2018 An Analysis of Automated Visual Analysis Classification Interactive Visualization Task Inference of Cancer Genomics Domain Experts Connor Gramazio, Jeff Huang, David Laidlaw TVCG Transactions on Visualization and Computer Graphics, 248, 2017 Strokes of Insight User Intent Detection and Kinematic Compression of Mouse Cursor Trails Daniel Martn-Albo, Luis Leiva, Jeff Huang, Rjean Plamondond IPM Information Processing Management, 526, 2016 Learning Behaviors via Human-Delivered Discrete Feedback Robert Loftin, Bei Peng, James MacGlashan, Michael Littman, Matthew Taylor, Jeff Huang, David Roberts JAAMAS Autonomous Agents and Multi-Agent Systems, 301, 2016 Representing Uncertainty in Graph Edges An Evaluation of Paired Visual Variables Hua Guo, Jeff Huang, David Laidlaw TVCG Transactions on Visualization and Computer Graphics, 2110, 2015 Building a Better Mousetrap Compressing Mouse Cursor Activity for Web Analytics Luis Leiva, Jeff Huang IPM Information Processing Management, 512, 2015 website A Strategy-Aware Technique for Learning Behaviors from Discrete Human Feedback Robert Loftin, James MacGlashan, Bei Peng, Matthew Taylor, Michael Littman, Jeff Huang, David Roberts AAAI 2014 Papers as a Student Mastering the Art of War How Patterns of Gameplay Influence Skill in Halo Jeff Huang, Thomas Zimmermann, Nachiappan Nagappan, Charles Harrison, Bruce Phillips CHI 2013 Best Paper Finalist RevMiner An Extractive Interface for Navigating Reviews on a Smartphone Jeff Huang, Oren Etzioni, Luke Zettlemoyer, Kevin Clark, Christian Lee UIST 2012 Improving Searcher Models Using Mouse Cursor Activity Jeff Huang, Ryen White, Georg Buscher, Kuansan Wang SIGIR 2012 User See, User Point Gaze and Cursor Alignment in Web Search Jeff Huang, Ryen White, Georg Buscher CHI 2012 No Search Result Left Behind Branching Behavior with Browser Tabs Jeff Huang, Thomas Lin, Ryen White WSDM 2012 Large-Scale Analysis of Individual and Task Differences in Search Result Page Examination Strategies Georg Buscher, Ryen White, Susan Dumais, Jeff Huang WSDM 2012 Remix and Play Lessons from Rule Variants in Texas Holdem and Halo 2 Gifford Cheung and Jeff Huang CSCW 2012 Interactive Search Support for Difficult Web Queries Abdigani Diriye, Giridhar Kumaran, Jeff Huang ECIR 2012 No Clicks, No Problem Using Cursor Movements to Understand and Improve Search Jeff Huang, Ryen White, and Susan Dumais CHI 2011 Best Paper Finalist Starcraft from the Stands Understanding the Game Spectator Gifford Cheung and Jeff Huang CHI 2011 Optimal Strategies for Reviewing Search Results Jeff Huang and Anna Kazeykina AAAI 2010 Assessing the Scenic Route Measuring the Value of Search Trails in Web Logs Ryen White and Jeff Huang SIGIR 2010 Best Paper Award Studying Trailfinding Algorithms for Enhanced Web Search Adish Singla, Ryen White, and Jeff Huang SIGIR 2010 Conversational Tagging in Twitter Jeff Huang, Katherine Thornton, and Efthimis Efthimiadis Hypertext 2010 short paper Parallel Browsing Behavior on the Web Jeff Huang and Ryen White Hypertext 2010 short paper Analyzing and Evaluating Query Reformulation Strategies in Web Search Logs Jeff Huang and Efthimis Efthimiadis CIKM 2009 Best Student Paper Finalist Graphstract Minimal Graphical Help for Computers Jeff Huang and Michael Twidale UIST 2007 Curious about the backstory behind my papers Workshop Papers Learning Something from Nothing Leveraging Implicit Human Feedback Strategies Robert Loftin, Bei Peng, James MacGlashan, Michael Littman, Matthew Taylor, Jeff Huang, David Roberts RO-MAN 2014 Influence of Gameplay on Skill in Halo Reach Jeff Huang, Thomas Zimmermann, Nachiappan Nagappan, Charles Harrison, Bruce Phillips CHI Games User Research Workshop 2013 Web User Interaction Mining from Touch-Enabled Mobile Devices Jeff Huang and Abdigani Diriye HCIR Workshop 2012 On the Value of Page-Level Interactions in Web Search Jeff Huang HCIR Workshop 2011", "metadata": {"last_modified": "2024-03-04T17:44:15+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Teaching", "Computer Science Open Data", "The Endlessness of Publishing", "On Long-Term Self-Tracking", "Papers from my", "Group", "Papers Led by Collaborators", "Papers as a Student", "Workshop Papers"], "word_count": 1895, "token_count_estimate": 3143}}, "https://cs.brown.edu/people/jlaviola/": {"text_content": "Joseph J. LaViola Jr., Ph.D. Although I am still an adjunct faculty at Brown, I am now an Assistant Professor in the School of Electrical Engineering and Computer Science at the University of Central Florida.My current web page can be found HERE . Latest News 3D User Interfaces Theory and Practice has been translated into Japanese and Chinese. Written withmy colleagues Doug Bowman Virginia Tech, Ernst Kruijff FraunhoferIMK, and Ivan Poupyrev Sony CSL, it is the first comprehensivetextreference book on 3D user interfaces. Order your copy from, Amazon , Barnes and Noble , or directly from Addison-Wesley . I am an adjunct assistant professor Research in the BrownUniversity Computer Science Department. I work with Andries van Dam , Robert Zeleznik. , and members of the MicrosoftCenter for Research on Pen-Centric Computing . My interests includepen-based computing, user interfaces, human motion estimation, virtualreality, and computer graphics. My Resume My Publications Courses and Projects Predictive Tracking MathPad 2 My PhD Work In addition to my academic pursuits, I also started JJL Interface Consultants, Inc. , aconsulting business specializing in a number of user interaction services. Check out pictures of my office mate Dingers Softball Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7662 voice 401-863-7657 fax jjlcs.brown.edu Finger me.", "metadata": {"last_modified": "2009-03-19T21:53:11+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Joseph J. LaViola Jr., Ph.D."], "word_count": 209, "token_count_estimate": 300}}, "https://cs.brown.edu/people/malte/research/pbc/": {"text_content": "Data Privacy by Construction Home Publications Can software offer better data privacy by construction Web services that store and process sensitive personal data are critical to the digital economy today, but are often built without sufficient attention to users rights over their data and its privacy. But doing a good job at data privacy is difficult, and requires substantial manual effort that costs billions of dollars every year. The goal of this research project is to develop new software systems that fundamentally democratize good privacy practices, make it easy for users and web service operators to handle data in compliance with privacy laws, and retain or improve the performance of todays software. Privacy-Compliant Storage Systems. Easier compliance with privacy laws GDPR , CCPA using off-the-shelf software. Privacy laws like the European Unions General Data Protection Regulation GDPR and the California Consumer Privacy Act CCPA give users new rights to control their data, with non-compliance carrying the risk of steep fines. But with todays systems, compliance with these rights requires onerous manual labor, particularly from small and medium-sized organizations. We are designing new storage and data processing systems that automate compliance with privacy legislation. Realizing this compliance by construction requires innovation in system design for example, we are developing a new database architecture that replaces relational tables which mix different users data with per-user micro-databases DBs as a primary abstraction. Making such a federation of DBs efficient requires new techniques to track the impact of changes to users DBs on derived data, and our system relies on dataflow computing , a well-understood technique from scalable big data processing , to make compliant-by-construction web services efficient. Kinan Justus Ishan Aaron Benjamin Raj Artem Leonhard Malte Flexible User Data Control with Edna. New user data control choices via systematic data sealing in web services. Privacy in complex, data-rich applications is hard. Consider a user who wants to remove their account from a service even once all their data is found, only some of it should be removed other data should be anonymized or decorrelated for legal reasons, or to maintain application utility for other users. Or, a user might wish to disavow and anonymize some of their contributions, but retain others. Some of these transformations should also be reversible in case the user wants to return or reassociate with their data. Edna is a library that helps web applictions implement secure data sealing and revealing without breaking application functionality for other users. Edna helps developers generate privacy transformations for database-backed web applications from a high-level specification and preexisting data relationships. Edna helps simplify privacy transformations that applications use today such as account deletion, but also goes beyond and makes it easier to support fine-grained and nuanced policies that would be cumbersome to implement manually today e.g., structural decorrelation of data, or decay of identifying information over time. Lily Hannah Eddie Frans Malte Publications Edna Disguising and Revealing User Data in Web Applications Lillian Tsai, Hannah Gross, Eddie Kohler, Frans Kaashoek, Malte Schwarzkopf SOSP 2023 K9db Privacy-Compliant Storage For Web Applications By Construction Kinan Dak Albab, Ishan Sharma, Justus Adam, Benjamin Kilimnik, Aaron Jeyaraj, Raj Paul, Artem Agvanian, Leonhard Spiegelberg, Malte Schwarzkopf OSDI 2023 Retrofitting GDPR Compliance onto Legacy Databases Archita Agarwal, Marilyn George, Aaron Jeyaraj, Malte Schwarzkopf VLDB 2022 Privacy Heroes Need Data Disguises Lilian Tsai, Malte Schwarzkopf, Eddie Kohler HotOS 2021 GDPR Compliance by Constructiono Malte Schwarzkopf, Eddie Kohler, M. Frans Kaashoek, Robert Morris Poly 2019 workshop at VLDB 2019 Getting involved If youre a Brown CS student and excited about this research, consider taking CSCI 2390 Privacy-Conscious Computer Systems . If youre curious about our work, reach out to Malte Schwarzkopf . Support This work is supported by a National Science Foundation NSF CAREER award and a Google Research Scholar Award . Back to top Malte Schwarzkopf . Last updated November 09, 2023", "metadata": {"last_modified": "2023-11-09T07:31:49+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Can software offer better data privacy", "?", "Privacy-Compliant Storage Systems.", "Flexible User Data Control with Edna.", "Publications", "Getting involved", "Support"], "word_count": 642, "token_count_estimate": 863}}, "https://cs.brown.edu/people/malte/": {"text_content": "Malte Schwarzkopf Assistant Professor ETOS and Systems Groups Computer Science Department , Brown University maltecs.brown.edu CIT 525 Im interested in computer systems, especially distributed systems, operating systems, and privacy-preserving systems. In Spring 2024, Im teaching CSCI 03001310 Fundamentals of Computer Systems . Outside of CS, I enjoy history, woodworking, biking, and art. News 202305 The Omega paper wins the Test-of-Time Award at EuroSys 2023 202305 Received a Barrett Hazeltine Citation for Excellence in Teaching, Guidance, and Support from Browns Class of 2023. 202204 Received Browns Henry Merritt Wriston Fellowship for 2022. 202104 Received a Google Research Scholar award. 202102 Received an NSF CAREER award for my work on privacy-compliance by construction in web applications . Publications all Edna Disguising and Revealing User Data in Web Applications ACM Lillian Tsai, Hannah Gross, Eddie Kohler, Frans Kaashoek, Malte Schwarzkopf SOSP 2023 K9db Privacy-Compliant Storage For Web Applications By Construction usenix code Kinan Dak Albab, Ishan Sharma, Justus Adam, Benjamin Kilimnik, Aaron Jeyaraj, Raj Paul, Artem Agvanian, Leonhard Spiegelberg, Malte Schwarzkopf OSDI 2023 Towards Increased Datacenter Efficiency with Soft Memory SIGOPS ACM Megan Frisella, Shirley Loayza Sanchez, Malte Schwarzkopf HotOS 2023 Unleashing True Utility Computing with Quicksand SIGOPS ACM Zhenyuan Ruan, Shihang Li, Kaiyan Fan, Marcos K. Aguilera, Adam Belay, Seo Jin Park, Malte Schwarzkopf HotOS 2023 Nu Achieving Microsecond-Scale Resource Fungibility with Logical Processes usenix Zhenyuan Ruan, Seo Jin Park, Marcos K. Aguilera, Adam Belay, Malte Schwarzkopf NSDI 2023 Retrofitting GDPR Compliance onto Legacy Databases VLDB Archita Agarwal, Marilyn George, Aaron Jeyaraj, Malte Schwarzkopf VLDB 2022 Privacy Heroes Need Data Disguises SIGOPS ACM Lillian Tsai, Malte Schwarzkopf, Eddie Kohler HotOS 2021 Best presentation runner-up Tuplex Data Science in Python at Native Code Speed ACM web code Leonhard F. Spiegelberg, Rahul Yesantharao, Malte Schwarzkopf, Tim Kraska SIGMOD 2021 AIFM High-Performance, Application-Integrated Far Memory usenix code Zhenyuan Ruan, Malte Schwarzkopf, Marcos Aguilera, Adam Belay OSDI 2020 Shared Arrangements practical inter-query sharing for streaming dataflows VLDB Frank McSherry, Andrea Lattuada, Malte Schwarzkopf, Timothy Roscoe VLDB 2020 GDPR Compliance by Construction Malte Schwarzkopf, Eddie Kohler, M. Frans Kaashoek, Robert Morris Poly 2019 workshop at VLDB 2019 Learning Scheduling Algorithms for Data Processing Clusters ACM arXiv1810.01963 website Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng, Mohammad Alizadeh SIGCOMM 2019 See also our related ICLR19 paper on reducing variance in training Towards Multiverse Databases ACM Alana Marzoev, Lara Timb Arajo, Malte Schwarzkopf, Samyukta Yagati, Eddie Kohler, Robert Morris, M. Frans Kaashoek, Sam Madden HotOS 2019 Conclave secure multi-party computation on big data ACM extended TR with proofs code Nikolaj Volgushev, Malte Schwarzkopf, Ben Getchell, Andrei Lapets, Mayank Varia, Azer Bestavros EuroSys 2019 Noria dynamic, partially-stateful data-flow for high-performance web applications usenix website code Jon Gjengset, Malte Schwarzkopf, Jonathan Behrens, Lara Timb Arajo, Martin Ek, Eddie Kohler, M. Frans Kaashoek, Robert Morris OSDI 2018 Firmament fast, centralized cluster scheduling at scale usenix web code Now available for Kubernetes Ionel Gog, Malte Schwarzkopf, Adam Gleave, Robert N. M. Watson, Steven Hand OSDI 2016 Queues dont matter when you can JUMP them usenix website Matthew P. Grosvenor, Malte Schwarzkopf, Ionel Gog, Robert N. M. Watson, Andrew W. Moore, Steven Hand, Jon Crowcroft NSDI 2015 Best paper award Musketeer all for one, one for all in data processing systems ACM website code Ionel Gog, Malte Schwarzkopf, Natacha Crooks, Matthew P. Grosvenor, Allen Clement, Steven Hand EuroSys 2015 Omega flexible, scalable schedulers for large compute clusters Malte Schwarzkopf, Andy Konwinski, Michael Abd-El-Malek, John Wilkes EuroSys 2013 Best student paper award Test-of-Time Award Ciel a universal execution engine for distributed data-flow computing Derek G. Murray, Malte Schwarzkopf, Christopher Smowton, Steven Smith, Anil Madhavapeddy, Steven Hand NSDI 2011 Students Justus Adam Howie Chen Kinan Dak Albab Lillian Tsai at MIT, with Frans Kaashoek, Eddie Kohler Artem Agvanian Aijah Garcia Megan Frisella Shirley Loayza Sanchez Carolyn Zech Alumni Livia Zhu ScB, Databricks Leonhard Spiegelberg PhD, with Tim Kraska Snowflake Sreshtaa Rajesh ScB, MIT Lincoln Labs Raj Paul ScB, Oracle Vic Li MSc, University of Washington Benjamin Kilimnik ScB New Relic Aaron Jeyaraj ScB Crusoe Energy Hannah Gross ScB, MIT Benjamin Givertz ScB, Twitch Ishan Sharma MSc, AWS Yunzhi Shao MSc, Amazon Sinan Pehlivanoglu MSc, VMware Eleonora Kiziv ScB, Google Jon Gjengset MIT PhD, AWS Jackie Bredenberg MIT MEng , Ab Initio Samyukta Yagati MIT UROP, UC Berkeley Gina Yuan MIT MEng , Stanford Lara Timb Arajo MIT MEng , Airbnb Courses Spring 2024 CSCI 0300 Fundamentals of Computer Systems Fall 2023 CSCI 2390 Privacy-Conscious Computer Systems Spring 2023 CSCI 0300 Fundamentals of Computer Systems Fall 2022 Junior Faculty Teaching Relief Spring 2022 CSCI 0300 Fundamentals of Computer Systems Fall 2021 CSCI 2390 Privacy-Conscious Computer Systems Spring 2021 CSCI 0300 Fundamentals of Computer Systems Fall 2020 CSCI 2390 Privacy-Conscious Computer Systems Spring 2020 CSCI 1310 Fundamentals of Computer Systems Fall 2019 CSCI 2390 Privacy-Conscious Computer Systems Spring 2018 6.824 Distributed Systems Engineering at MIT Support My research is supported by the NSF , Google , Microsoft , and VMware . Personal Before joining Brown, I was a postdoc in the PDOS group at MIT CSAIL. Prior to MIT, I spent several enjoyable years doing my PhD in the NetOS group in the other Cambridge . You can find me on Twitter and GitHub . My wife, Julia Netter , is a political philosopher.", "metadata": {"last_modified": "2024-01-18T02:25:55+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Malte Schwarzkopf", "Publications", "Students", "Courses", "Support", "Personal"], "word_count": 877, "token_count_estimate": 1606}}, "https://cs.brown.edu/people/meta-ta/": {"text_content": "Meta-TAs The Meta TAs coordinate the UTA Program . A more detailed jobdescription is available here .", "metadata": {"last_modified": "2021-12-14T16:14:47+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Information for:", "Meta-TAs"], "word_count": 17, "token_count_estimate": 22}}, "https://cs.brown.edu/people/orgs/artemis/2018/index.html": {"text_content": "The Artemis Project Empowering Students of Underrepresented Genders in STEM", "metadata": {"last_modified": "2018-02-28T21:59:33+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["", "", "The Artemis Project", "", ""], "word_count": 10, "token_count_estimate": 14}}, "https://cs.brown.edu/people/nmeyrowi/": {"text_content": "Norman K Meyrowitz Norm, nkm Adjunct Professor of the Practice of Computer Science Brown University Cell 415-505-9115 E-mail nkmbrown.edu Professional Bio Casual Bio Im originally from Brooklyn before it was hipster. I graduated from Brown in 1981 with Sc.B. CS. My computer science specialties are Hypertext, Multimedia, and Web Software. I have been fortunate eneough to do both academic research and build commercial software. I ran a research institute at Brown in the 1980s, then went to industry to develop lots of products at Macromedia now Adobe. My wife also a Brown alum and I have lived in San Francisco since 1991 way before it was hipster. I am a foodie, and if the food starts with P pastrami, pizza, or porchetta, I am probably either cooking it or eating it. In the distant past I did newspaper writing and design, and in the recent past did architectural plans for friends as a hobby. Users Guide to Norm Back in the late 1980s, I wrote a memo to all of the folks at our research institute outlining the kind of environment I hope we could build. It helped people figure out what makes me tick, but from then to the present, people have circulated it as a more general guide to building and being a part of great organization. It is linked here if it is of interest to you. Curriculum Vitae", "metadata": {"last_modified": "2022-11-13T23:49:22+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": [], "word_count": 232, "token_count_estimate": 294}}, "https://nediyana.github.io/": {"text_content": "Nediyana Daskalova About Me Projects Publications Updates About me I am a Research Scientist at Spotify in Boston. Before that, I completed my PhD in Computer Science, at Brown University , where I was fortunate to be advised by Jeff Huang , and I was a part of the Human-Computer Interaction research group . My research interests are in human-computer interaction and personal informatics with a special focus on sleep-tracking and self-experiments. CV LinkedIn Twitter Updates December 2021 Our paper with summer intern Savvas Petridis was accepted to IUI22 . December 2020 The Self-E paper the last chapter of my thesis was accepted to CHI 2021. July 2020 I started as a Research Scientist at Spotify. May 24, 2020 I graduated from my PhD. April 9, 2020 I defended my thesis Research Projects Self-E a self-experimentation app that helps users optimize various aspects of their lives. Website - Android App - iOS App SleepBandits a.k.a. SleepCoacher 2.0 a self-experimentation app that helps users optimize their sleep. Website - Android App - iOS App Publications Self-E Smartphone- Supported Guidance for Customizable Self-Experimentation. Nediyana Daskalova , Eindra Kyi, Kevin Ouyang, Arthur Borem, Sally Chen, Sung Hyun Park, Nicole Nugent, and Jeff Huang. ACM Conference on Human Factors in Computing Systems CHI 2021 PDF - Video SleepBandits Guided Flexible Self-Experiments for Sleep Nediyana Daskalova , Jina Yoon, Lisa Wang, Cintia Araujo, Guillermo Beltran, Nicole Nugent, John McGeary, Joseph Jay Williams, Jeff Huang. ACM Conference on Human Factors in Computing Systems CHI 2020 PDF - Video Investigating the Effectiveness of Cohort-Based Sleep Recommendations Nediyana Daskalova , Bongshin Lee, Jeff Huang, Chester Ni, Jessica Lundin. Ubicomp 2018 . PDF Cohorts of Self-Experimenters Lessons Learned from Personal Informatics Self-Experiments Nediyana Daskalova , Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Heather Sha, and Jeff Huang. Ubicomp 2017 . PDF If a person is emailing you, it just doesnt make sense Exploring Changing Consumer Behaviors in Email Frank Bentley, Nediyana Daskalova , Nazanin Andalibi. ACM Conference on Human Factors in Computing Systems CHI 2017 . PDF SleepCoacher A Personalized Automated Self-Experimentation System for Sleep Recommendations Nediyana Daskalova, Danae Metaxa-Kakavouli, Adrinne Tran, Nicole Nugent, Julie Boergers, John McGeary, and Jeff Huang. ACM User Interface Software and Technology Symposium UIST 2016 . PDF - Video - Source Code Webgazer Scalable webcam eyetracking using user interactions Alexandra Papoutsaki, Patsorn Sangkloy, James Laskey, Nediyana Daskalova , Jeff Huang, and James Hays. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence IJCAI 2016 . PDF - Website Informing Design of Suggestion and Self-Monitoring Tools through Participatory Experience Prototypes Nediyana Daskalova , Nathalie Ford, Ann Hu, Kyle Moorehead, Ben Wagnon, and Janet Davis. The 9th International Conference on Persuasive Technology Persuasive 2014 . PDF Case Studies and Other Publications HeyPillow Computationally Guided Sleep Behavior Study Through Sensing Nediyana Daskalova , Jiaju Ma, Tiffany Chen, Valerie Nguon, Jing Qian, Chonghui Chen and Jeff Huang. ACM Conference on Human Factors in Computing Systems CHI 2019 . Workgroup on Interactive Systems in Health WISH. Poster. Video Personalized Behavior-Powered Systems for Guiding Self-Experiments Nediyana Daskalova . ACM Conference on Human Factors in Computing Systems CHI 2018 . Doctoral Consortium. PDF Comparing the Reliability of Amazon Mechanical Turk and Survey Monkey to Traditional Market Research Surveys Nediyana Daskalova, Brooke White. ACM Conference on Human Factors in Computing Systems CHI 2017 . Case Study. PDF Its All About Coupons Exploring Coupon Use Behaviors in Email Nediyana Daskalova , Frank Bentley, Nazanin Andalibi. ACM Conference on Human Factors in Computing Systems CHI 2017 . Case Study. PDF Awards and Scholarships ACM-W Scholarship for attending UIST 2016 Best Aging in Place Hack at MITs Grand Hack 2016 Article CRA-W Grad Cohort Workshop Scholarships 2015, 2016 Dropbox Scholarship for Grace Hopper Celebration of Women in Computing GHC 2013", "metadata": {"last_modified": "2024-02-17T22:44:50+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Nediyana Daskalova", "About me", "Updates", "Research Projects", "Publications", "Case Studies and Other Publications", "Awards and Scholarships"], "word_count": 626, "token_count_estimate": 1012}}, "https://cs.brown.edu/people/joberlin/": {"text_content": "John Oberlin Computer Science PhD Student Brown University CIT 311 oberlin - at - cs - dot - brown - dot - expected domain Introduction I am a graduate student in Computer Science at Brown University. I started herein 2011 after transferring from U Chicago. I joined Stefanie Tellex in the Humans to Robots Laboratory in Fall 2014. My research involves the jointsolution of problems from artificial intelligence, robotics, computer vision,and control systems. My approaches emphasize a combination of theory andengineering. I have been strongly influenced by design patterns and algorithms,and I draw from my background in analysis and physics when appropriate. Before 2011 I worked at Havok in SF for a year and a half, and before that Ispent two years earning an MA in Math at UC Berkeley. My undergraduate degree is from FSU in Mathematics. Interests I am a fan of cats, trees, water, wind, and tea. Papers P. F. Felzenszwalb , J. G. Oberlin Multiscale Fields of Patterns Advances in Neural Information Processing Systems NIPS. 2014. P. F. Felzenszwalb , J. G. Oberlin Multiscale Fields of Patterns arXiv1406.0924 S. Naderi Parizi , J. Oberlin, P. Felzenszwalb Reconfigurable Models for Scene Recognition IEEE Conference on Computer Vision and Pattern Recognition CVPR, 2012 Last edited 622015.", "metadata": {"last_modified": "2015-06-02T22:47:09+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Introduction", "Interests", "Papers"], "word_count": 208, "token_count_estimate": 298}}, "https://brown-wics.github.io/website/": {"text_content": "You need to enable JavaScript to run this app.", "metadata": {"last_modified": "2023-11-04T18:51:47+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": [], "word_count": 9, "token_count_estimate": 10}}, "https://faculty.cc.gatech.edu/~hays/": {"text_content": "James Hays Associate Professor, School of Interactive Computing , College of Computing , Georgia Institute of Technology My research interests span computer vision, robotics, and machine learning. I work on problems related to recognition, synthesis, and manipulation.My research often involves finding new data sources to exploit e.g. geotagged imagery or creating new data sets where none existed e.g. sketches or grasps. Before joining Georgia Tech, I was the Manning Assistant Professor of Computer Science at Brown University . I was a postdoc at MIT with Antonio Torralba ,completed my Ph.D. at Carnegie Mellon University with Alexei Efros ,and received my B.S. from Georgia Tech. I am the recipient of the Alfred P. Sloan Fellowship, the NSF CAREER award, and the PAMI Mark Everingham Prize. From 2017 to 2022 I was a Principal Scientist at Argo AI researching self-driving vehicle perception. I am currently working with Overland AI on off-road autonomous vehicles. contact email haysgatech.edu office CODA S1155B mail 756 West Peachtree st NW, Suite 12E Atlanta, GA 30308 Teaching CS 4476-A Computer Vision Fall 2023 previous offering, fall 2022 previous offering, spring 2022 previous offering, fall 2021 previous offering, spring 2021 previous offering, fall 2018 previous offering, fall 2017 previous offering, fall 2016 previous offering, fall 2015 previous offering, fall 2013 previous offering, fall 2011 CS 7476 Advanced Computer Vision Spring 2024 Previous offering, fall 2020 Previous offering, spring 2018 Previous offering, spring 2017 Previous offering, spring 2016 Similar course, Fall 2014 Previous offering, spring 2013 Previous offering, spring 2012 Previous offering, fall 2010 CS 129 Computational Photography Fall 2012 Previous offering, spring 2011 Previous offering, spring 2010 Students and Collaborators Ph.D. Students Benjamin Wilson Akshay Krishnan Mengyu Yang Former Ph.D. Students Cusuh Ham now at Adobe Patrick Grady now at META Amit Raj now at Google Sean Foley now at NASA John Lambert now at Waymo Patsorn Sangkloy now at Phranakhon Rajabhat University Samarth Brahmbhatt now at Overland AI Nam Vo now at Roku Genevieve Patterson Libin Geoffrey Sun now at Apple Previous Postdoc Pierre-Yves Laffont now at Meta Visiting Students Daniel Brooks Telecom ParisTech Tsung-Yi Lin now at Nvidia Huaijin George Chen now at Vayu Mathias Eitz Masters Student Researchers Akash Kumar, Shenhao Jiang, Kapilan Baskar, Vishwas Uppoor alumni Nitin Kodialbail, Jianan Gao, Govin Vatsan, Vasavi Gajarla, Laura Jeyaseelen, Varun Agrawal, Nate Burnell, Xiaofeng Tao, Chao Qian, Chen Xu, Yipin Zhou , Hang Su , Vibhu Ramani, Paul Sastrasinh, Vazheh Moussavi, Yun Zhang, David Dufresne, Sirion Vittayakorn Undergraduate Researchers alumni Wenqi Xian, Cusuh Ham, Lawrence Moore, Sonia Phene, Eric Jang, Hari Narayanan, Sam Birch, Leela Nathan, Eli Bosworth, Jung Uk Kang, Reese Kuppig, Fuyi Huang, Travis Webb Recorded Talks Thermal Imaging for Grasp Understanding at Machines Can See 2020 . Argoverse 2020 Competitions at CVPR 2020 Workshop on Autonomous Driving . What we learned from Argoverse 3D for Free at ICML 2020 Workshop on AI for Autonomous Driving . Highlighted Recent Papers The Un-Kidnappable Robot Acoustic Localization of Sneaking People. Mengyu Yang, Patrick Grady, Samarth Brahmbhatt, Arun Balajee Vasudevan, Charles C. Kemp, and James Hays. ICRA 2024. Project page , arXiv ZeroFlow Fast Zero Label Scene Flow via Distillation. Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, and James Hays. ICLR 2024. Project page , arXiv PressureVision Estimating Fingertip Pressure from Diverse RGB Images. Patrick Grady, Jeremy A. Collins, Chengcheng Tang, Christopher D. Twigg, Kunal Aneja, James Hays, and Charles C. Kemp. WACV 2024. arXiv , WACV paper Lidar Panoptic Segmentation and Tracking without Bells and Whistles. Abhinav Agarwalla, Xuhua Huang, Jason Ziglar, Francesco Ferroni, Laura Leal-Taixe, James Hays, Aljosa Osep, and Deva Ramanan. IROS 2023. Project page , arXiv Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation. Shengcao Cao, Mengtian Li, James Hays, Deva Ramanan, Yu-Xiong Wang, and Liangyan Gui. ICML 2023. ICML paper Soft Augmentation for Image Classification. Yang Liu, Shen Yan, Laura Leal-Taixe, James Hays, Deva Ramanan. CVPR 2023. CVF Page Modulating Pretrained Diffusion Models for Multimodal Image Synthesis. Cusuh Ham, James Hays, Jingwan Lu, Krishna Kumar Singh, Zhifei Zhang, Tobias Hinz. Siggraph 2023 Conference. Project Page LANe Lighting-Aware Neural Fields for Compositional Scene Synthesis. Akshay Krishnan, Amit Raj, Xianling Zhang, Alexandra Carlson, Nathan Tseng, Sandhya Sridhar, Nikita Jaipuria, James Hays. arXiv, April 2023. arXiv Visual Estimation of Fingertip Pressure on Diverse Surfaces using Easily Captured Data. Patrick Grady, Jeremy A. Collins, Chengcheng Tang, Christopher D. Twigg, Kunal Aneja, James Hays, Charles C. Kemp. arXiv, January 2023. arXiv Far3Det Towards Far-Field 3D Detection. Shubham Gupta, Jeet Kanjani, Mengtian Li, Francesco Ferroni, James Hays, Deva Ramanan, Shu Kong. WACV 2023. CVF page PressureVision Estimating Hand Pressure from a Single RGB Image. Patrick Grady, Chengcheng Tang, Samarth Brahmbhatt, Christopher D. Twigg, Chengde Wan, James Hays, and Charles C. Kemp. ECCV 2022 Oral. arXiv A Sketch is Worth a Thousand Words Image Retrieval with Text and Sketch. Patsorn Sangkloy, Wittawat Jitkrittum, Diyi Yang, and James Hays. ECCV 2022. arXiv CoGS Controllable Generation and Search from Sketch and Style. Cusuh Ham, Gemma Canet Tarres, Tu Bui, James Hays, Zhe Lin, and John Collomosse. ECCV 2022. Project page , arXiv SALVe Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas. John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, and Sing Bing Kang. ECCV 2022. Argoverse 2 Next Generation Datasets for Self-driving Perception and Forecasting. Benjamin Wilson , William Qi, Tanmay Agarwal, John Lambert, Jagjeet Singh, Siddhesh Khandelwal, Bowen Pan, Ratnesh Kumar, Andrew Hartnett, Jhony Kaesemodel Pontes, Deva Ramanan, Peter Carr, and James Hays NeurIPS Datasets and Benchmarks 2021 Argoverse 2 home page , NeurIPS page Trust, but Verify Cross-Modality Fusion for HD Map Change Detection. John Lambert and James Hays. NeurIPS Datasets and Benchmarks 2021 Argoverse 2 home page , NeurIPS page ANR Articulated Neural Rendering for Virtual Avatars. Amit Raj , Julian Tanke, James Hays, Minh Vo, Carsten Stoll, and Christoph Lassner. CVPR 2021. Project page , arXiv PVA Pixel-aligned Volumetric Avatars. Amit Raj , Michael Zollhoefer, Tomas Simon, Jason Saragih, Shunsuke Saito, James Hays, and Stephen Lombardi. CVPR 2021. Project page , arXiv Scene Flow from Point Clouds with or without Learning. Jhony Kaesemodel Pontes , James Hays, Simon Lucey. 3DV 2020 Oral. Project page , arXiv 3D for Free Crossmodal Transfer Learning using HD Maps. Benjamin Wilson , Zsolt Kira, and James Hays. arXiv preprint arXiv2008.10592, August 2020. arXiv Tide A general toolbox for identifying object detection errors Daniel Bolya, Sean Foley, James Hays, Judy Hoffman. ECCV 2020 spotlight. Project page , arXiv ANR Articulated Neural Rendering for Virtual Avatars. Amit Raj , Julian Tanke, James Hays, Minh Vo, Carsten Stoll, Christoph Lassner. arXiv preprint arXiv2012.12890, December 2020. Project page , arXiv Computational discrimination between natural images based on gaze during mental imagery. Xi Wang , Andreas Ley ,Sebastian Koch, James Hays, Kenneth Holmqvist ,and Marc Alexa . Scientific Reports, August 2020. Open Access Article Related earlier conference paper The Mental Image Revealed by Gaze Tracking. Xi Wang , Andreas Ley ,Sebastian Koch, David Lindlbauer ,James Hays, Kenneth Holmqvist ,and Marc Alexa . CHI 2019. Project Page , MLGT blog post ContactPose A Dataset of Grasps with Object Contact and Hand Pose. Samarth Brahmbhatt , Chengcheng Tang, Chris Twigg, Charlie Kemp, and James Hays ECCV 2020. Project page , arXiv MSeg A Composite Dataset for Multi-domain Semantic Segmentation. John Lambert , Zhuang Liu, Ozan Sener, James Hays, and Vladlen Koltun. CVPR 2020. Project page , Paper ContactGrasp Functional Multi-finger Grasp Synthesis from Contact Samarth Brahmbhatt , Ankur Handa, James Hays, and Dieter Fox IROS 2019. Project page , arXiv paper Towards Markerless Grasp Capture. Samarth Brahmbhatt, Charlie Kemp, and James Hays. CVPR 2019 CV for ARVR Workshop. Project page , arXiv Argoverse 3D Tracking and Forecasting With Rich Maps. Ming-Fang Chang , John Lambert , Patsorn Sangkloy , Jagjeet Singh , Slawomir Bak , Andrew Hartnett, De Wang, Peter Carr, Simon Lucey , Deva Ramanan , and James Hays. co-first authors CVPR 2019 oral. Paper , Argoverse project page and data , API code Github ContactDB Analyzing and Predicting Grasp Contact via Thermal Imaging. Samarth Brahmbhatt , Cusuh Ham , Charlie Kemp , and James Hays. CVPR 2019 oral and best paper finalist. Project page , Blog post Composing Text and Image for Image Retrieval - An Empirical Odyssey. Nam Vo , Lu Jiang , Chen Sun , Kevin Murphy , Jia Li , Fei-Fei Li , andJames Hays. CVPR 2019 oral. Paper arXiv , Code Github Generalization in Metric Learning Should the Embedding Layer be the Embedding Layer Nam Vo andJames Hays. WACV 2019 Paper arXiv , Code Github Revisiting IM2GPS in the Deep Learning Era. Nam Vo , Nathan Jacobs , and James Hays. ICCV 2017. Project Page , Paper arXiv Scribbler Controlling Deep Image Synthesis with Sketch and Color. Patsorn Sangkloy , Jingwan Lu , Chen Fang , Fisher Yu , and James Hays. CVPR 2017. Project Page , Paper arXiv , Adobe Max Demo The Sketchy Database Learning to Retrieve Badly Drawn Bunnies. Patsorn Sangkloy , Nathan Burnell, Cusuh Ham, James Hays. Siggraph 2016. Project Page , Paper Earlier Papers click to expand Informative Features for Model Comparison. Wittawat Jitkrittum , Heishiro Kanagawa , Patsorn Sangkloy ,James Hays, Bernhard Schlkopf , and Arthur Gretton . NeurIPS 2018. Paper arXiv SwapNet Garment Transfer in Single View Images Amit Raj , Patsorn Sangkloy , Huiwen Chang,James Hays, Duygu Ceylan , and Jingwan Lu . ECCV 2018. Project page , Paper MapNet Geometry-Aware Learning of Maps for Camera Localization Samarth Brahmbhatt , Jinwei Gu , Kihwan Kim , James Hays, and Jan Kautz . CVPR 2018. Paper arXiv SketchyGAN Towards Diverse and Realistic Sketch to Image Synthesis. Wengling Chen and James Hays. CVPR 2018. Paper arXiv TextureGAN Controlling Deep Image Synthesis with Texture Patches. Wenqi Xian, Patsorn Sangkloy , Varun Agrawal,Amit Raj, Jingwan Lu , Chen Fang , Fisher Yu , and James Hays. CVPR 2018. Paper arXiv On Convergence and Stability of GANs. Naveen Kodali, Jacob Abernethy , James Hays, and Zsolt Kira . arXiv, May 2017. Paper arXiv DeepNav Learning to Navigate Large Cities. Samarth Brahmbhatt , James Hays. CVPR 2017. Paper arXiv StuffNet Using Stuff to Improve Object Detection. Samarth Brahmbhatt , Henrik I. Christensen , James Hays. WACV 2017. Paper arXiv Localizing and Orienting Street Views Using Overhead Imagery. Nam Vo , James Hays. ECCV 2016. Project Page , Paper COCO Attributes Attributes for People, Animals, and Objects. Genevieve Patterson , James Hays. ECCV 2016. Paper WebGazer Scalable Webcam Eye Tracking Using User Interactions. Alexandra Papoutsaki , Patsorn Sangkloy , James Laskey, Nediyana Daskalova , Jeff Huang , James Hays. IJCAI 2016. Project Page , Paper Learning to Match Aerial Images with Deep Attentive Architectures. Hani Altwaijry , Eduard Trulls, James Hays, Pascal Fua, and Serge Belongie. CVPR 2016. Paper Solving Small-piece Jigsaw Puzzles by Growing Consensus. Kilho Son , Daniel Moreno, James Hays, David B. Cooper. CVPR 2016. Project Page , Paper Tropel Crowdsourcing Detectors with Minimal Training. Genevieve Patterson, Grant Van Horn, Serge Belongie, Pietro Perona, James Hays HCOMP 2015 Best paper runner-up . Paper Learning Deep Representations for Ground-to-Aerial Geolocalization. Tsung-Yi Lin, Yin Cui, Serge Belongie, and James Hays. CVPR 2015 Oral. Paper Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes. Pierre-Yves Laffont, Zhile Ren, Xiaofeng Tao, Chao Qian, and James Hays. Siggraph 2014. Project Page , Paper Good Image Priors for Non-blind Deconvoluton Generic vs Specific. Libin Sun, Sunghyun Cho, Jue Wang, and James Hays. ECCV 2014. Project Page Solving Square Jigsaw Puzzles with Loop Constraints. Kilho Son , James Hays, and David B. Cooper. ECCV 2014. Project Page , Paper Microsoft COCO Common Objects in Context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick. ECCV 2014. Project Page , Paper The SUN Attribute Database Beyond Categories for Deeper Scene Understanding. Genevieve Patterson , Chen Xu, Hang Su, and James Hays. International Journal of Computer Vision. vol. 1081-2, 2014. Pp 59-81. Project Page , Paper Previously published as SUN Attribute Database Discovering, Annotating, and Recognizing Scene Attributes. Genevieve Patterson and James Hays. CVPR 2012. Paper Basic level scene understanding categories, attributes and structures. Jianxiong Xiao, James Hays, Bryan C. Russell, Genevieve Patterson, Krista A. Ehinger, Antonio Torralba, and Aude Oliva. Frontiers in Psychology, 2013, 4506. This paper is a survey of recent work related to the SUN database. Paper Cross-View Image Geolocalization. Tsung-Yi Lin, Serge Belongie, and James Hays. CVPR 2013. Paper FrameBreak Dramatic Image Extrapolation by Guided Shift-Maps. Yinda Zhang, Jianxiong Xiao, James Hays, and Ping Tan. CVPR 2013. Project Page , Paper Edge-based Blur Kernel Estimation Using Patch Priors. Libin Geoffrey Sun , Sunghyun Cho , Jue Wang , and James Hays. ICCP 2013. Project Page , Paper Dating Historical Color Images. Frank Palermo, James Hays, and Alexei A Efros. ECCV 2012. Project Page , Paper How do humans sketch objects Mathias Eitz , James Hays, and Marc Alexa . Transactions on Graphics TOG - Proceedings of ACM SIGGRAPH 2012. Project Page , Paper Previously presented as Learning to classify human object sketches Mathias Eitz and James Hays. ACM SIGGRAPH 2011 Talks Program. Super-resolution from Internet-scale Scene Matching. Libin Geoffrey Sun and James Hays. International Conference on Computational Photography ICCP 2012. Project Page , Paper Quality Assessment for Crowdsourced Object Annotations. Sirion Vittayakorn and James Hays. British Machine Vision Conference BMVC 2011. Project page , Paper , Bibtex Sun database Exploring a large collection of scene categories Jianxiong Xiao, Krista Ehinger, James Hays, Aude Oliva, and Antonio Torralba. International Journal of Computer Vision IJCV 2014. Project page , Paper , Browse database Previously published as SUN Database Large-scale Scene Recognition from Abbey to Zoo Jianxiong Xiao, James Hays, Krista Ehinger, Aude Oliva, and Antonio Torralba. IEEE Conference on Computer Vision and Pattern Recognition CVPR 2010. Paper Scene categorization and detection the power of global features James Hays, Jianxiong Xiao, Krista Ehinger, Aude Oliva, and Antonio Torralba. Vision Sciences Society annual meeting VSS 2010. We present the S cene UN derstanding SUN database containing 899 categories and 130,519 images. We use 397 well-sampledcategories to benchmark numerous algorithms for scene recognition. We measure human scene classification performanceon the SUN database and compare this with computational methods. Ph.D. Thesis Large Scale Scene Matching for Graphics and Vision Thesis Page Our visual experience is extraordinarily varied and complex. The diversity of the visual world makes it difficult for computer vision to understand images and for computer graphics to synthesize visual content. But for all its richness, it turns out that the space of scenes might not be astronomically large. With access to imagery on an Internet scale, regularities start to emerge - for most images, there exist numerous examples of semantically and structurally similar scenes. Is it possible to sample the space of scenes so densely that one can use similar scenes to brute force otherwise difficult image understanding and manipulation tasks This thesis is focused on exploiting and refining large scale scene matching to short circuit the typical computer vision and graphics pipelines for image understanding and manipulation. Image Sequence Geolocation with Human Travel Priors Evangelos Kalogerakis, Olga Vesselova, James Hays, Alexei A. Efros, and Aaron Hertzmann. IEEE International Conference on Computer Vision ICCV 09 Project Page An empirical study of Context in Object Detection Santosh Divvala, Derek Hoiem, James Hays, Alexei A. Efros, and Martial Hebert. IEEE Conference on Computer Vision and Pattern Recognition CVPR 2009. Project Page , Paper New Book chapter with expanded geolocalization experiments. Large-Scale Image Geolocalization James Hays and Alexei Efros. Multimodal Location Estimation of Videos and Images. Pages 41-62. 2014. Paper , Bibtex Previously published as IM2GPS estimating geographic information from a single image James Hays and Alexei Efros. IEEE Conference on Computer Vision and Pattern Recognition CVPR 2008. Paper . CVPR 2008 Project Page . Google Tech Talk . Abstract Estimating geographic information from an image is an excellent, difficult high-level computer vision problem whose time has come. The emergence of vast amounts of geographically-calibrated image data is a great reason for computer vision to start looking globally - on the scale of the entire planet In this paper, we propose a simple algorithm for estimating a distribution over geographic locations from a single image using a purely data-driven scene matching approach. For this task, we will leverage a dataset of over 6 million GPS-tagged images from the Internet. We represent the estimated image location as a probability distribution over the Earths surface. We quantitatively evaluate our approach in several geolocation tasks and demonstrate encouraging performance up to 30 times better than chance. We show that geolocation estimates can provide the basis for numerous other image understanding tasks such as population density estimation, land cover estimation or urbanrural classification. Scene Completion Using Millions of Photographs James Hays and Alexei Efros . Transactions on Graphics SIGGRAPH 2007. August 2007, vol. 26, No. 3. Project Page , SIGGRAPH Paper , CACM Paper , CACM Technical Perspective by Marc Levoy , Bibtex Abstract What can you do with a million images In this paper we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless but also semantically valid. Our chief insight is that while the space of images is effectively infinite, the space of semantically differentiable scenes is actually not that large. For many image completion tasks we are able to find similar scenes which contain image fragments that will convincingly complete the image. Our algorithm is entirely data-driven, requiring no annotations or labelling by the user. Unlike existing image completion methods, our algorithm can generate a diverse set of image completions and we allow users to select among them. We demonstrate the superiority of our algorithm over existing image completion approaches. Interactive Tensor Field Design and Visualization on Surfaces Eugene Zhang , James Hays,and Greg Turk . IEEE Transaction on Visualization and Computer Graphics, 2007, Vol 131, pp 94-107. Project Page , Paper , Bibtex This research project was primarily Eugenes work and I played only a small role. Image De-fencing Yanxi Liu , Tamara Belkina, James Hays, and Roberto Lublinerman . IEEE Conference on Computer Vision and Pattern Recognition CVPR 2008. Paper , Bibtex We introduce a novel image segmentation algorithm that uses translational symmetry as the primary foregroundbackground separation cue. We use texture-based inpainting to recover an un-occluded background. Discovering Texture Regularity as a Higher-Order Correspondence Problem James Hays, Marius Leordeanu , Alexei Efros , and Yanxi Liu . European Conference on Computer Vision ECCV 2006. Paper , Bibtex We find arbitrarily distorted regular patterns in real images by treating lattice-finding as a higher-order assignment problem. We leverage previous work from Marius Leordeanu and Martial Hebert to approximate the optimal assignment under second-order constraints. Source code available upon request, although thiscode by Minwoo Park et al. is likely more accurate and faster. Quantitative Evaluation of Near Regular Texture Synthesis Algorithms Steve Lin , James Hays, Chenyu Wu , Vivek Kwatra , and Yanxi Liu IEEE Conference on Computer Vision and Pattern Recognition CVPR 2006 Paper , Bibtex Quantitative evaluation is difficult for texture synthesis. Ground truth is not well defined. But for certain textures you can objectively decide whether an algorithm has failed or not. Regular and near-regular textures imply a definite structure that should be preserved. We tested several popular algorithms on a large group of structured textures. In addition to the CVPR 2006 paper, a more detailed technical report is available. Near-Regular Texture Database - link Online Database We created a database of regular and near-regular textures for other researchers to use. You can submit your own textures, as well, and help the database grow. Digital Papercutting Yanxi Liu , James Hays, Ying-Qing Xu , and Harry Shum SIGGRAPH 2005 Sketch Sketch , Bibtex Papercutting is a widespread and ancient artform which, as far as we could tell, had no previous computational treatment. We developed algorithms to analyze the symmetry of papercut patterns and produce efficient folding and cutting plans. Near-Regular Texture Analysis and Manipulation Yanxi Liu , Steve Lin , and James Hays.SIGGRAPH 2004 Project page , Paper , Bibtex Abstract A near-regular texture deviates geometrically and photometrically from a regular congruent tiling. Although near-regular textures are ubiquitous in the man-made and natural world, they present computational challenges for state of the art texture analysis and synthesis algorithms. Using regular tiling as our anchor point, and with user-assisted lattice extraction, we can explicitly model the deformation of a near-regular texture with respect to geometry, lighting and color. We treat a deformation field both as a function that acts on a texture and as a texture that is acted upon, and develop a multi-modal framework where each deformation field is subject to analysis, synthesis and manipulation. Using this formalization, we are able to construct simple parametric models to faithfully synthesize the appearance of a near-regular texture and purposefully control its regularity. Image and Video Based Painterly Animation James Hays and Irfan Essa . NPAR 2004 . Project Page , Paper , Bibtex We extend previous non-photorealistic rendering work to handle video significantly better by temporally constraining brush stroke properties in addition to other improvements. Support My research has been funded by a Sloan Fellowship, NSF Career award 1149853, Sandia National Labs, NSF medium 1563727, IARPAs Finder program FA8650-12-C-7212, and gifts from Intel, Google, Microsoft, Pixar, Adobe, and Argo AI.", "metadata": {"last_modified": "2024-02-12T18:21:16+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 3575, "token_count_estimate": 5776}}, "https://cs.brown.edu/people/pfelzens/engn1610/": {"text_content": "ENGN 1610 Image Understanding Instructor Pedro Felzenszwalb Lectures TTh 1030-1150 PM Barus Holley 751 Office hours Monday 2-3 PM Course description Image processing is a technology experiencing explosive growth it iscentral to medical image analysis and transmission, industrialinspection, image enhancement, indexing into pictorial and videodatabases, e.g., WWW, and to robotic vision, face recognition, andimage compression. This senior-level undergraduate course coverstheoretical underpinnings of this field and includes a series ofpractical MATLAB image processing projects. ENGN 1570 is recommendedbut not required. Topics Image formation Low-level image processing 3D reconstruction Motion estimation Image segmentation Object recognition Reference Computer Vision Algorithms and Applications. Szeliski. Springer. A draft PDF is available here . Calendar Topic 1 Image Formation Topic 2 Image Filtering and Edge detection Topic 3 Multiview geometry and stereo matching Topic 4 Image Segmentation Topic 5 Graph algorithms Topic 6 Template matching Topic 7 Convolutional Neural Networks Topic 8 Geometric Methods for Recognition Topic 9 Motion and Optical flow Readings Assignments 1 Szeliski chapter 2 2 Edge detection Handout and Additional examples 3 Mean shift and feature space analysis 4 Dynamic Programming and Graph Algorithms 5 Object Detection 6 LeNet paper pages 1 to 11 7 AlexNet paper 8 Optical flow review paper 9 Dense Optical flow paper Homework Using images in MATLAB example.m Assignment 1 and test images Due Wednesday February 19 Assignment 2 and test images Due Monday March 9 Assignment 3 and files Due Monday March 9 Assignment 4 and data Due Friday May 1", "metadata": {"last_modified": "2020-04-21T14:12:05+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["ENGN 1610 Image Understanding"], "word_count": 245, "token_count_estimate": 349}}, "https://cs.brown.edu/people/pfelzens/": {"text_content": "Pedro Felipe Felzenszwalb Professor of Engineering and Computer Science Office Barus Holley 355 Phone 401 863-1531 Email pff at brown.edu Office hours Thursday 1pm-2pm in BH 355 CV Research My main research interests are in computer vision, artificial intelligence, machine learning and discrete algorithms. I have worked on a range of different problems within computer vision, including the low-level problem of image restoration, the mid-level problem of image segmentation, and the high-level problem of object recognition. My research involves connections between computer vision and artificial intelligence to a variety of areas including combinatorial optimization, stochastic models, machine learning, and natural language processing. Papers Talk slides Code PhD students and Postdocs 3D printing Teaching Fall 2022 Linear System Analysis ENGN 1570 Spring 2023 Topics in Optimization ENGN 2912P Fall 2023 Linear System Analysis ENGN 1570 Spring 2024 Pattern Recognition and Machine Learning ENGN 25220 Person detection in the PASCAL challenge deformable part model Curve detection with the min-cover algorithm Random shapes defined by a stochastic context-free grammar Contour completion with belief propagation Mailing address Box D Brown University 184 Hope St. Providence, RI 02912", "metadata": {"last_modified": "2023-12-07T19:55:17+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 183, "token_count_estimate": 256}}, "https://cs.brown.edu/people/pkp/": {"text_content": "Phirum Peang Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7600 voice 401-863-7657 fax", "metadata": {"last_modified": "2022-08-11T18:29:19+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Phirum Peang"], "word_count": 16, "token_count_estimate": 37}}, "https://malk.in/": {"text_content": "Publications Courses Join Hello my name is Nathan Malkin Im an assistant professor in the Department of Informatics at New Jersey Institute of Technology NJIT in the New York City metro area. Previously, I received my PhD in computer science from UC Berkeley and was a postdoctoral researcher at the University of Maryland . Email Github LinkedIn Im looking for students to join my lab Learn more about the roles Im recruiting for. Research My field of research is usable security and privacy also known as human-centered security and privacy. It lies at the intersection of cybersecurity privacy with human-computer interaction social computing . My goal is to make technology more private and secure by studying and simplifying peoples decisions. I use observations and experiments, as well as surveys and interviews, to understand how human factors contribute to privacy and security problems. I then design systems to overcome these challenges and empirically validate them with user studies and real-world deployments. Currently, Im working on privacy for the Internet of Things , improving the digital safety of at-risk users , and helping developers create more secure software. Previous work has focused on privacy controls for always-listening devices , including smart speakers and smart TVs . Ive also drawn on behavioral economics to help users make security decisions while avoiding cognitive biases . See my publications for more details of my research. Teaching Spring 2024 ISCS 698 Human Factors in Security and Privacy Past teaching assistant for computer security , CS theory , software engineering Guest lectures Cornell Tech , ColumbiaBarnard Professional service 2024 USENIX Security , PETS 2023 USENIX Security , IEEE Security Privacy , NDSS , CHI , SecHOPE Special Recognitions for Outstanding Reviews ACM CHI 2017, 2018, 2021, 2022, 2023, 2024 Please consider submitting your work to these and other usable security venues And now for something completely different My email address is nathan.malkin at njit.edu", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Hello", "Nathan Malkin", "Research", "Teaching", "Professional service"], "word_count": 317, "token_count_estimate": 389}}, "https://cs.brown.edu/people/pklein/": {"text_content": "Home Publications Teaching Philip N. Klein Professor of Computer Science Brown University Box 1910 Providence, RI 02912 email philipbrown.edu or kleinbrown.edu Research Interests Algorithms Data Structures Combinatorial Optimization Approximation Algorithms Graphs planarity.org , a resource page for Optimization Algorithms on Planar Graphs Teaching Recipient of the 2007 Philip J. Bray Award for Excellence in Teaching in the Sciences . Courses originated TheMatrix in Computer Science Computer Science An Integrated Introduction I and II with Leslie P. Kaelbling Design and Analysis of Algorithms Topics in Advanced Algorithms Solving Hard Problems in Combinatorial Optimization Theory and Systems with Pascal Van Hentenryck Secrets and Promises A Course on Cryptography for Nonmajors Other Courses Taught IntroductiontoDiscrete Structures and Probability MOOC massive open online course Coding the Matrix Linear Algebra through Computer Science Applications Other Recipient of the NSF Presidential Young Investigator Award 1991 ACM Fellow 2010 Radcliffe Fellow 2015-2016 Program Chair of ACM-SIAM Symposium on Discrete Algorithms SODA 2017 Creator of Coding the Matrix Author of Coding the Matrix Linear Algebra through Applications to Computer Science Author of A Cryptography Primer Secrets and Promises Co-author of Optimization Algorithms for Planar Graphs", "metadata": {"last_modified": "2019-01-03T17:11:08+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 187, "token_count_estimate": 255}}, "https://cs.brown.edu/people/pw/": {"text_content": "Peter Wegner I am the former editor-in-chief of ComputingSurveys and of The Brown Faculty Bulletin. Some of my current research interests are interaction, compound andactive document systems such as OpenDoc , JavaBeans and ActiveX ,object oriented programming, and programming languages. Here are some of my papers on Interaction Date Paper Sep. 95 OOPSLA 95Tutorial Notes Models and Paradigms of Interaction Apr 96 Coordinationas Constrained Interaction ,LNCS 1061, pp. 28-33, April 1996 May 97 Why InteractionIs More Powerful Than Algorithms , Communications of the ACM. ,May 1997 December 96 InteractiveSoftware Technology , Handbook of Computer Science and Engineering,CRC Press, 1996. May. 97 Frameworksfor Compound Active Documents , work in Progress May. 97 InteractiveFoundations of Computing, Final Draft , Theoretical Computer Science,February 1998 Jan. 98 A ResearchAgenda for Interactive Computing , work in Progress May 98 TowardsEmpirical Computer Science , The Monist, Spring 1999 July 98 Persistenceas a Form of Interaction , Brown Technical Report CS 98-07, July 1998 January 99 MathematicalModels of Interactive Computing ,Brown Technical Report CS 99-13 January 99 Interactionas a Framework for Modeling ,LNCS 1565, April 99 February 99 CoinductiveModels of Finite Computing Agents ,Electronic Notes in Theoretical Computer Science, March 1999 February 99 InteractiveVisual Programming Principles and Examples , work in Progress March99 Modeling,Formalization, and Intuition , Brown Faculty Bulletin, March 99 May 99 Modelsof Interaction , ECOOP 99 Course Notes June 99 Interaction,Computability, and Churchs Thesis ,work in Progress June 99 Draftof ECOOP99 Banquet Speech , Lisbon, Portugal Aug. 00 An InteractiveViewpoint on the Role of UML ,Book chapter, published in Unified Modeling Language Systems Analysis, Design, and Development Issues , Idea Group Publishing, 2001. May. 02 Paraconsistency of Interactive Computation ,PCL 2002 Workshop on Paraconsistent ComputationalLogic, Denmark, July 2002 Jun. 02 ComputationBeyond Turing Machines RTF, Communications of the ACM , April 2003 Jun. 03 TuringsIdeas and Models of Computation .Book chapter, in Alan Turing Life and Legacy of a Great Thinker ,ed. Christof Teuscher,Springer 2004 co-authored with Eugene Eberbach, Dina Goldin Jun. 05 The Church-Turing Thesis Breaking the Myth PDF,Presented at CiE 2005, Amsterdam LNCS 3526, Springer 2005, pp. 152-168 Mar. 06 Principlesof Problem Solving , Communications of the ACM , July 2006 Sep. 06 InteractiveComputation the New Paradigm. Published by Springer-Verlag in September2006 co-edited with Dina Goldin, Scott Smolka Jan. 08 Refutingthe Strong Church-Turing Thesis the Interactive Nature of Computing PDF,accepted for publication in Minds and Machines . co-authoredwith Dina Goldin here is herlist of paperson interaction . Peter Wegner Box 1910, Computer Science Department Brown University Providence, RI 02912 pwcs.brown.edu Finger me. 401-863-7600 voice 401-863-7657 fax", "metadata": {"last_modified": "2008-02-01T22:24:43+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Peter Wegner"], "word_count": 423, "token_count_estimate": 708}}, "https://cs.brown.edu/people/sdollins/home.html": {"text_content": "Steven C. Dollins, Ph.D. no longer enslaved in the scrolls I completed my Ph.D. in the Brown Computer Graphics Group in the Computer Science Department at Brown University in May, 2002. I am currently the C.E.O. and portfolio manager for Dollins InvestmentAdvisors, LLC in Fremont, California. I maintain a page of Handy Mathematics Facts for Graphics . My research interests include Large scale, distributed virtual environments Procedural and multi-resolution modeling, animation, and computing Physical simulation including collision detection and response 3-D user interaction including navigation and object manipulation Game programming Kinetic art Applying object-oriented programming language technology to graphics systems Thesis On-the-fly Procedurally Generated Interactive Worlds For my thesis, I worked on the authoring and plausible emulation of procedurally generated, multi-resolution geometry and behaviors for large scale, interactive virtual environments the real goal is to come up with a thesis topic that is buzzword complete. By behaviors , I mean attributes of objects, such as their geometry, color, position, and motion, that change over time and in response to events triggered by time, by other entities in the world, or by the user. Game Programming For the spring of 1996, a group of students in our department created what at Brown is called a GISP, or Group Independent Study Project, on game programming for which I acted as one of the TAs. The course consisted of two parts 1 a series of research topics presented by the students and followed up with small programming assignments and 2 a final project done as part of a small group. The topics we covered in the initial part of the course were networking network topologies, UNIX sockets, data synchronization graphics coordinate systems, object geometry representations, DOOM-style texture-mapping simulation physical simulation, numerical methods, collision detection and response artificial intelligence autonomous agents interacting with an environment, state machines, path planning user interfaces defining and limiting user degrees of freedom, presentation of information Academic History I received my Bachelors degree in Mathematics and Computer Science from the University of Illinois at Urbana-Champaign in May of 1992. While at UIUC, I was the chairperson for the student ACM SIGGRAPH. I have been a member of the international ACM SIGGRAPH since 1990. I also worked in the Software Technology Group at the National Center for Supercomputing Applications NCSA . They started work on Mosaic, the precursor to both Netscape Navigator and Microsofts Internet Explorer, just as I left. While at Illinois, I wrote a game called Netspace that became a project of the student SIGGRAPH and which we showed off at UIUCs Engineering Open House in both 91 and 92. Netspace was a networked, multi-player, outer space dogfight game that ran over a network of PCs using TCPIP. The networking and much of the game play was written by Christopher Wilson and Jon Mittelhauser who worked with me at NCSA. After leaving Illinois, they went on to work on Microsofts Internet Explorer and Netscapes Navigator, respectively. I graduated from the Mt. Lebanon High School in 1988. Mt. Lebanon is a suburb in the South Hills of Pittsburgh, Pennsylvania which is at the western end of the state, near Ohio. Family My family tree . Personal Amusements Most of my personal interests are reflected by my rather extensive list of bookmarks , many of which are probably out of date. Contact Information 33400 Turnstone Pl. Fremont, CA 94555 650-773-0725 cell Email me at steven at dollins . org. My PGP key . 1,742,455,679 10 steven 36 Steven C. Dollins", "metadata": {"last_modified": "2013-01-01T06:59:48+00:00", "scraped_at": "2024-03-13T22:15:40+00:00", "headings": ["Steven C. Dollins, Ph.D.", "Academic History", "Family", "Personal Amusements", "Contact Information"], "word_count": 580, "token_count_estimate": 753}}, "https://cs.brown.edu/people/rfonseca/": {"text_content": "Rodrigo Fonseca Top News Teaching Research Students Publications Service Personal email office 329, CIT Building. Office hours by appointment. mail Box 1910, Brown University 115 Waterman St Providence , RI 02912 phone 401-863-6533 voice 401-863-7657 fax DBLP Google Scholar MSFT Academic Search About I am an associate professor at Brown University s Computer Science Department . My work revolves around distributed systems, networking, and operating systems. Broadly, I am interested in understanding the behavior of systems with many components for enabling new functionality, and making sure they work as they should. In particular, Im interested in how to build, operate, and diagnose large scale Internet systems and in networking and power management in embedded distributed systems such as sensor networks. Im updating this page. Take a look at my CV for the authoritative information. News Feb-2020 Im starting as a Principal Researcher at Microsoft Research Nov-2019 Im the General Chair for SoCC2020 Stay tuned. Nov-2019 Was PC co-chair for HotNets 2019 , with Sylvia Ratnasamy. The workshop was a big success May-2019 Congratulations to Dr. Da Yu, PhD 5 Going to Microsoft, to work on Azure Networking. May-2019 Congratulations to Dr. Jeff Rasley, PhD 4 Going to Microsoft, to work on AI Infrastructure at Bing. Jan-2019 Going for an 8-month visit to Microsoft Research in Redmond, WA Oct-2018 New NSF grant Network-centric IoT Security, with Theo Benson May-2018 Congratulations to Dr. Jonathan Mace , PhD 3 He is starting as a tenure track faculty at MPI-SWS Oct-2017 Keynote at The 17th International Conference on Runtime Verification, RV17. Seattle, WA Jul-2017 Now Associate Professor with Tenure Jun-2017 Busy summer Ill be spending the summer in Palo Alto, with Flowtune . Jeff will be at MSR in Seattle, Da at Alibaba, Seattle, and Jon at Facebook in Cambridge Apr-2017 Congratulations to Dr. Marcelo Martins, PhD 2 Mar-2017 NSDI Test of Time Award for X-Trace With George Porter, Ion Stoica, Scott Shenker, and Randy Katz Nov-2016 Switches are Monitors Too presented at HotNets Oct-2016 Raja presented our paper Principled Workflow-centric Tracing of Distributed Systems at SoCC. Aug-2016 Went to Floripa, Brasil for Sigcomm. We had a paper at the main conference, a paper in the Workshop on QoE, and I gave an invited talk at NetPL. May-2016 cDVD, on fair bandwidth allocation for competing DASH video streams, accepted at Internet-QoE 2016 Apr-2016 2DFQ accepted to Sigcomm 2016, which will be in Brazi Apr-2016 Teaching Networking in the Fall Apr-2016 NetEx pdf , our architecture for a network marketplace inside of a datacenter, accepted for HotCloud Feb-2016 Teaching Distributed Systems with Tom Doeppner Jan-2016 Yak, joint work with my student Jeff Rasley and Microsoft, accepted into Eurosys 2016 Oct-2015 Pivot Tracing gets best paper award at SOSP Oct-2015 Presented We are Tracing like its 1973 pptx at the Open Zipkin workshop in San Francisco Sep-2015 Presented We are Losing Tack a Case for Causal Metadata in Distributed Systems at the 16th Asilomar HPTS May-2015 Good Summer looking ahead Jeff and Jonathan will have internships at Microsoft Research, Da will go to HP Labs May-2015 Jonathan will be presenting our work Retro Targeted Resource Management in Multi-tenant Distributed Systems at NSDI 2015 This is join work with Peter Bodik and Madan Musuvathi from Microsoft Research. Apr-2015 Our paper Simon Scriptable Interactive Monitoring for SDNs, accepted at SOSR15 Joint work with Da Yu , Yiming Li, Tim Nelson , and Shriram Krishnamurthi . Apr-2015 Our paper Exodus Toward Automatic Migration of Enterprise Network Configurations to SDNs accepted at SOSR15 Joint work with Tim Nelson , Andrew Ferguson, and Shriram Krishnamurthi . Apr-2015 Marcelo s paper Selectively Taming Background Android Apps to Improve Battery Lifetime accepted at USENIX ATC, joint work with Justin Cappos . Mar-2015 Won an NSF CAREER Award on Understanding the Performance of Distributed Systems Through Causal Tracing Feb-2015 Teaching CS-138 Distributed Systems with Tom Doeppner. Oct-2014 Co-organizing the first New England Networking and Systems Day , Oct 24th, at the Hariri Institute at BU. We will gather more than 90 participants with many talks, posters, and much discussion time. Sep-2014 I recently documented in Portuguese an attack to a bank website in Brazil that got some media attention Sep-2014 The Brown-Brazil Initiative is hosting my former advisor Prof. Virgilio Almeida for the innaugural talk of the Fall Lecture Series. Sep-2014 Our paper Towards General-Purpose Resource Management in Shared Cloud Services with my PhD student Jon Mace , Peter Bodik , and Madan Musuvathi was accepted for publication at HotDep14, the 10th Workshop on Hot Topics in System Dependability Sep-2014 Teaching Computer Networks this fall Aug-2014 Jeff Rasley successfully presented Planck Millisecond-scale Monitoring and Control for Commodity Networks at Sigcomm 2014. Apr-2014 Our paper Planck Millisecond-scale Monitoring and Control for Commodity Networks was accepted for publication at Sigcomm 2014. See you in Chicago Apr-2014 Very proud of my first minted PhD student, Andrew Ferguson . Congrats, Andrew Mar-2014 Jeff Rasley will be interning at VMWare, and Marcelo at Intel. Feb-2014 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Jan-2014 Ill be part of the Program Committees for Sigcomm 2014 and IMC 2014 Dec-2013 Im part of the Program Committee for HotMobile 2014 July-2013 NSF NeTS Grant on Participatory Networking, to advance SDNs northbound APIs July-2013 Our paper Growth Analysis of a Large ISP was accepted at IMC May-2013 Highly successful internship season for students Andrew is going to the SDN group at Google with Amin Vahdat, Jeff is going to IBM Research in Austin with Collin Dixon, Jonathan is going to MSR Redmond with Peter Bodik Apr-2013 We are going to Sigcomm 2013 to present our paper on Participatory Networking Congrats to Andrew Ferguson, Arjun Guha, Chen Liang, and Shriram Krishnamurthi Apr-2013 Chen Liang accepted as a PhD student at Duke University Congrats, Chen Jan-2013 Teaching Advanced Networking as a special topics class, focusing on Datacenter Networking and SDNs. Dec-2012 Our paper Application Modes accepted for publication at HotMobile 2013 Sep-2012 Big welcome to Jeff Rasley new PhD student, Jonathan Mace new advisee, and Matheus Caldas visiting PhD student from UFMG, Brazil Sep-2012 Teaching CS168, Computer Networks this spring. Jul-2012 Spending the summer at MSR Redmond, with Victor Balhs group Jul-2012 Our paper PARMA A Parallel Randomized Algorithm for Approximate Association Rule Mining in MapReduce accepted at CIKM 2012 Jun-2012 Program Committee Member for NSDI13 May-2012 Our paper Hierarchical Policies for Software Defined Networks accepted for publication at the HotSDN 2012 workshop, co-held with Sigcomm 2012 Apr-2012 Nathans paper C-MR Continuously Executing MapReduce Workflows on Multi-Core Processors accepted for publication at the MAPREDUCE 2012 workshop Apr-2012 Andrew presented Jockey Guaranteed Job Latency in Data Parallel Clusters at Eurosys 2012 . Work with Srikanth Kandula and Peter Bodk from Microsoft Research. Mar-2012 Our paper Participatory Networking accepted for publication at HotICE12 , co-held with NSDI12. Mar-2012 External Review Committee Member for OSDI 2012 Feb-2012 Google funds research on distributed tracing Sep-2011 Teaching CSCI2950-U in Fall 2011, focusing on Large-scale data intensive computing Jul-2011 I will be co-chairing HotClouds12 with Dave Maltz, from MSR May-2011 Solomon Award from Brown University to work on energy managdtent in Wireless Sensor Networks Sep-2010 NSF funds research on security in Cloud Computing . Jun-2010 Program committee for NSDI11 Jun-2010 Intel funds research on Whole-platform Energy Usage of Software Activities Jun-2010 Andrews poster on block placdtent in Hadoop accepted at the USENIX ATC May-2010 Teaching CSCI1680 Computer Networks in Spring 2011 May-2010 Teaching CSCI2950-U Special Topics on Networking and Distributed Systdts in Fall 2010 Apr-2010 Experiences with X-Trace paper presented on INMWREN 2010 More... Teaching Fall 2019 CSCI1680 Computer Networks . Previous F16 , F16 , F16 , F14 , F12 , S12 , S11 Spring 2018 CSCI1380 Distributed Systems . Previous S17 S15 Spring 2017 Advanced Networking . Previous S14 - CSCI2950-U Advanced Networking SDNs and Datacenter Networking , S13 , F11 , F10 , F09 Research Projects Participatory Networking The PANE project aims to allow end-user applications to help in the configuration of a network. PANE is both a paradigm and a prototype SDN controller that solves the problem of privilege delegation and conflict resolution when unprivileged users are given read and write access to network services, configuration, and state. Read more... Mobile Device Energy We are interested in improving the battery life of mobile devices. Todays mobile devices need for energy far surpasses their battery capacity to allow for unrestricted use and long battery life. Users must prioritize their usage to avoid running out of battery. However, for a user to do this efficiently is almost impossible it requires knowledge of the energy and power characteristics of the applications and of the hardware components of the particular phone. This leads to a poor experience and to frustration. We propose an OS abstraction, Application Modes, that allow applications and the OS to collaborate in exposing to the user only what she cares about and understands the tradeoff between battery lifetime and functionality. Read our HotMobile paper for an introduction to our approach. Tracing Distributed Systems Distributed systems are growing ever more complex, spanning many layers of abstraction, machines, and administrative domains, and integrating code written, deployed, and operated by different people. In these scenarios it becomes increasingly difficult to understand how a system behaves, and, especially, how and why it fails. Causal tracing is a technique that captures the causality of events across all of these components, layers, and machines, and eases the task of understanding complex distributed systems. There are a multitude of causal tracing systems and frameworks, including many research and industry projects. Examples include our own X-Trace project GitHub , as well as systems such as Googles Dapper, Twitters Zipkin, and Clouderas HTrace. We are interested in how to extract information from both complex individual traces and across traces, to identify root causes of problems, detect unexpected anomalies, and make tracing more efficient, by biasing trace sampling and detail capture to maximize trace information on a fixed performance budget. Older Projects Quanto Fine-grained tracking of energy usage in wireless sensor networks, Quanto determines which applications used how much energy on each hardware component, even for applications that span multiple network nodes. Collection Tree Protocol Robust all-to-few routing in wireless sensor networks, CTP is de-facto routing protocol for TinyOS 2.x, and formed the basis for IETFs RPL Routing over Low Power and lossy networks - RFC 6550 . Beacon Vector Routing BVR is an anchor-based pseudo-geographical any-to-any routing protocol for wireless sensor networks. Students I am really very fortunate to work with an amazing set of students Graduate Students Michael Markovitch PhD Alumni Linnan Wang PhD 2021. Now at NVidia Nicholas DeMarinis PhD 2021. Now at Brown Jeff Rasley - PhD 2019. Now at Microsoft. Da Yu - PhD 2019. Now at ByteDance Jonathan Mace - PhD 2018. Now at MPI-SWS Marcelo Martins - PhD 2017 Sofware Analysis and Development for Energy Effciency in Mobile Devices . Now at Apple. Andrew D. Ferguson - PhD 2014 Policy Delegation and Migration for Software-Defined Networks . Now at Google. Junyang Chen - ScM 2016 George Hongkai Sun - ScM 2016 Wilson Cusack - AB 2016 - Honors Rui Zhou - ScM 2014 Datacenter Network Large Flow Detection and Scheduling from the Edge . Now at Google. Jonathan Leavitt - ScB 2014. Honors Thesis End-to-End Tracing Models Analysis and Unification. Now at Google. Matheus Caldas Visiting PhD from UFMG Chen Liang - ScM 2013, now a PhD student at Duke. ScM Project Software Defined Network Support for Real Distributed Systems Basil Crow - ScM 2012, now at Delphix. Thesis Time and Energy Profiling in Production Sensor Networks with Quanto Sunil Mallya - ScM 2011, co-founder at Neon Labs , now at Amazon. Thesis Entracker Energy Tracker for Homes Jake Eakle ScM 2011, now at Teespring. Sandy Ryza - ScB 2012, now at Cloudera. Honors Thesis Solving Hard Problems with Lots of Computers Walter Blaurock - ScB 2011, now at Next Big Sound. Project Automatic Scaling of Cloud-Based Web Applications Selected Publications All Publications . . , , pp. , In , pp. , , Eds., , , . ISBN . BibTex pdf talk video doi Professional Activities Conference Organization 2015 Co-Organizer, 2nd New England Networking and Systems Day 2014 Co-Organizer, 1st New England Networking and Systems Day Doctoral Symposium, IC2E 2014 2012 Program Co-Chair HotCloud12 Technical Program Committee 2016 Eurosys16, USENIX ATC16, NSDI16, SBRC16 2015 SBRC15, DCOSS15, NSDI15, HotCloud15, DSN15 2014 SIGCOMM14 PC, IMC14 PC, HotMobile 2014, Eurosys14 Ext. Review Committee 2013 NSDI13 PC, TRIOS, SOCC13 2012 OSDI12 Ext. Review Committee, Middleware12, HotDep12, MAD12, IGCC12, DSN12 2011 NSDI11, DSN11, CoNEXT11, HotPower11, HotCloud11, NetDB11 2010 ... Personal You can find some of my photography as 319studio on Instagram, or at 500px . I almost never tweet as rodrigofonseca . My wife Paula runs an amazing party design business, Festiva Party Design , check it out Back to top Template and css from Twitter bootstrap. Publications list automatically generated from BibTeX using Exhibit .", "metadata": {"last_modified": "2022-06-27T23:34:19+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["About", "News", "Teaching", "Research Projects", "Participatory Networking", "Mobile Device Energy", "Tracing Distributed Systems", "Older Projects", "Students", "Graduate Students", "", "Alumni", "", "", "Selected Publications", "Professional Activities", "Personal"], "word_count": 2158, "token_count_estimate": 3248}}, "https://cs.brown.edu/people/rpatel59/": {"text_content": "About ResearchCode Blog About ResearchCode Blog About Im a fourth-year PhD student at Brown University advised by the incredible Ellie Pavlick . I also work with Stefanie Tellex , George Konidaris , Michael Littman , and a lot of the other wonderful people at Brown. As an undergrad, I was advised by Ani Nenkova and Byron Wallace in various areas of machine learning and language processing. My research uses language to structure reinforcement learning, aiming towards building more intelligent and interpretable agents that can learn to use language to communicate and coordinate with each other. Language can be a powerful tool to help agents learn and adapt from small amounts of human-intelligible data. Im specifically interested in 1 using the structure of language to aid reinforcement learning and multi-agent algorithms, 2 allowing language to be used for communication between agents and 3 methods for better interpretability of models that use language to allow safer and more ethical systems. Apart from work, I enjoy reading vast amounts of literature, various kinds of music and mostly just programming for fun. Feel free to reach out with research related questions or otherwise Email romapatelbrown.edu Github roma-patel Office CIT 527 Appropriate Incongruities in Prototype Theory Research What Im most interested in is creating frameworks that incorporate language knowledge, RL exploration strategies and human-level inference, to work towards building systems that reason and act at a level that is at par with human intelligence. This includes augmenting existing reinforcement learning algorithms with language supervision, allowing multi-agent algorithms to use and extend to natural language, as well as modeling and probing interactions between agents to better interpret and explain their behaviours. Where Ive Been Microsoft Research Microsoft Turing Academic Program Worked with Dean Carignan, Saurabh Tiwary, Pooya Moradi, Ali Alvi and others at MSR.Summer 2021-current. DeepMind, London Research Intern Multi-agent Reinforcement Learning Worked with Angeliki Lazaridou, Richard Everett, Edward Hughes and Yoram Bachrach. Summer 2020. Google AI, Mountain View Research Intern Vision and Language Reinforcement Learning Worked with Alex Ku and Jason Baldridge. Summer 2019. Johns Hopkins University Jelinek Summer Workshop on Speech and Language Technology JSALT Worked with Ellie Pavlick, Brown University Sam Bowman, New York University Tal Linzen, Johns Hopkins University. Summer 2018. Max Planck Institute Cornell, Maryland, Max Planck Pre-doctoral Research School CMMRS Summer 2018. University of Pennsylvania Undergraduate Researcher Worked with Ani Nenkova, University of Pennsylvania and Byron Wallace, Northeastern University. Summer 2017-18. Princeton University Program in Algorithmic and Combinatorial Thinking PACT Led by Rajiv Gandhi, Rutgers University, Camden. Summer 2016. Tutorials Recognising Multimodal Entailment. Afsaneh Shirazi, Arjun Gopalan, Arsha Nagrani, Cesar Ilharco, Christina Liu, Gabriel Barcik, Jannis Bulian, Jared Frank, Lucas Smaira, Qin Cao, Ricardo Marino, Roma Patel. ACL 2021. Papers 2022 Mapping Language Models to Grounded Conceptual Spaces. Roma Patel and Ellie Pavlick. ICLR 2022. Generalising to New Domains by Mapping Natural Language to Lifted LTL. Eric Hsiung, Hiloni Mehta, Junchi Chu, Xinyu Liu, Roma Patel, Stefanie Tellex, George Konidaris. ICRA 2022. 2021 Does linguistic bias affect generative language models Roma Patel and Ellie Pavlick. EMNLP 2021. Game-theoretic Vocabulary Selection for Text Classification Tasks Roma Patel, Marta Garnelo, Ian Gemp, Chris Dyer and Yoram Bachrach. NAACL 2021. Affordance-based Robot Object Retrieval Thao Nguyen, Nakul Gopalan, Roma Patel, Ellie Pavlick, Stefanie Tellex. AuRO 2021. 2020 Room-Across-Room Multilingual Vision-and Language Navigation with Dense Spatiotempral Grounding Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, Jason Baldridge. EMNLP 2020. On the Relationship Between Structure in Natural Language and Models of Sequential Decision Processes Roma Patel, Rafael Rodriguez-Sanchez, George Konidaris. LAREL Workshop, ICML 2020. Grounding Language to Non-Markovian Tasks with No Supervision of Task Specifications. Roma Patel, Ellie Pavlick, Stefanie Tellex. RSS 2020. Robot Object Retrieval with Contextual Natural Language Queries. Thao Nguyen, Nakul Gopalan, Roma Patel, Matthew Corsaro, Ellie Pavlick, Stefanie Tellex. RSS 2020. 2019 How to Get Past Sesame Street Sentence-Level Pretraining Beyond Language Modeling Alex Wang, Jan Hula, Patrick Xia, Raghavendra Pappagari, R. Thomas Mccoy, Roma Patel, Najoung Kim, Ian Tenney, Yinghui Huang, Katherin Yu, Shuning Jin, Berlin Chen, Benjamin Van Durme, Edouard Grave, Ellie Pavlick and Samuel R. Bowman. ACL 2019. PDF Planning with State Abstractions for Non-Markovian Task Specifications Yoonseon Oh, Roma Patel, Thao Nguyen, Baichuan Huang, Ellie Pavlick, Stefanie Tellex. RSS 2019. PDF Learning Visually Grounded Meaning Representations with Sketches Roma Patel, Stephen Bach and Ellie Pavlick. How2 Workshop, ICML 2019. PDF Learning to Ground Language to Temporal Logical Form. Roma Patel, Ellie Pavlick and Stefanie Tellex. SpLU RoboNLP Workshop, NAACL 2019. PDF Probing What Different NLP Tasks Teach Machines about Function Word Comprehension Najoung Kim, Roma Patel, Adam Poliak, Alex Wang, Patrick Xia, R. Thomas McCoy, Ian Tenney, Alexis Ross, Tal Linzen, Benjamin Van Durme, Samuel R. Bowman, Ellie Pavlick. StarSEM. 2019. Best Paper Award PDF Looking for ELMos Friends Sentence-Level Pretraining Beyond Language Modeling. Samuel R. Bowman, Ellie Pavlick, Edouard Grave, Benjamin Van Durme, Alex Wang, Jan Hula, Patrick Xia, Raghavendra Pappagari, R. Thomas McCoy, Roma Patel, Najoung Kim, Ian Tenney, Yinghui Huang, Katherin Yu, Shuning Jin, and Berlin Chen. Unpublished manuscript. 2019. PDF i 2018 Modeling Ambiguity in Text A Corpus of Legal Literature. Roma Patel and Ani Nenkova. Unpublished manuscript. 2018. PDF A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature. Benjamin Nye, Jessy Li, Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova and Byron Wallace. ACL 2018. PDF Syntactic Patterns Improve Information Extraction for Medical Literature Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova and Byron Wallace. NAACL 2018. PDF Lectures and Invited Talks Columbia University, Data Science Institue Title Learning from Patterns for Information Extraction for Medical Literature Princeton University, PACT Summer Program Title Network Flows In todays garden path sentences The prime number few. Powered by w3.css", "metadata": {"last_modified": "2022-02-17T16:43:02+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["About", "In today's garden path sentences: The prime number few."], "word_count": 953, "token_count_estimate": 1548}}, "https://cs.brown.edu/people/sbach/": {"text_content": "Stephen Bach Assistant Professor Computer Science Department Brown University, Providence, RI sbachcs.brown.edu CIT 335 Home BATS Projects Publications Teaching CV My latest research is on improving the processes by which humans teach and instruct computers.That includes engineering training data, with methods like programmatic weak supervision,as well as learning to generalize from fewer examples, with methods like zero-shot andfew-shot learning.Often, our groups methods focus on exploiting high-level, symbolic or otherwise semanticallymeaningful domain knowledge.Lately Im particularly excited by the ways these directions intersect.Applications of our work include information extraction, image understanding,scientific discovery, and other areas of data science. News Our work on GPT-4 and low-resource languages won the Best Paper Award at the NeurIPS Workshop on Socially Responsible Language Modelling Research SoLaR 2023 Our paper exploring strategies for using CLIP as a pseudolabeler for prompt tuning will appear at NeurIPS 2023 Our work on integrating large language models into weak supervision is accepted to the ACMIMS Journal of Data Science Alfred is accepted to ACL 2023 as a demo Alfred is a prototype system for prompted weak supervision. New preprints out on weak supervision in non-stationary environments and assessing the compositional abilities of CLIP . Our paper on learning to compose soft prompts is accepted to ICLR 2023 We show that foundation models like CLIP can be fine-tuned to be better at composing concepts into novel combinations. BATS I lead the BATS machine learning research group. In the tradition of groups like LINQS and DAGS , BATS stands for Bachs Awesome Teamof Students. Ph.D. Students Reza Esfandiarpoor Yeganeh Kordi Aidan LaBella Nihal Nayak Francisco Piedrahita-Velez Co-advised with Michael Littman Jasper Solt Co-advised with Jonathan Pober Zheng-Xin Yong Peilin Yu Max Zuo Co-advised with Michael Littman Post-Doc Cristina Menghini Masters and Undergrad Students Charlie Duong Sarah Liu Oliver Nan Kevin Scroggins Avi Trost Alumni Role, Year, Next Position Andy Delworth Undergrad, 2023, Hive AI Chace Hayhurst Undergrad Masters, 2023, MIT Lincoln Laboratory Andrew Yuan Undergrad, 2023, IMC Trading Ross Briden Undergrad, 2022, Affirm George Hu Undergrad, 2022, Masters at Stanford Top Piriyakulkij Undergrad, 2022, Ph.D. at Cornell Gaurav Sharma Masters, 2022, MathWorks Tom Liu Undergrad, 2022, Scale AI Jessica Dai Undergrad, 2021, Ph.D. at UC Berkeley Tiffany Ding Undergrad Masters, 2021, Ph.D. at UC Berkeley Amy Pu Undergrad, 2021, Google Dylan Sam Undergrad, 2021, Ph.D. at Carnegie Mellon Berkan Hiziroglu Masters, 2020, Amazon Angie Kim Undergrad, 2020, The New York Times Esteban Safranchik Undergrad, 2020, Ph.D. at U. Washington Projects T0 is a family of large languagemodels fine-tuned for zero-shot task generalization. In collaboration with manyothers in the BigScienceWorkshop , we showed that by fine-tuning T5 on many variations of prompts forsupervised tasks, the resulting model could generalize to completely new taskslike natural language inference. All the models are publicly available, and T0 is probably thebest one to use for new tasks. We also built an IDE and repository for promptdevelopment called PromptSource ACL demo paper that containsover 2,000 prompted tasks. ZSL-KG is a framework for zero-shot learning with common sense knowledge graphs. ZSL-KG learns to identify classes described as nodes in a knowledge graph. We have applied it toboth text and image tasks. ZSL-KG uses a novel graph neural network encoder calledtransformer graph convolutional network TrGCN. TrGCN increases the expressivityof traditional inductive graph neural networks by using small transformers toaggregate nodes. TAGLETS is a system forautomatic semi-supervised learning with auxiliary data. It automatically exploits all available data, including labeled, unlabeled, and auxiliary data, for a giventask to produce a single classifier. TAGLETS extracts relevant auxiliary data fortraining using SCADs, a database of auxiliary data aligned with concepts inConceptNet, and passes all relevant data to an ensemble of user-specified modules,which are trained and distilled into a final classifier. WISER is a framework for programmatic weak supervision in sequence-tagging domains liked named entityrecognition. Users write tagging rules that tag sequence elementslinking rules that guide how those elements should be grouped into coherentspans. We introduced this approach to avoid the common problem of candidategeneration, in which users first have to heuristically convert their problemfrom sequence tagging to classification. Now users can supervise the taggingprocess with rules directly Snorkel is a framework for creating noisytraining labels for machine learning. It uses statistical methods to combine weaksupervision sources like heuristic rules and task-related data sets, i.e., distantsupervision, which are far less expensive to use than hand labeling data. With theresulting estimated labels, users can train many kinds of state-of-the-art models.Snorkel is used at numerous technology companies like Google, research labs, andagencies like the FDA. Probabilistic soft logic is a formalism forbuilding statistical models over relational data like knowledge bases and socialnetworks. PSL programs define hinge-loss MRFs, a type of probabilistic graphicalmodel that admits fast, convex optimization for MAP inference, which makes themvery scalable. Researchers around the world have used PSL for bioinformatics,computational social science, natural language processing, information extraction,and computer vision. Teaching In spring semesters, I teach machine learning CSCI 1420. In fall semesters, I usually teach a seminar on learning with limited labeled data CSCI 2952-C.", "metadata": {"last_modified": "2023-12-29T19:18:51+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 830, "token_count_estimate": 1254}}, "https://cs.brown.edu/people/seny/": {"text_content": "Home Papers Talks Lab Blog Seny Kamara Associate Professor, Brown University Lab Encrypted Systems Lab blog email senybrown.edu twitter senykam pub key B80B 84AC 9C5D 174D Overview I am an Associate Professor of Computer Science at Brown University and a Distinguished Scientist at MongoDB where I manage the Advanced CryptographyResearch Group. Before its acquisition by MongoDB, I was co-founder and ChiefScientist at Aroki Systems. Prior to that, I was a research scientist at Microsoft Research . My research is in cryptography and is driven by real-world problems fromprivacy, security and surveillance. I have worked extensively on the design andcryptanalysis of encrypted search algorithms, which are efficient algorithms tosearch on end-to-end encrypted data. I maintain interests in various aspectsof theory and systems, including applied and theoretical cryptography, datastructures and algorithms, databases, networking, game theory and technology policy. I co-direct the Encrypted Systems Lab and amaffiliated with the CAPS group, the Data ScienceInitiative , the Center for Human Rights and HumanitarianStudies and the Policy Lab . If you are interested in working in the Encrypted Systems Lab, please read this before sending me an email. In the Fall, I teach Algorithms for thePeople blog a course that surveys, critiques andaspires to address the ways in which computer science technology affectmarginalized communities. News Check out and attend the first Workshop on the Theory and Practice of Encrypted Search TPES An article on the Aroki acquisition and MongoDBs queryable encryption Wired , TechCrunch I recently did a QA with Nature My congressional testimony to the U.S. House Committee on Space, Science and Technology written , video Our report on End-to-End Encryption and Content Moderation with CDT is available blog report Check out our collaboration with Browns CSREA on Technology and Structural Inequity Our collaboration with Sen. Wyden D-OR on an encrypted gun registry appeared at Oakland 21 paper , Wired , Brown I gave a keynote at CRYPTO 2020 on Crypto for the People video , slides , Wired , Brown Check out our new blog Algorithms for the People on tech marginalized communities Thank you to Google for the Faculty Research Award My congressional testimony to the Financial Services Committee of the U.S. House of Representatives written , video Im teaching a new course this semester that explores if and how cryptography can help marginalized groups Slides for my encrypted search tutorial SAC intro , leakage attacks , leakage suppression Check out the Brown Center for Human Rights and Humanitarian Studies A few articles about MongoDBs new Field Level Encryption and how we helped review it Wired , Decipher , Brown CS Thank you to Mozilla and the Responsible CS challenge for their support Videos of the ICERM workshop on encrypted search are up Check out Archita and Tariks talks A discussion with PBSs White House Chronicle on developments in crypto and CS video Check out Pixek , our end-to-end encrypted photo app You can readhear moreabout it at Wired , BoingBoing , the CBCSpark podcast, Real-WorldCrypto and OURSA You can find our National Academies of Science report on encryption and exceptional access here Advising Postdoc Tarik Moataz 2016-2019 PhD students Marilyn George , Victor Youdom Kemmoe , Kweku Kwegyir-Aggrey ,Leah Rosenbloom co-advised with Anna Lysyanskaya, Lucy Qin , Graduated PhD students Archita Agarwal , Ghous Amjad , Sam Zhao co-advised with Stan Zdonik MSR interns Sherman Chow , Anurag Khandelwal , Xianrui Meng , Naveed Muhammad , Tarik Moataz , Olya Ohrimenko , Charalampos Papamanthou , Mariana Raykova , Ben Riva , Saeed Sadeghian ,Lei Wei Teaching CS2952-v Algorithms for the People CS2950-v Topics in Applied Cryptography Crypto for Social Good CS16 Introduction to Algorithms and Data Structures Recent Papers Full List Outside Looking In Approaches to Content Moderation in End-to-End Encrypted Systems Seny Kamara, Mallory Knodel, Emma Llans, Greg Nojeim, Lucy Qin, Dhanaraj Thakur, Caitlin Vogus Report for Center for Democracy and Technology 21 report pdf Cryptanalysis of Encrypted Search with LEAKER A framework for LEakage AttacK Evaluation on Real-world data Seny Kamara, Abdelkarim Kati, Tarik Moataz, Thomas Schneider, Amos Treiber, Michael Yonli IACR ePrint full pdf , code Structured Encryption and Dynamic Leakage Suppression Marilyn George, Seny Kamara, Tarik Moataz Eurocrypt 21 proceedings pdf A Decentralized and Encrypted National Gun Registry Seny Kamara, Tarik Moataz, Andrew Park, Lucy Qin IEEE Symposium on Security and Privacy Oakland 21 full pdf , Lucys talk video , Wired Encrypted Databases From Theory to Practice Zheguang Zhao, Seny Kamara, Tarik Moataz, Stan Zdonik Conference on Innovative Data Systems Research CIDR 21 proceedings pdf Adversarial Level Agreements for Two-Party Protocols Marilyn George, Seny Kamara IACR ePrint full pdf Encrypted Key Value Stores Archita Agarwal, Seny Kamara Indocrypt 20 proceedings pdf Encrypted Blockchain Databases Daniel Adkins, Archita Agarwal, Seny Kamara, Tarik Moataz Advances in Financial Technologies 20 full pdf , blog Towards Untrusted Social Video Verification to Combat Deepfakes via Face Geometry Consistency Eleanor Tursman, Marilyn George, Seny Kamara, James Tompkin Media Forensics CVPR Workshop 20 proceedings pdf , Eleanors Talk An Optimal Relational Database Encryption Scheme Seny Kamara, Tarik Moataz, Stan Zdonik, Zheguang Zhao IACR ePrint full pdf Encrypted Distributed Hash Tables Archita Agarwal, Seny Kamara IACR ePrint full pdf , blog , Architas talk Revisiting Leakage-Abuse Attacks Laura Blackstone, Seny Kamara, Tarik Moataz NDSS 20 full pdf Computationally Volume-Hiding Structured Encryption Seny Kamara, Tarik Moataz Eurocrypt 19 full pdf Forward and Backward Private Searchable Encryption with SGX Ghous Amjad, Seny Kamara, Tarik Moataz Eurosec 19 proceedings pdf Encrypted Databases for Differential Privacy Archita Agarwal, Maurice Herlihy, Seny Kamara, Tarik Moataz PETS 19 full pdf Breach-Resistant Structured Encryption Ghous Amjad, Seny Kamara, Tarik Moataz PETS 19 full pdf SQL on Structurally-Encrypted Databases Seny Kamara, Tarik Moataz Asiacrypt 18 full pdf 3rd most influential paper in cryptography from 2018 Structured Encryption and Leakage Suppression Seny Kamara, Tarik Moataz, Olya Ohrimenko CRYPTO 18 proceedings pdf National Academies Consensus Report Decrypting the Encryption Debate . F. Cate Chair, D. Boneh, F. Chang, S. Charney, S. Goldwasser, D. Hoffman, S. Kamara, D. Kris, S. Landau, S.Lipner, R. Littlehale, K. Martin, H. Rishikof, P. Weinberger. report , overviewLawfare Boolean Searchable Symmetric Encryption with Worst-Case Sub-Linear Complexity Seny Kamara, Tarik Moataz Eurocrypt 17 proceedings pdf Projects Pixek an end-to-end encrypted camera app Martin Zhu, Tarik Moataz, Seny Kamara overviewapp VideoRWC18 VideoOURSA Wired CBC Spark BoingBoing Clusion an open source encrypted search library Tarik Moataz, Seny Kamara overview code Signal Search Joe Engelman, Sam Zhao, Tarik Moataz, Seny Kamara overview code Essays Surveys Summer School Selected Areas in Cryptography SAC, 2019 Encrypted Search Intro and Basics Encrypted Search Leakage Attacks Encrypted Search Leakage Suppression How to Search on Encrypted Data 1 , 2 , 3 , 4 , 5 Is the NSA Metadata Program Legal Restructuring the NSA Metadata Program MIT Tech Review Are Compliance and Privacy Always at Odds Lawfare How Not to Learn Cryptography", "metadata": {"last_modified": "2022-08-11T19:33:43+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Seny Kamara", "Overview", "News", "Advising", "Teaching", "Recent Papers (", ")", "Projects", "Essays & Surveys"], "word_count": 1134, "token_count_estimate": 1749}}, "https://scivis.at/": {"text_content": "Johannes Novotny, PhD. Publications Talks Teaching CV Johannes Novotny Researching Medical Visualization and Deep-Learning at VRVis Follow Vienna, Austria VRVis ResearchGate Github Google Scholar ORCID About - Johannes Novotny I am currently a Senior Research Engineer at the VRVis Zentrum fr Virtual Reality und Visualisierung Forschungs-GmbH , one of Austrias 25 Competence Centers for Excellent Technologies COMET . As part of the Biomedical Image Informatics group , I am following my research interests in the improvement of medical image analysis through a fusion of novel rendering styles with machine-learning methods and immersive output devices. I obtained my PhD. degree in David H. Laidlaws Visualization Research Lab VRL at Brown University in 2020, with my work focusing on Using Virtual Reality Effectively in Scientific Data Exploration - Perception, Usability and Design in Immersive Displays. Before my research work at Brown University, I worked as a research scholar at the UC Davis VIDi group to develop remote real-time volume rendering applications. I hold an M.S. degree in visual computing and a BSc. degree in medical computer science from the Vienna University of Technology . Sitemap Follow GitHub Feed 2024 Johannes Novotny. Powered by Jekyll AcademicPages , a fork of Minimal Mistakes .", "metadata": {"last_modified": "2024-02-06T17:10:05+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["About - Johannes Novotny"], "word_count": 200, "token_count_estimate": 265}}, "https://browncsdug.com/": {"text_content": "Skip to content BROWN CS DUG Empowering Brown undergraduate students in computer science. view our events Join us on Discord Community Connect and network with a community of passionate computer science students at Brown. Academic Programs Access resources and learn more about the academic opportunities you have at Brown and in the CS department. Career Programs Discover professional opportunities and prepare for internships and jobs in computer science. CS DUG Events See below for event announcements and other news from the CS DUG To be the first to hear about our events, we recommend you join our Discord server. CS Concentration Declaration Party 2024 Date Monday, March 18, 2024 Time 830pm 1000pm Location Hazeltine Commons Barus and Holley Pi Day 2024 Date Thursday, March 14, 2024 Time 930am 430pm Location Hazeltine Commons Barus and Holley CS Formal 2023 Date Friday, November 17, 2023 Time 900pm 100am Location Sayles Hall About Us The Computer Science DUG works with the Brown CS department to best support undergraduates concentrating in CS We are here to help you make the most out of your academics at Brown and achieve all your career goals. Mission Statement The Brown Computer Science Departmental Undergraduate Group, more fondly called the CS DUG, was created to empower the undergraduate community of Browns Computer Science department, increase undergraduate participation, and continue Browns legacy of involved undergraduates. Organizing a broad range of activities from social mixers to technical talks, the DUG is always interested in new ideas to foster campus engagement and has historically been involved in many undergraduate computer science events. Activities and Events The DUG organizes a broad range of activities from social mixers to technical talks. The DUG is always interested in new ideas to foster computer science on campus and has historically been involved in many undergraduate computer science events. Lets talk Students can contact us with suggestions Companies can contact us with recruitment opportunities or other offers Lets talk email protected", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["BROWN CS DUG", "About Us", "Mission Statement", "Activities and Events", "Let\u2019s talk!"], "word_count": 325, "token_count_estimate": 405}}, "https://cs.brown.edu/people/staff/pvars/": {"text_content": "Paul D Vars Senior Hardware Technician Phone 401-863-7625 Email pvars cs.brown.edu", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "Paul D Vars"], "word_count": 11, "token_count_estimate": 22}}, "https://cs.brown.edu/people/staff/kkirman/": {"text_content": "Kathy Kirman Billings Project and Financial Manager Office CIT 572 Phone 401-863-7627 Email kathleenkirman brown.edu", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "Kathy Kirman Billings"], "word_count": 15, "token_count_estimate": 30}}, "http://jrenzhile.com": {"text_content": "Zhile Ren Email jrenzhile -at- gmail.com I work at Apple on hardware-aware efficient-ML frameworks, as well as 3D vision applications. Before that, I worked at Georgia Tech as a Postdoc with Dhruv Batra , Devi Parikh , and Irfan Essa . I got my PhD in Brown University working with Erik Sudderth in the computer science department. I did my undergrad in statistics at Zhejiang University . Google Scholar LinkedIn Curriculum Vitae in PDF Research Projects UPSCALE Unconstrained Channel Pruning Alvin Wan, Hanxiang Hao, Kaushik Patnaik, Sam Xu, Omer Hadad, David Gera, Zhile Ren , Qi Shan International Conference on Machine Learning ICML 2023 Paper Code AutoFocusFormer Image Segmentation off the Grid Chen Ziwen, Kaushik Patnaik, Shuangfei Zhai, Alvin Wan, Zhile Ren , Alexander G. Schwing, Alex Colburn, Li Fuxin IEEE Conference on Computer Vision and Pattern Recognition CVPR 2023 Paper Code Generative Multiplane Images Making a 2D GAN 3D-Aware Xiaoming Zhao, Fangchang Ma, David Gera, Zhile Ren , Alexander G. Schwing, Alex Colburn European Conference on Computer Vision ECCV 2022 oral presentation Paper Project Page FvOR Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction Zhenpei Yang, Zhile Ren , Miguel Angel Bautista, Zaiwei Zhang, Qi Shan, Qixing Huang IEEE Conference on Computer Vision and Pattern Recognition CVPR 2022 Paper Code MVS2D Efficient Multi-view Stereo via Attention-Driven 2D Convolutions Zhenpei Yang, Zhile Ren , Qi Shan, Qixing Huang IEEE Conference on Computer Vision and Pattern Recognition CVPR 2022 Paper Project Page Semantic MapNet Building Allocentric Semantic Maps and Representations from Egocentric Views Vincent Cartillier, Zhile Ren , Neha Jain, Stefan Lee, Irfan Essa, Dhruv Batra AAAI Conference on Artificial Intelligence AAAI 2021 Media coverage Venture Beat , MIT Technology Review , Digital Trends , ZDNet Paper Project Page Clouds of Oriented Gradients for 3D Detection of Objects, Surfaces, and Indoor Scene Layouts Zhile Ren , Erik Sudderth IEEE Transactions on Pattern Analysis and Machine Intelligence T-PAMI 2020 Paper Cross-Channel Communication Networks Jianwei Yang, Zhile Ren , Chuang Gan, Hongyuan Zhu, Devi Parikh Neural Information Processing Systems NeurIPS 2019 Paper Poster Code Embodied Amodal Recognition Learning to Move to Perceive Objects Jianwei Yang, Zhile Ren , Mingze Xu, Xinlei Chen, David Crandall, Devi Parikh, Dhruv Batra Equal Contribution IEEE International Conference on Computer Vision ICCV 2019 Paper MLGT Blog 3D Scene Reconstruction with Multi-layer Depth and Epipolar Transformers Daeyun Shin, Zhile Ren , Erik Sudderth, Charless Fowlkes IEEE International Conference on Computer Vision ICCV 2019 Paper Supplementary Video Project Page A Fusion Approach for Multi-Frame Optical Flow Estimation Zhile Ren , Orazio Gallo, Deqing Sun, Ming-Hsuan Yang, Jan Kautz, Erik Sudderth IEEE Winter Conference on Applications of Computer Vision WACV 2019 Nov 2019 MFF consistently ranks top-2 among published flow methods in KITTI and MPI Sintel Paper Project Page Supplementary Video 3D Object Detection with Latent Support Surfaces Zhile Ren , Erik Sudderth IEEE Conference on Computer Vision and Pattern Recognition CVPR 2018 Paper Code Latent-SSVM Cascaded Scene Flow Prediction using Semantic Segmentation Zhile Ren , Deqing Sun, Jan Kautz, Erik Sudderth International Conference on 3D Vision 3DV 2017 oral presentation Paper Supplementary Talk Slides Three-Dimensional Object Detection and Layout Prediction using Clouds of Oriented Gradients Zhile Ren , Erik Sudderth IEEE Conference on Computer Vision and Pattern Recognition CVPR 2016 oral presentation Paper Supplementary Detection Results Talk Slides Talk Recording Robust Graph SLAM in Dynamic Environments with Moving Landmarks Lingzhu Xiang, Zhile Ren , Mengrui Ni, Odest Chadwicke Jenkins IEEERSJ International Conference on Intelligent Robots and Systems IROS 2015 Paper Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes Pierre-Yves Laffont, Zhile Ren , Xiaofeng Tao, Chao Qian and James Hays ACM Transactions on Graphics SIGGRAPH 2014 Media coverage Brown News , NBC News , IEEE Spectrum , PBS , Mic Gizmodo Paper Project Page Code Color Transformation Talk Recording Image Segmentation by Cascaded Region Agglomeration Zhile Ren , Greg Shakhnarovich IEEE Conference on Computer Vision and Pattern Recognition CVPR 2013 Paper Supplementary Results Thesis Semantic Three-Dimensional Understanding of Dynamic Scenes Zhile Ren Doctoral Thesis, Brown University, May 2018 Thesis Miscellaneous Almost Everyone calls me Ren You can find me in social networks Facebook Instagram Twitter Goodreads Strava", "metadata": {"last_modified": "2023-07-16T23:17:20+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 691, "token_count_estimate": 1070}}, "https://cs.brown.edu/people/sk/": {"text_content": "Shriram Krishnamurthi Professor of Computer Science Brown PLT and CS Ed Bootstrap Computer Science Department Brown University Contact with Calendar Papers Talks Teaching Service Personal I do not have a research area so much as a research vision Abstractions are essential for progress in computing. Abstractions can also be hard to understand and learn. But abstraction is also beautiful . How do we help people effectively learn about abstractions My goal is quite simply to make progress on as many angles as possibleof this vision. My work is informed by my background. I was primarily trained in programming languages , but I have since trained myself in various aspects of software engineering , formal methods , HCI , security , and networking .Over the years I have contributed to several innovative anduseful software systems JavaScript tools , Flowlog , Racket formerly DrScheme, WeScheme , Margrave , Flapjax , FrTime , Continue , FASTLINK , PerMission ,and more.Currently, I mainly work on Pyret .For more of what Ive been doing lately, please see my research groups blog . Since 2016 manifesto , I have devoted a substantial portion of my time and energy to the hardest problem Ive worked on computing education research . Its the hardest because it requires substantial work on both technical and human-factors fronts the audience is often unsophisticated and vulnerable and if you screw up, you can do real damage to not only individuals but also the field and society. The research vision above is the distillation of the direction of my computing education research. I have been doing computing outreach since 1995. You may may know me through my co-authored books like HtDP , PLAI ,or DCIC formerly PAPL .Our current outreach program, Bootstrap , is usedinternationally to integrate computing into math, physics,social studies, and other disciplines. I have been privileged to work with a group of impressive PhD students Paul Graunke , Greg Cooper , Jay McCarthy , Danny Yoo , Arjun Guha , Tim Nelson , Joe Politz , Hannah Quay-de la Vallee , Justin Pombrio , and Jack Wrenn and currently, Kuang-Chen Lu , Elijah Rivera , and Siddhartha Prasad . I have also been delighted to work with several outstanding post-docs Serge Egelman , Ben Lerner , Tim Nelson , Tess Strickland , Tristan Dyer , Ben Greenman and currently, Will Crichton . Finally, Ive equally chuffed to have done research with several excellent masters students and over 50 amazing undergraduates. Im honored to be a recipient of SIGPLANs Robin Milner Young Researcher Award , SIGPLANs Distinguished Educator Award jointly, SIGSOFTs Influential Educator Award , SIGPLANs Software Award jointly, and Brown Universitys Wriston Fellowship . Disclosure My work has been supported financially by theUS National Science Foundation,DARPA,Amazon,Bloomberg,Cisco,Code.org,CSNYC,the ESA Foundation,Fujitsu,General Motors,Google,Infosys,Jane Street Capital,Meta,RelationalAI,Roblox,the State of Rhode Island, andTripAdvisor.I believe my views have not beenswayed by this support, but I provide this information so you canjudge for yourself. My names are not spelled Sriram or Shiram or Khrishnamurthi or Krishnamurthy orKrishnamurti like the philosopher. Find me, o search engine, findme", "metadata": {"last_modified": "2023-10-08T20:07:05+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Shriram Krishnamurthi"], "word_count": 507, "token_count_estimate": 702}}, "https://www.tamassia.net": {"text_content": "Search this site Skip to main content Skip to navigation Roberto Tamassia Isabel Cruz Roberto Tamassia James A. Julie N. Brown Professor of Computer Science Chair, Department of Computer Science Brown University CV Contact Faculty Affairs Manager Kate Correia In Memoriam Isabel Cruz Journal of Graph Algorithms and Applications Copyright 2021-23 Roberto Tamassia. All rights reserved. September 15, 2023 Google Sites Report abuse Page details Page updated Google Sites Report abuse", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 71, "token_count_estimate": 93}}, "https://cs.brown.edu/people/staff/slm10/": {"text_content": "Steven Martins Lead System Administrator Email stevenmartins brown.edu", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "Steven Martins"], "word_count": 8, "token_count_estimate": 12}}, "https://cs.brown.edu/people/stellex/": {"text_content": "Main Main Main Publications Research Personal projects Welcome to my home page. I am an assistant professor in the ComputerScience Department at Brown University .The aim of my research program is to construct robots that seamlesslyuse natural language to communicate with humans. In twenty years,every home will have a personal robot which can perform tasks such as clearing thedinner table , doing laundry ,and preparingdinner . As these machines become more powerful and moreautonomous, it is critical to develop methods for enabling people totell them what to do. Robots that can communicate with people usinglanguage can respondappropriately to commands given by humans, ask questions when they areconfused, and request help when they get stuck. We apply probabilistic methods, corpus-basedtraining, and decision theory to develop interactive robotic systemsthat can understand and generate natural language.I completed my Ph.D. at the MIT Media Lab in 2010, where I developedmodels for the meanings of spatial prepositions and motion verbs. Mypostdoctoral work at MIT CSAIL focused on creating robots thatunderstand natural language. I have published at SIGIR, HRI, RSS,AAAI, IROS, and ICMI, winning Best Student Paper at SIGIR and ICMI. Iwas named one of IEEE Spectrums AIs 10 to Watch and won the RichardB. Salomon Faculty Research Award at Brown University. Here is our language-understanding system running on a forklift Direction-understanding on a robotic helicopter Direction-understanding for the PR2 I am also interested in reinforcement learning as applied tohuman-cat communicationprojectsgizmo.html", "metadata": {"last_modified": "2014-08-06T20:58:45+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Main"], "word_count": 235, "token_count_estimate": 324}}, "https://cs.brown.edu/people/staff/jbazik/": {"text_content": "John Bazik Director of Information Technology Office CIT 573 Phone 401-863-7624 Email johnbazik brown.edu Home Page John has more than thirty years of experience as a software engineer and system administrator. As Director of Information Technology, he leads the Computer Science Departments Technical Staff which maintains the systems and services that support the departments research and educational mission. Vendors I am not the droid you are looking for. For Brown campus-wide IT, visit httpsit.brown.eduaboutleadership .", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "John Bazik"], "word_count": 75, "token_count_estimate": 101}}, "https://cs.brown.edu/people/tbn/": {"text_content": "Tim Nelson Lecturer in Computer Science Brown Computer Science E-mail tbn at cs dot brown dot edu Office CIT 355 Publications Service Teaching I am part of the PLT Group at Brown University Computer Science .Im interested in user-facing formal methods and formal-methods education, as well as applications like language design for network programming. Teaching is a major focus for me. Among other courses, I run Logic for Systems , a class that turns the usualformal-logic syllabus on its head by focusing on applications and tools. In the past, we used the excellent Alloy we now use our own pedagogically-focused version of Alloy, Forge . A note on my email address I used to be tn, not tbn. Unfortunately, times change andinstitutional policies become better enforced. Rather than spend my time engaging in a quixotic battle over one keystroke, Ive decided to view this as a mark of approvalthe Powers that Be have granted me one more letter in my login name. TLDR please use tbn, not tn, to avoid potential delays and other issues.", "metadata": {"last_modified": "2023-09-09T20:06:54+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 175, "token_count_estimate": 217}}, "https://cs.brown.edu/people/staff/spoc/": {"text_content": "The SPOCs SPOCs Systems Programmer, Operator, and Consultants assist in theinstallation, maintenance, development, and documentation of localsoftware. In addition, they represent the off-hours technical supportstaff, and assist with administrative tasks. The current SPOCs are Austin Miles Sophia Liu Jiahua Chen Kevin Lu Bokai Bi Edward Wibowo amiles6 sliu176 jchen345 klu25 bbi1 ewibowo How to get help In general, the best way to get help is to email problemcs.brown.edu more info . This helps us deal with problemsmost efficiently. If an issue needs immediate attention, you can try emailing the on-duty SPOC see the below schedule. On nights, weekends, and holidays, at least one SPOC will always beresponsible for reading submitted problem tickets remote coverage. Onweeknights, a SPOC will also be in the building to deal with requests inperson. Current Schedule The schedule is available as a Google Calendar Additional support resources Department Systems information documentation After-hours support information Reporting problems", "metadata": {"last_modified": "2024-02-22T03:00:52+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "The SPOCs", "How to get help", "Current Schedule", "Additional support resources"], "word_count": 150, "token_count_estimate": 217}}, "https://cs.brown.edu/people/ycheng79/": {"text_content": "Yu Cheng Home Research Misc I am an Assistant Professor in the Department of Computer Science at Brown University. I received my Ph.D. from the University of Southern California in 2017, advised by Shang-Hua Teng .I was a postdoc at Duke University , a visiting member at the Institute for Advanced Study , and an Assistant Professor at the University of Illinois at Chicago . My Research My main research interests include machine learning, optimization, and game theory.My recent work focuses on the design and analysis of scalable and provably robust algorithms for machine learning, especially in the areas of high-dimensional robust statistics, non-convex optimization, and learning with strategic agents. Email yucheng AT brown.edu Office CIT 413, 115 Waterman St, Providence, RI 02906. My CV and papers by date or by topic . Teaching Spring 2024 CSCI1952Q Algorithmic Aspects of Machine Learning . Fall 2023 CSCI2952Q Robust Algorithms for Machine Learning . Spring 2023 CSCI1952Q Algorithmic Aspects of Machine Learning . Fall 2022 CSCI2952Q Robust Algorithms for Machine Learning . Fall 2021 MCS 401 Computer Algorithms I . Fall 2021 MCS 425 Codes and Cryptography . Fall 2020 MCS 401 Computer Algorithms I . Fall 2020 MCS 425 Codes and Cryptography . Spring 2020 MCS 425 Codes and Cryptography . Spring 2020 MCS 590 Spectral Graph Theory . Research Group Current Ph.D. Students Binhao Chen Xing Gao co-advised with Lev Reyzin Former Undergraduate Students Haichen Dong Honghao Lin Publications Tight Lower Bounds for Directed Cut Sparsification and Distributed Min-Cut. Yu Cheng, Max Li , Honghao Lin , Zi-Yi Tai , David P. Woodruff , Jason Zhang . PODS 2024. Robust Matrix Sensing in the Semi-Random Model. Xing Gao ,Yu Cheng. NeurIPS 2023. Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing. Shuyao Li ,Yu Cheng, Ilias Diakonikolas , Jelena Diakonikolas , Rong Ge , Stephen Wright . NeurIPS 2023. Hiding Data Helps On the Benefits of Masking for Sparse Coding. arXiv Muthu Chidambaram , Chenwei Wu ,Yu Cheng, Rong Ge . ICML 2023. Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation. Hanrui Zhang ,Yu Cheng, Vincent Conitzer . EC 2023. Outlier-Robust Sparse Estimation via Non-Convex Optimization. arXiv , slides Yu Cheng, Ilias Diakonikolas , Rong Ge , Shivam Gupta , Daniel M. Kane , Mahdi Soltanolkotabi . NeurIPS 2022. Efficient Algorithms for Planning with Participation Constraints. arXiv Hanrui Zhang ,Yu Cheng, Vincent Conitzer . EC 2022. Planning with Participation Constraints. pdf Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2022. Sparsification of Directed Graphs via Cut Balance. arXiv Ruoxu Cen ,Yu Cheng, Debmalya Panigrahi , Kevin Sun . ICALP 2021. Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time. arXiv Yu Cheng, Honghao Lin . ICLR 2021. Fair for All Best-effort Fairness Guarantees for Classification. arXiv Anilesh Krishnaswamy , Zhihao Jiang , Kangning Wang ,Yu Cheng, Kamesh Munagala . AISTATS 2021. Classification with Few Tests through Self-Selection. pdf Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2021. Automated Mechanism Design for Classification with Partial Verification. arXiv Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2021. High-Dimensional Robust Mean Estimation via Gradient Descent. arXiv , slides Yu Cheng, Ilias Diakonikolas , Rong Ge , Mahdi Soltanolkotabi . ICML 2020. Distinguishing Distributions When Samples Are Strategically Transformed. pdf Hanrui Zhang ,Yu Cheng, Vincent Conitzer . NeurIPS 2019. Group Fairness in Committee Selection. arXiv Yu Cheng, Zhihao Jiang , Kamesh Munagala , Kangning Wang . EC 2019. Faster Algorithms for High-Dimensional Robust Covariance Estimation. arXiv , slides , talk video Yu Cheng, Ilias Diakonikolas , Rong Ge , David P. Woodruff . COLT 2019. When Samples Are Strategically Selected. pdf Hanrui Zhang ,Yu Cheng, Vincent Conitzer . ICML 2019. A Better Algorithm for Societal Tradeoffs. pdf Hanrui Zhang ,Yu Cheng, Vincent Conitzer . AAAI 2019. High-Dimensional Robust Mean Estimation in Nearly-Linear Time. arXiv , slides Yu Cheng, Ilias Diakonikolas , Rong Ge . SODA 2019. A Simple Mechanism for a Budget-Constrained Buyer. arXiv Yu Cheng, Nick Gravin , Kamesh Munagala , Kangning Wang . WINE 2018 Best Paper Award. Robust Learning of FixedStructure Bayesian Networks. arXiv Yu Cheng, Ilias Diakonikolas , Daniel M. Kane , Alistair Stewart . NeurIPS 2018. Non-Convex Matrix Completion Against a Semi-Random Adversary. arXiv , slides , talk video Yu Cheng, Rong Ge . COLT 2018. A Deterministic Protocol for Sequential Asymptotic Learning. arXiv Yu Cheng, Wade Hann-Caruthers , Omer Tamuz . ISIT 2018. On the Distortion of Voting with Multiple Representative Candidates. arXiv , slides Yu Cheng, Shaddin Dughmi , David Kempe . AAAI 2018. Computational Aspects of Optimal Information Revelation. pdf , slides , talk video Yu Cheng. Ph.D. Thesis. University of Southern California, 2017. Of the People Voting Is More Effective with Representative Candidates. arXiv , slides , talk video Yu Cheng, Shaddin Dughmi , David Kempe . EC 2017. Well-Supported versus Approximate Nash Equilibria Query Complexity of Large Games. arXiv , slides , talk video Xi Chen ,Yu Cheng, Bo Tang . ITCS 2017. Playing Anonymous Games using Simple Strategies. arXiv , slides Yu Cheng, Ilias Diakonikolas , Alistair Stewart . SODA 2017. On the Recursive Teaching Dimension of VC Classes. ECCC , talk video Xi Chen ,Yu Cheng, Bo Tang . NIPS 2016. Hardness Results for Signaling in Bayesian Zero-Sum and Network Routing Games. arXiv , slides Umang Bhaskar ,Yu Cheng, Young Kun Ko , Chaitanya Swamy . EC 2016. Mixture Selection, Mechanism Design, and Signaling arXiv , slides , talk video Yu Cheng, Ho Yee Cheung , Shaddin Dughmi , Ehsan Emamjomeh-Zadeh , Li Han , Shang-Hua Teng . FOCS 2015. Signaling in Quasipolynomial Time arXiv Yu Cheng, Ho Yee Cheung , Shaddin Dughmi , Shang-Hua Teng . Efficient Sampling for Gaussian Graphical Models via Spectral Sparsification arXiv Part I and Part II , slides Dehua Cheng ,Yu Cheng, Yan Liu , Richard Peng , Shang-Hua Teng . COLT 2015.", "metadata": {"last_modified": "2024-01-26T05:03:53+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Teaching", "Research Group", "Publications"], "word_count": 970, "token_count_estimate": 1656}}, "https://cs.brown.edu/research/areas.html": {"text_content": "General Areas of Research Algorithms and Theory Primary Yu Cheng , Lorenzo De Stefani , Pedro F Felzenszwalb , Shahrzad Haddadan , Ellis Hershkowitz , Sorin Istrail , Serdar Kadioglu , Philip Klein , Franco Preparata , Benjamin J Raphael , Roberto Tamassia , Eli Upfal Secondary Tim Nelson , Suresh Venkatasubramanian Artificial Intelligence Primary Alper Ahmetoglu , Stephen Bach , Eugene Charniak , Thomas L Dean , Carsten Eickhoff , Pedro F Felzenszwalb , Amy R Greenwald , Serdar Kadioglu , George D Konidaris , Michael L. Littman , David Paulius , Ellie Pavlick , Daniel C Ritchie , Ankit J Shah , Srinath Sridhar , Chen Sun , Stefanie A Tellex Secondary Nora Ayanian , Eli Upfal Computational Biology Primary Thomas L Dean , Sorin Istrail , David H. Laidlaw , Mark E Nadel , Franco Preparata , Sohini Ramachandran , Benjamin J Raphael , Ritambhara Singh Secondary Eli Upfal Computer Systems R. Iris Bahar , Theophilus A Benson , Thomas W Doeppner , Rodrigo Fonseca , Vasileios Kemerlis , Sherief Reda , Malte Schwarzkopf , Alan M Usas , Nikos Vasilakis Computer Vision Thomas L Dean , Pedro F Felzenszwalb , Daniel C Ritchie , Srinath Sridhar , Chen Sun , Gabriel Taubin , James H Tompkin Computing Education Primary Kathi Fisler , Shriram Krishnamurthi , Tim Nelson , Alexander Steinmaurer , Alan M Usas , Milda Zizyte Secondary Robert Y. Lewis Data Science Primary Stephen Bach , Karianne Bergen , Bruce Donald Campbell , Ugur Cetintemel , Andrew Crotty , Carsten Eickhoff , Pedro F Felzenszwalb , Jeff Huang , Serdar Kadioglu , David H. Laidlaw , Ellie Pavlick , Sohini Ramachandran , Matteo Riondato , Roberto Tamassia , Eli Upfal Secondary Shahrzad Haddadan , Tom Sgouros Database Systems Primary Carsten Binnig , Ugur Cetintemel , Andrew Crotty , Tim K Kraska , Stanley B Zdonik Secondary Malte Schwarzkopf Distributed Systems Theophilus A Benson , Ugur Cetintemel , Rodrigo Fonseca , Maurice P Herlihy , Malte Schwarzkopf , Nikos Vasilakis , Stanley B Zdonik Geometric Modeling Gabriel Taubin Graphics and Visualization Bruce Donald Campbell , John F Hughes , David H. Laidlaw , Joseph J Laviola , Barbara J. Meier , Steven P Reiss , Daniel C Ritchie , Gabriel Taubin , James H Tompkin , Andries van Dam Human-Computer Interaction Primary Adam Blumenthal , Bruce Donald Campbell , Thomas L Dean , Jeff Huang , Jose James , Shriram Krishnamurthi , David H. Laidlaw , Joseph J Laviola , Steven P Reiss , Donald L Stanford , James H Tompkin , Ernesto Zaldivar Secondary Norm Meyrowitz , Srinath Sridhar Machine Learning Primary Stephen Bach , Karianne Bergen , Eugene Charniak , Yu Cheng , Thomas L Dean , Carsten Eickhoff , Pedro F Felzenszwalb , Serdar Kadioglu , George D Konidaris , Michael L. Littman , Ellie Pavlick , Sohini Ramachandran , Daniel C Ritchie , Ritambhara Singh , Srinath Sridhar , Chen Sun , Stefanie A Tellex , Eli Upfal Secondary Lorenzo De Stefani , Suresh Venkatasubramanian Networking Primary Theophilus A Benson , Rodrigo Fonseca , Shriram Krishnamurthi Secondary Tim Nelson Programming Languages Primary Kathi Fisler , Shriram Krishnamurthi , Robert Y. Lewis , Nikos Vasilakis Secondary Tim Nelson Robotics Alper Ahmetoglu , Nora Ayanian , R. Iris Bahar , Thomas L Dean , Ian Gonsher , George D Konidaris , Joseph J Laviola , Michael L. Littman , David Paulius , Ankit J Shah , Srinath Sridhar , Stefanie A Tellex , Milda Zizyte Security Primary Vasileios Kemerlis , Nikos Vasilakis , Ernesto Zaldivar Secondary Eli Upfal Security and Cryptography Seny F Kamara , Shriram Krishnamurthi , Anna A Lysyanskaya , Peihan Miao , Tarik Moataz , Bernardo Palazzi , Steven P Reiss , Donald L Stanford , Roberto Tamassia , Alan M Usas Software Engineering Primary Shriram Krishnamurthi , Norm Meyrowitz , Tim Nelson , Steven P Reiss , Tom Sgouros , Milda Zizyte Secondary Vasileios Kemerlis Theory Primary Peihan Miao , Eli Upfal Secondary Robert Y. Lewis , John E Savage Specialized Areas of Research 3D Photography Gabriel Taubin 3D Scanning Gabriel Taubin Algorithmic Fairness Primary Tom Sgouros , Suresh Venkatasubramanian Secondary Shahrzad Haddadan , Michael L. Littman Algorithmic Game Theory Amy R Greenwald Computational Geosciences Karianne Bergen Computer Architecture R. Iris Bahar , Sherief Reda , Donald L Stanford Deep Learning Primary Alper Ahmetoglu , Eugene Charniak , Thomas L Dean , Carsten Eickhoff , Sherief Reda , Daniel C Ritchie , Ritambhara Singh , Srinath Sridhar , Chen Sun Secondary Eli Upfal Design Adam Blumenthal , Ian Gonsher , Jeff Huang , David H. Laidlaw , Steven P Reiss Digital Geometry Processing Gabriel Taubin Formal Methods Primary Kathi Fisler , Shriram Krishnamurthi , Robert Y. Lewis , Tim Nelson , Steven P Reiss , Milda Zizyte Secondary Mark E Nadel Haptics Jose James Multi-Agent Systems Primary Amy R Greenwald Secondary Nora Ayanian Natural Language Processing Primary Adam Blumenthal , Thomas L Dean , Carsten Eickhoff , Ellie Pavlick Secondary David Paulius Randomized Algorithms and Probabilistic Analysis Primary Eli Upfal Secondary Lorenzo De Stefani , Matteo Riondato Reinforcement Learning Thomas L Dean , Amy R Greenwald , Michael L. Littman Security Policy Timothy H Edgar , John E Savage , Ernesto Zaldivar Signal Processing Karianne Bergen Virtual Reality Adam Blumenthal , Jose James", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Information for:", "General Areas of Research", "Algorithms and Theory", "Artificial Intelligence", "Computational Biology", "Computer Systems", "Computer Vision", "Computing Education", "Data Science", "Database Systems", "Distributed Systems", "Geometric Modeling", "Graphics and Visualization", "Human-Computer Interaction", "Machine Learning", "Networking", "Programming Languages", "Robotics", "Security", "Security and Cryptography", "Software Engineering", "Theory", "Specialized Areas of Research", "3D Photography", "3D Scanning", "Algorithmic Fairness", "Algorithmic Game Theory", "Computational Geosciences", "Computer Architecture", "Deep Learning", "Design", "Digital Geometry Processing", "Formal Methods", "Haptics", "Multi-Agent Systems", "Natural Language Processing", "Randomized Algorithms and Probabilistic Analysis", "Reinforcement Learning", "Security Policy", "Signal Processing", "Virtual Reality"], "word_count": 883, "token_count_estimate": 1420}}, "https://cs.brown.edu/research/mri/mri_repository.html": {"text_content": "Brown-Edinburgh Diffusion MRI Resource This page presents a diffusion MRI resource of 80 normal subjects includingdemographic and neuropsychological measures. This work is supported by NIHR01 EB004155 in collaboration between David H. Laidlaw in the Visualization Research Lab atBrown University and Mark E. Bastin at University of Edinburgh. Under an IRB-approved protocol, diffusion-weighted MR images were acquired froma population of healthy volunteers, including a group of 80 normal aginghealthy controls. The subjects comprised a cross-sectional normal agingpopulation, which consisted of nearly equal number of each sex and roughlyuniformly distributed ages ranging from 25 to 65 years old. Imaging wasconducted on a GE 1.5T scanner with 2x2x2mm voxels and image resolution128x128x72. For each diffusion scan, seven baseline volumes were acquired, andthe diffusion-weighted images used a single-shell high angular resolutiondiffusion encoding scheme with 64 distinct gradient encoding directions at ab-value of 1000 smm2. To gain access to the dataset, please send a request containing your name,institution, and a brief description of your research interest to David H. Laidlaw at or Ryan P. Cabeen at . The data release page can then be accessed here .", "metadata": {"last_modified": "2016-10-10T17:43:05+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Brown-Edinburgh Diffusion MRI Resource"], "word_count": 182, "token_count_estimate": 265}}, "https://cs.brown.edu/research/plt/": {"text_content": "Computer Science Brown University Brown PLT Welcome to Brown PLT Located in beautiful, historic Providence , our work unifies under themes of design, learning, and languages. We build languages, analyze them, and take them apart. We work on verification and other forms of formal methods. We create environments and other tools for working with languages and verifiers. We also write books for understanding these topics. If you want to learn more or join us, get in touch Pyret Pyret is the main language were currently working on. We combine the best of functional and scripting languages to create an outstanding language for teaching and, down the road, general-purpose programming. Pyret is an umbrella for several efforts in compilation, type systems, error-reporting, language design, and much more. Forge Forge is a new tool and collection of languages for formal modeling. Forge is heavily inspired by Alloy, but offers its own opinionated take on modeling, analysis, and verification. DCIC A Data-Centric Introduction to Computing is a new book that lays out our research-driven approach to learning programming, following our data-centric perspective . Suppporting it requires a lot of the other work described on this page. PLAI Programming Languages Application and Interpretation is our programming languages book, in widespread use. All three editions are available online. People We have five faculty members Shriram Krishnamurthi , Kathi Fisler , Rob Lewis , Tim Nelson , Milda Zizyte , one post-doc Will Crichton , five PhD students Yanyan Ren , Kuang-Chen Lu , Elijah Rivera , Siddhartha Prasad , Skyler Austen , several undergraduates, and a research programmer Dorai Sitaram . Several other faculty in the department have done work that is related to ours, including Maurice Herlihy , Vasileios Kemerlis , Michael Littman , Steve Reiss , Daniel Ritchie , Malte Schwarzkopf , Nikos Vasilakis . Finally, we also collaborate with several faculty at other universities most notably Ben Lerner and Joe Politz and with the rest of Bootstrap . Location We are very convenient located in the greater-Boston area in the Northeast of the USA. If youre in the area, let us know Many of our talks are co-located with the systems folk. Other Groups Our take on programming languages strikes a balance between theory, systems, HCI, and more. As a result we often work closely with people in the systems and computing education groups. Blog We often blog about our work . Our blog is a convenient, lightweight way to learn about some of our research. Talks Thanks to our convenient location , we host numerous speakers. Since we share many interests with them, our talks are co-located with the systems folk. Papers All of our papers are online . They have associated repositories of code, data, proofs, and other artifiacts, as appropriate. Repositories Most of our recent work is in our github repository , although individual papers have their own repositories elsewhere. In general, a papers page above is the best source for material about that paper. Other Systems We view research and building systems as complementary and mutually-reinforcing. We have worked and in some cases continue to work on research-driven systems used by many other people, including JavaScript and Web tools , Flowlog and related tools , Racket and DrRacket , WeScheme , Margrave , Flapjax , FrTime , Continue , Captain Teach , and PerMission .", "metadata": {"last_modified": "2023-10-29T20:52:17+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": ["Welcome to", "Brown PLT!"], "word_count": 557, "token_count_estimate": 705}}, "https://cs.brown.edu/research/plt/dl/adsafety/v2/": {"text_content": "Type-Based Verification of Web Sandboxes Joe Gibbs Politz, Arjun Guha, and Shriram Krishnamurthi The paper adsafety.pdf The typed, annotated version of ADsafe discussed in the paper typed-adsafe.js The environment file that defines, among other things, the Untrusted type presented in the paper adsafe.env The source code adsafety-aug-2013.tgz", "metadata": {"last_modified": "2014-02-24T14:02:44+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 47, "token_count_estimate": 81}}, "https://cs.brown.edu/research/lads/": {"text_content": "LADS Large Artwork Display on the Surface Home About Links Download A platform for viewing large, digitized images on touch-enabled devices", "metadata": {"last_modified": "2011-09-29T15:57:56+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 21, "token_count_estimate": 26}}, "https://cs.brown.edu/research/plt/dl/aluminum/": {"text_content": "here here", "metadata": {"last_modified": "2013-05-19T13:49:23+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/research/plt/dl/flowlog/": {"text_content": "here here Once running the VM To run a Flowlog program, cd to the FlowLoginterpreter folder and then .flowlog.native program.flg for instance to load the learning switch program .flowlog.native examplesMacLearning.flg Mininet has already been installed. For instance sudo mn --controllerremote --topotree,depth2,fanout2 --mac --arp will load a tree topology with three switches and four hosts. The Alloy Analyzer has been downloaded into the default user root directory. To run it java -jar alloy4.2.jar Contact Tim Nelson Last Updated Mar 6, 2014", "metadata": {"last_modified": "2014-03-06T16:39:26+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 80, "token_count_estimate": 123}}, "https://cs.brown.edu/research/plt/dl/icer2014ct/": {"text_content": "Source Data and Analysis Scripts zip file Link to paper", "metadata": {"last_modified": "2014-07-25T20:09:44+00:00", "scraped_at": "2024-03-13T22:15:41+00:00", "headings": [], "word_count": 10, "token_count_estimate": 10}}, "https://cs.brown.edu/research/plt/dl/fse2017/": {"text_content": "explanations Installation here You can run the JAR file by typing java -jar amalgam.jarat your terminal. Example Specifications here Using Amalgam Provenance Commands Amalgam adds several new commands to the evaluator ln lists the locally-necessary positive literals ln- lists the locally-necessary negative literals why generates provenances for a positive literal whynot generates provenances for a negative literal prov displays the th provenance for the last why or whynot command. The evaluator will print only debugging information the structured provenance tree and highlighting will appear in the model-editing window. Scope not Provenance Detail ProvenanceDetail The default of 1 provides less information than 2 to seemore information about each alpha formula and derivation, change this settingto 2. Different users may prefer different settings. New Instance-Viewing Options", "metadata": {"last_modified": "2020-11-03T15:11:36+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Installation", "Example Specifications", "Using Amalgam"], "word_count": 124, "token_count_estimate": 171}}, "https://cs.brown.edu/research/plt/dl/icfp2017/": {"text_content": "Inferring Scope through Syntactic Sugar This page contains the supplemental materials for Inferring Scope through Syntactic Sugar by Justin Pombrio, Shriram Krishnamurthi, and Mitchell Wand, published in ICFP 2017. The implementation is published on github , or you can download it directly see the scope-inference folder. There is also an an extended version of the paper that contains all of the proofs and some additional material.", "metadata": {"last_modified": "2017-06-12T04:06:52+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Inferring Scope through Syntactic Sugar"], "word_count": 66, "token_count_estimate": 92}}, "https://cs.brown.edu/research/plt/dl/lambda-py/ae/index.html": {"text_content": "Python The Full Monty A Tested Semantics for the Python Programming Language Artifact Evaluation Submission This Document This documentat is intended to assist the OOPSLA Artifact Evaluation Committee AEC and any other interested parties reproduce and extend the results from our OOPSLA 2013 paper. This document is available at httpcs.brown.eduresearchpltdllambda-pyaeindex.html , and in the tarball that we submitted to the AEC. The tarball is also available from httpcs.brown.eduresearchpltdllambda-pyaelambda-py.tgz . This document covers Starting the virtual machine and verifying the papers results Exploring the implementation and tests Building from scratch Contact If you have any problems or questions that require consulting the authors during the review process, email joecs.brown.edu Getting Started The virtual machine is in the directory lambda-py-server . The file lambda-py-server.vbox is runnable by double-clicking on many platforms with VirtualBox installed. You can also create a new virtual machine, choosing Linux and Ubuntu not 64-bit, and use lambda-py-server.vmdk as the disk image. If you take this route, provide at least 1G of memory for the VM. In the first run wizard, choose lambda-py-server.vmdk as the disk image to use. Once you start the server, it may take a few minutes to start up on a screen that looks like There is one useful user on the virtual machine, reviewer , with sudo privileges and password reviewer . When prompted for a login, enter these credentials and you should be presented with a desktop that looks like The files for review are all in the directory homereviewerlambda-py . The implementation and tests for at artifact submission time are in lambda-py-artifact-submission . We focus on the current state of the implementation, which enjoys some significant improvements over the implementation at submission time. It passes all the same tests as the submission-time version and more we include the version from submission time with instructions at the end of this document for completeness. Our first goal should be to simply verify that lambda-py runs. Open a terminal Applications Menu at the top left, then Terminal Emulator, and lets first run a very small test so we can find out if anything goes wrong right away if you have the opportunity to ask the authors for help, were putting this here for quick diagnosis cd lambda-pylambda-py-artifact-submissionbase echo printlambda-py works racket python-main.rkt --interplambda-py works This will take a few seconds to run, and confirms that the interpreter is up and running for you. Step-by-Step Instructions Weve added new features since submission time, documented in CHANGES.txt. The new test cases are alongside the old in the testspython-reference subdirectory of lambda-py-artifact-submission . So if you run the following, you will see more tests passing than the 175 we report in the paper cd lambda-pylambda-py-artifact-submissionbase racket python-main.rkt --test ..testspython-reference205 tests succeeded0 tests failed We provide a script called linecount.sh that uses CLOC to count the lines of code in each directory of python-reference . This compares the current state of the repository to the numbers reported in the paper in Figure 12 the Built-in Datatypes count is the combination of the directories function, bool, builtin, tuple, lists, and dict, Iteration is the combination of directories iter and range, and Multiple Inheritance is the combination of directories super and multiple-inheritance. So, you can do cd lambda-pylambda-py-artifact-submissiontests .linecount.sh Feature of testsLOCBuilt-in Datatypes81902Scope39455Exceptions25247Multiple Inheritance16303Properties9184Iteration13214Generators9129Modules658Total2052636 The repository is also set up to run all the same tests using Python. Weve included an installation of Python 3.2.3 the version we are modelling in the VM, and these tests can be run with cd lambda-pylambda-py-artifact-submissionbase racket python-main.rkt --python-path install-stuffPython-3.2.3python --test-py ..testspython-reference Note We drive the Python tester with Racket , passing the Python path as an argument. The implementation of our test harness performs the same directory traversal as when running with , but runs with the Python executable, and checks standard out and standard error the same way. To go back in time and run all the tests that we report in the paper, you can visit the other pre-installed directory that contains the code from that time cd lambda-pylambda-py-28-march-2013base racket python-main.rkt --python-path install-stuffPython-3.2.3python --test ..testspython-reference175 tests succeeded0 tests failed We pass the Python path because we originally used Python to get the original Python AST for desugaring, and it has since been replaced. Also, the --test-py option, when run on the submission time code, reports 3 failures in the modules tests, this is an error in the test harness setting the working directory for Python. We have since fixed it. Thats enough to verify the test results reported in the paper, and some of what weve worked on since then. Looking Around Code from the paper Many of the discussions in the paper directly correspond to a few places in the code it is useful to see how they translate. These are presented as links to Github sources, since they have a nice viewer for the files. The Redex definition of the language which is also used to typeset the papers code examples is in lambda-py-core.rkt , and the definition of the reduction steps and related metafunctions which are also used to typeset the semantics shown in the paper are in lambda-py-reduction.rkt . The redex directory contains a number of tests for these. The interpreter implementation dubbed in the paper defines its abstract syntax in python-core-syntax.rkt , which is simply an encoding in Racket structs of the AST from lambda-py-core.rkt . Similarly, python-interp.rkt is a much more efficient implementation of the reduction relation from lambda-py-reduction.rkt . A number of straightforward operator desugarings are in python-desugar.rkt . The composition of all the steps of scope desugaring is split between python-phase1.rkt , which marks global variables and instance variables from classes and rewrites class bodies, and python-phase2.rkt , which rewrites rewrites class bodies, eliminating instance variables and introducing bindings for local and global variables. These do other less fundamental work that doesnt appear in the paper for straightforward desugarings of default arguments and decorators. The CPS transformation and code for the skeleton in Figure 11 are in the file python-cps.rkt We try to push functionality out of Racket and into Python-implemented libraries with some macros, as indicated in Section 6.2. These are in the basepylib directory. For example the object and type base classes implement a large swath of built-in functionality they are implemented in Python with macros for primitive operators, at type.py and object.py . As noted in the paper, isnt quite to the point of running Pythons full unittest library, so these tests use a limited language of assertions. For example, if we look at testspython-referencemultiple-inheritancemethods.py , we see lines like assertEqualFoo.getxfoo, 1 assertEqual basepy-prelude.py Playing around with Its easy to tweak the Python-implemented libraries of to see what their effects are on Python programs. Since these libraries implement so much built-in behavior, tweaking them can have interesting effects. You can run individual Python programs through by passing them through standard input and using the --interp option racket python-main.rkt --interp some-python-file.py Some things you might try Change the definition of the str method in pylibdict.py and run a simple program like printx5 . Change the definition of the getitem method on a built-in type like pyliblist or pylibdict and see the effects on lookup statements like print1,2,30 . Similarly, change add or sub and see the effect on and - expressions. Change the behavior of the various getattribute functions in pylibobject.py and see how it affects simple attribute lookup Building from Scratch These instructions are included so reviewers can see the build process for on their own machines. Reviewers should be able to evaluate the artifacts adequacy relative to the paper from the VM, but a manual installation hopefully demonstrates that the artifact is easy to install and extend. The code for is available at httpsgithub.combrownpltlambda-py . We have two points in the repositorys history that are interesting for this review One at the time of our OOPSLA submission 28 March, 2013, and one at the time of our artifact submission 1 June 2013. The former is tagged in the repository as oopsla2013 , and the latter is the HEAD of the artifactevaluation branch well push minor bugfixes here if any come up in the evaluation process, it contains this index file which isnt on the master branch, and if we do work and change master during the review process, we wont make breaking changes for the reviewers. Getting Racket Both require that you install Racket the main download link at httpracket-lang.orgdownload has installers for many platforms. We have tested on several different Ubuntus from 11.04 to 12.10, and on OSX, with both Racket 5.3.3 and Racket 5.3.4. For review, we recommend Racket 5.3.4. Download the installer and run it you can pick any of the options for installing Racket for example, you can install UNIX-style in usr , or keep the installation in your home directory. In the instructions that follow, we assume that the PATH environment variable is pointing to the bin directory of the Racket installation that holds the raco and racket commands this may be done for you automatically depending on which options you choose in the Racket installer. Example wget httpdownload.racket-lang.orginstallers5.3.4racketracket-5.3.4-bin-i386-linux-ubuntu-karmic.sh sh racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh Getting the Source of Github is the easiest way to get a copy of the code git clone httpsgithub.combrownpltlambda-py BE AWARE If you fork the repository on Github, it will leak your identity to us its up to you if thats a problem. Just using git clone as above wont. Artifact Submission-time Build Check out the artifactevaluation branch git checkout artifactevaluation PLAI-Typed is built in a language that sits on top of Racket called plai-typed. We have it included with the repository as plai-typed-18Feb2013.plt in the root of the repository. To install it, use the raco command raco setup -A plai-typed-18Feb2013.plt Ragg Since publication, we had a third-party contribution of a pure Racket parser for Python see this merge . It uses the Ragg parser package for Racket to install it, use the raco command raco setup -A ragg-mangled.plt Building The implementation of is in the base directory. To build, simply use make cd base make Running Use the same commands as above to run the tests e.g. the commands with the --test option. Paper Submission-time Build We recommend using the provided virtual machine to review the code as it was at submission time, since it involves additional build steps that we have since made much easier. Python At the time of submission, we used Pythons parser to get original ASTs for desugaring we have since switched to a pure-Racket Python parser. So, to run tests at the oopsla2013 tag, you will also need to install Python3 source is available at httpwww.python.orgdownloadreleases3.2.3 . Example wget httpwww.python.orgftppython3.2.3Python-3.2.3.tgz tar xzf Python-3.2.3.tgz cd Python-3.2.3 .configure make To view the code as it was at submission time, check out the oopsla2013 tag git checkout oopsla2013 PLAI-Typed As in the instructions for the current build, install plai-typed with raco setup -A plai-typed-18Feb2013.plt Running To run the tests that were reported in the paper, run One additional build step cd base raco make python-main.rkt racket python-main.rkt --python-path install-stuffPython-3.2.3python --test ..testspython-reference175 tests succeeded0 tests failed Where install-stuffPython-3.2.3python is the path to your Python3 installations python binary.", "metadata": {"last_modified": "2013-05-31T18:20:18+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Python: The Full Monty", "A Tested Semantics for the Python Programming Language"], "word_count": 1855, "token_count_estimate": 2689}}, "https://cs.brown.edu/research/plt/dl/jquery/": {"text_content": "Combining Form and Function Static Types for JQuery Programs Benjamin S. Lerner, Liam Elberty, Jincheng Li, andShriram Krishnamurthi INPROCEEDINGSLerner2013b, author Benjamin S. Lerner and Liam Elberty and Jincheng Li and Shriram Krishnamurthi, title Combining Form and Function Static Types for JQuery Programs, booktitle European Conference on Object-Oriented Programming ECOOP, year 2013, month jul The jQuery library defines a powerful query language for webapplications scripts to interact with Web page content. This languageis exposed as jQuerys API, which is implemented to fail silently sothat incorrect queries will not cause the program to halt. Since thecorrectness of a query depends on the structure of a page,discrepancies between the pages actual structure and what the queryexpects will also result in failure, but with no error traces toindicate where the mismatch occurred. This work proposes a novel typesystem to statically detect jQuery errors. The type system extendsTyped JavaScript with local structure about the page and withmultiplicities about the structure of containers. Together, these twoextensions allow us to track precisely which nodes are active in ajQuery object, with minimal programmer annotation effort. We evaluatethis work by applying it to sample real-world jQuery programs. Paper", "metadata": {"last_modified": "2014-01-17T15:44:45+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": [], "word_count": 189, "token_count_estimate": 276}}, "https://cs.brown.edu/research/plt/dl/lambda-py/ae/": {"text_content": "Python The Full Monty A Tested Semantics for the Python Programming Language Artifact Evaluation Submission This Document This documentat is intended to assist the OOPSLA Artifact Evaluation Committee AEC and any other interested parties reproduce and extend the results from our OOPSLA 2013 paper. This document is available at httpcs.brown.eduresearchpltdllambda-pyaeindex.html , and in the tarball that we submitted to the AEC. The tarball is also available from httpcs.brown.eduresearchpltdllambda-pyaelambda-py.tgz . This document covers Starting the virtual machine and verifying the papers results Exploring the implementation and tests Building from scratch Contact If you have any problems or questions that require consulting the authors during the review process, email joecs.brown.edu Getting Started The virtual machine is in the directory lambda-py-server . The file lambda-py-server.vbox is runnable by double-clicking on many platforms with VirtualBox installed. You can also create a new virtual machine, choosing Linux and Ubuntu not 64-bit, and use lambda-py-server.vmdk as the disk image. If you take this route, provide at least 1G of memory for the VM. In the first run wizard, choose lambda-py-server.vmdk as the disk image to use. Once you start the server, it may take a few minutes to start up on a screen that looks like There is one useful user on the virtual machine, reviewer , with sudo privileges and password reviewer . When prompted for a login, enter these credentials and you should be presented with a desktop that looks like The files for review are all in the directory homereviewerlambda-py . The implementation and tests for at artifact submission time are in lambda-py-artifact-submission . We focus on the current state of the implementation, which enjoys some significant improvements over the implementation at submission time. It passes all the same tests as the submission-time version and more we include the version from submission time with instructions at the end of this document for completeness. Our first goal should be to simply verify that lambda-py runs. Open a terminal Applications Menu at the top left, then Terminal Emulator, and lets first run a very small test so we can find out if anything goes wrong right away if you have the opportunity to ask the authors for help, were putting this here for quick diagnosis cd lambda-pylambda-py-artifact-submissionbase echo printlambda-py works racket python-main.rkt --interplambda-py works This will take a few seconds to run, and confirms that the interpreter is up and running for you. Step-by-Step Instructions Weve added new features since submission time, documented in CHANGES.txt. The new test cases are alongside the old in the testspython-reference subdirectory of lambda-py-artifact-submission . So if you run the following, you will see more tests passing than the 175 we report in the paper cd lambda-pylambda-py-artifact-submissionbase racket python-main.rkt --test ..testspython-reference205 tests succeeded0 tests failed We provide a script called linecount.sh that uses CLOC to count the lines of code in each directory of python-reference . This compares the current state of the repository to the numbers reported in the paper in Figure 12 the Built-in Datatypes count is the combination of the directories function, bool, builtin, tuple, lists, and dict, Iteration is the combination of directories iter and range, and Multiple Inheritance is the combination of directories super and multiple-inheritance. So, you can do cd lambda-pylambda-py-artifact-submissiontests .linecount.sh Feature of testsLOCBuilt-in Datatypes81902Scope39455Exceptions25247Multiple Inheritance16303Properties9184Iteration13214Generators9129Modules658Total2052636 The repository is also set up to run all the same tests using Python. Weve included an installation of Python 3.2.3 the version we are modelling in the VM, and these tests can be run with cd lambda-pylambda-py-artifact-submissionbase racket python-main.rkt --python-path install-stuffPython-3.2.3python --test-py ..testspython-reference Note We drive the Python tester with Racket , passing the Python path as an argument. The implementation of our test harness performs the same directory traversal as when running with , but runs with the Python executable, and checks standard out and standard error the same way. To go back in time and run all the tests that we report in the paper, you can visit the other pre-installed directory that contains the code from that time cd lambda-pylambda-py-28-march-2013base racket python-main.rkt --python-path install-stuffPython-3.2.3python --test ..testspython-reference175 tests succeeded0 tests failed We pass the Python path because we originally used Python to get the original Python AST for desugaring, and it has since been replaced. Also, the --test-py option, when run on the submission time code, reports 3 failures in the modules tests, this is an error in the test harness setting the working directory for Python. We have since fixed it. Thats enough to verify the test results reported in the paper, and some of what weve worked on since then. Looking Around Code from the paper Many of the discussions in the paper directly correspond to a few places in the code it is useful to see how they translate. These are presented as links to Github sources, since they have a nice viewer for the files. The Redex definition of the language which is also used to typeset the papers code examples is in lambda-py-core.rkt , and the definition of the reduction steps and related metafunctions which are also used to typeset the semantics shown in the paper are in lambda-py-reduction.rkt . The redex directory contains a number of tests for these. The interpreter implementation dubbed in the paper defines its abstract syntax in python-core-syntax.rkt , which is simply an encoding in Racket structs of the AST from lambda-py-core.rkt . Similarly, python-interp.rkt is a much more efficient implementation of the reduction relation from lambda-py-reduction.rkt . A number of straightforward operator desugarings are in python-desugar.rkt . The composition of all the steps of scope desugaring is split between python-phase1.rkt , which marks global variables and instance variables from classes and rewrites class bodies, and python-phase2.rkt , which rewrites rewrites class bodies, eliminating instance variables and introducing bindings for local and global variables. These do other less fundamental work that doesnt appear in the paper for straightforward desugarings of default arguments and decorators. The CPS transformation and code for the skeleton in Figure 11 are in the file python-cps.rkt We try to push functionality out of Racket and into Python-implemented libraries with some macros, as indicated in Section 6.2. These are in the basepylib directory. For example the object and type base classes implement a large swath of built-in functionality they are implemented in Python with macros for primitive operators, at type.py and object.py . As noted in the paper, isnt quite to the point of running Pythons full unittest library, so these tests use a limited language of assertions. For example, if we look at testspython-referencemultiple-inheritancemethods.py , we see lines like assertEqualFoo.getxfoo, 1 assertEqual basepy-prelude.py Playing around with Its easy to tweak the Python-implemented libraries of to see what their effects are on Python programs. Since these libraries implement so much built-in behavior, tweaking them can have interesting effects. You can run individual Python programs through by passing them through standard input and using the --interp option racket python-main.rkt --interp some-python-file.py Some things you might try Change the definition of the str method in pylibdict.py and run a simple program like printx5 . Change the definition of the getitem method on a built-in type like pyliblist or pylibdict and see the effects on lookup statements like print1,2,30 . Similarly, change add or sub and see the effect on and - expressions. Change the behavior of the various getattribute functions in pylibobject.py and see how it affects simple attribute lookup Building from Scratch These instructions are included so reviewers can see the build process for on their own machines. Reviewers should be able to evaluate the artifacts adequacy relative to the paper from the VM, but a manual installation hopefully demonstrates that the artifact is easy to install and extend. The code for is available at httpsgithub.combrownpltlambda-py . We have two points in the repositorys history that are interesting for this review One at the time of our OOPSLA submission 28 March, 2013, and one at the time of our artifact submission 1 June 2013. The former is tagged in the repository as oopsla2013 , and the latter is the HEAD of the artifactevaluation branch well push minor bugfixes here if any come up in the evaluation process, it contains this index file which isnt on the master branch, and if we do work and change master during the review process, we wont make breaking changes for the reviewers. Getting Racket Both require that you install Racket the main download link at httpracket-lang.orgdownload has installers for many platforms. We have tested on several different Ubuntus from 11.04 to 12.10, and on OSX, with both Racket 5.3.3 and Racket 5.3.4. For review, we recommend Racket 5.3.4. Download the installer and run it you can pick any of the options for installing Racket for example, you can install UNIX-style in usr , or keep the installation in your home directory. In the instructions that follow, we assume that the PATH environment variable is pointing to the bin directory of the Racket installation that holds the raco and racket commands this may be done for you automatically depending on which options you choose in the Racket installer. Example wget httpdownload.racket-lang.orginstallers5.3.4racketracket-5.3.4-bin-i386-linux-ubuntu-karmic.sh sh racket-5.3.4-bin-i386-linux-ubuntu-karmic.sh Getting the Source of Github is the easiest way to get a copy of the code git clone httpsgithub.combrownpltlambda-py BE AWARE If you fork the repository on Github, it will leak your identity to us its up to you if thats a problem. Just using git clone as above wont. Artifact Submission-time Build Check out the artifactevaluation branch git checkout artifactevaluation PLAI-Typed is built in a language that sits on top of Racket called plai-typed. We have it included with the repository as plai-typed-18Feb2013.plt in the root of the repository. To install it, use the raco command raco setup -A plai-typed-18Feb2013.plt Ragg Since publication, we had a third-party contribution of a pure Racket parser for Python see this merge . It uses the Ragg parser package for Racket to install it, use the raco command raco setup -A ragg-mangled.plt Building The implementation of is in the base directory. To build, simply use make cd base make Running Use the same commands as above to run the tests e.g. the commands with the --test option. Paper Submission-time Build We recommend using the provided virtual machine to review the code as it was at submission time, since it involves additional build steps that we have since made much easier. Python At the time of submission, we used Pythons parser to get original ASTs for desugaring we have since switched to a pure-Racket Python parser. So, to run tests at the oopsla2013 tag, you will also need to install Python3 source is available at httpwww.python.orgdownloadreleases3.2.3 . Example wget httpwww.python.orgftppython3.2.3Python-3.2.3.tgz tar xzf Python-3.2.3.tgz cd Python-3.2.3 .configure make To view the code as it was at submission time, check out the oopsla2013 tag git checkout oopsla2013 PLAI-Typed As in the instructions for the current build, install plai-typed with raco setup -A plai-typed-18Feb2013.plt Running To run the tests that were reported in the paper, run One additional build step cd base raco make python-main.rkt racket python-main.rkt --python-path install-stuffPython-3.2.3python --test ..testspython-reference175 tests succeeded0 tests failed Where install-stuffPython-3.2.3python is the path to your Python3 installations python binary.", "metadata": {"last_modified": "2013-05-31T18:20:18+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Python: The Full Monty", "A Tested Semantics for the Python Programming Language"], "word_count": 1855, "token_count_estimate": 2689}}, "https://cs.brown.edu/research/plt/dl/pldi2018/": {"text_content": "Inferring Type Rules for Syntactic Sugar Justin Pombrio and Shriram Krishnamurthi The paper The full version of the paper The artifact httpsgithub.combrownpltjudgmental-resugaringreleasestagv1.1", "metadata": {"last_modified": "2018-04-17T21:37:03+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Inferring Type Rules for Syntactic Sugar"], "word_count": 22, "token_count_estimate": 53}}, "https://cs.brown.edu/research/pubs/techreports/reports/CS-20-01.html": {"text_content": "Tech Report CS-20-01 Fast and Accurate 4D Light Field Depth Estimation Numair Khan, Min H. Kim and James Tompkin August 2020 Abstract We present an algorithm for accurate depth estimation from 4D light fields that runs almost an order of magnitude faster than classical methods. Our proposed approach use epipolar-plane image edges to estimate sub-pixel disparityat a small set of pixels in the 4D space. By optimizing constraints at these pixels we are able to diffuse the sparse set in an occlusion-aware manner to obtain dense disparity maps. Qualitative and quantitative results on both synthetic and real-world light fields show that we have comparable, or better performance than existing methods, while being significantly faster 8--11x than current non-learning-based methods. complete text in pdf", "metadata": {"last_modified": "2023-05-10T20:11:33+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Information for:", "Tech Report CS-20-01", "Fast and Accurate 4D Light Field Depth Estimation"], "word_count": 123, "token_count_estimate": 164}}, "https://ics.uci.edu/~sudderth/": {"text_content": "Toggle navigation Erik Sudderth News Group Projects Papers Courses Erik B. Sudderth, Statistical Computation Perception I am a Professor of Computer Science and Statistics , and Chancellors Fellow, at the University of California, Irvine . My Learning, Inference, Vision Group develops statistical methods for scalable machine learning, with applications in artificial intelligence, computer vision, and the natural and social sciences. My research affiliations at UC Irvine include Director of the UCI Center for Machine Learning and Intelligent Systems . See our seminar series . Director of the HPI Research Center in Machine Learning and Data Science at UC Irvine . UCI Computational Vision Group . UCI Algorithms, Combinatorics, and Optimization Center . See their seminar series . UCI Steckler Center for Responsible, Ethical, and Accessible Technology CREATE . UC Irvine Initiative in AI, Law, Society . UCI Institute for Mathematical Behavioral Sciences . UCI Data Science Initiative . Also see the statistics seminar series . For a tutorial introduction to probabilistic modeling and approximate inference, see the background chapter of my doctoral thesis , advised by Professors Alan Willsky and William Freeman at MIT EECS . My postdoctoral research at Berkeley EECS , advised by Professors Michael Jordan and Stuart Russell , focused on Bayesian nonparametric models see my CVPR tutorial . For more information bio curriculum vit research projects code publications lectures Research Highlights At NeurIPS 2023 , we present work incorporating graphical models in deep generative models to learn discrete representations , and advancing differentiable training of discriminative particle filters . A large NSF grant funds research making collaboration accessible for visually impaired workers . A new model for sparse graphs with overlapping communities appears at NeurIPS 2022 . Related work was presented at the 13th International Conference on Bayesian Nonparametrics . Work on inference for soil biogeochemical models , an important framework for quantifying the impact of rising global surface temperatures, appears at the ICML 2022 AI for Science Workshop . We advance the scalability and stability of fair machine learning methods in work at NeurIPS 2021 . The ICML 2021 Time Series Workshop best poster award goes to our work on prediction constraints for semi-supervised classification with Hidden Markov models . Work on better black-box variational inference for probabilistic programs appears at ICML 2021 . This work supported in part by a Facebook Probability and Programming research award . Our work on 3D scene reconstruction with multi-layer depth and epipolar transformers appears at ICCV 2019 . Previously at the CVPR 3D Scene Understanding and SUMO Challenge workshops. Our cascaded 3D detection framework, which integrates geometric and contextual cues for robust scene understanding from RGB-D images, is summarized by a 2020 paper appearing in IEEE PAMI . An NSF Robust Intelligence Award with Alex Ihler supports work on new particle-based algorithms for inference and learning with continuous graphical models. I gave a talk at the 2017 SoCal Machine Learning Symposium about our earlier diverse particle max-product algorithm, which gives state-of-the-art predictions of continuous protein side-chain conformations. Code available . At AISTATS 2018 , our framework for prediction-constrained training of probabilistic models leads to improved semi-supervised learning of topic models, with applications to the analysis of documents and electronic health records. This work received the SoCal NLP Symposium best paper award . An NSF CAREER Award supports our open source toolbox BNPy Bayesian Nonparametric clustering for Python . BNPy implements scalable, stochastic and memoized variational inference algorithms for a diverse range of Bayesian nonparametric models. Work with BrainGate on multiscale semi-Markov dynamics for improved brain-computer interfaces appeared at NIPS 2017 . A supplemental video demonstrates accurate, interactive control of a computer cursor by a clinical trial participant with tetraplegia. The 2014 ISBA Mitchell Prize for Bayesian analysis of an important applied problem goes to our NET-VISA system for global seismic monitoring , learned from data provided by the comprehensive nuclear-test-ban treaty organization CTBTO . For details see the Brown University news article . Weiss Pearl introduce our review article on Nonparametric Belief Propagation for the CACM . Editorial Highlights Action editor for the Journal of Machine Learning Research . Associate editor for the IEEE Transactions on Pattern Analysis and Machine Intelligence . Senior area chair for AISTATS 2024 . Scientific committee for the 12th International Conference on Bayesian Nonparametrics . Area chair for NeurIPS 2023 2021 2019 2016 , CVPR 2019 2015 , ICML 2017 2015 , ICCV 2015 . Sponsor chair for the 2018 2019 International Conference on Machine Learning . Editor, IEEE PAMI Special Issue on Bayesian Nonparametrics , Feb. 2015. editorial Organizer, ICERM Workshop Tutorials on Bayesian Nonparametrics , Sept. 2012. group photo Editor, IEEE Signal Processing Magazine special issue on Recent Advances Emerging Developments of Graphical Models , Nov. 2010. editorial Editor, IEEE PAMI Special Issue on Probabilistic Graphical Models in Computer Vision , Oct. 2009. editorial Erik B. Sudderth E lastnameuci.edu P 949 824-8169 Office Donald Bren Hall 4206 Mailing Address University of California, Irvine School of Information Computer Sciences Irvine, CA 92697-3435 2024 Erik B. Sudderth lastnameuci.edu", "metadata": {"last_modified": "2023-11-16T19:23:16+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Erik B. Sudderth,"], "word_count": 835, "token_count_estimate": 1115}}, "https://ics.uci.edu/~sudderth/group/": {"text_content": "Toggle navigation Erik Sudderth News Group Projects Papers Courses LIV Learning, Inference, Vision Group Principal Investigator Erik Sudderth , UC Irvine Computer Science CV LIV group members of the HPI Research Center in Machine Learning and Data Science at UC Irvine at a Sept. 2023 retreat in Rheinsberg, Germany. LIV group and alumni at the December 2017 Conference on Neural Information Processing Systems in Long Beach, CA. LIV Group Members Sakshi Agarwal , PhD student. Harry Bendekgey , PhD student. Mehrnaz Motamed, PhD student. Debora Sujono , PhD student. Ali Younis , PhD student. Federica Zoe Ricci , PhD student, co-advised by Michele Guindani . LIV Alumni PhD Theses Soumya Ghosh , IBM Research. 2015 Brown PhD Bayesian Nonparametric Discovery of Layers and Parts from Scenes and Objects . Gabriel Hope , Visiting Assistant Professor, Harvey Mudd College. 2023 UC Irvine PhD Prediction-Constrained Latent Variable Models . Michael Hughes , Assistant Prof. of Computer Science at Tufts University. 2016 Brown PhD Reliable and Scalable Variational Inference for Nonparametric Mixtures, Topics, and Sequences . Geng Ji , Facebook AI. 2019 UC Irvine PhD Efficient Variational Inference for Hierarchical Models of Images, Text, and Networks . Daeil Kim , founder of AI. Reverie. 2017 Brown PhD Scalable Bayesian Nonparametric Models for Networks and Documents . Jason Pacheco , Assistant Prof. of Computer Science at Univ. of Arizona. 2016 Brown PhD Variational Approximations with Diverse Applications . Zhile Ren , applied research scientist at Apple. 2018 Brown PhD Semantic Three-Dimensional Understanding of Dynamic Scenes . LIV Alumni Masters Undergraduate Research Madina Abdrakhmanova , MS 2019 Prediction Constrained Factor Analysis . Samuel Ainsworth , ScB 2016. Michael Bryant, ScM 2012 Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes . Soravit Changpinyo , ScB 2012 honors Learning Image Attributes using the Indian Buffet Process . Xiaoyin Chen, BS 2021 Learning Consistent Deep Generative Models from Sparse Data via Prediction Constraints . Rajkumar Kothapa, ScM 2011 Max-Product Particle Belief Propagation . Andrew Miller , ScM 2010 Image and Audio Annotation Approximate Inference in Dense Conditional Random Fields . Daniel Milstein, ScB 2015, ScM 2017 Multiscale Semi-Markov Dynamics for Intracortical Brain-Computer Interfaces . Mengrui Ni, ScM 2015 Variational Inference for Beta-Bernoulli Dirichlet Process Mixture Models . Carl Olsson , ScM 2016 Scene Category Context for 3D Object Detection with RGBD Cameras . Sonia Phene , ScB 2015 honors Parallelization of Variational Inference for Bayesian Nonparametric Topic Models . Roshan Rao , ScB 2017 honors Protein Structure Prediction from Low-Resolution Electron Density Data using Particle Belief Propagation. Jake Soloff , ScB 2016. William Stephenson , ScB 2015 honors Variational Inference for Hierarchical Dirichlet Process Based Nonparametric Models . Donglai Wei , ScB 2011. Leah Weiner, ScM 2017. 2024 Erik B. Sudderth lastnameuci.edu LIV Group LIV Alumni", "metadata": {"last_modified": "2024-01-19T22:06:35+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["LIV:"], "word_count": 459, "token_count_estimate": 731}}, "https://cs.brown.edu/research/plt/dl/progressive-types/": {"text_content": "Progressive Types Joe Gibbs Politz, Hannah Quay-de la Vallee, and Shriram Krishnamurthi inproceedingspolitzprogressive-types, author Joe Gibbs Politz and Hannah Quay-de la Vallee and Shriram Krishnamurthi, title Progressive Types, year 2012, booktitle SPLASHOnward The paper. pdf Update 13 May 2013 Updated versions of the proofs presented in the paper pdf . The link below is included for reference. We fixed bugs in the Application and Substitution Lemmas. Original proofs for the type system presented in the paper. pdf The Redex model and mechanized proofs in Coq. github .", "metadata": {"last_modified": "2013-05-13T16:20:11+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": [], "word_count": 87, "token_count_estimate": 141}}, "https://cs.brown.edu/research/plt/dl/quizius-2019/": {"text_content": "Harnessing the Wisdom of the Classes This page contains the supplemental materials for this SIGCSE 2019 paper by Sam Saarinen , Shriram Krishnamurthi , Kathi Fisler , and Preston Tunnell Wilson . Answer input types columns excel Answer input types data excel Answer equivalences columns excel Answer equivalences data excel Answer prototypes columns excel Answer prototypes data excel Answers columns excel Answers data excel Completion records columns excel Completion records data excel Courses columns excel Courses data excel Enrollments columns excel Enrollments data excel Question input types columns excel Question input types data excel Question priorities columns excel Question priorities data excel Questions columns excel Questions data excel Quizzes columns excel Quizzes data excel", "metadata": {"last_modified": "2018-12-03T14:47:08+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Harnessing the Wisdom of the Classes"], "word_count": 114, "token_count_estimate": 140}}, "https://cs.brown.edu/research/plt/dl/resugaring/v1/": {"text_content": "Resugaring Lifting Evaluation Sequences through Syntactic Sugar Justin Pombrio and Shriram Krishnamurthi The paper resugar.pdf The source code for Confection confection.zip . This is a snapshot of the brownpltResugarer repository on Github. The README is in the zipfile. Partial proofs in Coq coq.tgz . These are also available in the Confection repo above. The source code for Pyret with Confection attached is available on Github brownpltpyret-lang-resugarer .", "metadata": {"last_modified": "2014-03-22T17:35:54+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": [], "word_count": 67, "token_count_estimate": 108}}, "https://cs.brown.edu/research/thmon/thmon.html": {"text_content": "A Tool for Monitoring Multithreaded Program Performance Introduction. An overview ofThreadMon and its uses. The Solaris 2.5 Threads Library. A description of Solariss many-to-many thread model implementationincluding background information on other threads package implementation models . ThreadMon. A description of thetool itself, including some implementation notes. References. Sources of moreinformation. Examples. Some examples of the types of problems ThreadMon can help identify. paper Bryan M. Cantrill Thomas W. Doeppner Jr. Greg Foxman gmfcs.brown.edu", "metadata": {"last_modified": "1996-08-15T16:18:33+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["A Tool for Monitoring Multithreaded Program Performance"], "word_count": 73, "token_count_estimate": 113}}, "https://sites.google.com/a/brown.edu/ugur-cetintemel/": {"text_content": "Search this site Skip to main content Skip to navigation Ugur Cetintemel Ugur Brown University Brown CS Ugur Cetintemel Ugur Brown University Brown CS More Ugur Brown University Brown CS Ugur Cetintemel Khosrowshahi University Professor of Computer Science Brown University Box 1910, 115 Waterman Street , Room 4 37 , CIT Providence, RI 02912 Research Interests Data management Data science systems and appl ications Distributed systems Brown Data Management Group Teaching CSCI 1951-I CS for Social Change DATA 1030 Intro to Data and Computer Science CSCI 2950-T Interacting with Big Data CSCI 1310 Fundamentals of Computer Systems Select Articles more complete list at dblp Machine Learning for Database Systems DeepSqueeze Deep Semantic Compression for Tabular Data SIGMOD20 The Case for a Learned Sorting Algorithm SIGMOD20 A Fully Pluggable NL2SQL Training Pipeline SIGMOD20 DBPal A Learned Natural Language Interface for Database Systems SIGMOD18 Making the Case for Query-by-Voice with EchoQuery SIGMOD16 Portable Workload Performance Prediction in the Cloud ICDE13 Learning-based Query Performance Modeling and Prediction ICDE12 Performance Prediction for Concurrent Database Workloads SIGMOD11 The Case for Predictive Database Systems Opportunities and Challenges CIDR11 Database Support for Continuous Prediction Queries over Streaming Data PVLDB10 Applied Data Engineering End-to-end artificial intelligence platform for the management of large vessel occlusions a preliminary study Journal of Stroke and Cerebrovascular Diseases, Vol 31, No 11, 2022 Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network Radiology, Vol 297, No 3, 2020 Modern Hardware for Database Systems The Case for In-Memory OLAP on Wimpy Nodes ICDE21 A Morsel-Driven Query Execution Engine for Multi-Cores VLDB19 Revisiting Reuse in Main Memory Database Systems SIGMOD17 SiliconDB Rethinking DBMSs for Modern Heterogeneous Co-Processor Environments DaMoN17 An Architecture for Compiling UDF-centric Workflows PVLDB15 Tupleware Big Data, Big Analytics, Small Clusters CIDR15 Data Exploration Dynamic Query Refinement for Interactive Data Exploration EDBT20 Interactive Search and Exploration of Waveform Data with Searchlight SIGMOD16 Searchlight Enabling Integrated Search and Exploration over Large Multidimensional Data PVLDB15 Interactive Data Exploration using Semantic Windows SIGMOD14 Query Steering for Interactive Data Exploration CIDR13 Stream Processing S-Store Streaming meets Transaction Processing PVLDB15 S-Store A Streaming NewSQL System for Big Velocity Applications PVLDB14 Report abuse Page details Page updated Report abuse", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": [], "word_count": 366, "token_count_estimate": 559}}, "https://cs.brown.edu/research/plt/dl/sigcse2016plancomp/": {"text_content": "Modernizing Plan-Composition Studies Supplemental Materials This page contains the problem statements and coding rubrics used in this SIGCSE 2016 paper by Kathi Fisler , Shriram Krishnamurthi , and Janet Siegmund . Problem Statements Here are the versions of the problem statements as handed out ineach course used in the study Java version English, used at the school labeled US1-IM in the paper Java version German Programming Reviewing , used at the school labeled GM-IM in the paper Racket version English, used at the schools labeled US1-FP and US2-FP in the paper OCaml version English, used at the school labeled FR-FP in the paper Coding Rubric This coding rubric details the datarecorded for each programming problem solution, including instructionsabout how to interpret solutions relative to each datum. This spreadsheet template has columns corresponding to the various data items described in thecoding manual. There is one sheet for each of the programming problemsinvolved in the study.", "metadata": {"last_modified": "2016-01-22T11:26:32+00:00", "scraped_at": "2024-03-13T22:15:42+00:00", "headings": ["Modernizing Plan-Composition Studies: Supplemental Materials"], "word_count": 154, "token_count_estimate": 206}}, "https://cs.brown.edu/research/pubs/theses/ugrad/": {"text_content": "Undergraduate Honors Theses 2023 Ahluwalia.Anika The Role of Context and Demographics in Emotional Online Interpretation 519.9 KB Chang.Adrian Neuro Symbolic Methods for Indoor Scene Synthesis 2.1 MB Foiani.Michael Interactive Branching Presentation Trails 24.1 MB Gross.Hannah Funhouse A Hall of Mirrors Database so Good That Even People on the Inside Cant See the Truth 772.7 KB Handa.Kunal How does environment understanding emerge in transformer-based policy networks 76.0 KB Kobayashi.Momoka Evaluation of Explainability Methods on Single-Cell Classification Tasks Using Graph Neural Networks 677.5 KB Levy.Amanda Mental Health and Innovative Technologies The Use of Virtual Reality to Address Post-Traumatic Stress Disorder and Anxiety Disorders 387.1 KB Li.Jessica Compositional Reasoning in Vision-Language Models 755.8 KB Ma.Rachel Skill Generalization With Verbs 1.2 MB Manjal.Anoop Examining the Antibody Response From a Covid-19 Booster Shot in Immunocompromised Patients. 566.7 KB Mapeke.Marc Flowed Flight Fields Dynamic View Synthesis and Time-of-Flight Corrections Under Motion 5.8 MB Patel.Shalin Interpretability in Graph Neural Networks 29.1 KB Rajesh.Sreshtaa Using Dependency Analysis and SAT Solving to Communicate Privacy Problems in Code 1.3 MB Riya.Dulepet Using Dependency Analysis and SAT Solving to Communicate Privacy Problems in Code 3.1 MB Roberts.Geireann Lindfield A User-Controlled Document Recommendation System for Knowledge Workers 4.6 MB Thakkar.Nitya Using Graph Neural Networks to Model the Glioblastoma Free Energy Landscape 3.4 MB Venkatachalam.Harshini Exploratory Analysis and Clustering of COVID-19 and Intellectual Developmental Disorders in Electronic Health Record Data 630.3 KB Wang.Yuanhao On Human-like Biases in Deep Neural Networks for the Perception of Slant from Texture 8.0 MB Yalavarti.Arvind Observatory Fast and Scalable Systems Observability 1.1 MB Yi.Xinjie Anonymous CVPR submission 3.6 MB Yuan.Andrew Prompting and weak supervision 255.3 KB Zhan.Xiao CharacterMixer Rig-Aware Interpolation of 3D Characters 5.6 MB Zhou.Zhiyuan Skill Generalization with Attention-Based Ensemble in Lifelong Reinforcement Learning 1.5 MB 2022 Asif, Muhammad Haider Beyond DNA methylation chromatin age of human tissues 1.6 MB Bers, Tali Effects of Target Words and Their Locations in Prompts 3.0 MB Bhalla, Usha Do Vision-Language Pretrained Models Learn Primitive Concepts 2.7 MB Chairattana-Apirom, Rutchathon Compact Cut-and-Choose Boosting the Security of Blind Signature Schemes, Compactly 556.8 KB Chen, Qianfan Language Levels in Teaching an Introductory Formal Methods Course 1.3 MB Ciabaton, Jack Cost Function Based Prediction Markets Aggregate Risk-Averse Experts Beliefs as Opinion Pools 552.1 KB de Campos, Jackson Best Response in Alternating-Offers Negotiation 4.4 MB Espiritu, Zachary Time- and Space-Efficient Aggregate Range Queries over Encrypted Databases 630.1 KB Givertz, Benjamin Incremental Exception Resolution in Tuplex 1.9 MB Idehen, Jordan Evaluating Machine Learning Methods for Predicting Gene Expression from Epigenetic Glioblastoma Data 816.9 KB Ivanov, Alexander Discovering Options that Minimize Average Planning Time 2.9 MB Kim, Jung Yeop Designing an Actuated Walker for Improving User Stability 2.2 MB Laidlaw, Eliot Towards a More Object-Centric Dynamic Scene Reconstruction Model 30.4 MB Lim, Jing Wei Nicholas Termination Classifiers for Image-Based Observation Spaces 2.8 MB Ninagawa, Kotone Strategies in Automated Negotiation Against Time-based Opponents 1.4 MB Pikielny, Adam Consistent Depth Estimation for Video 11.7 MB Polatty, Jacob Securing Veracity Defenses Against the Pervasive Influence of Social Media 1.0 MB Randolph, John Banzhaf Power in Hierarchical Games 839.9 KB Roy, Monica Task Specification in LTL with Quantifiers for Robotic Instruction Following 247.8 KB Sachan, Kshitij Learning a Distance Metric over Markov Decision Processes 4.8 MB Sharma, Gaurav and Glass, Geoffrey Handling Concept Drift in Weakly Supervised Learning 843.2 KB Smits, Daniel The Data Structure of Ad-Hoc Alternatives 866.5 KB So, Leonard Learning to Optimize L20 304.4 KB Srivastava, Aryan Examining the effects of the like-dislike ratio on users consumption of and interaction with political content on YouTube 340.2 KB Syed, Sara Understanding and Increasing Empathy in Online Text-Based Peer Support Systems 1.5 MB Trotz, Caleb Disentangling Levels of Detail in Implicit Shape Generation with Explicit Bounding Proxies 1.1 MB Tung, Nathan Neuro-Hotnet A Graph Theoretic Approach for Brain FC Estimation 4.4 MB Wang, Jeremy Interpretable Modeling of Cellular Perturbations 403.9 KB Yu, Jacob Towards Social Video Verification to Combat Deepfakes via Deep Learning 16.1 MB Zaki, Hossam Predicting Cell Type and Extracting Key Genes using Single Cell Multi-Omics Data and Graph Neural Networks 416.8 KB Zhang, William Learning Relabelled Convex Combinations of Weak Labellers 2.6 MB 2021 Berg, Matthew Natural Language to Long-Range Robot Navigation in Outdoor Environments 16.7 MB Blinn, Bryce Functional Chair Programs in ShapeAssembly 5.2 MB Gonzalez, Lucia Regina Reyes What You See Is Not Always What You Get An Analysis of Informative Graphs in Formal Methods Languages 14.5 MB Jurayj, William Scaling Bias in Journalism using Contextual Embeddings 1.4 MB Milefchik, Isa Interactive Image Synthesis Using a Latent 3D Gaussian Model 15.8 MB OHalloran, Amelia The Technical, Legal, and Ethical Landscape of Deepfake Pornography 1.7 MB Pal, Koyena The Effect of Multi-Document Summarizations on User SERP Experience 1.1 MB Sam, Dylan Learning from Dependent Weak Supervision Sources 1.4 MB Walke, Homer Learning Finite Linear Temporal Logic Formulas 669.6 KB 2020 Baruah, Prakrit Predicting Hospital Readmission using Unstructure Clinical Note Data 729.7 KB Bayazit, Deniz Generalizing Natural Language Instruction Following to Aerial Robots and Arbitrary Environments 4.9 MB Christ, Miranda New Lower Bounds on the Complexity of Provably Anonymous Onion Routing 608.6 KB Galgana, Rigel Optimal Reserve Price Estimation in the Generalized First and Second Price Auctions with Best Response Dynamics 1.8 MB Guo, Erica Information Retrieval for Genetic Mutations and Diseases 968.8 KB Huang, Amy Mystery Functions 1.0 MB Huang, Shawna Downstream Effects of the Brown Computer Science Introductory Sequences 4.1 MB Jha, Rohan Data augmentation and the role of hardness for feature learning in NLP 853.1 KB Levin, Joshua ViperProbe Using eBPF Metrics to Improve Microservice Observability 4.0 MB Ouyang, Kevin Self-E Procedurally Guided Self-Experiments for Novice Health Hackers 1.9 MB Renshaw, Lena Determining which Sentiment Analysis Predictive Model to use for a given Social Media Election Dataset 981.0 KB Simons, Shoshana What Communication Complexity Can Tell Us About Circuit Complexity 199.5 KB Stone, Henry Transparent Voxelized Geometry Representations for Machine Learning 18.0 MB Tu, Karen Explaining Black Box Models for Document Retrieval 1.3 MB Wagner, Andrew Where to Begin Synthesizing Initial Configurations for Cellular Automata 382.1 KB 2019 Ball, Michael RIPPED Recursive Intent Propagation using Pretrained Embedding Distances 1.9 MB Brennan, Nathaniel Remote Object Fetching with Descriptive Question Asking 339.1 KB Chaudhry, Abraar Uncertainty Quantification for Robust Classification 1.7 MB Diwan, Renuka The Effect of Rural Road Development on Hospital Births Evidence from India 656.2 KB Farley, Edwin Missing Data Methods when Values are Missing Together A Simulation-Based Examination of Joint Modeling and Fully Conditional Specification Imputation Schemes 289.4 KB Fong, Grant Direct Message Extraction for Automatic Emotional Inference and Drug Detection 838.3 KB Gleyzer, Leonard Weakly-Supervised Classifier Learning via Temporal Logic 1.1 MB Guerrant, Elisa Hardening the Linux Kernal Key Retention Service against Information Disclosure Vulnerabilities 615.8 KB Jiang, Elaine Practicing in Virtual Reality Improves Mental Rotation Ability Lower Scorers Benefit More 626.3 KB Kasser, Lucas Lightfield Superpixel Segmentation and Segmentation-Based Editing 23.3 MB Li, Michael Natural Language Understanding within the context of Question Matching 841.6 KB Murphy, Daniel Markerless 3D Pose Estimation from RGB Data 667.5 KB Nadimpalli, Shivam Discrete Isoperimetry and Protein Folding 1.8 MB Ramos, Jerome Explainability in Transparent Information Retrieval Systems 711.9 KB Romano, Joseph WebMesh A Browser-Based Computational Framework for Serverless Applications 277.7 KB Roy, Josh Learning Feature Extraction for Transfer from Simulation to Reality 3.4 MB Servan-Schreiber, Sacha Cryptographically Certified Hypothesis Testing 1.1 MB Shteinfeld, Benjamin LibFilter Debloating Dynamically-Linked Libraries through Binary Recompilation 122.9 KB Turcu, Adrian Protein Folding Prediction and Visualization Techniques Based on Hydrophobic Side Chain Interactions 5.3 MB Weir, Nathaniel Bootstrapping Generalization in Neural Text-to-SQL Semantic Parsing Models 1.3 MB Zhang, Aaron Proofs of sequential work with unique proofs 479.9 KB 2018 Gadre, Samir Teaching Robots Using Mixed Reality 6.1 MB Guo, Yue Sophie Finding Optimal Strategies over Families of Tasks in Reinforcement Learning 909.4 KB Hou, Andrew Light Field Super Resolution with Convolutional Neural Networks 3.2 MB Karamcheti, Siddharth Grounding Natural Language to Goals for Abstraction, Generalization, and Interpretability 1.8 MB Kim Jr., Isaac Advancing Precision Medicine - Investigating The Relationship Between Race, Comorbidities, and Cancer Through Network Analysis 20.2 MB Kubala, Vincent Inferring the Intentions of Learning Agents 265.0 KB Lightsey, Connor Restricted Transactional Memory and SkipLists 339.7 KB Picard, Noah Smooth Segmentation in Videos Blind Consistency Over Semantic Segmentations Produced by Fully Convolutional Networks 21.6 MB Porncharoenwase, Sorawee An Inside-Out Resugaring System 338.4 KB Pratt, Sarah A Machine Learning Approach to Improve Automated Kinematics Tracking of Non-Human Primates 4.9 MB Sanford, Clayton Applying Rademacher-Like Bounds to Combinatorial Samples and Function Selection 719.5 KB Shi, Di Yang Steven An Exposition of Adversarial Examples in Neural Networks 8.3 MB Whang, Sungseob Exploiting Timing Violations under Voltage Scaling with Hardware Transactional Memory 2.6 MB 2017 Chen, Frances Exploring the Conversion of Videos into 3D Models 14.2 MB Chitra, Uthsav Random Walks on Hypergraphs with Applications to Disease-Gene Prioritization 904.6 KB Cunningham, Nick Two-Party Generation of Shared RSA Keys through Encryption Switching Protocols 218.5 KB Jayaram, Rajesh Learning Stochastically Evolving Networks via Local Probing 831.5 KB Liu, David Nonparametric Clustering with Variational Inference for Tumor Heterogeneity 2.9 MB Perera, Sudheesha A Haplotype-Based Predictive Model for GenotypeExpression Datasets 878.8 KB Vemuri, Keshav Growth Rate of the Cube Recurrence 429.8 KB 2016 Hoff, Timothy Adam Extending Open vSwitch to Facilitate Creation of Stateful SDN Applications 119.9 KB Kim, YounHun Algebraic Connectivity of Graphs, with Applications 309.5 KB Nado, Zachary Deep Recurrent and Convolutional Neural Networks for Automated Behavior Classification 2.8 MB Sachs, Sarah Similar-Part Approximation Using Invariant Feature Descriptors 4.5 MB Thompson, Joseph Recent Applications in Mechanism Design 252.8 KB Wallace, Henry Clustering of Musical Genres 980.3 KB 2015 Acheson-Field, Hannah Reconstructing Clonal Trees From Multi-Sample Sequencing Data 1.2 MB Correa Orozco, David TeachWithGlass Improving the Teaching Experience through Google Glass 509.1 KB Eldon, Miles Incrementally Interpreting Multimodal Referring Expressions in Real Time 4.6 MB Hershkowitz, D. Ellis Leveraging and Learning Propositional Functions for Large State Spaces in Planning and Reinforcement Learning 5.1 MB Light, Alex Reenix Implementing a Unix-Like Operating System in Rust 335.3 KB Lu, Jeffrey Avoiding Parameter Overfitting in a Monte Carlo Approach to Real-Time Strategy Games 329.8 KB Metaxa-Kakavouli, Danae SleepCoacher Combining Computational and Clinician-Generated Sleep Recommendations 3.2 MB Phene, Sonia Parallelization of Variational Inference for Bayesian Nonparametric Topic Models 506.0 KB Schvimer, Judah Take the First Right and Go Straight Forever Novel Planning Algorithms in Stochastic Infinite Domains 429.0 KB Siranosian, Benjamin A Multi-scale Ensemble Model of Chromatin Conformation 1.7 MB Steen, Frances Teleportation as a Strategy for Improving Concurrent Skiplist Performance 476.2 KB Stephenson, Will Variational Inference for Hierarchical Dirichlet Process Based Nonparametric Models 3.0 MB Wu, Chenggang Nested Transaction An Efficient Facility to Enforce the Nesting and the Partial Ordering Requirements in S-Store 1.1 MB Yauney, Gregory Artificially and Hopefully Intelligently Modeling Program Synthesis Planning in a Large, Strange State Space 232.5 KB 2014 Aebi, Bryce Peernote Status Report Boreiko, John Implementation Analysis of Haze Protocol Frantz, Jacob Dynamic Resolution Fluid Simulation by Spectral Methods Herlihy, Anna Compilation Techniques for Distributed Analytics Hou, Ning Two Problems Related to cis-Regulatory Architecture of Transcription Factor Encoding Genes Homologous Translation and Evolutionary Conservation-Based cis-Module Inference Hsiao, Vivian Network Constrained Regression Jain, Vishesh Network-Based Analyses of Pathological Gene Pathways in Neuropsychiatric Disorders 546.4 KB Janthong, Abhabongse Streaming Algorithm for Determining A Topological Ordering of a Digraph 411.8 KB Leavitt, Jonathan End-to-End Tracing Models Analysis and Unification Wald, Elias A More Performant List Under Concurrent Environments Using Hardware Support for Transactional Memory 2013 Clay, Patrick Discovery of Mutated Collections of Genes Associated with Survival in Cancer Using Local Search 182.0 KB Kang, Jung Uk Computational Modeling of Scene-selective Visual Neurons in area LIP Lateral Intraparietal 1.3 MB Karumbunathan, Aswin Using Predictive Models for Compression in Database Systems 597.4 KB Lauria, Kshitij Combinatorial Algorithms for Bipole Self-Assembly on Lattices with Applications to the Lipid Bilayer 522.7 KB Malkin, Nathan Waiting Makes the Heart Grow Fonder and the Password Grow Stronger 298.6 KB McErlean, Doug One Constraint to Rule Them All How to simplify optimizations under constant variable sum, with applications for maximum likelihood 311.2 KB Storch, David Towards an Intelligent Bidding Agent in QuiBids Penny Auctions 453.3 KB Tremel, Edward Real-World Performance of Cryptographic Accumulators 747.5 KB Zweig, Jonathan Procedural Architectural Facade Modeling 2.0 MB 2012 Boger, Sam Defense Against the Dark Arts An Approach to Introductory Computer Security Education 433.0 KB Bressler, Garrett Software Transactional Memory in the Linux Kernel 954.2 KB Changpinyo, Soravit Learning Image Attributes using the Indian Buffet Process 2.5 MB Franco, Jacob Cryptic Population Substructure and Fuzzy Clustering 1.5 MB Gillani, Nabeel Joint Assessment and Restoration of Power Systems 2.4 MB Herman, Jeffrey A Markov random field model for inferring population structure 731.0 KB Ryza, Sandy Solving Hard Problems with Lots of Computers 455.2 KB Stix, Eric An Empirical Study of Online Penny Auctions 202.8 KB Stix, Jeffrey Designing a Bidding Algorithm for Online Penny Auctions 302.8 KB Weis, James Computational Genomics and Bioenergy Modeling and Clustering of RNA-SEQ Data 1.0 MB 2011 Donahue, Evan Searching for the Blackbox Unsupervised Recovery of Relational Schema from Unstructured Airplane Crash Reports 259.4 KB 2010 Mustacchi, Robert StashFS Generalized Disconnected Operation 237.4 KB Saftoiu, Claudiu JSTrace Run-time Type Discovery for JavaScript 268.1 KB Stewart, Allan Face-center cubic FCC lattice models for protein folding energy function inference and biplane packing 657.9 KB 2009 Cheever, Elizabeth One Dimensional Simulations of Cerebral Blood Flow 3.6 MB Fischer, Travis Milton 6.5 MB Franks, Alexander An Efficient Image Search Algorithm For Object Feature Identification in Biological Vision 525.5 KB Lapping-Carr, Micah RGame A Video Game for Interactive Robot Learning 4.2 MB 2008 Baskin, Jacob Comparing Apples and Oranges Using Consensus Rankings for Decision Support 141.7 KB Cunningham, Sam Predicting when seam carved images become unrecognizable 4.9 MB Diamond, Brandon incr Insight An easy to use, easy to extend module system for InsightGDB 353.8 KB Garton, Lian An Investigation of Population Subdivision Methods in Disease Associations with a Focus on Markov Chain Monte Carlo 208.3 KB Gordon, Colin Stebbins Type-safe Stack Traversal for Garbage Collector Implementation 313.3 KB Panda, Aurojit An Empirical Study of Structural Symmetry Breaking 267.4 KB Quirk, Lincoln Ownership of a queue for practical lock-free scheduling 146.6 KB Winograd-Cort, Daniel Deducing Relevant Bridge Bidding Information from Double Dummy Data 1.6 MB 2007 Austerweil, Joe A Unified, Global and Local, Hierarchical Generative Document Ordering Model 249.4 KB Greenberg, Michael Declarative, composable views 156.5 KB Lee, Seong Jae Comparison of Bidding Algorithms for Simultaneous Auctions 454.7 KB Meyerovich, Leo Flapjax Functional Reactive Web Programming 709.4 KB 2006 Ballard, Lucia Conflict Avoidance Data Structures in Transactional Memory 213.4 KB Chang, Edwin Sketching Articulation and Pose for Facial Meshes 1.6 MB Tse, Ronald Henry TCP Fairness in Multipath Transport Protocols 1.6 MB 2005 Arnaudov, Vesselin Unified Management of Heterogeneous Sensor Networks In the Atlantis Framework 239.3 KB Bookstaber, Daniel Using Markov Decision Processes to Solve a Portfolio Allocation Problem 532.5 KB Bromberg-Martin, Ethan Partial-Order Alignment of RNA Structures 1.5 MB Kern, Edward The Crunch Mobile Robot 426.8 KB Lee, Stephanie Quantitative Metrics for White Matter Integrity Based on Diffusion Tensor MRI Data 608.6 KB Sakai, Haruyoshi Internet Poker Data Collection and Analysis 1.4 MB Taubman, Gabriel MusicHand A Handwritten Music Recognition System 419.8 KB Tom, Nancy GuShi An Innovative Multimedia Program Implementing Traditional Textbook Methods for Teaching Intermediate Second Language Learners 442.4 KB Tschantz, Michael The Clarity of Languages for Access-Control Policies 205.7 KB Ye, Jason Atlantis Location Based Services with Bluetooth 248.2 KB 2004 Benisch, Michael Optimization Under Uncertainty in Online Trading Agents 252.1 KB Licata, Daniel Verifying Interactive Web Programs 509.9 KB 2003 Blundell, Colin A Constraint-Based Approach to Open Feature Verification 230.6 KB Egan, Kevin Techniques for Real-Time Rigid Body Simulation 397.3 KB Eigen, David Java Demonstration Software for Differential Geometry and Polyhedral Theories 191.9 KB Finkel, Benjamin Curvilinear Graph Drawing Using The Force-Directed Method 135.5 KB Ho, Kate Data Replication under Latency Constraints 340.7 KB Huang, Albert Ad-hoc Collaborative Document Annotation on a Tablet PC 221.8 KB Kern, Josh Aurora Performance Monitoring Tool Programmers Guide 355.1 KB Lederman, Roger Optimization of Stochastic Inventory Control with Correlated Demands 159.7 KB McClain, Andrew W. CaveSculpture Creating sculpture from CavePaintings 691.5 KB Pytlik, Brock Automatic Debugging Using Potential Invariants 833.6 KB Schrock, Eric Dynamic Lock Dependency Analysis of Concurrent Systems 333.3 KB Sigelman, Ben Video-Based Tracking of 3D Human Motion Using Multiple Cameras 12.0 MB Straub, Christian D. Authentication of Embedded Data in HTML Documents through the Use of Prooflets 379.1 KB", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Undergraduate Honors Theses"], "word_count": 2732, "token_count_estimate": 4648}}, "https://cs.brown.edu/degrees/undergrad/extended.html": {"text_content": "Our Fifth Year And Alternative Masters Options Staying A Fifth Year A student earning an ScB in one field for example, computer science and an AB in another for example, economics is permitted to stay an extra year if needed to finish up concentration requirements. The student must pass a minimum of 38 courses and declare their intent to stay for a fifth year by their fifth semester. Another option please see below is to earn a Masters degree. Earning A Fifth-Year Masters Degree Brown has three programs under which an undergraduate can stay for a fifth year to earn a Masters degree The Master of Science in Cybersecurity is the only program of its kind in the Ivy League, a fully online degree designed to bring together students from all over the world. Cybersecurity at Brown is rooted in the Universitys interdisciplinary approach to learning and solving problems and participants will attend the same classes as in-person students, graduating with a sophisticated understanding of subjects like cryptography, network security, and cloud security. Click here to learn more and here to apply. The Fifth-Year Masters Degree program allows students, after completing their Baccalaureate degree, to continue at Brown for a Masters degree and use courses taken while an undergrad to satisfy two of their Masters course requirements. Applications open in mid September. Students completing their undergraduate degree requirements in December or May must apply by May 1 of that academic year for entry into the program in September. In addition, students who complete their undergraduate degree requirements in December may opt to apply by October 15 for entry into the program the following January. To apply, go to httpsapply.professional.brown.eduapply and indicate on your application that youre a current Brown senior. This last instruction will soon change. Of the eight courses used to satisfy the Masters degree requirements, two may be completed while the student is an undergraduate, even if they are also used to satisfy undergraduate concentration requirements. At least six semester courses must be taken while in residence as a masters student the student should complete their graduate study in two semesters. While a student must be enrolled as an active undergrad student at the time of application, admission to the masters program can be deferred for up to two years with approval of the departments director of graduate studies masters. The Concurrent BaccalaureateMasters Degree program click here to apply allows exceptionally capable students to combine their last year or two of undergrad study with grad study, resulting in the simultaneous completion of both a Baccalaureate degree and a Masters degree. Students must apply for this program during their junior year. Their applications must be first approved by the Committee on Academic Standing, which will ascertain that the students academic performance has been outstanding and that the students undergrad program is sufficiently broad normally meaning taking at least ten courses outside their fields of concentration. Applications then must be approved by the Graduate Council and the appropriate department, which may place additional requirements on admission to this special program. The candidate must complete a minimum of thirty-six courses within eight or nine semesters and complete the requirements of both the Baccalaureate degree and the Masters degree. No more than two courses may be used to satisfy both Baccalaureate concentration requirements and Masters requirements. Brown CS permits only those students pursuing an ScB in any of its concentrations to obtain a concurrent BaccalaureateMasters degree.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Our Fifth Year And Alternative Master's Options", "Staying A Fifth Year", "Earning A Fifth-Year Master's Degree"], "word_count": 574, "token_count_estimate": 663}}, "https://cs.brown.edu/video/171/": {"text_content": "Susanne Schennach, Brown University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Ffmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Ffmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Ffmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Ffmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1017 a.m. Duration 04948 Learning from Errors Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Ffmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Ffmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Ffmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Ffmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Susanne Schennach, Brown University"], "word_count": 73, "token_count_estimate": 289}}, "https://cs.brown.edu/video/172/": {"text_content": "Mark Satterthwaite, Northwestern University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fgmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fgmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fgmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fgmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1025 a.m. Duration 05702 Designing Economic Institutions Accomplishments and Constraints Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fgmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fgmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fgmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fgmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Mark Satterthwaite, Northwestern University"], "word_count": 76, "token_count_estimate": 296}}, "https://cs.brown.edu/about/system/services/files/filesystem/backups/snapshots/": {"text_content": "Snapshots Introduction The CS Department uses a GPFS General Parallel File System file server to provide network file service to both Unix and Windows clients. This server has a feature known as snapshots which allows for file recovery of recently changed or deleted files. On our system, snapshots are enabled for the main filesystem which includes the admin, course, home, and research directories. This document will show you how this mechanism works and how to use it. How does it work A snapshot is a read-only copy of all the files and directories in the filesystem. The server creates a snapshot every four hours. Snapshots can be accessed as quickly and easily as the live filesystem from the .snapshots directory in every directory. Snapshot directories are named for the GMT time the snapshot was taken. On disk we keep the most recent six snapshots, the last seven snapshots taken at midnight, and the last four snapshots taken at midnight on Sundays. This means that the live filesystem will have backups going back about a month. The snapshot mechanism is independent of our normal tape backup mechanism, which goes much further back. Using Snapshots How you use the snapshots depends on whether youre using Windows or Unix . For more information See the Backups, Restores, and Snapshots page for more information.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Snapshots"], "word_count": 220, "token_count_estimate": 251}}, "https://cs.brown.edu/video/173/": {"text_content": "Vincent Crawford, Oxford University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fhmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fhmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fhmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fhmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1035 a.m. Duration 13827 Efficient Mechanisms for Level-k Bilateral Trading Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fhmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fhmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fhmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fhmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:44+00:00", "headings": ["Information for:", "Vincent Crawford, Oxford University"], "word_count": 76, "token_count_estimate": 293}}, "https://cs.brown.edu/video/174/": {"text_content": "Panel DiscussionSweat-Box Session with Professors Satterthwaite and Crawford video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fjmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fjmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fjmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fjmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1048 a.m. Duration 05954 Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fjmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fjmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fjmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fjmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Panel Discussion/Sweat-Box Session with Professors Satterthwaite and Crawford"], "word_count": 74, "token_count_estimate": 297}}, "https://cs.brown.edu/degrees/undergrad/jobs/consult/": {"text_content": "Sunlab Consultants The consultants support the machines and users in the Sunlab and the MSlab . The consultant on duty sits at 9a, the machine nearest the door when you enter the Sunlab. The consultants also maintain other labs throughout the department when there is need. CIT 201 is currently used for this purpose. The Project and Financial Manager and head consultants manage the Sunlab, MSlab, and the student consulting staff. New consultants are hired for the following year each spring semester. Hiring is conducted by the Project and Financial Manager and head consultants . Occasionally, if vacancies need to be filled, one or more additional consultants will be hired in December. Schedule Consultant Hiring Schedule Sunlab consultant applications are currently open Click here to apply. Current Consultants Name Login Nicholas Vadasz nvadasz Richard Tang rtang26 Dylan Hu dhu24 Adam Bredvik abredvik Nick Bottone nbottone Melvin He mhe36 Damir Kulzhanov dkulzhan Christian Armstrong carmstr8 Alexander Mazansky amazansk", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Sunlab Consultants", "Schedule", "Consultant Hiring Schedule", "Current Consultants"], "word_count": 157, "token_count_estimate": 213}}, "https://cs.brown.edu/video/175/": {"text_content": "Freeman Dyson, Institute for Advanced Study video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fkmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fkmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fkmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fkmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1101 a.m. Duration 05135 The Blacksmiths Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fkmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fkmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fkmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fkmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Freeman Dyson, Institute for Advanced Study"], "word_count": 74, "token_count_estimate": 291}}, "https://cs.brown.edu/degrees/undergrad/jobs/": {"text_content": "Undergraduate Jobs There are many opportunities for undergraduates to work in the department. This page only contains Computer Science department-specific opportunitiessee the Student Employment Office for other student jobs at Brown. In addition to working as consultants, working for the UTA program, and working with the technical staff, there are also opportunities for undergraduates to assist with or conduct their own research. Note that most of these positions are hired regularly, but some become available on a less predictable basis. Check the individual pages, which should provide information about hiring and which faculty or staff person you should contact. Undergraduate Research Undergraduate Research Assistantships URAs Several undergraduates in the Computer Science department routinely assist with or even conduct their own research. Undergraduates generally receive academic credit for research work but, in some cases, can receive pay. Meta Undergraduate Research Assistants MURAs MURAs help coordinate undergrad research opportunities in the department. They answer questions about research, advertise research opportunities for semester andor summer positions, and host various outreach events throughout the semester to encourage students to get involved with research. MURAs are compensated for their work with pay. Teaching Assistant TA program Head Teaching Assistants HTAs HTAs work with professors to coordinate many aspects of a course and manage a staff of UTAs if the course has any. An HTAs role can be very different from a UTA. HTAing often requires more attention to administrative details, organization, and often is a greater time commitment. Being an HTA really gives you the chance to shape a course and work closely with a professor. Shortly after being hired, HTAs begin coordinating the process of hiring UTAs if the course has any. HTAs are compensated for their work with their choice of either credit or pay or, in some cases, a combination of both. Teaching Assistants UTAs UTAs work with professors and HTAs to support one of the departments courses during the semester. UTAs responsibilities typically include holding TA hours, grading assignments, writingrevising course assignments and materials, working on lecture slides, preparing support code or demos of programs, attending class, and in some cases, presenting supplemental materials for the class. UTAs are compensated for their work with their choice of either credit or pay or, in some cases, a combination of both. Meta Teaching Assistants MTAs MTAs work in conjunction with the Director of Undergraduate Studies to coordinate the TA Program and several other department-wide activities. Responsibilities include overseeing HTA, UTA, and STA hiring and training, managing TA program resources, and providing logistical and technical support for the program as a whole. MTAs are compensated for their work with pay. Socially Responsible Computing Teaching Assistants STAs STAs formerly known as ETAs work directly with professors, HTAs, and the Head STAs to identify social issues relevant to their designated course, communicate with course staff, study the course structure, and collaborate with course staff to develop a curriculum plan for socially responsible computing content. STAs directly report to their courses HTA and the HSTAs, and their responsibilities also may include writing new assignments and grading STA-specific content for their course. STAs are compensated for their work with pay. Head Socially Responsible Computing Teaching Assistants HSTAs HSTAs formerly known as EHTAs work in conjunction with the Department Chair to coordinate the STA Program. They also organize several department-wide events related to ethics in Computer Science and socially responsible computing. HSTAs are compensated for their work with pay. Technical Staff Sunlab Consultants The Sunlab Consultants are paid to watch over the undergraduate computing labs and to help people use their accounts. The consultants provide support for remote login via SSH and FastX and various programs on the ugrad Linux systems that are commonly used by CS courses at Brown. Sunlab Consultants report to the Head Sunlab Consultants . They are compensated for their work with pay. Head Sunlab Consultants Head Sunlab Consultants work in conjunction with the Director of Information Technology John Bazik and the Project and Finance Manager Kathy Kirman Billings to manage the Sunlab Consultants. They are hired from the pool of Sunlab Consultants when a Head Sunlab Consultant opening arises. Head Sunlab Consultants are compensated for their work with pay. Systems Programmer, Operator, and Consultants SPOCs SPOCs work as fully-fledged members of the departments Technical Staff tstaff and assist in the installation, maintenance, development, and documentation of local software. In addition, they represent the off-hours technical support staff and assist with administrative tasks. The SPOCs report to the Director of Information Technology John Bazik and the Project and Finance Manager Kathy Kirman Billings . SPOCs are compensated for their work with pay. Student Advocates Diversity and Inclusion Student Advocates DI Advocates DI Advocates work in conjunction with the Financial and Outreach Coordinator to identify and advocate for change regarding academic and social diversity issues in the Computer Science department, with the goal of increasing the retention number of students from historically underrepresented groups in Computer Science. DI Advocates are compensated for their work with pay. Health Wellness Student Advocates HW Advocates HW Advocates work in conjunction with the Financial and Outreach Coordinator to aim to improve the mental and physical health with the CS department on an individual and systemic level, as well as increase the sense of departmental community. In addition, they serve as resources that can direct students to campus resources that are relevant to the issues or pressures they may be facing. HW Advocates are compensated for their work with pay.", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Undergraduate Jobs"], "word_count": 909, "token_count_estimate": 1110}}, "https://cs.brown.edu/video/176/": {"text_content": "Nima Arkani-Hamid, Institute for Advanced Study video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Flmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Flmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Flmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Flmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 1217 p.m. Duration 11910 Quantum Mechanics and Space-Time in the 23rd Century Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Flmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Flmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Flmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Flmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Nima Arkani-Hamid, Institute for Advanced Study"], "word_count": 80, "token_count_estimate": 293}}, "https://cs.brown.edu/video/177/": {"text_content": "Leon Cooper, Brown University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fmmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fmmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fmmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fmmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 228 p.m. Duration 03912 Can Free Will and Locality Exist Together in the Quantum Theory Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fmmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fmmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fmmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fmmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Leon Cooper, Brown University"], "word_count": 81, "token_count_estimate": 294}}, "https://cs.brown.edu/video/178/": {"text_content": "Frank Wilczek, MIT video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fnmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fnmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fnmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fnmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 230 p.m. Duration 10355 Physics in 100 Years Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fnmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fnmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fnmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fnmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:45+00:00", "headings": ["Information for:", "Frank Wilczek, MIT"], "word_count": 73, "token_count_estimate": 280}}, "https://cs.brown.edu/video/179/": {"text_content": "Panel DiscussionSweat-Box Session with Professors Dyson, Arkani-Hamid, Wilczek, and Cooper video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fpmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fpmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fpmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fpmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 235 p.m. Duration 04924 Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fpmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fpmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fpmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fpmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Panel Discussion/Sweat-Box Session with Professors Dyson, Arkani-Hamid, Wilczek, and Cooper"], "word_count": 76, "token_count_estimate": 304}}, "https://cs.brown.edu/video/180/": {"text_content": "Marina von Neumann Whitman, University of Michigan video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fqmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fqmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fqmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fqmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 20, 2015, 237 p.m. Duration 01723 A View from Johnnys Daughter Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fqmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fqmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fqmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fqmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Marina von Neumann Whitman, University of Michigan"], "word_count": 78, "token_count_estimate": 295}}, "https://cs.brown.edu/video/181/": {"text_content": "Michael Jordan, University of California video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Frmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Frmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Frmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Frmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 847 a.m. Duration 14226 Computational Thinking, Inferential Thinking and Big Data Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Frmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Frmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Frmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Frmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Michael Jordan, University of California"], "word_count": 78, "token_count_estimate": 284}}, "https://cs.brown.edu/video/182/": {"text_content": "Tom Leighton, MIT, Akamai Technologies video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fsmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fsmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fsmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fsmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 858 a.m. Duration 10040 Grand Challenges Facing the Internet Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fsmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fsmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fsmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fsmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Tom Leighton, MIT, Akamai Technologies"], "word_count": 76, "token_count_estimate": 284}}, "https://cs.brown.edu/video/183/": {"text_content": "Panel Discussion with Professor Leighton video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Ftmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Ftmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Ftmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Ftmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 905 a.m. Duration 04538 Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Ftmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Ftmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Ftmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Ftmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Panel Discussion with Professor Leighton"], "word_count": 71, "token_count_estimate": 283}}, "https://cs.brown.edu/video/184/": {"text_content": "Christos Papadimitriou, University of California video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fvmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fvmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fvmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fvmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 916 a.m. Duration 10402 Games Johnny Would Play Computation as a Lens Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fvmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fvmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fvmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fvmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "Christos Papadimitriou, University of California"], "word_count": 79, "token_count_estimate": 297}}, "https://cs.brown.edu/video/188/": {"text_content": "David Berson, Brown University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fzmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fzmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fzmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fzmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 210 p.m. Duration 12809 The Brain in Your Eye Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fzmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fzmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fzmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fzmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:46+00:00", "headings": ["Information for:", "David Berson, Brown University"], "word_count": 75, "token_count_estimate": 288}}, "https://cs.brown.edu/research/pubs/theses/masters/": {"text_content": "Masters Project Reports 2023 Chen, Catherine Evaluating Search Explainability with Psychometrics and Crowdsourcing 2.6 MB Chen, Yiwen and Ren, Jiahao CLIP NeRFlica Unsupervised Semantic Recognition of Room-scaled Scenes 4.2 MB Chernosky, Brynn Physics Simulations in the Dash Hypermedia System 1.1 MB Christou, Neophytes Preventing Speculative Probing Attacks 246.5 KB Dekle, Max Quantifying Static Privilege Reduction in External JavaScript Libraries 110.1 KB Demetci, Pinar Statistical and Cominatorial Methods to Predict Gene Expression and Identify eQTLs from Haplotype Sequences 2.7 MB Fu, Changcheng Prompt-based Object-centric Video Representation for Action Anticipation 7.0 MB Fu, Haotian Model-based Lifelong Reinforcement Learning with Bayesian Exploration 2.2 MB Goktas, Denizalp Ttonnement in Homothetic Fisher Markets 702.1 KB Golovanevsky, Michal Multimodal Attention-based Deep Learning for Alzheimers Disease Diagnosis 3.0 MB Howe, Wyatt A Federated Public-Document Private-Query Search System 426.6 KB Kaan, Ozulkulu Analysis of Leveraging C via Pybind11 for POMDP Problems Defined in Python 169.4 KB Li, Shihang Leave Nothing Idle Filling Datacenter Resource Utilization Gaps with Quicksand 802.8 KB Lu, Cheng-You HyperBuff Branched Per-Frame Neural Radiance Fields using HyperNetwork 35.4 MB Luo, Calvin Understanding Diffusion Models A Unified Perspective 4.9 MB Maynard, Patrick Enabling Few-Shot Learning on TESS Data with Prototypical Neural Networks 3.8 MB Peng, Kathy Attention-Eraser Training Latents in the Denoising Process to Adjust the Size of User-Select Tokens 20.0 MB Ramesh, Dev Teaching Robots Social Norms with Behavior Trees 3.8 MB Ryjikov, Benjamin Detailing a Translation From the Calculus of Inductive Constructions into Higher Order Logic 189.4 KB Scherick, James A Survey of De Bruijn Graph Properties, Theorems, and Algorithms 13.1 MB Sriram, Abhinav Decentralized Markets for Public Goods Solving Collective Action Problems Using Blockchains 3.6 MB Zhou, Peisen Medical Imaging Segmentation with Self-Supervised Learning 1.9 MB Zhou, Tongyu Filtered ink Creating Dynamic Illustrations with SVG Filters 15.6 MB Zhuo, Wang FLEXIMLearning similarity functions for time-series data 1.4 MB 2022 Alabdulrazzaq, Bader and Zhang, Ce and Fu, Changcheng Addressing Limitations of Slot Attention using a Multiscale Hierarchical Approach 1.6 MB Bagaria, Akhil and Senthil, Jason Skill Discovery for Exploration and Planning using Deep Skill Graphs 3.0 MB Blinn, Bryce Body-Aware Chair Generative Models 173.9 KB Chaaya, Richard Abou Type-based System Call Filtering with Temporal Specialization 193.3 KB Ding, Sijie Canonical Arrangements 1.3 MB Gong, Zhouqi Towards a Perceptual Similarity Measure for 3D Shapes 8.6 MB Houchens, Trevor Neural Omnidirectional Distance Fields 1.1 MB Kim, Yongjeong P4GPP A GPU Accelerated P4 Packet Processing 789.9 KB Nelson, Casey Eliminating Micro-architectural Side-Channel Attacks using NDP 480.6 KB Pal, Koyena Summarization and Generation of Discharge Summary Medical Reports 1.1 MB Pehlivanoglu, Sinan Harpocrates A Statically Typed Privacy Conscious Programming Framework 136.8 KB Pierce, Joshua, Neural Causal Discovery and Social Science Research 1.2 MB Romero, Alejandro CatchAR Prototyping Partial Object Manipulation, Naturalistic Throwing Interactions, and Intuitive Navigation Systems with AR Glasses 6.5 MB Roy, Chitradeep Dutta Shapely residual estimation 329.7 KB Rudman, William and Gillman, Nate IsoScore Measuring the Uniformity of Embedding Space Utilization 1.2 MB Shao, Yunzhi Speculative Compilation of Complex UDFS in Python Data Science 378.3 KB Sharma, Gaurav and Glass, Geoffrey Handling Concept Drift in Weakly Supervised Learning 843.2 KB Sharma, Ishan Read-Your-Writes Consistency in Streaming Dataflow Systems 471.6 KB Woodard, Brandon Increasing the Use of LiDAR Data for Forestry Applications Model for Ground Identification in Waveforms 1.2 MB Yun, Tian and Bhalla Usha Do Vision-Language Pretrained Models Learn Primitive Concepts 2.0 MB 2021 Berckmann, Tucker Structure and Meaning in Word Embedding Spaces 384.9 KB Boger, Sam L-Diversity for Data Analysis Data Swapping with Customized Clustering 364.5 KB Qin, Lucy A Decentralized and Encrypted National Gun Registry 1.9 MB Sumigray, Austin Improving Remote Environment Visualization through 360 6DoF Multi-sensor Fusion for VR Telerobotics 17.9 MB 2020 Alfajardo, Jearson Assessing the Correctness of Debloating Binary Shared Libraries with LibFilter 106.7 KB Beck, Jacob Human-Actor Human-Critic Human Demonstrations and Human Feedback in the Action-Space 3.7 MB Cohen, Loudon Shape From Tracing Report 7.4 MB Goel, Purvi Shape from Tracing Reconstructing 3D Geometry and SVBRDF Material from Images via Differentiable Pathtracing 204.5 KB Hiziroglu, Berkan Perceptual Image Similarity for Unsupervised Representation Learning 440.8 KB Horvitz, Zachary Context-Driven Satirical Headline Generation 1.8 MB Ilkhechi, Amir Rahimzadeh DeepSqueeze Deep Semantic Compression for Tabular Data 1.8 MB Kim, Seungchan Chan Adaptive Tuning of Temperature in Mellowmax using Meta-Gradients 520.9 KB Lei, Leon Assembly of 3D Rooms into Floor Plans from Retrieved Layouts 1.4 MB Lindsay, Natalie Roominoes Learning to Assemble 3D Rooms into Floor Plans 477.8 KB Ma, Jingxiao Approximate Logic Synthesis Using Boolean Matrix Factorization 1.0 MB Ma, Ziyin Fauxtoshop Modeling Image Editing Operations with Kernel Prediction Networks and Parameter Blocks 6.8 MB Narain, Akshar Using Rust to Implement WEASELMUSE and RustyDB 655.7 KB Roy, Josh Visual Transfer for Reinforcement Learning via Wasserstein Domain Confusion 1.5 MB Shah, Aansh Comparing Global with Disease specific Machine-learned Readmission Prediction Models 443.2 KB Shin, Milla Applications of computer vision to population dynamics detecting flowering trees in high-resolution cube-sat imagery 1.0 MB Sinha, Shash Assisting with Scalable Scalable Vector Graphics and VisConnect 7.3 MB Slivinski, Matthew Robust Deep Skill Chaining 1.1 MB Snower, Michael Improving Unpaired Object Translation for Unaligned Domains 10.6 MB Srinivasan, Naveen Causal Inference for Planning in Reinforcement Learning Part 2 334.6 KB Sunkara, Veda Causal Inference for Planning in Reinforcement Learning Part 12 739.7 KB Teng, Changmin NestFuzz A Framework for Fuzzing Nested Virtualization Environments 116.1 KB Varga, Alexander Forging Forge Contributions to the Forge Programming Language 1.1 MB Vexler, Jonathan Characterization of Forward-edge Control-flow Integrity Targets in LLVM-compiled Linux 96.4 KB Wang, Siqi Stylistic Compatibility Learning with Deep Neural Networks for Indoor Scene 2.6 MB 2019 Blum, Roman Treating Agents as Workers 517.7 KB Conard, Ashley Identification of Subclonal Drivers and Copy-Number Variants from Bulk and Single-Cell DNA Sequencing of Tumors 12.8 MB Drelich, Arun Experiments with AIR A Generative Model for Scenes 199.3 KB Gokaslan, Aaron Exploring the Spectrum of Mask Supervision for unpaid Image-to-Image Translation 3.4 MB Huang, Baichuan Flight, Camera, Action Using Natural Language and Mixed Reality to Control a Drone 3.1 MB Lister, Jonathan Project Report Leveraging Near Memory Processing for Cuckoo Cycles 102.4 KB Luo, Shiyang Weak Supervision for Sequence Modeling 133.4 KB McKinney, Samuel Graph-Based Analysis for IoT Devices with Manufacturer Usage Descriptions 1.5 MB Rice, Freddie Color Constancy through Adjusting for Ambient Light 530.8 KB Yang, Jordan Simple Representation of Protein Structure and Folding Techniques 310.8 KB 2018 Arumugam, Dilip Deep Reinforcement Learning from Policy-Dependent Human Feedback 979.0 KB Dutta, Abhishek Applied Machine Learning to Healthcare Predictive Analytics 434.4 KB Fu, Jessica Sochiatrist - Using Conversational and Biometric Data to Predict Mood 659.1 KB Haq, Aman Sketchy Interactive-Influenced Design 77.8 KB He, Yuze Final Project Report 64.0 KB Jones, Andrew Computational modeling of visual attention and saliency in the Smart Playroom 1.9 MB Pendse, Sachin Sochiatrist Inferring the Relationship Between Emotion and Private Social Messages 2.1 MB Sharma, Abhishek Off-Chain Insured Networks 348.6 KB Tumkur Vani, Sumukha Rethinking Distributed Indexing for RDMA-Based Networks 468.0 KB Utama, Prasetya Evaluating Attribute-Object Compositionality in Text-Image Multimodal Embeddings 7.4 MB Wilson, Preston Student Understanding of Aliasing and Procedure Calls 528.5 KB Xiang, Yu Final Project Report 101.5 KB 2017 Camery, Luke On Information Aggregation in Prediction Markets 275.1 KB Hawkins, Craig BrownNow A Current Events Application for Brown University 3.5 MB Hrytsenko, Yana Blockchain for PKI Using Blockchain data structure for Public Key Infrastructure 144.1 KB Johnson-Roberson, Cora Content-Based Genre Classification and Sample Recognition Using Topic Models 161.4 KB Kelly, Samuel Fast Type-based Indexing and Querying of Dynamic Hierarchical Data 571.7 KB Pane, Gianluca Hypergraph Valuations with Restricted Overlapping 423.9 KB Singhal, Kartik How to Reason about Correctness of Programs Designed for Non-Volatile Memory 1.0 MB Solanka, Dronika Automatic Lung Cancer Detection Using Volumetric CT Imaging Features 1.7 MB Su, Ying Data Visualization of the EchoQuery System 2.1 MB Tian, Yulong Data Migration from S-Store to BigDAWG 572.6 KB Tveite, Joshua Masters Project Report 43.8 KB Wang, Bikong The Release of S-Store System 249.0 KB Watson, Jeremy Automating the Collection and Processing of Cancer Mutation Data 708.6 KB 2016 Chen, Junyang Achieving QoE Fairness in Video Streaming via Client-Network Interaction 1.7 MB Hendricks, Jordan kGuard Improving the Performance of kGuard with Low-latency Code Inflation 200.2 KB Murphy, Michael YURT Project Document 82.8 KB Olsson, Carl Scene Category Context for 3D Object Detection with RGBD cameras 4.0 MB Painton, Lee BURLAP BAG An Adjustable Game Engine for the BURLAP framework 314.7 KB Romanski, Julia Algorithms for Large-Scale Prescriptive Evacuations 1.7 MB Rosenthal, Eli Linearizable Iterators 203.0 KB Shao, Qiming Spark, BlinkDB and Sampling 790.6 KB Shen, John Developing an annotations system for the collaborative web application MAGI Mutation Annotation and Genome Interpretation 1.3 MB Sun, Hongkai General Baggage Model for End-to-End Tracing and Its Application on Critical Path Analysis 692.4 KB Tang, Jikai TrendsMap A Real-time US Trends Map for Twitter 1.8 MB Whalen, Christine TrendsMap A Real-time US Trends Map for Twitter 6.1 MB 2015 Abel, David Learning to Plan in Complex Stochastic Domains 829.3 KB Barth-Maron, Gabriel Learning Deep State Representations With Convolutional Autoencoders 549.0 KB Eichmann, Philipp Evaluating Subjective Accuracy in Time Series Pattern-Matching Using Human-Annotated Rankings 1.2 MB Harder, Brigitte Implementing TPC-E, A Streaming Benchmark 1.1 MB The Effect of Visual Aspects of Website Design on User Perception Project Specification 234.9 KB Ho, Mark Teaching Agents with Evaluative Feedback Communication versus Reward 3.5 MB Li, Junsong Shrinking Desugaring 88.4 KB Li, Yiming Simon Scriptable Interactive Monitoring for SDNs 187.3 KB Ni, Mengrui Variational Inference for Beta-Bernoulli Dirichlet Process Mixture Models 6.3 MB Parsons, Timothy SimVis - A Portable Framework for Simulating Virtual Environments 529.0 KB Repetti, Thomas A Case Study in Optimizing HTM-Enabled Dynamic Data Structures Patricia Tries 317.9 KB Roelke, Ryan Dynamic Causal Monitoring for Distributed Systems 3.1 MB Xiang, Lingzhu Mapping and Control with Telepresence Robots 820.6 KB Zhao, Zhe zhao.zhe.pdf 1.1 MB 2014 Ellis, Marquita Early Foundations of a Transactional Boosting Library for Scala and Java 213.2 KB Gao, Fan A Concurrent Skip List Implementation with RTM and HLE 139.6 KB Ghosh, Esha Verifiable Member and Order Queries on a List in Zero-Knowledge 639.3 KB LeVeque, Benjamin Extending Touch Art Gallery 18.8 MB Li, Yan Laboratory for Engineering Man-Machine System LEMS Report of the Reading Research 1.2 MB Lu, Xinyi HDFS Cluster Installation Automation for TupleWare 402.6 KB Shah, Valay Y. Sketch2Real A New photoediting tool for digital alchemy 18.2 MB Zhang, Minrui CS2980 Model-based Semantic Compression in Database Project Report 478.9 KB Zhang, Shu Column-based Database Semantic Compression and Prediction-based Query Optimization 551.8 KB Zhong, Zhigang Fractal Tree Implementation with Intel Hardware Supported Transactional Memory 106.1 KB Zhou, Rui Ray Datacenter Network Large Flow Detection and Scheduling from the Edge 920.0 KB Zhou, Yipin Explore the Power of External Data in Denoising Task 5.0 MB 2013 Bost, Raphael Submatrix maximum queries in Monge matrices an implementation 465.7 KB Boucher, Alicia Interactive Volume Rendering 671.7 KB Holla, Aditya Lock Elision for Memcached Power and Performance analysis on an Embedded Platform 767.6 KB Huang, Huanzhong PUF-Based UC-Secure Commitment without Fuzzy Extractor 211.4 KB Icingir, Hasan Tuna Visualization of Semantic Windows with SciDB Integration 287.2 KB Jia, Xin An Investigation of Performance Bottlenecks in a Main-Memory Database Management System 693.4 KB Leiserson, Mark DM Methods for Identifying Driver Pathways in Cancer 3.6 MB Lester, Ryan A Fast Implementation of FR-Dijkstra 161.0 KB Liang, Chen Software Defined Network Support for Real Distributed Systems 109.2 KB Loomis, Andrew Web Interfaces for Human Bidding Agents and General Auction Scheduling with the Java Auction Configuration Kit JACK 547.8 KB Mahmoody, Ahmad Reconstructing Genome Mixtures From Partial Adjacencies 591.5 KB Moussavi, Vazheh Learning Visual Scene Attributes 1.3 MB Parker, B. Tyler Shadow Figures An Interactive Shadow Animation Platform for Performance 2.7 MB Quay-de la Valle, Hannah Modeling and Reasoning About Effective User Permissions in Social-Sharing Systems 339.1 KB Ramani, Vibhu Regions in Retrievals - Using memorability regions in image retrieval pipelines 1.9 MB Rocco, Dominic Food Streamlined meal planning and invitation application for iOS 709.2 KB Su, Hang Scene Parsing Using Scene Attributes As Global Features 386.2 KB Sun, Li An Attempt to Build Object Detection Models by Reusing Parts 4.9 MB Xu, Chen Applications of Scene Attributes 1.9 MB Zhang, Tan Charles A web application for splicing online videos with annotations 1.3 MB 2012 Ayer, Andrew KVMSandbox Application-Level Sandboxing with x86 Hardware Virtualization and KVM 107.0 KB Calakli, Fatih High Resolution Colored Surface Reconstruction from Oriented Points 10.9 MB Crow, Basil Time and Energy Profiling in Production Sensor Networks with Quanto 327.0 KB Dertat, Arden Meliper Making News Personal 347.8 KB Duc, Phong Nguyen Event-based Phylogeny Inference and Multiple Sequence Alignment 893.1 KB Ehmoda, Omran Statistical Stylometrics and the Marlowe-Shakespeare Authorship Debate 295.2 KB Gillmor, Alexander Linear Methods for SNP Selection 284.6 KB Goldenberg, Seth Exploratory Search in WorkTop 1.5 MB Guha, Arjun Semantics and Types for Safe Web Programming 1.5 MB Hills, Alexander LADS and TAG touch-first Systems for Museum Exhibition and Display 868.9 KB Jin, Li Locality Aware Fair Scheduling for Hammr 225.9 KB Lee, Sungmin Auto-colorization Exploiting Annotated Dataset 6.6 MB Lee, Jihoon Web Applications for Robots using rosbridge 783.4 KB Lu, Yang Serializable Snapshot Isolation in Shared-Nothing, Distributed Database Management Systems 627.4 KB Ma, Zhongyu NUMA aware locks Implementation and Evaluation 172.8 KB Megrelishvili, Georgy GradRanking Online Personalized University Recommendation System 167.5 KB Nguyen, Duy Verification of Web-Content Searching Through Authenticated Web Crawler 960.2 KB Price, Michael NPR.js A JavaScript library for Interactive Non-Photorealistic Rendering in WebGL 1.2 MB Sastrasinh, Paul Improving Data Driven Image Geolocation 5.8 MB Shen, Aaron Aspect-Specific Ranking of Product Reviews Using Topic Modeling 234.0 KB Simon, Benjamin Randomized Adaptive Vehicle Decomposition for Large-Scale Power Restoration 310.8 KB Verch, Shaun Performance Analysis of 64-Bit Capriccio 290.2 KB Wang, Xiaowei Operating System Protection Domains 1021.5 KB 2011 Angkanawaraphan, Visawee AuctionMark OLTP Benchmark 1.0 MB Baldimtsi, Foteini Berg, Jordan Rank and Impression Estimation in a Stylized Model of Ad Auctions 883.4 KB Chin, James C. LADS Tour Authoring Playback System 367.8 KB de Nijs, Joost Decision DAGS - A new approach 645.2 KB Eisenstat, David Random road networks the quadtree model 1.8 MB Elliott, Nell Kiyoko An Algorithm to Find Efficient Supported Solutions of Non-Convex Multiobjective Optimization Problems 2.2 MB Ferguson, Andrew Ghosh, Soumya Image Understanding in a Nonparametric Bayesian Framework 1.3 MB Goldmints-Orlov, Arcady Exploded Images 2.0 MB Gomez, Steve Imhmed, Hassan Distributed Debugging Tool 719.1 KB Jayaraman, Venkatasubramanian Distributed Debugging Tool 719.1 KB Kendall, Donnie Garibaldi LADS Interactive Multitouch Systems for the Visual Arts 1.0 MB Ko, Hsu-Sheng Linear Gesture Recognition and Large Screen Simulation of Gesture Select 586.8 KB Kothapa, Rajkumar Max-Product Particle Belief Propagation 280.1 KB Li, Yu Making Programming More Easily in Code Bubbles 1.2 MB Mallya, Sunil Entracker Energy Tracker for Homes 4.2 MB Martins, Marcelo Mason, Rebecca Extractive Multi-Document Summaries Should Explicitly Not Contain Document-Specific Content 1.1 MB McCann, Paul Caging the Muse Metrics for Unconcious Author Markers 123.0 KB Pattabiraman, Karthik Distributed Debugging Tool 719.1 KB Politz, Joseph ADsafety Type-Based Verification of JavaScript Sandboxing 310.5 KB Santhanam, Deepak Learning to Fuse Disparate Sentences 207.8 KB Segal, Aaron Rational Secret Sharing with Side Information in Point-to-Point Networks via Time-Delayed Encryption 262.8 KB Song, Wei Effective Data Transmission in Distributed Visual Sensor Systems 1.0 MB Swanson, Ben Using Probabilistic Tree Substitution Grammars 473.4 KB Tarvo, Alexander Using computer simulation to predict performance of parallel programs 856.2 KB Vittayakorn, Sirion Quality Assessment for Crowdsourced Object Annotations 3.3 MB Wang, Zikai A Distributed Implementation of Continuous-MapReduce Stream Processing Framework 143.0 KB Zuffi, Silvia 2010 Aguiar, Derek The Clark Phase-able Sample Size Problem Long-range Phasing and Loss of Heterozygosity in GWAS 726.2 KB Coffrin, Carleton Constraint-Based Local Search for the Automatic Generation of Architectural Tests 296.2 KB Doran, Patrick J. Expressive Rendering with Watercolor 12.7 MB Feijoo, Milagro I. Improving Mobile GeoMaps Applications with Expressive Rendering A Test Case 28.8 MB Feldman, Michael Distributed Transactional Boosting 53.6 KB Guan, Peng Estimating Human Shape and Pose from a Single Image 2.1 MB Hristov, Borislav H. Optimizing Directed Acyclic Graphs via Simulated Annealing for Reconstructing Human Segmental Duplications 1.3 MB Hussain, Ahsan Query Generator 195.4 KB Ikhariale, Newton Fractured Indexes Improved B-trees To Reduce Maintenance Cost and Fragmentation 200.0 KB Islam, Sidra Provenance, Lineage, and Workflows 579.0 KB Jablin, James Ragnarok RAndom Graphs Never ARe OK 362.2 KB Kaya, Lutfi Ilke Trading Agents 51.8 KB Keskin, R. Onur Spatial Querying for Camera-Based Tracking Platforms 2.2 MB Miller, Andrew C. Image and Audio Annotation Approximate Inference in Dense Conditional Random Fields 417.6 KB Ohrimenko, Olga Finding Compensatory Pathways in Yeast Genome 258.3 KB Park, Hojoon A Method for Controlling Mouse Movement using a Real-Time Camera 302.2 KB Riondato, Matteo Mining Top-K Frequent Itemsets Through Progressive Sampling 420.2 KB Rosenberg, Dan On-Disk Authenticated Data Structures for Verifying Data Integrity on Outsourced File Storage 133.6 KB Shi, Ning Resolving Ambiguous Paths Using BorderPatrol 178.8 KB Tierney, Kevin GGA A Gender-Based Genetic Algorithm for the Automatic Configuration of Algorithms 175.5 KB Vondrak, Marek Physical Simulation for Probabilistic Motion Tracking 1.4 MB Wang, Dongbo Object Identification by enhanced Local SIFT Features 215.3 KB Wang, Juexin A Rank-Based Skip Lists in Dynamic Provable Data Possession 330.6 KB Xie, Qiao Implementation of Methods for Distributed Data Authentication 143.8 KB Zhang, Zhe An Automatic Source Code Generation Tool for OLTP Database Benchmarks 438.1 KB 2009 Backman, Nathan A Fine-Grained, Dynamic Load Distribution Model for Parallel Stream Processing 246.9 KB Bartholomew, Andy The performance of select STAMP benchmarks with transactional cache hardware configurations 43.3 KB Bascetincelik, Aysun WiiRobot Controlling Robots with Wii Gestures 1.5 MB Berg, Bradley Disentangling Exceptions 309.9 KB Bragdon, Andrew GestureBar Improving the Approachability of Gesture-based Interfaces 732.0 KB Cha, Sanghoon RCHeli Infrastructure for PC-Controlled Micro Helicopter 173.9 KB Conrad, Adam Database Economic Cost Optimization for Cloud Computing 228.8 KB Daniel, Scott An Energy Minimization Approach to Surface Reconstruction 642.2 KB Diamond, Brandon iCDA Continuous Double Auction on the Web 602.3 KB Doutre, Will Providing Captured Images and Video to REVEAL 81.9 KB Eisenstat, Sarah Learning Underlying Forms With MaxEnt 238.6 KB Gbarayor Jr., Kembey Linear Dynamical Systems A Machine Learning Framework for Financial Time Series Analysis 281.1 KB Hickey, Brendan Detection of Correlated Breakpoints in Cancer 897.7 KB Huang, Ling-Ya Improve Chinese Parsing with Max-Ent Reranking Parser 354.6 KB Kadioglu, Serdar Grammar Constraints Combining Expressiveness with Efficiency 557.0 KB Kalafarski, E.J. SurfaceShop Techniques for Complex Adjustments in Multi-Touch Computing 6.2 MB Kallman, Rob Volt GUI Console A Graphical User Interface for Volt Distributed Transaction Processing Database 456.0 KB Kim, Dong Wook Haplotype Phasing using Pre-Resolved Table on the Ancestral Tree Structure 499.0 KB Kumar, Mayank Automating Visual Sensor Networks 312.2 KB Lara, Laura Sevilla Bone tracking from X-Ray sequences 673.4 KB Lin, Ming-Li A Case Study in Extracting DEMs from High-Resolution Mars Stereo Pairs Using a Simple Computer Vision Algorithm 668.6 KB Liu, Chu-chi Contributions on Lineogrammer 974.8 KB Meiklejohn, Sarah An Extension of the Groth-Sahai Proof System 399.2 KB Mozes, Shay Some Lower and Upper Bounds for Tree Edit Distance 603.0 KB Nicholas, Greg Building part compositions for hierarchical object recognition 445.9 KB Odean, Tyler Marginal Bidding An Application of the Equimarginal Principle to Bidding in TAC SCM 166.0 KB Reddy Cherabuddi, Neehar Exergaming Video Games as a form of Exercise 368.6 KB Rogers, Jennie Towards a Generic Data Compression Advisor 1.0 MB Sun, Deqing Learning Optical Flow 1.3 MB Tarpine, Ryan CYRENE A Database, Browser, and Library of Tools for Regulatory Genomics 518.8 KB Wilson, Ahmad Exergaming A Fusion of Exercise and Video Gaming 531.6 KB Yadollahpour, Payman Neurally Constrained Subspace Learning of Reach and Grasp 1.6 MB Yip, Justin Bound Consistency for Binary Length-Lex Set Constraints 175.5 KB Zhao, Zhenyuan Architectural Models for Visual Sensor Networks 127.8 KB Zhou, Wenjin An Analytical Model of Water Diffusion and Exchange in White Matter from Diffusion MRI and Its Application in Measuring Axon Radi 620.0 KB 2008 Akdere, Mert Combining Proactive and Retroactive Processing for Distributed Complex Event Detection 597.0 KB Bircan, Korhan Making Next-Gen Video Games in Your Basement 584.4 KB Boller, Ryan Application of Uncertainty Visualization Methods to Meteorological Trajectories 639.8 KB Bragdon, Andrew GestureBar Making Gestures Browseable, Discoverable, Learnable and Training-Free 688.0 KB Buller, Mark Thermal State Estimation Model Development Using Time Series Machine Learning Techniques 532.5 KB Fuller, Matt RSS Feed Complex Event Detection 299.5 KB Grabiner, David A Treatment of Correlated Attribute Uncertainty in Array Database Systems 215.8 KB Kahn, Crystal Duplication Distance 231.5 KB Kim, Sangjin A Global Credibility Measure in Pairwise Sequence Alignment 1.0 MB Kimura, Hideaki Designing Correlation Indices with Bucketing and Composition 358.5 KB Kostandov, Mykhaylo Qualitative Visual Comparison of Three Simulations of Fluid Flow around a Flying Bat 910.2 KB Lim, Kian Huat Eric A Computational Method to Identify Splicing Elements 6.4 MB Loper, Matthew Research Comprehensive Final Exam Action Recognition on a Mobile Robotic Platform 772.7 KB Maloney, Christopher Michael Reactor An Organic Chemistry Reaction Prediction System 182.0 KB McCorkle, Eric Realizing Concurrent Functional Programming Languages 397.1 KB Miles, Jadrian A Characteristic-Oriented User Evaluation of Immersive Virtual Reality Comparison Visualizations 769.3 KB Mozes, Shay Some Lower and Upper Bounds for Tree Edit Distance 603.0 KB Myers, Aaron Operating System Protection Domains, a New Approach 434.5 KB Pacheco, Jason Temporal Decomposition for Online Multisensor-Multitarget Tracking 813.4 KB Ritz, Anna A Minimum Description Length Approach to the Multiple Motif Problem 1.2 MB Schwertfeger, Jonas Multi-Robot Belief Propagation for Distributed Robot Allocation 156.6 KB Tsoli, Aggeliki Sparse Control of Robot Grasping from 2D Subspaces 388.4 KB 2007 Boghraty, Kaveh Art Gallery Positioning System 513.2 KB Burchett, Kimberley Lowering A Static Optimization Technique for Transparent Functional Reactivity 174.8 KB Dickinson, Brendan Roomba Pac-Man Teaching Autonomous Robotics through Embodied Gaming 1.7 MB Donaldson, John A Marginal Revenue Approach to Bidding in TAC SCM 215.8 KB Elsner, Micha A Unified Local and Global Model for Discourse Coherence 87.8 KB Gaiman, Michael Cellarium A Computational Biology Workflowing Environment Hiratsuka, Tamaki An Algorithm to Compute the Secondary Structure of tRNA Molecules 51.2 KB Hoenselaar, Andreas Mutual Information as a Measure of Relevance in Neural Coding 699.0 KB Jianu, Radu Viewing proteomic experiments in context with known protein 334.4 KB Joo, Jong Wha Joanne Haplotype Phasing Algorithms and Comparison 3.8 MB Koskinen, Eric BorderPatrol Isolating Events for Precise Black-box Tracing 264.2 KB Kupcu, Alptekin SECMECE Optimizing Lifetime of Federated Sensor Networks by Exploiting Data and Model Redundancy 679.6 KB Liang, Vince SmartCIT An Intelligent Sensor Network System 1.3 MB McCarthy, Jay Interaction-Safe State for the Web 821.3 KB Mercier, Luc Strong Polynomiality of Resource Constraint Propagation 521.6 KB Moseley, Mark Technical Aspects of Roomba Pac-Man 1.2 MB Papamanthou, Charalampos Efficient Localization for Wireless Sensor Networks Using Power Measurements Sampling 1.2 MB Penney, Devon A Comparison of Rendering Techniques for Scenes with High Geometric Complexity 80.1 KB Schreiber, Ethan A Distributed Model for Image Recognition Using Pyramidal Bayesian Networks 200.2 KB Schudy, Warren How to rank with few errors A PTAS for Weighted Feedback Arc Set on Tournaments 277.0 KB Tamura, Eric Protection Domains 51.2 KB Tran, Ha Sonic Gallery 171.9 KB Vu, Theresa Modeling the Visual Cortex Object Recognition with Extended Hierarchical Bayesian Networks 178.2 KB Weinberger, Joel Protection Domains 61.4 KB Wicks, John Stochastic Stability 216.0 KB 2006 Apte, Salil Time-varying Azimuth Discrimination and Resynthesis A New Method for Music Repurposing 813.6 KB Birck, Andrew Extending Click to Support Block Requests 408.8 KB Cho, Kyu Wook A Simple Event Detection System for Wireless Sensor Networks 309.7 KB Domanic, Nevzat Onur An Algorithm for Detecting Approximate Tandem Repeats in Genomic Sequences 972.5 KB Erway, Chris Designing the Network Layer for End-Host Traffic Engineering 81.8 KB Fisher, Jessica Motor Cortical Decoding Using an Autoregressive Moving Average Model 152.5 KB Ge, Tingjian Fast, Secure Encryption for Indexing in a Column-Oriented DBMS 287.2 KB Headden, William Learning Phrasal Categories 67.7 KB Ketpreechasawat, Suamporn Hierarchical Landmark Charting 3.8 MB Leland, Ethan The Brown University Robocup 2006 Four-Legged League Team Report 565.7 KB Lemmerman, Dmitri The Effect of Interaction-Display Offset on User Performance for a 3D-Widget Task in the Cave 8.6 MB McClosky, David Effective Self-Training for Parsing 81.1 KB Park, Austin Architecture and Implementation of a Content-based Data Dissemination System 102.1 KB Peng, Luke The Sandbox Improving File Access Security in the Internet Age 754.2 KB Pivkin, Igor Visualization and Interpretation of the Proper Orthogonal Decomposition of Bat Wing Kinematics 337.6 KB Pozar, Michael Bllip An Improved Evaluation Metric for Machine Translation 94.8 KB Rachlin, Eric Robust Nanowire Decoding 2.8 MB Snyder, Derek A Framework for Creating Distributed GUI Applications 206.1 KB Tse, Ronald Henry TCP Fairness in Multipath Transport Protocols 1.6 MB Wrotek, Pawel Dynamo Dynamic Data-driven Character Control with Adjustable Balance vgsp0007 12.0 MB 2005 Cole, Christopher Snapshots and Software Transactional Memory 88.0 KB Fein, Andrea Disney Curves 167.9 KB Funaro, Jesse Diversity as an Objective in Informational Retrieval Experiments with a Navigation System 331.3 KB Jhingran, Anjali Implementation of Type Checker in Borealis 147.4 KB Tenneson, Dana ChemPad A Pedagogical Tool For Exploring Handwritten Organic Molecules 154.5 KB 2004 Chan-Tin, Sebastien Sandboxing programs 1.5 MB Yao, Danfeng Role-Based Cascaded Delegation 4.0 MB 2003 Almanza, Robert Reliable Multicast for Small Wireless Networks 6.2 MB Altshuler, Robert Charles Decomposing Image Sequences into Layers According to Motion with the use of an Appearance Model 8.4 MB Altun, Yasemin Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences 119.3 KB Antoniu, Tudor A Framework for Checking Spreadsheets 12.6 MB Audleman, Kevin Forbes TIV Thread Interaction Visualizer 6.5 MB Ciaramita, Massimiliano Hierarchical Semantic Classification Word Sense Disambiguation with World Knowledge 3.8 MB Convey, Christian The Aurora Storage Manager 4.1 MB Erwin, Christina Aurora Box Research 2.6 MB Flinders, Andrew Energy-Efficient Dynamic Data Scheduling in Wireless Multihop Networks 15.8 MB Jafari, Amir On the Notion of Regret in Infinitely Repeated Games 5.2 MB Karelitz, David Using CavePainting to Create Scientific Visualizations 2.1 MB Kong, George Replica Location in Sand 6.3 MB Leroy, Christian Matthew Exploration of the Routing Task Domain 9.9 MB Nachbar, Curran Detecting Features Through Concept Analysis 8.8 MB Nisenfeld, Scott Using Reality to Evaluate the ITC Presence Questionnaire 3.9 MB Rasin, Alexander Priority-Based Bandwidth Allocation in Aurora 2.3 MB Sigal, Leonid Fabricating People Assembling Articulated 3D Models using Non-parametric Belief Propagation 3.8 MB Sobel, Jason SciVL A Descriptive Language for 2D Multivariate Scientific Visualization Synthesis 4.3 MB Tenneson, Dana Overview of the Goals and Present Status of the Graphics Teaching Tool Project 3.6 MB Wu, Wei Neural Decoding in Motor Cortex 5.0 MB Yan, Robin Implementing a Persistent Query Graphical User Interface for a Streaming Database 5.2 MB Ye, Qiang Security in Reliable Multicasting Security for the Electronic Notebook Project 8.8 MB Zheng, Cheng Distributed Obstruction-Free Transactional Memory 3.0 MB 2002 Chen, Jeff Performance Evaluation of Scheduling Algorithms in Aurora 742.1 KB Cooper, Gregory A Modular Compilation Strategy for Open Classes and Multimethods in Java 2.2 MB Gao, Yun Nonparametric Representation of Neural Activity in Motor Cortex 710.2 KB Hasic, Jasminka An Efficient Dynamic and Distributed Cryptographics Accumulator 579.3 KB Hu, Xiaolan Simulation of Quality of Service QoS Graph-Based Load-Shedding Algorithm in Aurora System Using CSIM 1.3 MB 2001 Acevedo, Daniel ARCHAVE A Virtual Reality Research Environment for Scientific Applications 278.0 KB Chen, Feng Statistical Methods Of Motion Estimation From Omni-Directional Image Sequences 285.8 KB Coglianese, Michael Mobile Aleph A System for Distributed Mobile Applications 263.7 KB Engel, Donald Edward The Utility of Filled Pauses, Interjections, and Parentheticals in Parsing Conversational Language 39.2 KB Gilbert, Richards C. A Program for Quantifying Humanlike Finger Forces Using an Anatomic Hand Tendon Model 529.8 KB Hall, Keith B. A Statistical Model of Nominal Anaphora 227.2 KB Jeon, Seung Hoan A Statistical Model of Nominal Anaphora 66.4 KB Karpenko, Olga Interactively generating 3D models from contour drawings 520.5 KB Keefe, Daniel Kirby, Robert M. Visualizing Fluid Flow Data From the Canvas to the CAVE 997.7 KB Marai, Liz Modeling the Length of Distal Radioulnar Ligaments 371.0 KB Moscovich, Tomer Animation Sketching An Approach to Accessible Animation 129.5 KB Paranthaman, Pramod Prabhat Comparative Evaluation of Desktop and Cave Environments for Learning Hypercube Rotations 213.5 KB Pyo, Changhee Reiter, Jonathan Immersive Hierarchical Visualization and Steering for Spectralhp Element Methods 159.1 KB Reitsma, Paul S. A. Metrics for Motion Editing 206.2 KB Schmidt, Keith Using Tabu Search to Solve the Job Shop Scheduling Problem with Sequence Dependent Setup Times 633.9 KB Shi, Shaoqing Mobile Collaboration System For An Electronic Notebook 76.7 KB Tatbul, E Nesime Index Structures and Algorithms for Efficient Profile Matching 289.8 KB Vega, Luis J. WOODSTOCK A Wireless Stock Trading Game for Windows CE 392.6 KB Xing, Ying Caching on the Changing Web 137.4 KB Zhang, Jie E-Seminar 430.2 KB 2000 Carney, Donald P. Channelization for Publish-Subscribe Systems 291.8 KB Chang, Remco K. Simulation Techniques For Deformable Animated Characters 1.8 MB Coglianese, Michael Mobile Aleph A System for Distributed Mobile Applications 1.3 MB Ho, Jimmy Sketching Interfaces for 2D Animation of Simple Objects 871.6 KB Hu, Ying Monte Carlo Simulation of United States Power Network with Faulty Nodes and Fail Propagation 469.8 KB Zhang, Song Visualizing Diffusion Tensor MR Image Using Streamtubes and Streamsurfaces 5.7 MB 1999 Bhuphaibool, Dom Sithikorn Multi-resolution Animation and Behavior in Densely Populated Scenes 2.3 MB Bose, Rahul The Pub-Sub Simulator 656.5 KB Chen, Qiusheng Checkpointing Transaction-based Distributed Shared Memory 911.2 KB Dahllof, Caroline Painterly Rendering with a Painters Perspective 1.5 MB Guo, Dongbai Automatic image mosaic assembly 1.0 MB 1998 Atanassova, Zornitza Applying Traditional Animation-Techniques to Shared 3D Virtual Worlds 510.2 KB Ayers, Matthew R. A Framework for the Synchronous Editing of Multiple Curve Representations 830.4 KB Bourdev, Lubomir Rendering Nonphotorealistic Strokes with Temporal and Arc-Length Coherence 356.3 KB Bremer, David Rapid Silhouette Rendering of Implicit Surfaces 986.4 KB Choi, Sumi Y. Orthogonal Straight Line Drawing of Trees 715.5 KB Cui, Jie Client-Server Performance Evaluation in Pushed-based Systems 1.2 MB Cummings, Jonathan R. Motion Blending and Editing 1.9 MB Yang, Baolin Project Report Extensions to GeomLib 727.8 KB 1997 Beall, Jeffrey Evan New Java Technologies and a Java-based Framework for Interactive Illustration Development 2.0 MB Chin, Bing Sketching Curved Three-Dimensional Surfaces 190.0 KB Dai, Peng The Performance of Large Software Systems A Case Study 649.0 KB Drew, Kenrick Edward Sketching 2D Stick Figures for 3D Jointed Figures An interaction paradigm applied to a constrained modeling task 145.3 KB Fayan, Randy M. DCE-Web GradeServer 466.8 KB Gorguner, Murat VBnB - Visual Branch and Bound 929.6 KB Luo, Chenghui Construction of an Image Mosaicing and Image-based Rendering System 565.2 KB 1996 Chien, Yung-Ming chien.pdf 3.2 MB Forsberg, Andrew Stephen An Implementation of 6-DOF-Based Direct-Manipulation Techniques for Immersive Virtual Environments 1.5 MB Herndon, Kenneth P. Three-Dimensional User Interfaces for Scientific Visualization 2.3 MB Hoecker, Charles G. A Distributed Threads Package for Solaris 2.4 415.8 KB Leach, Sonia Learning Dynamical Systems Using Hidden Markov Models 1.2 MB Meyer, Thomas Scheduling Time-Critical Graphics on Multiple Processors for Virtual Environments 1.1 MB Wong, Jasper Y. Mini-Distributed System MDS 918.5 KB Wong, Hoog-Shen A Heuristic Search For Linear Programs with 0-1 Variables 1.4 MB Young, Joel D. On Unifying Time and Uncertainty The Probabilistic Temporal Network 484.9 KB 1995 Anderson, Brian G. A Visual Interface for Producing Queries in the AQUA Algebra 1.8 MB Ersan, Murat Extracting Grammatical Information From Large Corpora 572.8 KB Ersan, Ebru Clustering Words 393.2 KB Hasson, Laurent-David GPEC, A Graphical Programming Environment for C 1.3 MB Ignatowicz, Jovanna Ava 3D Menu Text Menus in a 3D World 783.1 KB Jacobson, Neil A. Robotic Object Recognition Utilizing Multiple Views to Recognize Partially Occluded Objects 814.3 KB Jalan, Madhu Estimating Cadinalities of Sets in EPOQ 2.0 MB Lu, Weining Implementation of the EAT-Based Control Strategy for the EPOQ Optimizer 1.1 MB Mamdani, Alnoor Checkpointing and Migration for Quahog 780.2 KB Mander, Bobby Reading Signs Robot Vision for Optical Character Recognition and Motion Planning 1.5 MB Marcus, Mark A Parallel Adaptive Point-Sampling Algorithm 2.2 MB Martin, John K. Building a Client Application in the CORBA Environment Using HyperDesks Object Services 1.1 MB McCann, John Neural Networks for Mobile Robot Navigation 1.1 MB Paglione, Laura Ann Dorival Braitenberg Vehicles in a Virtual Environment 1.3 MB Snibbe, Scott Gestural Controls for Computer Animation 1.8 MB Spiewak, Joshua S. Replication in Spring A New Subcontract 1.1 MB Stradal, Eric The Performance of Various Tracing Algorithms for Shared-Memory Parallel Programs 1.3 MB Vorbrich, David W. Assembly-to-Assembly Translation for Instrumenting User Code 2.4 MB Walker, Peter A. Identifying Failure Modes in Compiler Algorithms applied to Distributed Memory Data Parallel Computation 1.4 MB Yan, Weihua The Performance of Two Tracing and Replay Algorithms for Message-Passing Parallel Programs 1.1 MB 1994 Agarwal, Lalit K. A System for Supporting Mark-based Interaction in Motif 4.5 MB Ashar, Rachita Hierarchical Learning in Stochastic Domains 3.0 MB Cassandra, Anthony Rocco Optimal Policies for Partially Observable Markov Decision Processes 3.7 MB Castanos, Jose Gabriel The Dynamic Adaptation of Parallel Mesh-Based Computation 3.9 MB Corkum, Matt Three Dimensional Morphing Using an Adaptive Oriented Particle System 2.8 MB Ji, Shuang Information Query in Trace-based Debugging 1.3 MB Loughlin, Maria M. An Annotation System for 3D Fluid Flow Visualization 1.2 MB Mamaysky, Harry Three Dimensional Morphing Using an Adaptive Oriented Particle System 2.8 MB Moussavi-Aghdam, Shamsi NISNSI A Name Service Adjunct to SUNs NIS 845.3 KB Phalen, Elizabeth Jean Executing Parallel Programs on a Network of User owned Workstations 2.7 MB Rocha, Renato C. Transaction Management for Multidatabases Interactions Synchronization of Transactions Used on Planning Applications 1.7 MB Rubino, Vincent C. MOM A Memory Object Manager for BOSS 1.4 MB Stevens, Marc A Toolkit for the Construction of Three Dimensional Interfaces 1.4 MB Thatte-Potter, Nisha D. Displaying Multivariate US Census and Migration Data Using Three-Dimensional Graphics and Animation 7.1 MB Vorbrich, David W. Assembly-to-Assembly Translation for Instrumenting User Code 2.4 MB 1993 Baynes, Robert T. Interactions Recovery System IRS Rollback and Recovery for Multidatabases in a Heterogeneous, Distributed Computing Environment 1.8 MB Bhatia, Yashesh V. Design and Implementation of the Logging and Recovery System for InterAction - Multidatabase Transaction Model 1.7 MB Chou, Tsung-Jen A Multiple-Process Implementation of Threads 4.2 MB Curewitz, Kenneth Marion Practical Prefetching via Data Compression 1.8 MB Krupka, John J. 3D Texture Synthesis 1.8 MB Lin, Yueh-hong CCEL The C Constraint Expression Language 1.7 MB Lough, Ira Earl A Tool for Portable Distributed Debugging 1.3 MB Lu, Ming-Tsung Local Database Support for Long-Term Multidatabase Transactions 2.0 MB MacKeith, Andrew EREQ Query Representation and Cost Model 2.8 MB Marshall, Ralph Bringing Graphic Design Expertise to Computer Generated Presentations 1.4 MB McCluskey, Peter C. Feedfoward and Recurrent Neural Networks and Genetic Programs for Stock Market and Time Series Forecasting 1.4 MB Nakai, Sergio A. The Concurrency Control Mechanism of the Mongrel System Design and Implementation 1.3 MB Nakos, Noela V. Specification Environment For Multidatabase Applications 1.3 MB Nuzum, Christopher FutureFone 1.0 MB Papka, Ron Net-time and Conflation Improving Classification Models with Ablated Input 1.7 MB Radhakrishnan, Rajesh Explicit Versus Implicit Remote Procedure Call Based Parallel Programming Languages An Analysis 2.0 MB Reilly, Paul Alan Logging and Recovery in ObServer2 766.8 KB Rosenzweig, Seth H. A Comparative Study of Relational and Object-Oriented Database Technology using The INGRES and ObjectStore Database Management Systems 6.6 MB Stauffer, Adam Concurrency Control and Transaction Management in Observer2 547.8 KB Thamel, Stephen W. Monotonic Chain Decomposition in Randomly Generated Terrains 1.1 MB Tversky, Oren J. Using Texture Mapping and WYSIWYG Painting to Create Geometric Tools 929.2 KB Wong, Eddy XEMS An X-based Event Messaging System 4.9 MB 1992 Apgar, Scott W. Interactive Animation of Fault Tolerant Parallel Algorithms 2.1 MB Axel G. Merk, Ronald C.F. Antony DeTerminator 4.5 MB Chang, Daniel Ta-Ping Browsing in Hypertext Documents With the Assistance of Automatic Link Generation 923.3 KB Cheng, Ming-Li Contribution to Incremental Constraint Algorithms 2.4 MB Duby, Carolyn Kay CCEL A Metalanguage for C 722.5 KB Good, Timothy Todd Blank Map Orienteering For an Autonomous Mobile Robot Using Certainty Grids 7.1 MB Hamlyn, Stuart NeXTPIEMail A Graphical, Personalized Environment Mail Tool 2.0 MB Huang, Chih-Yung Two Phase Commit 563.5 KB Katie Mohrfeld, David Ross Bat A Source-level Debugger for C 8.7 MB Knep, Brian Mapping a 3D Surface to the UV Plane for Texture Mapping, Patchifying and Metamorphosing 883.7 KB Li, Yu-Fang Integrity Constraints for Object-Oriented Database System 3.2 MB Teng, Choh Man On Generic Consistency Algorithms and their Specializations 2.1 MB True, Thomas J. Volume Warping A New Technique for Modeling with Volumetric Data 1.2 MB Weiner, Bob PIEmail A Personalized Information Environment Mail Tool 3.6 MB Wen, James A Three Dimensional Browser for Visualizing Orthogonal Hierarchies Using Only Two-and-a-Half Dimensions 1.2 MB Wood, Christopher A. XComment An Interactive Documentation Tool 2.1 MB Zachwieja, Stephan J. Interactive Collision Detection 1.1 MB 1991 Barman, Dilip K. RelType Relaxed Typing for Intelligent Hypermedia 1.8 MB Bartsocas, Spyros-Nicholas THEODORA Users Manual for Version 0.6 1.1 MB Boyer, Robert An Operating System Development Environment 2.3 MB Chiang, Yi-Jen Dynamization of the Trapezoid Method for Planar Point Location 777.7 KB Delott, Gregory Performance Improvements in the ObServer Object Server 1.5 MB Fitzmaurice, George Form-Centered Workflow Automation Using an Agent Framework 3.7 MB Haring-Smith, Robert Object Models 2.8 MB Hsu, William M. A Direct Manipulation Interface to Free-Form Deformations 1.5 MB Huang, Nathan The Addition of Simulation to BAGS 623.5 KB Husain, Saadia Heuristics for Cost-based Abduction in Belief Networks for Story Understanding 1.2 MB Lee, Jin Joo Localization with Extended Kalman Filtering 822.9 KB Meyers, James M. Automating Multi-Locus Viability Analyses for Human Linkage with Emilie 5.2 MB Morse, Erik J. The CARE Package for CApture and REplay of Parallel Code Sequences 2.4 MB Palmer, Mark L. A Data Cache that Learns to Fetch 947.9 KB Reilly, George V. Text Objects 586.2 KB Singh, Sumeet Kaur User Constraints for Giotto 974.9 KB Stern, Mark L. Interaction Objects 1.8 MB Tegan, Patrice Pattern Specification and Global Transaction Management in Heterogeneous Multidatabases 2.0 MB Wagner, Peter Class Library for the Automation of Motif CLAM Programmers Manual 1.3 MB 1990 Anand, Mala Integrating Observer and Intermedia A Case Study 408.7 KB Borden, Lisa Kay Articulated Objects in BAGS 1.5 MB Chekaluk, Robert Alan Using Influence Diagrams in Recognizing Locally-Distinctive Places 3.0 MB Gold, Melissa Y. Multi-Dimensional Input Devices and Interaction Techniques for a Modeler-Animator 1.9 MB Hagemark, Bent Site A Language and System for Configuring Many Computers as One Computing Site 2.1 MB Hyun, Seungseok Handling Uncertainties in Classifying Junctions 3.7 MB Ishii, Katsuji Garbage Collection for EncoreObserver 1.0 MB Kogut, Richard M. Report on Implementing Caching for ObServer Clients 495.6 KB Kozlowski, Raymond Inferring Knowledge and Ignorance about Motion from the Limits of Vision and Physics 2.5 MB Lee, Shin Y. Collections, Tuples and Iterators in Object-Oriented Database Systems 933.6 KB Liu, Chen Hui-ching An Implementation of Cooperative Concurrency Control in an OODB 3.9 MB Randazza, Margaret J. The Feature Recognition Module of the LDP System for the Robot Huey 3.1 MB Shriver, Elizabeth A. Optimal Disk IO with Parallel Block Transfer 2.1 MB Stone, Margaret D. A System Model Which Accounts for Previous Experience A Combined Interface and Help System 8.2 MB Tsai, Tu-Hsin An Implementation of Certainty Grids for Mobile Robot Exempt from the Higher Order Echo Reflection 1.6 MB 1989 Da Silva, Dilip Raster Algorithms for 2D Primitives 2.8 MB DiPalma, Louis P. Temporal Reasoning with Infinitesimals 1.8 MB Ewald, Alan N. Implementing Views in the ENCORE Object-Oriented Database System 1.6 MB Fernandez, Mary F. Transaction Groups in ObServer 1.7 MB Koh, Young Woo Graphical User Interface to ENCORE -- Type and Instance Browser 2.3 MB Mead, David S. Learning Through Exploration 665.9 KB Nunez, Linda Relationship Between Temporal Bayes Networks and Markov Random Process Transition Tables 3.8 MB Wong, Wayne Dexter A Query Processor for an Object Oriented Database 4.0 MB Zeleznik, Robert C. Visualization of Disassemblies of Mechanical Objects 1.4 MB", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Master's Project Reports"], "word_count": 6611, "token_count_estimate": 11531}}, "https://cs.brown.edu/video/185/": {"text_content": "Leslie Valiant, Harvard University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fwmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fwmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fwmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fwmdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 925 a.m. Duration 10434 How Nature Exploits Big Data Learning and Evolution Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801Fwmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801Fwmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801Fwmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801Fwmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Leslie Valiant, Harvard University"], "word_count": 78, "token_count_estimate": 294}}, "http://architaagarwal.com/": {"text_content": "Home Publications Archita Agarwal E-mail archita.agarwal19gmail.com About Me I am a computer scientist focusing on cryptography and distributed systems. I currently work in the Cryptography Research Group of MongoDB where I design protocols to integrate cryptography into large distributed storage systems, thus making them inherently secure to use. Even though I am a cryptographer by training, I have very broad research interests touching multiple subfields of computer science, including approximation algorithms, databases, and social networks. For example, during my stay at IBM Research, I developed data analysis and visualization tools for large weather datasets, and also designed approximation algorithms for set cover and resource allocation problems. Before joining MongoDB, I was an Assistant Professor for a year at Denison University in Ohio, where I taught both introductory and intermediate CS courses. In general, I like to experiment with non-traditional teaching methods such as flipped classrooms, group exercises to teach content, and theming courses to make them more fun. In my spare time, you can find me challenging a friend to a card game I take pride in knowing at least 30 of them. I am passionate about all things beach-related, watercoloring, and Hindi music. I dream of one day owning a board-game cafe on an ocean beach where people can paint and play to relax with Hindi music older than 2010 playing in the background. I love cricket but I am very slowly moving toward soccer.", "metadata": {"last_modified": "2023-01-20T21:04:12+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Archita Agarwal", "About Me"], "word_count": 236, "token_count_estimate": 288}}, "https://cs.brown.edu/video/189/": {"text_content": "Patricia Churchland, University of California video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F2mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F2mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F2mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F2mdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 228 p.m. Duration 10651 Nerve Agents You and Your Amazing Old-Fangled Reward System Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F2mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F2mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F2mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F2mdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Patricia Churchland, University of California"], "word_count": 80, "token_count_estimate": 297}}, "https://cs.brown.edu/video/194/": {"text_content": "Panel Discussion with Professors Valiant and Papadimitriou video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F8mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F8mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F8mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F8mdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 31, 2015, 225 p.m. Duration 05420 Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F8mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F8mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F8mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F8mdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Panel Discussion with Professors Valiant and Papadimitriou"], "word_count": 73, "token_count_estimate": 291}}, "https://cs.brown.edu/video/190/": {"text_content": "Kenneth Arrow, Stanford University video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F4mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F4mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F4mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F4mdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 21, 2015, 234 p.m. Duration 10218 How the Future Influences the Present Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F4mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F4mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F4mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F4mdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Kenneth Arrow, Stanford University"], "word_count": 76, "token_count_estimate": 290}}, "https://cs.brown.edu/video/195/": {"text_content": "A Conversation with Freeman Dyson video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F9mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F9mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F9mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F9mdres.ogvappletvideo 1280x720 512x288 640x360 Channel Brown University 250th Anniversary Symposium Talks Owner Suzanne Alden Group no group Published July 31, 2015, 227 p.m. Duration 04927 Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801F9mdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801F9mdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801F9mdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801F9mdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "A Conversation with Freeman Dyson"], "word_count": 71, "token_count_estimate": 283}}, "https://cs.brown.edu/video/351/": {"text_content": "Distinguished Lecture Elizabeth Mynatt video controls width640 height360 posterhttpstreamod.cs.brown.edu8801KLmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801KLmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801KLmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801KLmdres.ogvappletvideo 1280x720 512x288 640x360 Channel 2018 Talks Owner John Meehan Group no group Published Feb. 8, 2018, 1105 p.m. Duration 10501 Elizabeth Mynatt Georgia Tech Thursday, February 8, 2017 at 400 PM Room 368 CIT 3rd Floor Rethinking Ubiquitous Computing to Transform Healthcare Healthcare for chronic disease is the dominant cost for many healthcare systems, now and for the foreseeable future. The unique capabilities of pervasive computing technologies have the potential to transform healthcare by shifting care from institutional to home settings, by helping individuals engage in their own care, by facilitating problem solving and decision making, and by creating a network of communication and collaboration channels that extends healthcare delivery to everyday settings. In this talk, I will draw from a number of research projects that integrate computing research, human-centered design, and health management theory to create promising approaches for promoting wellness, supporting behavior change and delivering improved health outcomes. Dr. Elizabeth Mynatt is Distinguished Professor in the College of Computing and the Executive Director of Georgia Techs Institute for People and Technology IPaT. IPaT aims to promote healthy, productive and fulfilling lives on a global scale. By fostering an interdisciplinary and collaborative environment between Georgia Tech faculty, students, and external partners, IPaT provides the continuity and capacity to address and solve todays scientific, social, and economic grand challenges surrounding the health and well being of people, their families, and communities. In her research, Mynatt directs the Everyday Computing Lab. There she investigates the design and evaluation of health information technologies including creating personalized mobile technology for supporting breast cancer patients during their cancer journey, evaluating mobile sensing and mHealth engagement for pediatric epilepsy patients and their caregivers, and investigating the positive and negative influence of social media on self-harm behaviors such as eating disorders. She is also one of the principal researchers in the Aware Home Research Initiative investigating the design of future home technologies, especially those that enable older adults to continue living independently as opposed to moving to an institutional care setting. Mynatt is also the Chair of the Computing Community Consortium, an NSF-sponsored effort to engage the computing research community in envisioning more audacious research challenges. She serves as member of the National Academies Computer Science and Telecommunications Board CSTB and as an ACM Council Member at Large. She has been recognized as an ACM Fellow, a member of the SIGCHI Academy, and a Sloan and Kavli research fellow. She has published more than 100 scientific papers and chaired the CHI 2010 conference, the premier international conference in human-computer interaction. Prior to joining the Georgia Tech faculty in 1998, Mynatt was a member of the research staff at Xerox PARC. Host Professor Amy Greenwald Embed this video video controls width640 height360 posterhttpstreamod.cs.brown.edu8801KLmdres.jpg source typevideomp4 srchttpstreamod.cs.brown.edu8801KLmdres.mp4 source typevideoogg srchttpstreamod.cs.brown.edu8801KLmdres.ogv applet codecom.fluendo.player.Cortado.class archivecortadocortado.jar width640 height360param nameurl valuehttpstreamod.cs.brown.edu8801KLmdres.ogvappletvideo Videos Home Channels", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Information for:", "Distinguished Lecture: E\u200blizabeth Mynatt"], "word_count": 494, "token_count_estimate": 800}}, "https://cs.brown.edu/~amazzett/": {"text_content": "Alessio Mazzetto Publications Alessio Mazzetto amazzett at cs dot brown dot edu PhD student in Computer Science Advisor Eli Upfal Brown University My CV Google Scholar I am a fifth year Computer Science Ph.D. student at Brown University with a research focus in Theoretical Computer Science , where I am fortunate to be advised by Eli Upfal. In Spring 2024, my work is supported by the Kanellakis Fellowship. In Fall 2023, I was a co-instrucor for Advanced Introduction to Probability for Computing and Data Science CS145 . In Summer 2023, I was an intern at Yahoo Research on the Scalable Machine Learning team. My main research area is Machine Learning Theory . I am broadly interested in learning settings where there is access to a small amount of data for the target task. In my work, I developed theoretically sound methods that can quantify and use the knowledge provided by different sources other than labeled data for weak supervision . Recently, I worked on the problem of learning with distribution drift , where we are given a sequence of samples from a distribution that gradually changes in time, and we want to solve a learning task with respect to the current distribution. Prior to coming to Brown, I completed a Master in Computer Science and a Bachelors in Information Engineering from University of Padua in Italy. News January 2024 My first solo-author paper An Improved Algorithm for Learning Drifting Discrete Distributions was accepted at AISTATS 2024 September 2023 Our paper An Adaptive Algorithm for Learning with Unknown Distribution Drift was accepted at NeurIPS 2023 April 2023 Our paper Nonparametric Density Estimation under Distribution Drift was accepted at ICML 2023 Publications An Improved Algorithm for Learning Drifting Discrete Distributions Alessio Mazzetto To appear in Artificial Intelligence and Statistics AISTATS 2024 An Adaptive Algorithm for Learning with Unknown Distribution Drift Alessio Mazzetto and Eli Upfal Conference on Neural Information Processing Systems NeurIPS 2023 pdf Nonparametric Density Estimation under Distribution Drift Alessio Mazzetto and Eli Upfal International Conference on Machine Learning ICML 2023 pdf Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with Attributes Alessio Mazzetto, Cristina Menghini, Andrew Yuan, Eli Upfal, and Stephen H. Bach Conference on Neural Information Processing Systems NeurIPS 2022 pdf Adversarial Multiclass Learning under Weak Supervision with Performance Guarantees Alessio Mazzetto, Cyrus Cousins, Dylan Sam, Stephen H. Bach, and Eli Upfal International Conference on Machine Learning ICML 2021 pdf code Semi-Supervised Aggregation of Dependent Weak Supervision Sources with Performance Guarantees Alessio Mazzetto, Dylan Sam, Andrew Park, Eli Upfal, and Stephen H. Bach Artificial Intelligence and Statistics AISTATS 2021 pdf appendix code Accurate MapReduce Algorithms for k-Median and k-Means in General Metric Spaces Alessio Mazzetto, Andrea Pietracaprina, and Geppino Pucci International Symposium on Algorithms and Computation ISAAC 2019 pdf Manuscripts An Adaptive Method for Weak Supervision with Drifting Data Alessio Mazzetto, Reza Esfandiarpoor, Eli Upfal, and Stephen H. Bach Preprint. Under submission. pdf code Awards Best Master Thesis in Theoretical Computer Science award from Capitolo Italiano of EATCS , 2020. The award was given to the best master thesis in Theoretical Computer Science in Italy for the year 2019. Alessio Mazzetto Last Updated September 2023", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": [], "word_count": 527, "token_count_estimate": 747}}, "https://cs.brown.edu/~aritz/": {"text_content": "HOME RESEARCH PUBLICATIONS SOFTWARE TEACHING Contact Info Dept. of Computer Science 114 McBryde Hall 0106 Virginia Tech Blacksburg, VA 24061 Email annaritz-at-vt-dot-edu I am currently a Postdoctoral Associate in the Department of Computer Science at Virginia Tech , working with T. M. Murali . I develop graph and hypergraph algorithms for signaling pathway prediction. I received my PhD in 2012 from the Department of Computer Science at Brown University , advised by Ben Raphael . My dissertation focused on developing algorithms for structural variant detection for a number of different experimental applications, including array-CGH and various DNA sequencing technologies. I received my Masters from Brown in 2008 for work in motif identification from phosphoproteomic data. From 2008-2011, I was a National Science Foundation Graduate Research Fellowship Program GRFP Fellow. I received my undergraduate degree from Carleton College in 2006. Advised by Dave Musicant , I worked with chemists to develop useful and scalable tools to analyze atmospheric particles.", "metadata": {"last_modified": "2014-12-02T02:08:09+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Contact Info:"], "word_count": 158, "token_count_estimate": 218}}, "https://cs.brown.edu/~bcz/": {"text_content": "Intra-Mural Football Champs, 2001", "metadata": {"last_modified": "2022-02-02T20:40:30+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": [], "word_count": 4, "token_count_estimate": 11}}, "https://david-abel.github.io/": {"text_content": "David Abel Home Publications Notes Teaching Blog Collaborators Welcome I am a Senior Research Scientist at DeepMind in the UK. Before that, I completed my Ph.D in Computer Science at Brown University where I was fortunate to be advised by Prof. Michael Littman . I got my start in research working with Prof. Stefanie Tellex at Brown, and before that studied Philosophy and Computer Science at Carleton College. News Aug. 2024 On a panel at RLC . Jun. 2024 Giving a talk at a workshop in Bath May 2024 Visiting Montreal. Apr. 2024 Visiting the Autonomous Agents group at the University of Edinburgh. Mar. 2024 I am moving to Edinburgh, Scotland. Feb. 2024 Podcast with Ather. Dec. 2023 Attending NeurIPS. Oct. 2023 Recording of Three Dogmas of Reinforcement Learning available. Oct. 2023 Podcast with Ron. Sep. 2023 A Definition of Continual Reinforcement Learning accepted to NeurIPS. Jul. 2023 Attended ICML and gave a talk at the interactive learning workshop . Jun. 2023 Attended a workshop in California. Apr. 2023 Settling the Reward Hypothesis accepted to ICML Apr. 2023 Guest lecture in Prof. Ben Van Roys course at Stanford. Feb. 2023 Attended the Barbados RL Workshop. Jan. 2023 Invited talk at Fidelity AI Lab Interests My research focuses on bringing clarity to the central philosophical questions surrounding agency, computation, and learning. I value research that provides new understanding, and tend to get excited by simple but foundational questions. I typically work with the reinforcement learning problem, drawing on tools and perspectives from across philosophy, math, and computer science. I am currently interested in better defining the main concepts of AI, such as learning, agency, and goals. Previously, my dissertation studied how agents model the worlds they inhabit, focusing on the representational practices that underly effective learning and planning. Featured Research A Definition of Continual Reinforcement Learning NeurIPS 2023 We present a precise definition of the continual reinforcement learning problem. Joint with Andr Barreto , Benjamin Van Roy , Doina Precup , Hado van Hasselt , and Satinder Singh . Settling the Reward Hypothesis ICML 2023 We illustrate the implicit requirements on goals and purposes under which the reward hypothesis holds. Led by Michael Bowling and John D. Martin , joint with Will Dabney . People Construct Simplified Mental Representations to Plan Nature 2022 We develop a new theory describing how people simplify and represent problems when planning. Led by Mark K. Ho , joint with Carlos G. Correa , Jonathan D. Cohen , Michael L. Littman , Thomas L. Griffiths . On the Expressivity of Markov Reward NeurIPS 2021 Outstanding Paper Award We study the expressivity of Markov reward functions in finite environments by analysing what kinds of tasks such functions can express. Joint work with Will Dabney , Anna Harutyunyan , Mark K. Ho , Michael L. Littman , Doina Precup , Satinder Singh . A Theory of Abstraction in Reinforcement Learning Ph.D Thesis, 2020 My dissertation, aimed at understanding abstraction and its role in effective reinforcement learning. Advised by Michael L. Littman . Value Preserving State-Action Abstractions AISTATS 2020 We prove which combinations of state abstractions and options are guaranteed to preserve representation of near-optimal policies in any finite Markov Decision Process. Joint work with Nate Rahn , Khimya Khetarpal , Dilip Arumugam , Doina Precup , and Michael L. Littman . The Value of Abstraction Current Opinions in Behavioral Science 2019 We discuss the vital role that abstraction plays in efficient decision making. Led by Mark K. Ho , joint with Michael L. Littman , Thomas L. Griffiths . Finding Options that Minimize Planning Time ICML 2019 We prove that the problem of finding options that minimize planning time is NP-Hard. Led by Yuu Jinnai , joint with D Ellis Hershkowitz , Michael L. Littman , and George Konidaris . Selected Awards Outstanding Paper Award , NeurIPS 2021, On the Expressivity of Markov Reward Presidential Award for Excellence in Teaching , Brown University Runner-Up , 2020 AAAIACM SIGAI Dissertation Award 7x Top Reviewer ICML 2018, 2019, 2020, 2021 NeurIPS 2019, 2020, AISTATS. About Me Im a big fan of basketball, lifting, baking, reading, games, snowboarding, and music I play guitarpianoviolin and love listening to just about everything. I live in Edinburgh with my wife Elizabeth and our dog Barley. Always up for a chat -- shoot me an email if youd like to discuss anything If you would like to arrange a call, I have a recurring open slot in my calendar here . If you have feedback of any kind, please feel free to fill out this anonymous feedback form . Theme based on minimal by orderedlist Copyright David Abel", "metadata": {"last_modified": "2024-03-12T11:34:22+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["David Abel"], "word_count": 773, "token_count_estimate": 1084}}, "https://cs.brown.edu/~ccousins/": {"text_content": "About News Major Projects Publications Teaching Curriculum Vitae The Life and Times of Cyrus Cousins Finitely Wise, Infinitely Curious About Me Abridged Biography I am Cyrus Cousins, a visiting assistant professor at Brown University in the BIGDATA group, where I also completed my doctoral studies under the tutelage of the great Eli Upfal .Before arriving at Brown University, I earned my undergraduate degree in computer science, mathematics, and biology from Tufts University. My research interests lie primarily in showing novel techniques to bound uniform convergence rates and generalization error in exotic settings, and applying these bounds to tasks of real-world interest, most notably in data science, empirical game theory, and fair machine learning. My favorite theorem is the Dvoretzky-Kiefer-Wolfowitz Inequality , and my favorite algorithm is simulated annealing . Research Overview In my research, I strive to strike a delicate balance between theory and practice.On the theory side, my work primarily lies in sample complexity analysis for machine learning algorithms, as well as time complexity analysis and probabilistic guarantees for efficient sampling-based routines in randomized algorithms and statistical data science 1 2 3 4 .In addition to statistical analysis, much of my work deals with delicate computational questions, like how to optimally characterize and estimate the sample-complexity of various estimation tasks with applications to oblivious algorithms, which achieve near-optimal performance while requiring limited a priori knowledge, as well as the development of fair-PAC learning , with the accompanying computational and statistical reductions between classes of learnable models. On the practical side, much of my early work was led by the observation that modern methods in statistical learning theory Rademacher averages and localized Rademacher averages often yield vacuous or unsatisfying guarantees, so I strove to understand why, and to show sharper bounds , with particular emphasis on constant factors and performance in the small sample setting . From there, I have worked to apply statistical methods developed for these approaches to myriad practical settings, including statistical data science tasks, and the analysis of machine learning, and more recently, fairness sensitive machine learning algorithms. By blurring the line between theory and practice, I have been able to adapt rigorous theoretical guarantees to novel settings. For example, my work on adversarial learning from weak supervision stemmed from a desire to apply statistical learning theory techniques in absentia of sufficient labeled data. Conversely, I have also been able to treat theoretical problems that previously seemed unmotivated or irrelevant my work in fair machine learning led to the fair-PAC learning formalism, where power-means over per-group losses rather than averages are minimized. The motivation to optimize power-means derives purely from the economic theory of cardinal welfare, but the value of this learning concept only becomes apparent when one observes that many of the desirable computational and statistical properties of risk minimization directly translate to power-mean minimization. Research Statements My research statement is publicly available 5 pages. The best mostly current overview of my research is given in my thesis summary 4 pages. The piece is a non-mathematical, but still somewhat technical, overview of my dissertation . The best mathematical overview of my research for general audiences is given in this piece 5 pages. Here the focus is less on applications and implications, and more on intuition for the deeper mathematical connections between my various areas of study. Results are selected for elegance and simplicity, and the piece should be broadly accessible to all audiences with a basic grounding in probability and statistics. News 2021 I was honored to recieve a NeurIPS 2021 Outstanding Reviewer Award . This award is given to the top 8 of reviewers, based on area chair and author feedback. It even came with free registration to the entire conference I received the Deans Faculty Fellowship at Brown University, and will be returning to Brown University in the fall of 2021 as a visiting assistant professor, in order to continue my research and to teach . On March 25, I successfully defended my thesis . I was awarded the Joukowsky Outstanding Dissertation Prize in the physical sciences for my dissertation Bounds and Applications of Concentration of Measure in Fair Machine Learning and Data Science . 2020 I survived an apocalyptic event, largely by staying inside, writing my dissertation , and publishing many papers . 2019 I will be returning to the Labs group at Two Sigma Investments to work with Larry Rudolph . 2018 I have accepted a summer internship offer with Two Sigma Investments, and will be working with Matteo Riondato in the Labs group. Major Projects Axiomatically Justified and Statistically Sound Fair Machine Learning Fair Adversarial Machine Learning from Partial Demographic Information Making mean-estimation more efficient using an MCMC trace variance approach DynaMITE Adversarial Multi Class Learning under Weak Supervision with Performance Guarantees Sharp Uniform Convergence Bounds through Empirical Centralization CADET Interpretable Parametric Conditional Density Estimation with Decision Trees and Forests Empirical Game Theoretic Analysis My dissertation Bounds and Applications of Concentration of Measure in Fair Machine Learning and Data Science A Complete List of Publications Find My Work DBLP Google Scholar ResearchGate Scopus ArXiv Teaching Professor Fall 2021 CS1450 Advanced Introduction to Probability for Computing and Data Science Graduate Teaching Assistant Spring 2020 CS2550CS1550 Probabilistic Methods in Computer Science , with professor Eli Upfal Fall 2018 CS1450 Advanced Introduction to Probability for Computing and Data Science , with professor Eli Upfal Spring 2018 DATA2040 Deep Learning and Special Topics in Data Science , with professors Eli Upfal and Dan Potter Fall 2016 CS1810 Computational Molecular Biology , with professor Sorin Istrail Curriculum Vitae CV Last updated August 2022", "metadata": {"last_modified": "2022-08-08T21:26:07+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["The Life and Times of", "Cyrus Cousins \ud83d\udd0a", "Finitely Wise, Infinitely Curious", "", "", "Abridged Biography", "Research Overview", "Research Statements", "", "", "", "", "", "", "Find My Work", "", "", "Professor", "Graduate Teaching Assistant", "", ""], "word_count": 928, "token_count_estimate": 1159}}, "https://cs.brown.edu/people/am104/": {"text_content": "Ahmad Mahmoody Site Navigation Skip Sidebar Skip Contact first name AT CS dot BROWN dot EDU Department of Computer Science, Brown University, B.O. 1910 115 Waterman St., Providence , RI zip 02912 I am a PhD candidate at the Department of Computer Science of Brown University working under the supervision of Eli Upfal . I am interested in GraphsData mining, and the theory of Machine Learning. Previously, I have done some work in studying cancer evolution under supervision of Ben Raphael . I did my undergraduate studies in mathematics at Sharif University of Technology . Graph Theory, Combinatrics and Linear Algebra were my favorites. During my Masters in mathematics at Simon Fraser University I became interested in the field of Computational Biology and worked under the supervision of Cedric Chauve and Ladislave Stacho . My master thesis . You can download my CV from here . Publications A. Mahmoody and E. Upfal Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection EXTENDED To Appear in Theoretical Computer Science. A. Mahmoody, C. E. Tsourakakis, and E. Upfal Scalable Betweenness Centrality Maximization via Sampling The 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD 2016. A. Mahmoody, M. Riondato, and E. Upfal Wiggins Detecting Valuable Information in Dynamic Networks Using Limited Resources The 9th ACM International Conference on Web Search and Data Mining WSDM 2016. A. Mahmoody, E. kornaropoulos, and E. Upfal Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection The 9th Annual International Conference on Combinatorial Optimization and Applications COCOA15. A. Mahmoody, I. Hajirasouliha, and B. Raphael, Binary tree partitions A combinatorial approach for analyzing intra-tumor heterogeneity from high-throughput sequencing data . , The 22th Annual International Conference Intelligent Systems for Molecular Biology, ISMB 2014, Also, Bioinformatics 30 12, i78-i86. L. Oesper, A. Mahmoody, and B. Raphael, Inferring Intra-tumor Heterogeneity from High-Throughput DNA Sequencing Data , Genome Biology. A preliminary version accepted at 17th Annual International Conference on Research in Computational Molecular Biology RECOMB 2013, LNCS 7821, Pages 171--172 Extended Abstract. A. Mahmoody, C. Kahn, and B. Raphael, Reconstructing Genome Mixtures From Partial Adjacencies , RECOMB-CG, BMC Bioinformatics 2012, 13Suppl 19S9. Ahmad Mahmoody, Tractability Results for The Double-Cut-and-Join Mutlichromosomal Median Problem , M.Sc. Thesis, Simon Fraser University, 2011. Ahmad Mahmoody, A Note on Graceful Graphs with Large Chromatic Numbers , Ars Combinatoria 90 2009, 423--424. S. Akbari, N. Ghareghani, G.B. Khosrovshahi, and A. Mahmoody, On Zero-Sum 6-flows of Graphs , Linear Algebra and Its Appl. 430 2009, no. 11-12, 3047--3052. S. Akbari, M. Jamaali, A. Mahmoody, and S. A. Seyed Fakhari, On the size of graphs whose cycles have length divisible by a fixed integer , Australasian Journal of Combinatorics 45 2009, 67--72. A. Mahmoody, P. Ronagh, and K. Alishahi, Introductory Combinatorics Book in Persian, Fatemi Pub. Co., Tehran, Iran, March 2009. Back To Top", "metadata": {"last_modified": "2016-06-12T05:59:04+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["Site Navigation"], "word_count": 469, "token_count_estimate": 813}}, "https://cs.brown.edu/~dhl/": {"text_content": "David H. Laidlaw Computer Science Brown University Visualization Research Lab lab research pages Research Interests Caltech graphics group Beckman Institute Biology division web pages Some of the projects I am directing and participating in are alsodescribed in the scientific visualization pages of the Brown Graphics Group. Check out the VR Wiki that my cs1951t class has been building. My CV lists publications, teaching,service, funding, and has links to papers. List of allpublications at DPLP , and at PubMed diffusion MRI data Questions, comments, suggestions E-mail me dhlcs.brown.edu Office CIT 521 Snail mail Box 1910, Computer Science Department Brown University Providence, RI 02912 Packages Computer Science Dept 115 Waterman St 4th floor Providence, RI 02906 401-863-7600 voice 401-863-7657 fax For students If you are in CS, See my tips for advisees page", "metadata": {"last_modified": "2022-03-20T18:20:35+00:00", "scraped_at": "2024-03-13T22:15:47+00:00", "headings": ["", "David H. Laidlaw", "Visualization Research Lab", "Research Interests", "For students"], "word_count": 131, "token_count_estimate": 191}}, "https://cs.brown.edu/~gmpatter/cocottributes.html": {"text_content": "COCO Attributes Attributes for People, Animals, and Objects Hays Lab 2016 People Genevieve Patterson James Hays Abstract In this paper, we discover and annotate visual attributes for the COCO dataset. With the goal of enabling deeper object understanding, we deliver the largest attribute dataset to date. Using our COCO Attributes dataset, a fine-tuned classification system can do more than recognize object categories -- for example, rendering multi-label classifications such as sleeping spotted curled-up cat instead of simply cat. To overcome the expense of annotating thousands of COCO object instances with hundreds of attributes, we present an Economic Labeling Algorithm ELA which intelligently generates crowd labeling tasks based on correlations between attributes. The ELA offers a substantial reduction in labeling cost while largely maintaining attribute density and variety. Currently, we have collected 3.5 million object-attribute pair annotations describing 180 thousand different objects. We demonstrate that our efficiently labeled training data can be used to produce classifiers of similar discriminative ability as classifiers created using exhaustively labeled ground truth. Finally, we provide baseline performance analysis for object attribute recognition. Paper Genevieve Patterson, James Hays. COCO Attributes Attributes for People, Animals, and Objects. ECCV 2016. paper , Bibtex , poster COCO Attribute Dataset COCO Attribute Dataset Statistics 84,000 images 180,000 unique objects 196 attributes 29 object categories 3.5 Million objection-attribute pairs Attribute Labels including references to COCO dataset images. Example of how to read COCO Attributes annotations. New Code Release v1.0 Updated 10132016 This is code for the Flask server used to generate the Mechanical Turk tasks for annotating COCO Attributes. Code for finetuning the COCO Attributes network and training attribute classifiers from other pretrained features is also included. GitHub Repo Pretrained COCO Attributes Network 205 MB Pretrained COCO Attributes Network with LBDM formatted training data 6.1 GB", "metadata": {"last_modified": "2017-02-06T21:00:46+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["COCO Attributes:", "Attributes for People, Animals, and Objects"], "word_count": 295, "token_count_estimate": 396}}, "https://cs.brown.edu/~erfanz/": {"text_content": "Erfan Zamanian Computer Science PhD student at Brown University About Me I am currently on the job market. I am a PhD student in the Computer Science Department at Brown University. I am advised by Tim Kraska and am a member of Data Management Group . I received my BSc from Sharif University of Technology , Iran and my MSc from ETH Zurich , Switzerland under the supervision of Donald Kossmann . I can be reached at erfanzcs.brown.edu .You can see my resume here . Research Interests High-performance Transactoin Processing Data Management Systems Distributed Systems Systems for Analytics and Data Science Publications Distributed Data Stores Chiller Contention-centric Transaction Execution and Data Partitioning for Modern Networks , SIGMOD 2020 Rethinking Database High Availability with RDMA Networks , VLDB 2019 The End of a Myth Distributed Transactions can Scale , VLDB 2017 The End of Slow Networks Its Time for a Redesign , VLDB 2016 I-Store Data Management for Fast Networks , NEDB, 2015 Analytics Systems Locality-aware partitioning in parallel database systems , ACM SIGMOD 2015 Spotgres - Parallel Data Analytics on Spot Instances , IEEE ICDE, 2015 XDB A novel Database for Data Analytics as a Service , ACM SoCC, 2013 Fault Tolerance Cost-based Fault-tolerance for Parallel Data Processing , ACM SIGMOD 2015 DoomDB - Kill the Query , ACM SIGMOD 2014 Other Crowd Access Path Optimization Diversity Matters , HCOMP 2015 2018 Erfan Zamanian Carte Noir theme by Jacob Tomlinson and Simon Brand", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Erfan Zamanian", "About Me", "Research Interests", "Publications"], "word_count": 243, "token_count_estimate": 330}}, "https://cs.brown.edu/~gmpatter/sunattributes.html": {"text_content": "SUN Attribute Database Discovering, Annotating, and Recognizing Scene Attributes Hays Lab 2011 People Genevieve Patterson Xu Chen James Hays Abstract In this paper we present the first large-scale scene attribute database. First, we perform crowd-sourced human studies to find a taxonomy of 102 discriminative attributes. Next, we build the SUN attribute database on top of the fine-grained SUN categorical database. Our attribute database spans more than 700 categories and 14,000 images and has potential for use in high-level scene understanding and fine-grained scene recognition. We use our dataset to train attribute classifiers, and evaluate how well these relatively simple classifiers can recognize a variety of attributes related to materials, surface properties, lighting, functions and affordances, and spatial envelope properties. Papers Genevieve Patterson, Chen Xu, Hang Su, James Hays. The SUN Attribute Database Beyond Categories for Deeper Scene Understanding. IJCV 2014. paper , Bibtex Genevieve Patterson, James Hays. SUN Attribute Database Discovering, Annotating, and Recognizing Scene Attributes. Proceedings of CVPR 2012. paper , Bibtex SUN Attribute Dataset Thisdataset includes the 102 attribute labels x 3 worker annotations for each of the 14340 images included.The subset of images from the SUN Dataset used in this project are also available for download from the link below.Users can also download the SUN dataset images used in this project at the SUN Database website . Attribute Labels532 KB including list of images used from SUN dataset. AttributeDB Images1.7 GB including all 14340 images used in the SUN Attribute dataset. Attribute Detectors 102 SUN scene attribute detectors using FC7 feature of Places205-AlexNet, courtesy Bolei Zhou MIT.", "metadata": {"last_modified": "2017-11-06T14:42:32+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["SUN Attribute Database:", "Discovering, Annotating, and Recognizing Scene Attributes"], "word_count": 260, "token_count_estimate": 361}}, "https://cs.brown.edu/people/cerway/": {"text_content": "C. Chris Erway Hi I received a PhD from Brown in 2011.My advisor was John Jannotti .Since then I co-founded Tracelytics , and am now Chief Architect of the SolarWinds Monitoring Cloud . ccecs dot brown dot ee-dee-yew academics, publications While at Brown I was a member of the Brownie Points project , which aimed to provide incentives and accountability in peer-to-peer systems using secure, anonymous e-cash. Before that I worked on the BlueGeneL systems software team at IBM Research to help build the worlds fastest supercomputer. As the Brown CS blog noted , our DPDP paper was recently ranked by Influential Security Papers as the 4th most cited paper in computer security in 2009, and the 50th most cited paper since 1981 Dynamic Provable Data Possession. C. Chris Erway, Alptekin Kp, Charalampos Papamanthou, Roberto Tamassia.In ACM Transactions on Information and System Security TISSEC , Volume 17 Issue 4, April 2015. ACM DL link Anonymous Accounting for Decentralized Systems, PhD thesis pdf ZKPDL A Language-based System for Efficient Zero-Knowledge Proofs and Electronic Cash.Sarah Meiklejohn, C. Chris Erway, Alptekin Kp , Theodora Hinkle, Anna Lysyanskaya. In USENIX Security 2010 . pdf , project page Dynamic Provable Data Possession. C. Chris Erway, Alptekin Kp, Charalampos Papamanthou, Roberto Tamassia.In ACM CCS 2009 . full version on eprint MicroID considered harmful to privacy . C. Chris Erway. Brown CS technical report , 2008. PDF , details Incentivizing Outsourced Computation. Mira Belenkiy, Melissa Chase, C. Chris Erway, John Jannotti, Alptekin Kp, Anna Lysyanskaya. In NetEcon 2008 . full TR version with proofs pdf Making P2P Accountable without Losing Privacy. Mira Belenkiy, Melissa Chase, C. Chris Erway, John Jannotti, Alptekin Kp, Anna Lysyanskaya, Eric Rachlin. In WPES 2007 . PET Award finalist press release , pdf Designing the Network Layer for End-Host Traffic Engineering, masters thesis, from 2006. pdf Optimization of MPI Collective Communication on BlueGeneL Systems. George Almsi, Charles J. Archer, C. Chris Erway, Philip Heidelberger, Xavier Martorell, Jose E. Moreira, Burkhard Steinmacher-Burow, Yili Zheng. In ICS 2005 . pdf , ACM Efficient Implementation of Allreduce on BlueGeneL Collective Network.George Almsi, Gbor Dzsa, C. Chris Erway, Burkhard D. Steinmacher-Burow.In PVMMPI 2005 . doi.org System Management in the BlueGeneL Supercomputer.George S. Almasi, Leonardo R. Bachega, Ralph Bellofatto, Jos R. Brunheroto, Calin Cascaval, Jos G. Castaos, Paul Crumley, C. Christopher Erway, Joseph Gagliano, Derek Lieber, Pedro Mindlin, Jos E. Moreira, Ramendra K. Sahoo, Alda Sanomiya, Eugen Schenfeld, Richard A. Swetz, M. Bae, G. Laib, Kavitha Ranganathan, Yariv Aridor, Tamar Domany, Y. Gal, Oleg Goldshmidt, Edi Shmueli.In IPDPS 2003 . pdf more publications are listed on DBLP , CSB . other my brown.edu public key show hide -----BEGIN PGP PUBLIC KEY BLOCK-----Version GnuPG v1.2.4 GNULinuxmQGiBEFIXf8RBACKfysBOvzeW9Ysjm7AWzMTUc4xWRKuhhehv8PNqjAnl2kGT0rBWWRqCmslfJohOvJooWwYU87xYI78kYOgQCFRAK2UZfbdUAAAxFduzhX6bq06jIqGsCJdcyYxp5oUUB1qElg8fWQy6CWhtIJOb0WikbzRrGSLWy6w0t7LmFaxwCgrcygI642nqsKvfbtNHHPSM30nED2VqDUeVKKa9mO0xDWUr9QDEPI1uAHXL4ZI7mnxi3ODbWGSz5H4ctFCox6b17txT5N1GF4eXEGkpK7TkKFmgNIgHD2LFfDINXtfvZNqST0ZaR97wsJGanxFojY827gfLLmjcpHybr8hmbgdqXDHxMDjQTYhCa9bV4T3PtpqAkBzH3F7mMaoJ6NITnaY1buHAQjGO77nBDa8ZG6uxlf0K6IhYRbE1qLtxUILUhc3klUD9QKA7CorzYqKMRKL1gswk2q7mXl2sloCfmaH87u66TyrAUuogzEWp5Npm8Ep4DPk8l5vTrMkb08Skwti8AxDtyANtR6gwJ5qfuorYAAAApQ2hyaXMgRXJ3YXkgKEJyb3duIENTKSA8Y2NlQGNzLmJyb3duLmVkdT6IXQQTEQIAHgUCQUhdwIbAwYLCQgHAwIDFQIDAxYCAQIeAQIXgAAKCRCwHHqQZfa61sn3AJdTmMTGYYLSl4etgIYMXiFgLDAJ42AP46Y04NgCepAkBZJ5MmkQBLkBDQRBSF3EAQA1LE1VpWysVPUuZ0x6XXXkGC9tLzsPwJlVr3yukQlqMgClItyACnLc2SNYxbcHUftzVNGlKrriLvHIKDYeZ3OB7XPl5xryycoOHZ09ko7KIr4ebhfvlFk4v7ap4SfGqfoRUJ518cr4I2CTrefPNiSGSBbHLMSWlDGY6ipOx8AAwUDilUjDIqQNecqJY4lSLAWTqyuShQZOurDR9yEpRvmqI5ZkQgZFRFOKuFyDTkNdJrrnS3z45BEhJmNqJveZl5PBOUqDopHpOmvAU8MwopoVKj5FpeqluAzLzsQehk5ZLlAE9z5e39FcucHxDcFiaHQkxvpsSaTkh5hK5uuiEkEGBECAAkFAkFIXf8CGwwACgkQsBx6kGX2utbN3gCgopk4vqp4IhQ5PYDoURzvcrWCXUAniVplgnikdifrdH52Wx7w30XAY6e0zYF-----END PGP PUBLIC KEY BLOCK----- I play trombone in the What Cheer Brigade . my sisters blog, Not Eating Out in New York . Brown CS", "metadata": {"last_modified": "2017-05-20T16:08:12+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["C. Chris Erway"], "word_count": 472, "token_count_estimate": 1686}}, "https://cs.brown.edu/~gamjad/": {"text_content": "Announcements About Publications Experience Other Interests Contact Me Ghous Amjad 1 401 837-4081 ghousamjadbrown.edu I am a fifth year PhD student at Brown CS where I work on problems in the area of Cryptography and Applied Cryptography with Seny Kamara and Tarik Moataz . I am a member of the Encrypted Systems Lab and CAPS group at Brown. Recently, my research has been particularly focused on Encrypted Search and Structured Encryption where I work on designing and implementing provably secure, efficient and usable schemes with well defined leakage profiles, that also guarantee various desirable security properties of Searchable Symmetric Encryption schemes such as Forward Privacy, Snapshot Security, Volume-Hiding, Past-Hiding etc. Currently, I am working on new efficient designs for Structured Encryption schemes and Private Data Structures. Before coming to Brown, I was an undergrad at Lahore University of Management Sciences LUMS and was advised by Fareed Zaffar . In LUMS, I worked on projects in different areas of Computer Science such as Privacy, Networks and Graphics etc. Please email me for a detailed list of my research and other projects Recent News August 2021 I am very happy to announce that I will be joining the Private Computing team at Google NYC in a full-time role. May 2021 I successfully defended my PhD Dissertation titled Theoretical and Practical Advances in Structured Encryption. Special thanks to Seny Kamara Tarik Moataz for all the help over the years and to my committee Moti Yung Giuseppe Persiano September 2020 I will be a Teaching Assistant for Algorithms For The People this Fall. September 2020 I was an intern at Google NYC this summer with the Private Computing team I was hosted by Kevin Yeo and Joon Young Seo. September 2019 I will be a Teaching Assistant for Topics in Applied Cryptography Crypto for Social Good this Fall. I will be consulting on and be a part of many amazing projects that are expected to come out of his class. Stay tuned September 2019 I was an intern at Google NYC this summer with the Private Computing team I was hosted by Kevin Yeo and Sarvar Patel. July 2019 I presented my paper titled Breach Resistant Structured Encryption at PETS 2019 . Video link to the talk is available here . March 2019 I presented my paper titled Forward and Backward Private Searchable Encryption with SGX at EuroSec 2019 September 2018 Nominated for Microsoft Research Fellowship by Brown Computer Science. March 2018 Won the Award for the best Poster at ACM CODASPY 2018. Also presented our paper on the same work there. Publications Breach-Resistant Structured Encryption Paper G. Amjad, T. Moataz, S. Kamara PETS 19 Forward and Backward Private Searchable Encryption with SGX Paper G. Amjad, T. Moataz, S. Kamara EuroSec 19 Forgetting with Puzzles Using Cryptographic Puzzles to support Digital Forgetting Paper G. Amjad, S. Mirza, C. Ppper ACM CODASPY 18 Past-Hiding Dynamic Encrypted Storage Securing Cloud Data Before and After Server Breaches G. Amjad, S. Patel, G. Persiano, K. Yeo, M. Yung In Submission. Correlation-Secure Leakage Revisiting Forward Privacy and Achieving Injection Security G. Amjad, T. Moataz, S. Kamara In Progress. Self Erasing and Auditable Databases G. Amjad, S. Kamara, L. Qin In Progress. Experience Education Summer Intern at Google NYC Hosts Kevin Yeo and Joon Young Seo Integrated the backend service I developed last year at Google, with an existing API within Google. Implemented a proof of concept prototype for clients within Google, in C. Vetted the privacy guarantees of the integration and helped flesh out the protocols. June 2019 - September 2019 PhD Candidate at Brown Advisor Seny Kamara Major Computer Science. Recieved my Master of Science degree in May 2018. Primarily working on designing and implementing Searchable Encryption Schemes. Serving as a Teaching Assistant for Algorithms For The People August 2016 - Present Summer Intern at Google NYC Hosts Kevin Yeo and Sarvar Patel Implemented a general backend service for Chrome Password Breach Checker. Vetted the privacy guarantees of the service and helped flesh out the protocol. Implemented load-tests for the service using Googles various load testing frameworks and programmatically generated queries for the load-tests and end to end latency tests. June 2019 - September 2019 Research Assistant at NYU Abu Dhabi Advisor Christina Ppper Our Research was focused on the area of Digital Forgetting. June 2016 - August 2016 Research Assistant, Teaching Assistant and Undergrad at LUMS Advisor Fareed Zaffar Major Computer Science. Graduated with the NMF Gold Medal and the Award of Distinction. I have served as a Teaching Assistant for Discrete Mathematics, Data Structures, Operating Systems and Digital Image Processing. August 2012 - May 2016 Selected Coursework Advanced Programming, Algorithms, Data Structures Class Rank 1, Software Security and Exploitation, Topics in Advanced Cryptography, Topics in Applied Cryptography, Topics in Software Security, Probabilistic Methods in Computer Science, Artificial Intelligence, Big Data Analytics, Computer Vision, Digital Image Processing, Operating Systems Class Rank 1, Network Security, Software Engineering, Databases, Network Security, Cryptography Classical and Quantum, Topics in Internet Research, Applied Probability Skills CC, Java, Python, Rust, MATLAB, SGX, Clusion, SQL, Android, HTML, Network Simulator, Bash Scripting, Spark, R, Pyret, Ruby on Rails, Emulab, TCL, MIPS, JSP Other Interests Random Things I love to travel. I have been to a few different countries and a lot of cities in the United States. For me, the best thing about travel is that I get to sample and relish in the local cuisine. One of the notable trips I took was my trip to Japan. Majority of my time was spent in Tokyo, Kyoto and Osaka. I did take day trips to Yokohama and Nara. I miss the food I had there everyday. I love New York Lahore is the best city ever though Well, you can say I am a little biased. I served as the Chair of Technology on the Brown Graduate Student Council from 2016 to 2018. I also served on the GSC International Committee led by the Chair of International Advocacy. Contact Me Get in touch for a detailed CV, a short resume or for any other queries. I can be reached either by phone 1 401-837-4081 or email .", "metadata": {"last_modified": "2021-05-17T17:32:32+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Ghous", "", "Publications", "Experience / Education", "Other Interests / Random Things", "Contact Me"], "word_count": 1022, "token_count_estimate": 1398}}, "https://cs.brown.edu/people/acrotty/": {"text_content": "Andrew Crotty andrew.crottynorthwestern.edu Google Scholar DBLP About Me I am an Assistant Professor of Computer Science at Northwestern University .I was previously a postdoctoral researcher at Carnegie Mellon University and Brown University . I received my Ph.D. in Computer Science from Brown in 2019. Publications Wan Shen Lim, Matthew Butrovich, William Zhang, Andrew Crotty, Lin Ma, Peijing Xu, Johannes Gehrke, Andrew Pavlo.Database Gyms.CIDR 2023 Andrew Crotty, Viktor Leis, Andrew Pavlo. Are You Sure You Want to Use MMAP in Your Database Management System CIDR 2022 talk Franco Solleza, Andrew Crotty, Suman Karumuri, Nesime Tatbul, Stan Zdonik. Mach A Pluggable Metrics Storage Engine for the Age of Observability. CIDR 2022 Jiwon Choe, Andrew Crotty, Tali Moreshet, Maurice Herlihy, R. Iris Bahar. HybriDS Cache-Conscious Concurrent Data Structures for Near-Memory Processing Architectures. SPAA 2022 Andrew Crotty. Hist-Tree Those Who Ignore It Are Doomed to Learn. CIDR 2021 talk Andrew Crotty, Alex Galakatos, Connor Luckett, Ugur Cetintemel. The Case for In-Memory OLAP on Wimpy Nodes. ICDE 2021 Connor Luckett, Andrew Crotty, Alex Galakatos, Ugur Cetintemel. Odlaw A Tool for Retroactive GDPR Compliance. ICDE 2021 Andrew Crotty, Alex Galakatos, Tim Kraska. Getting Swole Generating Access-Aware Code with Predicate Pullups. ICDE 2020 talk Amir Ilkhechi, Andrew Crotty, Alex Galakatos, Yicong Mao, Grace Fan, Xiran Shi, Ugur Cetintemel. DeepSqueeze Deep Semantic Compression for Tabular Data. SIGMOD 2020 Nathaniel Weir, Prasetya Utama, Alex Galakatos, Andrew Crotty, Amir Ilkhechi, Shekar Ramaswamy, Rohin Bhushan, Nadja Geisler, Benjamin Hattasch, Steffen Eger, Ugur Cetintemel, Carsten Binnig. DBPal A Fully Pluggable NL2SQL Training Pipeline. SIGMOD 2020 Andrew Crotty. NullDB Instantaneously Answering Any OLAP Query. CIDR 2019 Nathaniel Weir, Andrew Crotty, Alex Galakatos, Amir Ilkhechi, Shekar Ramaswamy, Rohin Bhushan, Ugur Cetintemel, Prasetya Utama, Nadja Geisler, Benjamin Hattasch, Steffen Eger, Carsten Binnig. DBPal Weak Supervision for Learning a Natural Language Interface to Databases. CASTVLDB 2019 Alex Galakatos, Andrew Crotty, Tim Kraska. Distributed Machine Learning. EDBS 2018 Alex Galakatos, Andrew Crotty, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. Revisiting Reuse for Approximate Query Processing. VLDB 2017 Emanuel Zgraggen, Alex Galakatos, Andrew Crotty, Jean-Daniel Fekete, Tim Kraska. How Progressive Visualizations Affect Exploratory Analysis. TVCG 2017 Carsten Binnig, Fuat Basik, Benedetto Buratti, Ugur Cetintemel, Yeounoh Chung, Andrew Crotty, Cyrus Cousins, Dylan Ebert, Philipp Eichmann, Alex Galakatos, Benjamin Hattasch, Amir Ilkhechi, Tim Kraska, Zeyuan Shang, Isabella Tromba, Arif Usta, Prasetya Utama, Eli Upfal, Linnan Wang, Nathaniel Weir, Robert C. Zeleznik, Emanuel Zgraggen. Towards Interactive Data Exploration. BIRTEVLDB 2017 Philipp Eichmann, Andrew Crotty, Alex Galakatos, Emanuel Zgraggen. Discrete Time Specifications in Temporal Queries. CHI LBW 2017 Carsten Binnig, Andrew Crotty, Alex Galakatos, Tim Kraska, Erfan Zamanian. The End of Slow Networks Its Time for a Redesign. VLDB 2016 Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. The Case for Interactive Data Exploration Accelerators IDEAs. HILDASIGMOD 2016 Andrew Crotty, Alex Galakatos, Kayhan Dursun, Tim Kraska, Carsten Binnig, Ugur Cetintemel, Stan Zdonik. An Architecture for Compiling UDF-centric Workflows. VLDB 2015 Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, Tim Kraska. Vizdom Interactive Analytics through Pen and Touch. VLDB 2015 Best Demo Award Andrew Crotty, Alex Galakatos, Kayhan Dursun, Tim Kraska, Ugur Cetintemel, Stanley B. Zdonik. Tupleware Big Data, Big Analytics, Small Clusters. CIDR 2015 Carsten Binnig, Ugur Cetintemel, Tim Kraska, Stan Zdonik, Erfan Zamanian, Andrew Crotty. I-Store Data Management for Fast Networks. NEDB 2015 Andrew Crotty, Alex Galakatos, Tim Kraska. Tupleware Distributed Machine Learning on Small Clusters. IEEE Data Eng. Bull. 2014 Teaching CS496 Special Topics in Data Systems Northwestern University Fall 2022 Instructor 15-445645 Database Systems Carnegie Mellon University Fall 2021 Co-Instructor CSCI 1270 Database Management Systems Brown University Fall 2014 Grad TA CSCI 2257 Database Systems and Applications Boston College Spring 2011 TA, Spring 2012 TA Awards Service Google PhD Fellowship 20162018 VLDB Best Demo Award 2015 Brown CS Application Feedback Program for Underrepresented Applicants 2020 Brown CS PhD Admissions 2016, 2019 Research PC SIGMOD 24, VLDB 23, SIGMOD 23, CIDR 23, VLDB 20 Demo PC VLDB 23, VLDB 22 Reviewer SIGMOD 18, IEEE Data Eng. Bull. 17, OSDI 16, ICDE 16, SIGMOD 15, HotCloud 14, SIGMOD 14, ICDE 14, SOCC 13", "metadata": {"last_modified": "2022-12-05T17:30:53+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["About Me", "Publications", "Teaching", "Awards & Service"], "word_count": 673, "token_count_estimate": 1423}}, "https://cs.brown.edu/~jcmace/": {"text_content": "Jonathan Mace PhD Candidate Department of Computer Science Brown University CV About Me News Publications Education Demos Contact Copyright 2018 by Jonathan Mace Jonathan Mace PhD Candidate Brown University Department of Computer Science This web page is deprecated as of September 2018 I am now a tenure-track faculty member at the Max Planck Institute for Software Systems in Saarbrcken, Germany Click here to visit my home page at MPI-SWS About Me I graduated in May 2018 and I am now a tenure-track faculty member at the Max Planck Institute for Software Systems in Saarbrcken, Germany At Brown, I was advised by Professor Rodrigo Fonseca . My research focuses on monitoring, understanding, and enforcing distributed system behaviors . In my PhD work I adapted techniques from end-to-end request tracing to new applications in multi-tenant resource management and dynamic causal profiling . My work on Pivot Tracing introduced baggage , a concept for generic cross-system metadata now widely used by tracing systems like Zipkin and OpenTracing . I am currently working on large-scale end-to-end performance analysis , ranging from data collection, aggregation, and storage, to deriving high-level insights using machine learning and statistical analysis. My ongoing work is a collaboration with researchers in Facebooks tracing and performance groups. Interests Distributed Systems Networking Operating Systems Multi-Tenant Cloud Systems Multi-Resource Scheduling End-to-End Request Tracing Data-Driven Performance Analysis Recent News 2018-05 I have accepted a faculty position at the Max Planck Institute for Software Systems, in Saarbrcken, Germany 2018-01 Our paper on Context Propagation in Distributed Systems was accepted to EuroSys 2018 See you in Portugal. 2017-11 Our SOSP paper, Canopy , was featured on the Morning Paper blog today 2017-08 Canopy, our paper on end-to-end tracing at Facebook, is accepted to appear at SOSP 2017. 2017-05 Prototype of our Baggage Definition Language BDL compiler and libraries for Java and Go released on GitHub with a paper soon to come 2016-04 2DFQ is accepted to appear in SIGCOMM 2016 This is joint work with my colleagues from Microsoft. 2016-01 Im very fortunate to be awarded a Facebook Graduate Fellowship 2015-10 Pivot Tracing received a Best Paper Award at this years SOSP Publications SoCC 2018 Weighted Sampling of Execution Traces Capturing More Needles and Less Hay Pedro Las-Casas, Jonathan Mace , Dorgival Guedes, Rodrigo Fonseca In Proceedings of the 9th ACM Symposium on Cloud Computing SoCC 18 Abstract End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems, by performing dynamic verification and diagnosing correctness and performance problems. Contrary to logging, end-to-end traces enable coherent sampling of the entire execution of specific requests, and this is exploited by many deployments to reduce the overhead and storage requirements of tracing. This sampling, however, is usually done uniformly at random, which dedicates a large fraction of the sampling budget to common, normal executions, while missing infrequent, but sometimes important, erroneous or anomalous executions. In this paper we define the representative trace sampling problem, and present a new approach, based on clustering of execution graphs, that is able to bias the sampling of requests to maximize the diversity of execution traces stored towards infrequent patterns. In a preliminary, but encouraging work, we show how our approach chooses to persist representative and diverse executions, even when anomalous ones are very infrequent. inproceedingslascasas2018weighted, titleWeighted Sampling of Execution Traces Capturing More Needles and Less Hay, authorLas-Casas, Pedro and Mace, Jonathan and Guedes, Dorgival and Fonseca, Rodrigo, booktitle9th ACM Symposium on Cloud Computing SoCC 18, Ph.D. Thesis 2018 A Universal Architecture for Cross-Cutting Tools in Distributed Systems Jonathan Mace Ph.D. Thesis, Brown University, May 2018 Abstract Recent research has proposed a variety of cross-cutting tools to help monitor and troubleshoot end-to-end behaviors in distributed systems. However, most prior tools focus on data collection and aggregation, and treat analysis as a distinct step to be performed later, offline. This restricts the applicability of such tools to only doing post-facto analysis. However, this is not a fundamental limitation. Recent research has proposed tools that integrate analysis and decision-making at runtime, to directly enforce end-to-end behaviors and adapt to events. In this thesis I present two new applications of cross-cutting tools to previously unexplored domains resource management, and dynamic monitoring. Retro, a cross-cutting tool for resource management, provides end-to-end performance guarantees by propagating tenant identifiers with executions, and using them to attribute resource consumption and enforce throttling decisions. Pivot Tracing, a cross-cutting tool for dynamic monitoring, dynamically monitors metrics and contextualizes them based on properties deriving from arbitrary points in an end-to-end execution. Retro and Pivot Tracing illustrate the potential breadth of cross-cutting tools in providing visibility and control over distributed system behaviors. From this, I identify and characterize the common challenges associated with developing and deploying cross-cutting tools. This motivates the design of baggage contexts, a general-purpose context that can be shared and reused by different cross-cutting tools. Baggage contexts abstract and encapsulate components that are otherwise duplicated by most cross-cutting tools, and decouples the design of tools into separate layers that can be addressed independently by different teams of developers. The potential impact of a common architecture for cross-cutting tools is significant. It would enable more pervasive, more useful, and more diverse cross-cutting tools, and make it easier for developers to defer development-time decisions about which tools to deploy and support. A Universal Architecture for Cross-Cutting Tools in Distributed Systems phdthesismace2018thesis, titleA Universal Architecture for Cross-Cutting Tools in Distributed Systems, authorMace, Jonathan, schoolBrown University, year2018 EuroSys 2018 Universal Context Propagation for Distributed System Instrumentation Jonathan Mace , Rodrigo Fonseca In Proceedings of the 13th ACM European Conference on Computer Systems EuroSys 18 Abstract Many tools for analyzing distributed systems propagate contexts along the execution paths of requests, tasks, and jobs, in order to correlate events across process, component and machine boundaries. There is a wide range of existing and proposed uses for these tools, which we call cross-cutting tools, such as tracing, debugging, taint propagation, provenance, auditing, and resource management, but few of them get deployed pervasively in large systems. When they do, they are brittle, hard to evolve, and cannot coexist with each other. While they use very different context metadata, the way they propagate the information alongside execution is the same. Nevertheless, in existing tools, these aspects are deeply intertwined, causing most of these problems.In this paper, we propose a layered architecture for cross-cutting toolsthat separates concerns of system developers and tool developers, enabling independent instrumentation of systems, and the deployment and evolution of multiple such tools. At the heart of this layering is a general underlying format, baggage contexts, that enables the complete decoupling of system instrumentation for context propagation from tool logic. Baggage contexts make propagation opaque and general, while still maintaining correctness of the metadata under arbitrary concurrency and different data types. We demonstrate the practicality of the architecture with implementations in Java and Go, porting of several existing cross-cutting tools, and instrumenting existing distributed systems with all of them. Universal Context Propagation for Distributed System Instrumentation inproceedingsmace2018universal, titleUniversal Context Propagation for Distributed System Instrumentation, authorMace, Jonathan and Fonseca, Rodrigo, booktitle13th ACM European Conference on Computer Systems EuroSys 18, SOSP 2017 Canopy An End-to-End Performance Tracing And Analysis System Jonathan Kaldor, Jonathan Mace , Micha Bejda, Edison Gao, Wiktor Kuropatwa, Joe ONeill, Kian Win Ong, Bill Schaller, Pingjia Shan, Brendan Viscomi, Vinod Venkataraman, Kaushik Veeraraghavan, Yee Jiun Song In Proceedings of the 26th ACM Symposium on Operating Systems Principles SOSP 17 ----- Also featured in The Morning Paper Abstract This paper presents Canopy, Facebooks end-to-end performance tracing infrastructure. Canopy records causally related performance data across the end-to-end execution path of requests, including from browsers, mobile applications, and backend services. Canopy processes traces in near real-time, derives user-specified features, and outputs to performance datasets that aggregate across billions ofrequests. Using Canopy, Facebook engineers can query and analyze performance data in real-time. Canopy addresses three challenges we have encountered in scaling performance analysis supporting the range of execution and performance models used by different components of the Facebook stack supporting interactive ad-hoc analysis of performance data and enabling deep customization by users, from sampling traces to extracting and visualizing features. Canopy currently records and processes over1 billion traces per day. We discuss how Canopy has evolved to apply to a wide range of scenarios, and present case studies of its use in solving various performance challenges. Canopy An End-to-End Performance Tracing And Analysis System inproceedingskaldor2017canopy, titleCanopy An End-to-End Performance Tracing And Analysis System, authorKaldor, Jonathan and Mace, Jonathan and Bejda, Michal and Gao, Edison and Kuropatwa, Wiktor and ONeill, Joe and Ong, Kian Win and Schaller, Bill and Shan, Pingjia and Viscomi, Brendan and Vekataraman, Vinod and Veeraraghavan, Kaushik and Song, Yee Jiun, booktitle26th ACM Symposium on Operating Systems Principles SOSP 17, SIGCOMM 2016 2DFQ Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services Jonathan Mace , Peter Bodik, Madanlal Musuvathi, Rodrigo Fonseca, Krishnan Varadarajan In Proceedings of the 2016 ACM SIGCOMM Conference Abstract In many important cloud services, different tenants execute their requests in the thread pool of the same process, requiring fair sharing of resources. However, using fair queue schedulers to provide fairness in this context is difficult because of high execution concurrency, and because request costs are unknown and have high variance. Using fair schedulers like WFQ and WFQ in such settings leads to bursty schedules, where large requests block small ones for long periods of time. In this paper, we propose Two-Dimensional Fair Queuing 2DFQ, which spreads requests of different costs across di erent threads and minimizes the impact of tenants with unpredictable requests. In evaluation on production workloads from Azure Storage, a large-scale cloud system at Microsoft, we show that 2DFQ reduces the burstiness of service by 1-2 orders of magnitude. On workloads where many large requests compete with small ones, 2DFQ improves 99th percentile latencies by up to 2 orders of magnitude. 2DFQ Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services inproceedingsmace20162dfq, title2DFQ Two-Dimensional Fair Queuing for Multi-Tenant Cloud Services, authorMace, Jonathan and Bodik, Peter and Musuvathi, Madanlal and Fonseca, Rodrigo and Varadarajan, Krishnan, booktitleProceedings of the ACM SIGCOMM 2016 Conference SIGCOMM 16, SOCC 2016 Principled Workflow-Centric Tracing of Distributed Systems Raja R. Sambasivan, Ilari Shafer, Jonathan Mace , Benjamin H. Sigelman, Rodrigo Fonseca, Gregory R. Ganger In Proceedings of the 7th ACM Symposium on Cloud Computing SOCC 16 Abstract Workflow-centric tracing captures the workflow of causally-related events e.g., work done to process a request within and among the components of a distributed system. As distributed systems grow in scale and complexity, such tracing is becoming a critical tool for understanding distributed system behavior. Yet, there is a fundamental lack of clarity about how such infrastructures should be designed to provide maximum benefit for important management tasks, such as resource accounting and diagnosis. Without research into this important issue, there is a danger that workflow-centric tracing will not reach its full potential. To help, this paper distills the design space of workflow-centric tracing and describes key design choices that can help or hinder a tracing infrastructures utility for important tasks. Our design space and options for them are based on our experiences developing several previous workflow-tracing infrastructures. Principled Workflow-Centric Tracing of Distributed Systems inproceedingssambasivan2016principled, titlePrincipled Workflow-Centric Tracing of Distributed Systems, authorSambasivan, Raja R and Shafer, Ilari and Mace, Jonathan and Sigelman, Benjamin H and Fonseca, Rodrigo and Ganger, Gregory R, booktitle7th ACM Symposium on Cloud Computing SoCC 16, SOSP 2015 Best Paper Award Pivot Tracing Dynamic Causal Monitoring for Distributed Systems Jonathan Mace , Ryan Roelke, Rodrigo Fonseca In Proceedings of the 25th ACM Symposium on Operating Systems Principles SOSP 15 In ACM Transactions on Computer Systems TOCS, forthcoming 2017 In Communications of the ACM CACM, forthcoming 2017 ----- Also featured in The Morning Paper. Abstract Monitoring and troubleshooting distributed systems is notoriously difficult potential problems are complex, varied, and unpredictable. The monitoring and diagnosis tools commonly used today logs, counters, and metrics have two important limitations what gets recorded is defined a priori, and the information is recorded in a component- or machine-centric way, making it extremely hard to correlate events that cross these boundaries. This paper presents Pivot Tracing, a monitoring framework for distributed systems that addresses both limitations by combining dynamic instrumentation with a novel relational operator the happened-before join. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, filter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. We have implemented a prototype of Pivot Tracing for Java-based systems and evaluate it on a heterogeneous Hadoop cluster comprising HDFS, HBase, MapReduce, and YARN. We show that Pivot Tracing can effectively identify a diverse range of root causes such as software bugs, misconfiguration, and limping hardware. We show that Pivot Tracing is dynamic, extensible, and enables cross-tier analysis between inter-operating applications, with low execution overhead. Pivot Tracing Dynamic Causal Monitoring for Distributed Systems inproceedingsmace2015pivot, titlePivot Tracing Dynamic Causal Monitoring for Distributed Systems, authorMace, Jonathan and Roelke, Ryan and Fonseca, Rodrigo, booktitle25th ACM Symposium on Operating Systems Principles SOSP 15, NSDI 2015 Retro Targeted Resource Management in Multi-tenant Distributed Systems Jonathan Mace , Peter Bodik, Rodrigo Fonseca, Madanlal Musuvathi In Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation NSDI 15 Abstract In distributed systems shared by multiple tenants, effective resource management is an important pre-requisite to providing quality of service guarantees. Many systems deployed today lack performance isolation and experience contention, slowdown, and even outages caused by aggressive workloads or by improperly throttled maintenance tasks such as data replication. In this work we present Retro, a resource management framework for shared distributed systems. Retro monitors per-tenant resource usage both within and across distributed systems, and exposes this information to centralized resource management policies through a high-level API. A policy can shape the resources consumed by a tenant using Retros control points, which enforce sharing and rate-limiting decisions. We demonstrate Retro through three policies providing bottleneck resource fairness, dominant resource fairness, and latency guarantees to high-priority tenants, and evaluate the system across five distributed systems HBase, Yarn, MapReduce, HDFS, and Zookeeper. Our evaluation shows that Retro has low overhead, and achieves the policies goals, accurately detecting contended resources, throttling tenants responsible for slowdown and overload, and fairly distributing the remaining cluster capacity. Retro Targeted Resource Management in Multi-tenant Distributed Systems inproceedingsmace2015retro, titleRetro Targeted Resource Management in Multi-tenant Distributed Systems, authorMace, Jonathan and Bodik, Peter and Fonseca, Rodrigo and Musuvathi, Madanlal, booktitle12th USENIX Symposium on Networked Systems Design and Implementation NSDI 15, HPTS 2015 We are Losing Track a Case for Causal Metadata in Distributed Systems Rodrigo Fonseca, Jonathan Mace In Proceedings of the 15th International Workshop on High Performance Transaction Systems HPTS 15 As our systems move to more concurrent and distributed execution patterns, the tools and abstractions we have to understand, monitor, schedule, and enforce their behavior become progressively less effective or adequate. We argue that systems should be built with causal propagation of generic metadata as a first class primitive, to serve as the narrow waist upon which many debugging and troubleshooting tools could be built, in an analogy to the role of the IP layer in networking We are Losing Track a Case for Causal Metadata in Distributed Systems inproceedingsfonseca2015losing, titleWe are Losing Track a Case for Causal Metadata in Distributed Systems, authorFonseca, Rodrigo and Mace, Jonathan, booktitle15th International Workshop on High Performance Transaction Systems HPTS 15, HotDep 2014 Towards General-Purpose Resource Management in Shared Cloud Services Jonathan Mace , Peter Bodik, Rodrigo Fonseca, Madanlal Musuvathi In Proceedings of the 10th Workshop on Hot Topics in Dependability HotDep 14 Abstract In distributed services shared by multiple tenants, managing resource allocation is an important pre-requisite to providing dependability and quality of service guarantees. Many systems deployed today experience contention, slowdown, and even system outages due to aggressive tenants and a lack of resource management. Improperly throttled background tasks, such as data replication, can overwhelm a system conversely, high-priority background tasks, such as heartbeats, can be subject to resource starvation. In this paper, we outline ve design principles necessary for effective and efficient resource management policies that could provide guaranteed performance, fairness, or isolation. We present Retro, a resource instrumentation framework that is guided by these principles. Retro instruments all system resources and exposes detailed, real-time statistics of pertenant resource consumption, and could serve as a base for the implementation of such policies. Towards General-Purpose Resource Management in Shared Cloud Services inproceedingsmace2014towards, titleTowards General-Purpose Resource Management in Shared Cloud Services, authorMace, Jonathan and Bodik, Peter and Fonseca, Rodrigo and Musuvathi, Madanlal, booktitle10th Workshop on Hot Topics in System Dependability HotDep 14, year2014 Other Documents 2018 Job Application Documents Jonathan Mace Documents relating to my academic job search in 2018 These are the application documents I used during my faculty job search in 2018. The outcome of my job search was to accept a faculty position at the Max Planck Institute for Software Systems. CV Diversity Statement Research Statement Teaching Statement Survey 2017 End-to-End Tracing Adoption and Use Cases Jonathan Mace Survey, Brown University, March 2017 Abstract This document summarizes information about end-to-end tracing for 26 companies. The information was gathered from documents shared to the Distributed Tracing Workgroup and through in-person conversations at tracing workshops. End-to-End Tracing Adoption and Use Cases techreportmace2017survey, titleEnd-to-End Tracing Adoption and Use Cases, authorJonathan Mace, typeSurvey, institutionBrown University, year2017, login 2016 Pivot Tracing Dynamic Causal Monitoring for Distributed Systems Jonathan Mace , Ryan Roelke, Rodrigo Fonseca USENIX login Magazine, Spring 2016 Abstract Pivot Tracing is a monitoring framework for distributed systems that can seamlessly correlate statistics across applications, components, and machines at runtime without needing to change or redeploy system code. Users can define and install monitoring queries on-the-fly to collect arbitrary statistics from one point in the system while being able to select, filter, and group by events meaningful at other points in the system. Pivot Tracing does not correlate cross-component events using expensive global aggregations, nor does it perform offline analysis. Instead, Pivot Tracing directly correlates events as they happen by piggybacking metadata alongside requests as they executeeven across component and machine boundaries. This gives Pivot Tracing a very low runtime overheadless than 1 for many cross-component monitoring queries. Pivot Tracing Dynamic Causal Monitoring for Distributed Systems M.Sc. Project 2013 Revisiting End-to-End Trace Comparison with Graph Kernels Jonathan Mace , Rodrigo Fonseca Masters Project, Brown University, May 2013 Abstract End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems by performing dynamic verification and diagnosing correctness and performance problems. End-to-end traces are commonly represented as richly annotated directed acyclic graphs, with events as nodes and their causal dependencies as edges. Being able to automatically compare these graphs at scale is a key primitive for tasks such as clustering, classification, and anomaly detection. In this paper we explore recent developments in the theory of graph kernels, and investigate the feasibility of using a family of kernels based on the Weisfeiler-Lehman graph isomorphism test as an efficient and robust graph comparison primitive. We find that graph kernels provide a good formulation of the execution graph comparison problem, and present preliminary but encouraging results on their ability to distinguish high-level differences between execution graphs. Revisiting End-to-End Trace Comparison with Graph Kernels mastersthesismace2013revisiting, titleRevisiting End-to-End Trace Comparison with Graph Kernels, authorJonathan Mace, typeM.Sc. Project, schoolBrown University, year2013, Experience 2011 - 2018 expected Ph.D. Candidate Department of Computer Science Brown University, USA Summer 2016 Research Intern Facebook, New York Summer 2013 Summer 2015 Research Intern Microsoft Research, Redmond 2011 - 2014 MSc Computer Science Brown University, USA 2009 - 2011 Software Developer IBM UK 2005 - 2009 Mathematics Computer Science MMathComp, 1st Class Oxford University, UK Awards 2017 SIGCOMM Student Scholar 50 Years of the ACM Turing Award Celebration 2016 Facebook Graduate Fellowship Pervasive Monitoring, Diagnostics, and Analytics of Distributed Systems through Dynamic Causal Tracing 2016 USENIX ATC Best of the Rest Invited speaker for Pivot Tracing Dynamic Causal Monitoring for Distributed Systems 2015 Best Paper Award Pivot Tracing Dynamic Causal Monitoring for Distributed Systems , SOSP 15 2015 Great TA Award Nominated by students of Brown CS138 Distributed Systems, Spring Semester 2015 Student Scholar 3rd Heidelberg Laureate Forum 2011 Graduate School Fellowship Brown University 2006 Hertford College Scholarship Oxford University , Hertford College Demos Interactive Hadoop Visualization HDFS Swimlane Visualization Hadoop example Spark tracing example Critical Path Analysis example Execution Graph Comparison Execution Graph Clustering Contact Me jcmace cs.brown.edu 206 489-6067 brownsysjmace JonathanMace jonathanmace JonathanMace", "metadata": {"last_modified": "2018-10-31T10:40:01+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Jonathan Mace", "Jonathan Mace", "This web page is deprecated as of September 2018!", "I am now a tenure-track faculty member at the", "in Saarbr\u00fccken, Germany", "About Me", "Demos", "Contact Me"], "word_count": 3421, "token_count_estimate": 4903}}, "https://cs.brown.edu/~jj/startup.html": {"text_content": "csciStartup More than a class In csciStartup, you will incorporate and run a startup. Apply as a team to be a part of a prototype class to remove the mystery from starting a company, and to focus entirely on a product youre passionate about. Apply as a team You should apply if you have a team in place and a product in mind. Teams of two and three are probably best, and a great team might not be all CS students. We will focus on products that a small team can implement in months web sites and mobile apps will be the norm. If you nearly have a team in place, and want to meet other students who are looking for a team or vice versa, you might check out this Facebook group . For this year, youll ned to apply as a complete group, by January 19th . Apply Product Focused We will learn by doing. Each team will incorporate, build a product for real customers, advertise their product, and improve it week after week. Well spend at least half of our class meetings with individual attention to each groups progress and how to improve your offerings. Assignments will be designed to apply to any company, with enough flexibility to ensure youre always working things that make sense for your business. Lectures Talks Once a week, well have a more traditional class with a topic that should apply broadly to all teams. The current plan is for Tuesday and Thursday meetings, one for progress reports and one for guest lectures. Development environment and hosting. What goes into an MVP Incorporation, Equity, Vesting Case study consumer product Teespring, Foodler Case study business product Vertica, SightPath, Tracelytics Growth Advertising, AB tests, Market testing, Email marketing Hiring real, contract, gig Sales Conducting User Studies From MVP to 1.0 Raising money Syllabus John Jannotti", "metadata": {"last_modified": "2016-01-07T03:16:25+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["More than a class", "Apply as a team", "Product Focused", "Lectures / Talks"], "word_count": 311, "token_count_estimate": 375}}, "https://cs.brown.edu/~jj/": {"text_content": "John Jannotti Courses cs161 Building High-Performance Servers cs168 Computer Networks cs296-2 Large-Scale Networked Systems Publications Distributed Systems Making P2P Accountable Without Losing Privacy XPORT SIGMOD XPORT SeNS Locality Aware Networked Join Evaluation Overcast Reliable Multicasting with an Overlay Network System Software BorderPatrol in submission, write for a copy Safe at Any Speed Fast, Safe Parallelism in Servers poster Exokernel MEng Exokernel SOSP Sensors and Mobile Networking Distributed Calibration of Smart Cameras Data-Centric Visual Sensor Networks for 3D Sensing Image Based Routing for Image Based Rendering CarNet Grid NetworkingRouting Blind Source Routing in submission, write for a copy ReflectPaint PhD ReflectPaint OpenArch Click TOCS Click SOSP Companies Foodler is a site to order takeout and delivery food in the Boston area. I used to work for Cisco after they bought a content distribution company I worked for, SightPath. jjcs.brown.edu Box 1910, Computer Science Department Brown University Providence, RI 02912 401-863-7755 voice 401-863-7657 fax", "metadata": {"last_modified": "2007-09-25T03:35:38+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["John Jannotti", "Courses", "Publications", "Companies"], "word_count": 152, "token_count_estimate": 228}}, "https://cs.brown.edu/~jmacglashan/": {"text_content": "home burlap curriculum vitae publications contact Welcome Hello and welcome to my home page I am postdoctoral researcher at Brown University in computer science and I received my PhD in computer science from the University of Maryland, Baltimore County in 2013. My research spans a large range of artificial intelligence topics, though I primarily am involved in reinforcement learning and autonomous planning research. To that end, I am the creator of the Brown-UMBC Reinforcement Learning and Planning BURLAP Java library. BURLAP provides a very large range of tools an algorithms from classic A, to value function approximation, to multi-agent learning in stochastic games. My dissertation work was in transfer learning in reinforcement learning and I also have done research in human-AI interaction, evolutionary dynamics of social reward functions in multi-agent environments, the optimization and evaluation of learning algorithms in classes of environments, and learning planning knowledge to accelerate planning. In the near future, I will be providing example programscode to demonstrate some of the active research that I am doing and what can be done with BURLAP. home burlap curriculum vitae publications contact James MacGlashan 2010", "metadata": {"last_modified": "2015-05-08T19:44:34+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Welcome"], "word_count": 186, "token_count_estimate": 229}}, "https://cs.brown.edu/people/ihajiras/": {"text_content": "About me Email imanh at stanford.edu Please do NOT use my old SFU or Brown email addresses -- they no longer work I am a Post Doctoral scholar with Serafim Batzoglou at Stanford University. More info ... My Erds number is 2 Tweets by hajirasouliha Research Publications My research field is Computational Biology and I am excited about recent developments in genomics and sequencing technologies. See the following short video, featuring Bonnie Berger my academic grandmother of MIT, about modern challenges of this field in the 21st century. The highlights of my research can be seen in my publications A full list of my recent publications is available here . You may also check the following databases PUBMED DBLP Google Scholar H-index 16 Curriculum vitae Updated September 2015 NIH Biosketch Updated September 2015 EventsNews I receive a Simons-Berkeley Research Fellowship for the Spring semester 2016 in connection with Algorithmic Challenges in Genomics program. I served as a Program Committee member for AlCoB 2016 , ISMBECCB 2015 , GIWInCoB 2015 and Genome Medicine 2015 . I presented a Reviewers Choice poster at the ASHG 2015 , an oral presentation at the ISMB-HitSeq 2015 , and two earlier presentations in the Proceedings Track of ISMB 2014 and WABI 2014 . All were on my recent studies on somatic variations and reconstructing mutational history in heterogeneous tumor samples. A list of upcoming and past events as well as media releases is available here .", "metadata": {"last_modified": "2015-12-03T02:37:33+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 241, "token_count_estimate": 325}}, "https://cs.brown.edu/~kfisler/Pubs/index.html": {"text_content": "Kathi Fisler Publications by Area This list is also available sorted by year . Education for Socially-Responsible Computing Active Area A New Model for Weaving Responsible Computing Into Courses Across the CS Curriculum . Lena Cohen, Heila Precel, Harold Triedman, and Kathi Fisler. SIGCSE 2021. Data-Centric Computing Education for K-12 and University Active Area Data-Centricity A Challenge and Opportunity for Computing Education . Shriram Krishnamurthi and Kathi Fisler. Communications of the ACM Viewpoint. 2020. Data Science as a Route to AI for Middle- and High-School Students. Shriram Krishnamurthi, Emmanuel Schanzer, Joe Gibbs Politz, Benjamin S. Lerner, Kathi Fisler, Sam DoomanAAAI 2019 Fall Symposium Teaching AI in K-12, 2019. Computing Education General Active Area Harnessing the Wisdom of the Classes Classsourcing and Machine Learning for Assessment Instrument Generation. Sam Saarinen, Shriram Krishnamurthi, Kathi Fisler and Preston Tunnell Wilson. SIGCSE 2019. What Help Do Students Seek in TA Office Hours Yanyan Ren, Shriram Krishnamurthi, and Kathi Fisler. ICER 2019. Who Tests the Testers Avoiding the Perils of Automated Testing .John Wrenn, Shriram Krishnamurthi, Kathi FislerSIGCSE International Computing Education Research Conference, 2018. Plan Composition Computing Education Active Area Qualitative Analyses of Movements Between Task-level and Code-level Thinking of Novice Programmers. Francis Castro and Kathi Fisler. SIGCSE 2020. Designing a Multi-Faceted SOLO Taxonomy to Track Program Design Skills Through an Entire Course . Francis Castro and Kathi Fisler. Koli Calling 2017. Best paper award . The Impact of a Single Lecture on Program Plans in First-Year CS short paper. Francis Castro, Shriram Krishnamurthi, and Kathi Fisler. Koli Calling 2017. longer tech report version Sometimes, Rainfall Accumulates Talk-Alouds with Novice Functional Programmers . Kathi Fisler and Francis Castro. ICER 2017. On the Interplay Between Bottom-Up and Data-Driven Program Design . Francis Castro and Kathi Fisler. SIGCSE 2016. Modernizing Plan-Composition Studies . Kathi Fisler, Shriram Krishnamurthi, and Janet Siegmund. SIGCSE 2016. The Recurring Rainfall Problem. Kathi Fisler. International Conference on Computing Education Research ICER, 2014. coding manual, analysis notes, and errata Notional Machines and Language Learning Computing Education Active Area Using Design Alternatives to Learn About Data Organizations . Xingjian Gu, Max A. Heller, Stella Li, Yanyan Ren, Kathi Fisler and Shriram Krishnamurthi. ICER 2020. Programming Paradigms and Beyond . Shriram Krishnamurthi and Kathi Fisler. In The Cambridge Handbook of Computing Education Research. Cambridge University Press, 2019. Evaluating the Tracing of Recursion in the Substitution Notional Machine . Preston Tunnell Wilson, Shriram Krishnamurthi, and Kathi Fisler. SIGCSE 2018. Student Understanding of Aliasing and Procedure Calls . Preston Tunnell Wilson, Kathi Fisler, Shriram Krishnamurthi. SPLASH-E 2017. Assessing and Teaching Scope, Mutation,and Aliasing in Upper-Level Undergraduates . Kathi Fisler, ShriramKrishnamurthi, Preston Tunnell Wilson. SIGCSE 2017 Teaching Programming Languages byExperimental and Adversarial Thinking . Justin Pombrio,Shriram Krishnamurthi, Kathi Fisler. Summit on Advances inProgramming Languages SNAPL, 2017. Do Values Grow on Trees Expression Integrity in Functional Programing. Guillaume Marceau, Kathi Fisler, and Shriram Krishnamurthi. ICER 2011 Discussion Paper. Bootstrap-Related incl Transfer and Tool Design Active Area Evolving a K-12 Curriculum for Integrating Computer Science into Mathematics Kathi Fisler, Emmanuel Schanzer, Steve Weimar, Annie Fetter, K. Ann Renninger, Shriram Krishnamurthi, Joe Gibbs Politz, Benjamin Lerner, Jennifer Poole, Christine Koerner. SIGCSE 2021. What Does It Mean for a Curriculum to Succeed Emmanuel Schanzer, Shriram Krishnamurthi, Kathi Fisler.Communications of the ACM, 2019. Assessing BootstrapAlgebra Students on Scaffolded and Unscaffolded Word Problems . Emmanuel Schanzer, Kathi Fisler, and Shriram Krishnamurthi. SIGCSE 2018. Creativity, Customization, and Ownership Game Design in BootstrapAlgebra . Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler. SIGCSE 2018. Blocks versus Text Ongoing Lessons from Bootstrap .Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler.Blocks and Beyond Workshop in conjunction with VLHCC, 2015. Transferring Skills atSolving Word Problems from Computing to Algebra ThroughBootstrap. Emmanuel Schanzer, Kathi Fisler, ShriramKrishnamurthi, and Matthias Felleisen. SIGCSE 2015. Bootstrap Going Beyond Programming in After-School ComputerScience . Emmanuel Schanzer, Kathi Fisler, and ShriramKrishnamurthi. SPLASH-E Education track of the OOPSLASPLASHconference, 2013. WeScheme The Browser is Your Programming Environment. Danny Yoo, Emmanuel Schanzer, Shriram Krishnamurthi, and Kathi Fisler. ITiCSE 2011. Error Messages Computing Education Mind Your Language On Novices Interactions with Error Messages . Guillaume Marceau, Kathi Fisler, and Shriram Krishnamurthi. OOPSLA Onward 2011. Measuring the Effectiveness of Error Messages Designed forNovice Programmers . Guillaume Marceau, Kathi Fisler, ShriramKrishnamurthi. Follow link for comparison to Scheme Workshop 10 paper ACM SIGCSE 2011. Best Paper Award Measuring the Effectiveness of Error Messages Designed forNovice Programmers . Guillaume Marceau, Kathi Fisler, ShriramKrishnamurthi. Scheme Workshop 2010. Peer Review Computing Education Peer Review in Cybersecurity Education . William M. Temple, Kathi Fisler. SPLASH-E 2017. The Sweep Essential Examples for In-Flow PeerReview . Joe Gibbs Politz, Joseph Collard, ShriramKrishnamurthi, Arjun Guha, and Kathi Fisler. SIGCSE 2016. In-Flow Peer-Review of Tests in Test-First Programming. JoeGibbs Politz, Shriram Krishnamurthi, and Kathi Fisler. InternationalConference on Computing Education Research ICER, 2014. datasources In-Flow Peer Review . Dave Clarke, TonyClear, Kathi Fisler, Matthias Hauswirthm, Shriram Krishnamurthi, JoeGibbs Politz, Ville Tirronen, and Tobias Wrigstad. Working groupreport from ITiCSE 2014. CaptainTeach Multi-Stage, In-Flow Peer Review forProgramming Assignments. Joe Gibbs Politz, Daniel Patterson, ShriramKrishnamurthi, and Kathi Fisler. International Conference onInnovation and Technology in Computer Science Education ITiCSE,2014. Policy Analysis and Authoring Usable Security as a Static Analysis Problem . HannahQuay de la Vallee, James M. Walsh, William Zimrin, Kathi Fisler, andShriram Krishnamurthi. Onward 2013. A Balance of Power Expressive, Analyzable ControllerProgramming . Tim Nelson, Arjun Guha, Daniel J. Dougherty,Kathi Fisler, and Shriram Krishnamurthi. Workshop on Hot Topics inSoftware Defined Networks HoTSDN, August 2013. Aluminum Principled ScenarioExploration through Minimality. Tim Nelson, Salman Saghafi,Daniel J. Dougherty, Kathi Fisler, and Shriram Krishnamurthi. ICSE2013. Towards a More Complete Alloy. Tim Nelson, Dan Dougherty,Kathi Fisler, and Shriram Krishnamurthi. ABZ Conference, June2012. Embracing Policy Engineering . Kathi Fisler, Shriram Krishnamurthi, and Daniel J. Dougherty. NSFFSE Workshop on the Future of Software Engineering, Nov 2010. The Margrave Tool for Firewall Analysis . Timothy Nelson,Christopher Barratt, Daniel J. Dougherty, Kathi Fisler, ShriramKrishnamurthi. Usenix Large System Administration Conference LISA 2010. A Model of Triangulating Environments for Policy Authoring .Kathi Fisler, Shriram Krishnamurthi.ACM Symposium on Access Control Models and Technologies, July 2010. EscapeFrom the Matrix Lessons From a Case Study in Access-ControlRequirements . Kathi Fisler and Shriram Krishnamurthi.Symposium on Usable Security and Privacy SOUPS Poster Session. July2009. fulltechnical report version Obligations and their Interaction with Programs .Daniel J. Dougherty, Kathi Fisler, and Shriram Krishnamurthi.European Symposium on Research in Computer Security ESORICS,September 2007. Specifying and Reasoning about Dynamic Access ControlPolicies . Daniel J. Dougherty, Kathi Fisler, and ShriramKrishnamurthi. International Joint Conference on Automated ReasoningIJCAR, August 2006. Verification and Change Impact Analysis of Access-ControlPolicies . Kathi Fisler, Shriram Krishnamurthi, Leo Meyerovich, and Michael Tschantz. International Conference on SoftwareEngineering ICSE, May 2005. Synthesizing APIs from Relational Specifications Towards An Operational Semantics for Alloy . DanielJ. Dougherty, Shriram Krishnamurthi, Kathi Fisler, and TheophilosGiannakopoulos. International Conference on Formal Methods FM.November 2009. Alchemy Transmuting Base Alloy Specificationsinto Implementations . Shriram Krishnamurthi, DanielJ. Dougherty, Kathi Fisler, and Daniel Yoo. International Conferenceon Foundations of Software Engineering FSE. November 2008. Features and Capabilities Features and Object Capabilities Reconciling Two Visions ofModularity. Salman Saghafi, Kathi Fisler, and Shriram Krishnamurthi.International Conference on Aspect-Oriented Software DevelopmentAOSD, Modularity Visions track. March 2012 Timing Diagrams Diagrammatic Reasoning and Formal Methods Towards an Aspect Language for Bus Protocols. KathiFisler, Paul Freitas, and Dan Bjorge. Workshop on Domain-SpecificAspect Languages DSAL, held in conjunction with AOSD, March 2012. Two-Dimensional Regular Expressions forCompositional Bus Protocols short paper. Kathi Fisler.International Conference on Formal Methods in Computer-Aided DesignFMCAD. November 2007. Temporal Modalities for ConciselyCapturing Timing Diagrams . With Hana Chockler. CHARME 2005. Towards Diagrammability and Efficiency in Event SequenceLanguages . CHARME 2003. Journal version in SoftwareTools for Technology Transfer 84--5 431--447, 2006. Diagrams and ComputationalEfficacy . In Words, Proofs, and Diagrams, DaveBarker-Plummer, David I. Beaver, Johan van Benthem, and Patrick Scottodi Luzio, editors. CSLI Publications, 2002. On Tableau Constructions for TimingDiagrams . NASA Langley Workshop on Formal Methods, June 2000. Timing Diagrams Formalizationand Algorithmic Verification . Journal of Logic, Language, and Information volume 8, number 3, July 1999. Containment of Regular Languages in Non-Regular Timing DiagramLanguages is Decidable . Proceedings of CAV 97, LNCS, June 1997. A Unified Approach to Hardware Verification Through aHeterogeneous Logic of Design Diagrams. PhD Dissertation.Indiana University Department of Computer Science, August 1996 abstract , fulldissertation postscript Visualizing System Language Relationships with Logic. CADE 96 workshop on Visual Reasoning, July 1996. Exploiting the Potential ofDiagrams in Guiding Hardware Reasoning . In Logical Reasoning with Diagrams, edited by Gerard Allwein and JonBarwise, Oxford University Press, 1996. Integrating Design and Verification Environments Through a LogicSupporting Hardware Diagrams. With Steven D. Johnson. CHDL 95, June 1995. ACanonical Form for Circuit Diagrams . Indiana University TechnicalReport 432, May 1995. ALogical Formalization of Hardware Design Diagrams . Indiana University Technical Report 416.September 1994. Extending Formal Reasoning with Support for Hardware Diagrams. TPCD 94, September 1994. Aspect-Oriented Verification Foundations of Incremental Aspect Model-Checking . ShriramKrishnamurthi and Kathi Fisler. TOSEM 162, 2007. Verifying Aspect Advice Modularly . Shriram Krishnamurthi, Kathi Fisler, andMichael Greenberg. International Conferenceon Foundations of Software Engineering FSE. November 2004. Feature-Oriented Verification DecomposingVerification Around End-Users Features . Kathi Fisler andShriram Krishnamurthi. IFIP Working Conference on Verified SoftwareTheories, Tools, Experiments, 2005. A Case Study in Using ACL2 for Feature-OrientedVerification . Kathi Fisler and Brian Roberts. Proceedings ofthe ACL2 Workshop. November 2004. Parameterized Interfaces for Open SystemVerification of Product Lines . Colin Blundell, KathiFisler, Shriram Krishnamurthi, and Pascal Van Hentenryck.International Conference on Automated Software Engineering ASE.September 2004. Modular Verification of Open FeaturesThrough Three-Valued Model Checking . Harry Li, ShriramKrishnamurthi and Kathi Fisler. Journal of AutomatedSoftware Engineering 123 349--382, 2005. Verifying Cross-Cutting Features as OpenSystems. Harry Li, Shriram Krishnamurthi and Kathi Fisler.International Conference on Foundations of Software Engineering.November 2002. Interfaces for Modular FeatureVerification. Harry Li, Shriram Krishnamurthi and KathiFisler. International Conference on Automated Software Engineering.September 2002. The Influence of Software ModuleSystems on Modular Verification. Harry Li, Kathi Fisler, andShriram Krishnamurthi. 9th International SPIN Workshop on ModelChecking of Software. April 2002. Modular Verification ofCollaboration-Based Software Designs . With ShriramKrishnamurthi. International Conference on Foundations of SoftwareEngineering. September 2001. full technical report version A Model Checking Framework for Layered Command and ControlSoftware. With Shriram Krishnamurthi, Don Batory, and JiaLiu. Monterey Workshop on Software Engineering, June 2001. Verifying Component-Based Collaboration Designs. With Shriram Krishnamurthi and Don Batory. 4th ICSE Workshop onComponent-Based Software Engineering Component Certification andSystem Prediction, May 2001. General Computer-Aided Verification Bisimulation and Model Checking . With MosheY. Vardi. Formal Methods in System Design, 2002. Shortversion presented at Conference on Correct Hardware Reasoning MethodsCHARME 1999. full technical reportversion . Is There a Best Symbolic Cycle-Detection Algorithm With Ranan Fraer, Gila Kamhi, Moshe Y. Vardi and Zijiang Yang.Proceedings of TACAS 2001, April 2001. Bisimulation Minimization in an Automata-TheoreticVerification Framework . With Moshe Y. Vardi. Proceedings ofthe Conference on Formal Methods in Computer-Aided Design FMCAD,1998. full technical report version Testing the FormalCheck Query Library .S. Dershowitz, K. Fisler, S. K. Shukla, G.J. Holzmann, R.P. Kurshan,and D. Peled. Proceedings of LCET 96, Vol. 14, pp. 173-176, LucentTechnologies, 1997. Software Engineering Issues Implementing ExtensibleTheorem Provers. With Shriram Krishnamurthi and KathrynE. Gray. Theorem Proving in Higher-Order Logics EmergingTrends. INRIA Research Report, September 1999. Verification in Practice Modelling and Model Checking aShared Memory Consistency Protocol. With ClaudeGirault. International Conference on Applications and Theory of Petri Nets, 1998. Verifying VHDL Designs with COSPAN. With R.P. Kurshan. In Formal Hardware Verification Methods and Systems inComparison, Thomas Kropf, ed, Springer Verlag Lecture Notes inComputer Science 1287, 1997. Verification Using Abstractions, Reductions, and Decompositions ACase Study in COSPAN. Unpublished report, 1996. Using COSPAN to Partially Verify and Debug a BarcodeReader. ATTBell Laboratories Technical Memorandum, December 1995. Teaching Issues CounterMeasures A Game for Teaching Computer Security . Craig Jordan, Matt Knapp, Dan Mitchell, Mark Claypool, and Kathi Fisler. NetGames 2011 WPI MQP project Little Language Project Modules . With John Clements. Journalof Functional Programming Educational Pearl. January 2010. Implementing domain-specific languages as the foundations ofan honors CS course . SIGPLAN Notices 4311 66-70, 2008. Teaching Reasoning Using Heterogeneous Logic . With Jon Barwiseand Ruth Eberle. Presented at DIMACS workshop on Teaching Logic in anIllogical World, July 1996.", "metadata": {"last_modified": "2021-07-18T14:00:32+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 1982, "token_count_estimate": 3961}}, "https://cs.brown.edu/~kfisler/": {"text_content": "Kathi Fisler Research Professor, Computer Science Co-Director of the CS Undergraduate Program Research Director, Bootstrap previously Professor, WPI Computer Science CIT 309 401-863-7607 kfislercs.brown.edu Contact Schedule Publications Brown PLT Im interested in various facets of how people learn and use formalsystems. My current focus is computing education, where Im lookingat models and representations for explaining program behaviornotional machines and how to leverage contrasts between concreteexamples to teach computing concepts. Ive been developing a course and textbook on teaching computing through a data-centriclens data science data structures. I am also one of the facultyleading the design andassess of our department-wide effort on integrating socially-responsiblecomputing across all four years of our CS curriculum. Through thisproject, Im trying to understand how people learn to perceive andreason about social systems.Ive also worked ondiagrammatic logics for hardware design late 1990s, modularverification of feature-oriented programs early 2000s, and reasoningabout access-control and privacy policies mid-late 2000s. Thoseprojects emphasized formal systems over human reasoning. My work incomputing education tilts the balance, but is part of the same broadtheme. I have been heavily involved in outreach for K-12 computing education since the late 1990s. Almost all of my work is done in collaboration with two terrificteams the Brown ComputingEducation Research group and Bootstrap K-12 outreach. Research Teaching Outreach Professional Personal Current Projects Data-Centric ComputingEducation With both computing and data science becomingessential across disciplines, its time to rethink introductorycomputer science education. Were developing data-centriccomputing as a blend of computer science, data science, and dataengineering that provides skills to students across campus. We have an op-edsummarizing the goal , an introductory collegiatecourse , and a textbook releasedAugust 2021. Our decisions are driven by our research incomputing education. Our BootstrapDataScience curriculum provides a high-school pre-cursor for thosestarting in K-12. Program Design and PlanComposition in Computing Education Programming problemstypically contain multiple subtasks, solutions to which must beintegrated into a single program. This project explores how noviceprogrammers decompose problems and compose subtask immplementations.Our work emphasizes both the impact of programming languages andlibraries on planning behavior, and pedagogies for teaching programdesign, planning, and composition. Cross-Discipline Transfer of Knowledge in Computing Education Bootstrap produces a family of curricula that integrate computing education for middle- and high-school students with other disciplines such as algebra, physics, and social sciences. The research components of this project study the pedagogical techniques and curricular conditions under which knowledge gained through computing transfers back to the host discipline and vice-versa for teachers Notional Machines for Computing Education Notional machines are the abstract machines that programmers are attempting to control when they write programs. Different programming languages afford different notional machines, which in turn allow different misconceptions about language behavior. We are studying tradeoffs among notional machines and pedagogies for avoiding misconceptions in various CS courses, both intro- and upper-level. Past Projects Security Policy Analysis Analysis of Datalog-based policies, such as those used for access-control and privacy. Our Margrave policy analyzer was a SAT-based engine for verifying properties of policies, as well as for verifying and exploring consequences of changes to policies. We also worked on models of how policies interact with underlying software systems. Feature-Oriented SoftwareVerification Features are cohesive, user-facing behaviors ofsystems. Feature-oriented designs like aspect-oriented designmodularize code around features. Shriram Krishnamurthi and I developeda theory of compositional verification of feature-based softwaredesigns our approach generated logical constraints as interfaces onfeatures used in open systems in which not all features were known inadvance. Formal Reasoning withTiming Diagrams Given a semantics, timing diagrams become aformal representation of system behavior. This project exploredsemantics and analysis techniques for such specifications. I provedthat timing diagram verification is decidable, even though timingdiagrams capture some non-context-free languages. Work and Education History 2017-present Research Professor and Co-Director of Undergraduate Program in Computer Science , Brown University 2014-2017 Professor of Computer Science , WPI 2007-2014 Associate Professor of Computer Science , WPI 2000-2007 Assistant Professor of Computer Science , WPI 1996-2000 Postdoc and Instructor of Computer Science , Rice University 1997 Summer Intern at IBM Haifa formal verification group 1991-1996 PhD student in Computer Science , Indiana University 1987-1991 Undergraduate at Williams College Computer Science and Asian Studies Editorial and Program Committees Editorial Board Communications of the ACM Program Chair for ICER 2022 junior chair and 2023 senior chair Former Associate Editor ACM Transactions on Computing Education Former Associate Editor IEEE Transactions on Education Recent Program Committees SEET 2024, ICER2021, ICER 2020, ICER 2019, SIGCSE 2018, SIGCSE 2017, ICER 2016 , SIGCSE 2016, ICER 2015 , ISSEP 2015 , SPLASH-E 2014 Chair, FOSD 2013, FOSD 2012, ABZ 2012 I mostly teach introductory-level courses and research seminars on computing education. I have also taught programming languages, software security, computer-aided verification, and various research seminars. Courses at Brown Spring 2024 CSCI0200 Program Design with Data Structures and Algorithms also Spring 2023, Spring 2022 Fall 2022 CSCI0111 Computing FoundationsData also Fall 2021, Fall 2020 Summer 2020 CSCI0180 Computer Science, An Integrated Introduction also Spring 2020, Spring 2019, Spring 2018 Summer 2019 CS0050 A Data-Centric Introduction to Programming 2017 offering Courses at WPI Links are to my last offering of each course, but I taught several of these many times CS2102 Object-Oriented Design Concepts CS525 Spring 17 Theory and Practice of Computing Education A Research Seminar CS4536 Programming Languages CS4401 Software Security Engineering CS1101 Introduction to Program Design CS1102 Accelerated Intro to Program Design Links to Older Courses TeachSchemeProgram by Design I have also developed various TeachScheme exercises and materials over the years. I began doing serious K-12 computer science outreach in 1997, whenI joined the Program byDesign team then called TeachScheme. I co-directed Program By Design with Shriram Krishnamurthi, starting in 2000. Bootstrap I co-founded Bootstrap with Emmanuel Schanzer and Shriram Krishnamurthi. Bootstrapproduces a series of CS curricular modules for middle- andhigh-school, with an emphasis on modules that integrate into existingsubjects. We currently have modules that integrate into algebra,physics science modeling, and social science data science. Wealso have a computer science module that follows on the algebra module for those looking for a complete introductory CS course. Bootstrap is active on the national level. We train hundreds ofteachers in many states each year, reaching roughly 25,000 studentsper year. We are actively engaged in both national and state-level CSforAll projects, including CS4RI. Details are on the Bootstrap website . Within Bootstrap, I take the lead on grant writing, research and assessment, our partnership with the Oklahoma State Dept of Education, our social studiesdata science curriculum, and our software infrastructure for producing curricular materials. We all do a bit of everything though, so feel free to reach out if you have a question about the project. CS Standards Efforts I have been involved in several efforts to develop educational standards for K-12 CS I was a consultant on the K-12 CS standards for New York. In 2017-18, I was a lead author on the K-12 CS standards for Rhode Island. In 2014-15, I was on the authoring panel that developed the K-12CSDigital Literacy standards for Massachusetts. I was an advisor to the NationalK-12 CS Framework Project . I was also part of the group that developed the programming languages component of the ACM 2013 CS curriculum. I was a theater junkie through high school. As an undergraduate at Williams College , I rang handbells, worked in the college archives, walked campus backwards giving tours, danced folk and jitterbug, double majored in Chinese and Computer Science, and sang in an acapella group for folks who couldnt carry a tune. These days, I like to hike, sing, exercise, and cook vegetarian food from around the world. Jigsaw puzzles distract me for hours. I love puns and other forms of word-play. As a native New Yorker, Im a thin-crust pizza snob. Four years living in Houston learned me in salsa. Im yet to live in a place that offers both great pizza and great salsa.", "metadata": {"last_modified": "2024-01-12T13:34:21+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 1296, "token_count_estimate": 1859}}, "https://cs.brown.edu/~lbsun/GoodPriors2014/goodpriors2014eccv.html": {"text_content": "Good Image Priors for Non-blind Deconvolution Generic vs Specific Libin Sun 1 Sunghyun Cho 2 Jue Wang 2 James Hays 1 1 Brown University 2 Adobe Research Abstract Most image restoration techniques build universal image priors, trained on a variety of scenes, which can guide the restoration of any image. But what if we have more specific training examples, e.g. sharp images of similar scenes Surprisingly, state-of-the-art image priors dont seem to benefit from from context-specific training examples. Re-training generic image priors using ideal sharp example images provides minimal improvement in non-blind deconvolution. To help understand this phenomenon we explore non-blind deblurring performance over a broad spectrum of training image scenarios. We discover two strategies that become beneficial as example images become more context-appropriate 1 locally adapted priors trained from region level correspondence significantly outperform globally trained priors, and 2 a novel multi-scale patch-pyramid formulation is more successful at transferring mid and high frequency details from example scenes. Combining these two key strategies we can qualitatively and quantitatively outperform leading generic non-blind deconvolution methods when context-appropriate example images are available. We also compare to recent work which, like ours, tries to make use of context-specific examples. Paper goodpriorseccv2014.pdf , 20MB Supplementary Materials Full Results , 53MB Poster goodpriorseccv2014poster.pdf , 12MB Citation Libin Sun, Sunghyun Cho, Jue Wang, James Hays. Good Image Priors for Non-blind Deconvolution Generic vs Specific.Proceedings of the European Conference on Computer Vision ECCV, 2014. Bibtex inproceedingsgoodpriorseccv2014, Author Libin Sun and Sunghyun Cho and Jue Wang and James Hays, Title Good Image Priors for Non-blind Deconvolution Generic vs Specific, Booktitle Proceedings of the European Conference on Computer Vision ECCV, Year 2014 Example Results Comparison of our non-blind deconvolution results against numerous well-known methods in generic non-blind deconvolution 25 as well as leading method in example-based deconvolution 8, please choose a test image and click through the slider buttons. Please note that methods 2 through 5 do not make use of specific example images, whereas method 8 and ours do. For full detailed results, please refer to our supplementary material.From left to right 1.input image with known blur kernel 2. Krishnan and Fergus 2009 3. Levin et al 2007 4. Zoran and Weiss 2011 5. Schmidt et al 2013 6. Ours 7x7x2 local priors 7. Groundtruth image 8. HaCohen et al 2013 blind deconvolution, estimated kernel shown in top-left. 9. Ours non-blind deconvolution, using kernel estimates from 8.", "metadata": {"last_modified": "2014-09-19T18:42:09+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["Good Image Priors for Non-blind Deconvolution: Generic", "Specific", "Abstract", "Paper", "Supplementary Materials", "Poster", "Example Results"], "word_count": 399, "token_count_estimate": 613}}, "http://www.john-meehan.com": {"text_content": "john john meehan meehan PhD Candidate Brown University CS PhD Candidate Brown University CS john at cs.brown.edu john at cs.brown.edu about I am a PhD candidate at Brown Universitys Computer Science department , focusing on database research, particularly relating to adding transactions to high-velocity streaming systems. I am advised by Stan Zdonik , and primarily work on the S-Store project with collaborator Nesime Tatbul of Intel Labs. I recently obtained my ScM in computer science at Brown, and am currently in my 3rd year of PhD candidacy. Before Brown, I obtained my undergraduate degree from the University of Notre Dame , and worked for several years as a database engineer at SP Capital IQ. publications S-Store A Streaming NewSQL System for Big Velocity Applications Ugur Cetintemel, Jiang Du, Tim Kraska, Samuel Madden, David Maier, John Meehan , Andrew Pavlo, Michael Stonebraker, Erik Sutherland, Nesime Tatbul, Kristin Tufte, Hao Wang, Stanley Zdonik VLDB 2014", "metadata": {"last_modified": "2014-12-15T22:27:05+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 153, "token_count_estimate": 220}}, "https://cs.brown.edu/~lspiegel/": {"text_content": "Leonhard Spiegelberg Ph.D. StudentBrown About Hello world I am a 4th year Ph.D. student in Computer Science at Brown University . My advisors are Dr. Malte Schwarzkopf and Dr. Tim Kraska in the database management group. My research interests include building more efficient big data analytics systems that are designed for modern, UDF driven data pipelines, dealing with dirty data in a better way and designing future systems for sensor-driven Machine Learning products. Furthermore, I am interested in applications for Computer Vision especially for self-driving cars and how to retrieve statistically sound insights from data. Before coming to Brown I was working for Mentat Innovations as Data Scientist and as Machine LearningData Engineer for BMW s self-driving car group. Research Projects Tuplex Data Science in Python at Native Code Speed Tuplex , short for tuples and exceptions , is a novel big data anlytics framework that is inherently more robust to exceptions and errors produced when processing raw data. Written with a powerful C backend and easy-to-use Python frontend it provides a novel programming paradigm, an order of magnitude faster execution speed than Apache Spark and efficient parsers for raw data. The project is currently under heavy development and available under tuplex.cs.brown.edu . A preprint can be accessed below. VizCertify A framework for secure data exploration Visual representations of data visualizations are tools of great importance and widespread use in data analytics as they provide users visual insight to patterns in the observed data in a simple and effective way. When visualizations are retrieved from sample data however, there is a a risk of visualizing random fluctuations in the sample rather than a true pattern in the data. This problem especially arises when differences between visualizations are compared, e.g. to identify an interesting deviation in a pair of observations among many possible pairs. Using theorems from VapnikChervonenkis we developed a novel framework VizRec to provide a safe space for visualization recommendations. This work has been published in DSAA 2019 . Publications Spiegelberg, L. , Yesentharao, R., Schwarzkopf, M. Kraska, T. 2020. Tuplex Data Science in Python at Native Code Speed pub preprint De Stefani, L., Spiegelberg, L. , Kraska, T., Upfal, E. 2019. VizCertify A framework for secure data exploration. DSAA19 pub slides Spiegelberg, L. , Kraska, T. 2019. Tuplex Robust, Efficient Analytics When Python Rules VLDB19 pub Engel, J., Scherer, M., Spiegelberg, L. 2017. One-Factor Lvy-Frailty Copulas with Inhomogeneous Trigger Rates. In M. B. Ferraro, P. Giordani, B. Vantaggi, M. Gagolewski, M. ngeles Gil, P. Grzegorzewski, O. Hryniewicz Eds., SMDS17 Other Projects This is a non-complete list of other projects I have been working on in the past Picture Perfect Plates Building a model to classify restaurant images We developed a computer vision from the ground up to classify restaurant images into different categories together with TripAdvisor, Inc . More can be read about this project here and here . Two-stage Dictionary Selection via greedy selection In this project we developed a two-stage optimization algorithm for dictionary selection under a supermodular assumption that is based on greedy minimization of weakly supermodular set functions. Our final report can be found here . Adaptive Extendible Hashmaps with a better in-bucket strategy Extendible Hashmaps are a commonly used data-structure in filesystems or databases for dynamic hashing i.e. a growable hashmap. In this work we relaxed the assumption of using fixed buckets and experimented with different in-bucket structures to adapt better to different workloads. Ordinal regression in Apache Spark With ratings and curated lists being widespread, ordinal regression is a modified version of the popular linear model that takes the ordering property of such data into account. In this project we extended Spark by an ordinal regression model and performed various experiments. All content copyright L. Spiegelberg 2017-2020.", "metadata": {"last_modified": "2020-09-09T16:06:16+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["About", "Research Projects", "Publications", "Other Projects"], "word_count": 625, "token_count_estimate": 860}}, "https://marilyngeorge.com/": {"text_content": "Toggle navigation Home Publications CV I am a Research Scientist in the Cryptography Research Group at MongoDB. I currently focus on designing practical techniques for leakage suppression in structured encryption. Before this, I was a Ph.D. student in the Brown University Encrypted Systems Lab , working with Professor Seny Kamara . Recent News Aug 2023 Queryable Encryption has gone GA Aug 2023 Participated in the StorySLAM for RISE at CRYPTO 2023. July 2023 Our work on Synq Public Policy Analytics over Encrypted Data is accepted to IEEE SP 2024. Aug 2022 Joined the Cryptography Research Group at MongoDB as a Research Scientist. May 2022 Defended my thesis on Compliant and Secure Databases. Marilyn George marilyn.george at mongodb.com MongoDB Inc. 1633 Broadway New York City, NY Google Scholar Publications Synq Public Policy Analytics over Encrypted Data Z. Espiritu, M. George , S. Kamara, L. Qin IEEE SP 2024 proceedings pdf On the Cost of Suppressing Volume for Encrypted Multi-maps M. Ando, M. George PETS 2022 proceedings pdf GDPRizer Retrofitting GDPR Compliance onto Legacy Databases A. Agarwal, M. George , A. Jeyaraj, M. Schwarzkopf VLDB 2022 proceedings pdf Adversarial Level Agreements for Two-Party Protocols M. George , S. Kamara AsiaCCS 2022 proceedings pdf IACR Cryptology ePrint Archive full pdf Structured Encryption and Dynamic Leakage Suppression M. George , S. Kamara, T. Moataz EUROCRYPT 2021 proceedings pdf Towards Untrusted Social Video Verification to Combat Deepfakes via Face Geometry Consistency E. Tursman, M. George , S. Kamara, J.Tompkin Workshop on Media Forensics, CVPR 2020 proceedings pdf Plain Academic", "metadata": {"last_modified": "2023-11-29T18:39:24+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 254, "token_count_estimate": 395}}, "https://cs.brown.edu/~mlittman/courses/hcri14/": {"text_content": "CS 1951C, Designing Humanity Centered Robots, Spring 2014 Brown University Fall 2014 Michael L. Littman Ian Gonsher steamstudio.us browncreativemind.com Andrew Harpin Time TueThu 9am-1020am Place CIT Center Thomas Watson CIT 345 Semester Fall 2014 Office hours By appointment. Description The course has two tracks, one intended for CS concentrators, and oneintended for non-concentrators with previous design experience. Thenon-concentrator track cannot be used toward fulfilling a ComputerScience concentration requirement. Prerequisites Permission of an instructor. telepresence robots Planned Schedule Date Place In Class Assignment Thu 94 CIT 345 Introduction . Each student test-drives an existing telepresencerobot to understand its capacity and limitations. Students will testthe following telepresence robots VGo, Beam, and, a Roomba-basedkit. Collect contact information. Get your paragraphs in. Tue 99 BDW Context . Students continue to explore robot-mediatedhuman-to-human interaction. In-class assignment Ideation exercise. We will begin in a group with a big roll of paper and sharpies,identifying areas of telepresence we want to explore. Then, webreak into groups of 3-4 to refine some of the better ideas. Set up tumblr blog. Thu 911 CIT 345 Sketches . Develop an idea from last week in a small group. Begin creating a small 3-d model and scenario to motivate your design. Meet outside of class to refine the ideafurther, prepare a short presentation for next Thursdays class. Tue 916 CIT 345 Field Trip . We will travel to St. Elizabeths nursing and rehab center in East Greenwich. Students will observe telepresence robots in a real-world environment to understand their shortcomings and identify areas of improvement. Brainstorm about Better World By Design. Thu 918 CIT 345 Stories . Share your 3-d model and scenario for feedback. Iterate the design. Tue 923 BDW Laser cutters . Ian will run a tutorial in the Brown Design Workshop. Michael is away. Thu 925 Rosh Hashana Industrial design . In-class presentation from Prof. Michael Lye. Tue 930 Quarter scale . Read last weeks stories out loud. Now, pairs create a quarter-scale sketchmodel of an improved telepresence robot that utilizes one additionalfeature to enhance human interaction. Complete models. Thu 102 Building up . Group review of quarter-scalesketch models. After the review, we will combine groups with similarthemes and interest to form groups of 4 students in total. Each of these newly formed groups will meet up with instructors individually to identify one consistent group concept. After identifying the group concept, create a full-scale cardboard mock-up that highlights the new features of your telepresence robot without neglecting proportions. Tue 107 Cardboard . Continue to work on cardboard prototypes. Learn some mock-up techniques. Complete prototype. Thu 109 BDW Kits . Group review of full-scale cardboard mock-ups. Switching modes to introduction of robot kit consisting of a base on wheels and a laptop. This kit will act as the foundation for building up to the final prototype. We will work together in class to create a rough mockup for how to mount the computer on the robot base using materials such as cardboard, chipboard, and foamcore. Complete the first iteration robot, dealing with the constraints of the Roomba and the computer. Tue 1014 BDW Body . The goal for this week is to create a version of the robot from last time using refined materials plastic, metal, wood. Complete the second iteration robot. Thu 1016 BDW Refinement . Feedback on 2nd iteration robots. Hone second iteration robot based on feedback. Tue 1021 Servos . Learning about motors, servos, microphones, Arduinos. This introduction will help students to understand how to control mechanical functions remotely via Arduino. We will work on creating a simple mechanical function to add to your telepresence robot.The custom-made mechanical components needed for this assignment can be made out of very basic materials such foam core and straight pins. At this point, do not focus on aesthetics or machined precision. Complete servo project. Thu 1023 Control . We will augment the telepresence software to allow remote control of the servo. Experiment with interface. Tue 1028 Project . We will review the servo controls created by each group. At this point, we transition to the design and creation of the final projects. Individual desktop reviews with each group. Michael away. Design sketches, concepts. Thu 1030 Maker bot . Introduction of MakerBot desktop rapid prototype machine. Individual desktop reviews with each group. Small scale mockup. Tue 114 Progress review . Presentations of 1 Full-scale cardboardfoam core mock-up that houses the provided kit with functioning motors and servos, 2 Drawingcollage that places your telepresence robot in a specific environment, 3 Your motorservo assignment, 4 Additional support material as sketches and drawings are optional. Thu 116 Progress review . Complete reviewsfeedbackdiscussion. Rebuild and refine full-scale cardboardfoam core mock-up according to progress review feedback. Tue 1111 Construction . Final construction of your final prototype starts. Individual desktop reviews with each group to discuss construction process. Thu 1113 Work . Tue 1118 Work . Individual desktop reviews with each group. Thu 1120 Work . Tue 1125 Work . Individual desktop reviews with each group. Thu 1127 Thanksgiving Greetings . Maybe some people can stop in on each others celebrations via robot. Tue 122 Final crit . Presentation material includes 1 Final prototype. 2 Drawingcollage that places your telepresence robot in a specific environment, 2 Additional support material as sketches, drawings, and mock-ups are optional. Thu 124 Final crit . Tue 129 Wrap-up review . Presentation of refined prototype that incorporates feedback of final crit. Thu 1211 Discussion . What impact could our designs have How could we know What are the next steps to making them a reality", "metadata": {"last_modified": "2014-10-06T18:35:46+00:00", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": ["CS 1951C, Designing Humanity Centered Robots, Spring 2014"], "word_count": 923, "token_count_estimate": 1232}}, "https://cs.brown.edu/~ml137/": {"text_content": "Molly Long About Design Coding Hi Im currently a junior at Brown University studying computer science. Im an aspiring developer who likes to build cool stuff in my free time, while honing on my creative pursuits on my spare time. When Im not studying, I love petting bunnies, eating chocolate croissants and instagramming things that inspire me. Feel free to contact me for an ice cream date Some press Google Student Blogpost CBS News Why are women not pursuing tech jobs 2 Billion Under 20 NAF Alumni scholarship", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:48+00:00", "headings": [], "word_count": 88, "token_count_estimate": 106}}, "https://nkhan2.github.io": {"text_content": "Numair Khan I am a research scientist at Meta Reality Labs in Redmond, Washington. I work on computer vision and machine learning for applications in computational photography. I completed my PhD at Brown where I was advised by James Tompkin . I received a Fulbright Scholarship for my Masters at the Courant Institute of New York University where my Masters thesis was advised by Ken Perlin . Email nbspnbsp CV nbspnbsp Google Scholar Research Your browser does not support the video tag. GauFRe Gaussian Deformation Fields for Real-time Dynamic Novel View Synthesis Yiqing Liang , Numair Khan , Zhenqin Li , Thu Nguyen-Phuoc , Douglas Lanman, James Tompkin , Lei Xiao , ArXiv , 2024 nbsp arXiv project page bibtex We propose a method for dynamic scene reconstruction based on a deformable set of 3D Gaussians residing in a canonical space, and a time-dependent deformation field defined by a multi-layer perceptron MLP Your browser does not support the video tag. TextureDreamer Image-guided Texture Synthesis through Geometry-aware Diffusion Yu-Ying Yeh , Jia-Bin Huang , Changil Kim , Lei Xiao , Thu Nguyen-Phuoc , Numair Khan , Cheng Zhang , Manmohan Chandrakar , Carl Marshall , Zhao Dong , Zhenqin Li , ArXiv , 2024 nbsp arXiv project page bibtex We present a novel image-guided texture synthesis method to transfer relightable textures from a small number of input images to target 3D shapes across arbitrary categories. Your browser does not support the video tag. Tiled Multiplane Images for Practical 3D Photography Numair Khan , Douglas Lanman, Lei Xiao , ICCV , 2023 nbsp arXiv code coming soon bibtex We propose a method for generating tiled multiplane images with only a small number of adaptive depth planes for single-view 3D photography in the wild. Your browser does not support the video tag. Temporally Consistent Online Depth Estimation Using Point-Based Fusion Numair Khan , Eric Penner, Douglas Lanman, Lei Xiao , CVPR , 2023 nbsp arXiv code bibtex We aim to estimate temporally consistent depth maps of video streams in an online setting by using a global point cloud along with a learned fusion approach in image space. Neural Fields in Visual Computing and Beyond Yiheng Xie , Towaki Takikawa , Shunsuke Saito , Or Litany , Shiqin Yan , Numair Khan , Federico Tombari James Tompkin Vincent Sitzmann Srinath Sridhar Eurographics State-of-the-Art Report , 2022 project page website arXiv We present a comprehensive review of neural fields by providing context, mathematical grounding, and an extensive literature review. A companion website contributes a living version that can be continually updated by the community. Differentiable Diffusion for Dense Depth Estimation from Multi-View Images Numair Khan Min H. Kim , James Tompkin CVPR , 2021 project page code arXiv bibtex A method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision. Edge-Aware Bidirectional Diffusion for Dense Depth Estimation from Light Fields Numair Khan , Min H. Kim , James Tompkin BMVC , 2021 arXiv project page code bibtex We present an algorithm to estimate fast and accurate depth maps from light fields via a sparse set of depth edges and gradients. Your browser does not support the video tag. View-Consistent 4D Light Field Depth Estimation Numair Khan , Min H. Kim , James Tompkin BMVC , 2020 arXiv project page code bibtex We propose a method to compute depth maps for every sub-aperture image in a light field in a view-consistent way. Your browser does not support the video tag. View-Consistent 4D Light Field Superpixel Segmentation Numair Khan , Qian Zhang , Lucas Kasser, Henry Stone, Min H. Kim , James Tompkin ICCV , 2019 Oral Presentation paper code bibtex We use occlusion-aware angular segmentation of an Epipolar Plane Image EPI to generate light field superpixels that are consistent across views. Rethinking the Mini-Map A Navigational Aid to Support Spatial Learning in Urban Game Environments Numair Khan , Anis Ur Rahman IJHCI , 2017 paper bibtex We propose landmark-based verbal directions as an alternative to mini-maps, and examine the development of spatial knowledge in an open-world urban game environment. Data Analysis and Call Prediction on Dyadic Data from an Understudied Population Mehwish Nasim, Aimal Rextin, Shumaila Hayat, Numair Khan , Mudassir Malik Pervasive and Mobile Computing , 2017 paper bibtex Predicting outgoing mobile phone calls using machine learning and time clusters-based approaches. Space-Efficient Pointwise Computation of the Distance Transform on GPUs Numair Khan , Mohamed Zahran International Parallel and Distributed Processing Symposium Workshops IPDPSW , 2017 paper bibtex The distance transform is decomposed into a map-and-reduction pattern for efficient computation on GPUs. Understanding Call Logs of Smartphone Users for Making Future Calls Mehwish Nasim, Aimal Rextin, Numair Khan , Mudassir Malik International Conference on Human-Computer Interaction with Mobile Devices and Services MobileHCI , 2016 paper bibtex In this measurement study, we analyze whether mobile phone users exhibit temporal regularity in their mobile communication. Misc In Search of a Strategy Against Misinformation I, Entrepreneur The Essentials of a Computer Scientists Toolkit Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2020 Teaching Assistant, CSCI 1290 - Computational Photography, Fall 2018 Teaching Assistant, CSCI 2240 - Interactive Computer Graphics, Spring 2018 Instructor, Advanced Programming Spring 2016 Instructor, Operating Systems Fall 2015 The source code for this website was copied from Jon Barrons website. It is freely available for personal use here .", "metadata": {"last_modified": "2024-01-24T18:32:00+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 901, "token_count_estimate": 1287}}, "http://people.csail.mit.edu/kraska/index.html": {"text_content": "Home Biosketch Research People Teaching Publications Awards Grants I am an Associate Professor of Electrical Engineering and Computer Science in MITs Computer Science and Artificial Intelligence Laboratory CSAIL , founding co-director of the Data System and AI Lab DSAIL at MIT, and co-founder of einblick analytics, inc. My group aims to dramatically increase the efficiency of data-intensive systems and democratize data science by enabling a broader range of users to unfold the potential of their data through the development of a new generation of algorithms and systems. This entails exploring how we can build systems to better support the recent advances in machine learning Systems for ML and how we can leverage machine learning to improve systems ML for Systems .For example, with our work on SageDB we started to explore how we can enhance or even replace core systems components using machine learning models and early results suggest, that we can improve the state-of-the-art by more than an order-of-magnitude in performance.On the other hand, with Northstar we are exploring new user interfaces and infrastructure to democratize data science by enabling visual, interactive, and assisted data exploration and model building. One particular focus of this work is to help all types of users to analyse data and build models faster, but also make data exploration and model building safer by automatically preventing the user from common pitfalls. Our work has been featured several times by the media TechCrunch , Science , OReilly among others and we are proud, that we had significant impact on academia and industry. For example, Northstar is now being commercialized by einblick analytics backed by venture capital and our ML for Systems work is getting extended by countless researchers around the world for a slightly outdated overview see our SIGMOD 2019 tutorial on Learned Data Structuresand Algorithms and is even finding its way into some cloud products of leading internet companies. I am fortunate to be working with an outstanding team of grad student, under-graduates, and post-docs , with numerous collaborators from academia and industry, and grateful for the research funding we have been receiving from NSF, DARPA, Airforce, Google, Microsoft, and Intel . Biosketch Research Statement Current Research Interests ML-enhanced data structures and algorithms Systems for interactive data exploration and model building Infrastructure for rack-scale analytics and machine learning Transaction processing over high-speed networks Hybrid human-machine data management systems Research Projects In the following, a list of my current and past research projects Learned Systems Components - How to Enhance traditional data structures and algorithms through machine learning Northstar - A System for Interactive Data Science NAM - Redefining Databases for the Next Generation of Networks QUDE - Quantifying the Uncertainty in Data Exploration Tupleware - Redefining Modern Analytics on Modern Hardware MLBase - The Distributed Machine-Learning Management System S-Store - A streaming OLTP system for big velocity applications MDCC - The Fastest Strong Consistent Multi-Data Center Replication Protocol CrowdDB - Answering Queries with Crowdsourcing PIQL - Performance Insightful Query Language CloudySmoky - a distributed storage and streaming service in the cloud Building a database on cloud infrastructure CloudBench - a benchmark for the cloud Zorba - a general purpose XQuery processor implementing in C MXQuery - A lightweight, full-featured Java XQuery Engine Mapping Data to Queries MDQ - data integration with XQuery XQIB - XQuery In the Browser Room 32-G914 MIT - CSAIL 32 Vassar St. Cambridge, MA 02139 Phone 1 510 926-5856 News August 31, 2020 I am giving an online keynote about learned systems at AIDBVLDB as well as I am organizing a round-table on the same topic at VLDB. August 11, 2020 Our work on learned storage systems and query optimizers is featured on MIT News . May 10, 2020 Our paper on automatic joins to improve model prediction got accepted at VLDB. ARDA Automatic Relational Data Augmentation forMachine Learning . March 26, 2020 We got 8 papers accepted at SIGMOD 2018 7 research, 1 demo. In addition we also already got an ICDE paper and an SMDB paper accepted. Just a pity that most of these conferences might end up to be virtual. January , 2020 Erfan Zamanian successfully defended his PhD thesis. Big congrats October 5, 2019 We got 1 NIPS paper, 5 workshop papers at NIPS, and 1 workshop paper at the AI Systems Workshop at SOSP accepted. I am particular proud of Darryl Hos he is an undergraduate at MIT work on using learning to improve DNA index search. August 12, 2019 The VLDB 2019 tutorial slides on Learned and Self-Designed Data Structures and Algorithms are now uploaded. Support", "metadata": {"last_modified": "2021-09-04T15:03:22+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Associate Professor, MIT"], "word_count": 762, "token_count_estimate": 975}}, "https://cs.brown.edu/~pck/": {"text_content": "This web site is dedicated to the memory of Paris Christos Kanellakis Dec. 3, 1953 - Dec. 20, 1995 Professor, Computer Science Dept. Brown University, Providence RI, USA He combined Mediterranean passion about all aspects of life - family, friends, colleagues, his research, and teaching - with great precision of thought and language.quot Andries van Dam, Brown University In Honor of Paris Awards and Fellowships The ACM Paris Kanellakis Theory and Practice Award The Kanellakis Graduate Fellowship at Brown The Kanellakis Graduate Fellowship at MIT The Kanellakis Fellowship at NTUA In Greek Events If you are organizing an event in memory of Paris, please email alexpap at cs.brown.edu to include a link to your event on this page. The annual Paris Kanellakis Lecture at Brown If you would like to be included to the mailing list for this lecture series, please email alexpap at cs.brown.edu. Principles of Computing and Knowledge, an FCRC 2003 Workshop Proceedings The 1st Hellenic Data Management Symposium HDMS 2002 Past events Remembering Paris An announcement from the Brown News Bureau of a Memorial Service at Brown University on Jan. 29, 1996. Here is the speech presented at the service by Eugene Charniak , then chair of the department. Articles from the Associated Press and the Brown Daily Herald about the accident, Paris and his family. Paris Professional Life Paris unfinished work - Paris was involved in many professional activities in PostScript Paris CV - as he left it in PostScript Technical Obituary - appeared in Computing Surveys , March 1996 issue in PostScript A partial list, with e-mail addresses, of Paris co-authors and colleagues . Paris Other Side An article in PS about Browns sexual harassment policies, published in the faculty bulletin. A cartoon illustrating the ISA principle. Some quotes collected by the students in Paris Theory of Computation course. Paris Publications Journal Articles , Book Chapters , Conference Abstracts , Miscellaneous Manuscripts This page is maintained by Alexandra Papoutsaki alexpap at cs.brown.edu.", "metadata": {"last_modified": "2015-02-16T02:46:40+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Paris Christos Kanellakis", "In Honor of Paris", "Remembering Paris", "Paris' Professional Life", "Paris' Other Side", "Paris' Publications"], "word_count": 327, "token_count_estimate": 430}}, "https://cs.brown.edu/~pvaliant/": {"text_content": "Website moved", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 2, "token_count_estimate": 2}}, "https://cs.brown.edu/people/pfelzens/engn2520/": {"text_content": "ENGN 2520 Pattern Recognition and Machine Learning Instructor Pedro Felzenszwalb Office Barus Holley 355 Email pff at brown.edu Office hours Thursday 1pm-2pm in BH 355 Course Description This course will cover fundamental concepts in pattern recognition and machine learning. We will focus on mathematical formulations and computational methods that are broadly applicable. Topics include supervised learning, parametric and non-parametric models, decision theory, bayesian inference, dimensionality reduction, clustering, feature selection, generalization bounds, support vector machines and neural networks. We will consider motivating applications in computer vision, signal processing, medical diagnostics, and information retrieval. Prerequisites probability and statistics, linear algebra, calculus and programming experience. Textbook C. Bishop, Pattern Recognition and Machine Learning, Springer. Grading Grading will be based on regular homework assignments and a final exam. Homework will involve both mathematical exercises and programming assignmentsprojects. Students can use python or Matlab for programming.", "metadata": {"last_modified": "2023-12-08T02:58:29+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 141, "token_count_estimate": 195}}, "https://cs.brown.edu/people/pfelzens/engn2520-2012/": {"text_content": "ENGN 2520 Pattern Recognition and Machine Learning Spring 2012 Lecture TueThu 230pm-350pm Location Barus Holley 159 Instructor Pedro Felzenszwalb Email pff at brown.edu Office Barus Holley 355 Office hours by appointment Course description Textbook Grading Homework Homework 1 Data for programming assignment Homework 2 Due Wednesday February 22 by 4pm Data for programming assignment Homework 3 Due Friday March 9 by 4pm Homework 4 Due Friday April 6 by 4pm Data for programming assignment Homework 5 Due Thursday May 3 by 4pm Data for programming assignment Final exam Take-home Lectures Lecture Date Topic Reference book sections 1 January 26 Introduction and overview 2 January 31 Linear models for regression, basis functions, least squares 1.1, 3.1 3 February 2 Linear models for regression, regularization, probabilistic perspective 3.1.1, 3.1.2, 3.1.4 4 February 7 Classifiers, decision theory 1.5, 1.5.1 5 February 9 Decision theory, loss functions 1.5.2 6 February 14 Naive bayes classifier, ML estimation 4.2.2, 4.2.3 7 February 16 Linear threshold classifier, Perceptron 4.1.7 8 February 23 Linear Support Vector Machines 7.1, 7.1.1 9 February 28 Generalization bounds, VC-dimension 7.1.5 10 March 1 Kernels 6, 6.1 11 March 6 Sequential data 13, 13.1 12 March 8 Hidden Markov Models 13.2 13 March 13 HMM computation forwardbackward Rabiner 14 March 15 HMM computation viterbi Rabiner 15 March 20 Bayesian networks 8.1, 8.2 16 March 22 Bayesian networks 17 April 3 Markov Random Fields 8.3.1, 8.3.2, 8.3.4 18 April 5 MRFs for image analysis 8.3.3 19 April 10 Markov chains 11.2 20 April 12 Gibbs sampling 11.3 21 April 17 Clustering, k-means 9.1 22 April 19 Mixtures of gaussians 9.2 23 April 24 Expectation Maximization 9.4 24 April 26 Principal Component Analysis 12.1 25 May 1 Linear Discriminant Analysis Random Projections", "metadata": {"last_modified": "2013-02-01T14:19:28+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["ENGN 2520 Pattern Recognition and Machine Learning", "Spring 2012", "Lecture: Tue/Thu 2:30pm-3:50pm", "Location: Barus & Holley 159", "Course description", "Textbook", "Grading", "Homework", "Final exam", "Lectures"], "word_count": 287, "token_count_estimate": 552}}, "https://cs.brown.edu/~rfonseca/notes/net-bb-dns-poison.html": {"text_content": "Gerao de Boletos Falsos do Banco do Brasil com acesso pela NET Rodrigo Fonseca Universidade de Brown 29 de Agosto de 2014 Introduo Esta pgina documenta as causas da gerao de boletos bancrios falsos no site do Banco do Brasil, quando acessado de pontos de acesso da NET em Belo Horizonte. As falhas apontadas foram observadas no dia 27 de agosto de 2014. Uma amiga minha, Fernanda, assinante da NET, foi vtima de um golpe no processo de atualizao de um boleto bancrio vencido, originalmente emitido pelo Banco do Brasil. A operao, iniciada no site do Banco do Brasil, causou a gerao de um boleto falso, e o eventual pagamento da quantia do boleto para uma conta que no a do destinatrio. Ela documentou o ocorrido em um video . Neste documento mostramos as falhas tcnicas que permitem a fraude. O objetivo de documentar o ocorrido e apontar as causas, para que tanto o Banco do Brasil quanto a NET possam corrigir os problemas e evitar futuras ocorrncias. A investigao criminal, includindo a identificao da conta para onde foi desviado o dinheiro, no objeto deste documento. As fraudes de boletos tem sido muito comuns ultimamente , com um relatrio pdf da firma de segurana RSA estimando at US 3,75 bilhes em fraudes. Este no deve ser o primeiro e nem ser o ltimo ataque, mas o documentamos aqui para apontar falhas tanto da NET quanto do Banco do Brasil , alertar usurios a apontar algumas prticas de segurana que fariam o ataque muito mais difcil. Resumo Se voc s quer um resumo rpido do que aconteceu, a fraude em questo ocorre da seguinte forma Antes da criao de um boleto, o site do Banco do Brasil, entre outros objetos, requisita o arquivo httpwww57.bb.com.breniAPPSarquivosid.js , que usado para identificao do navegador pelo banco, logo antes da pgina de gerao do boleto. O endereo do servidor www57.bb.com.br normalmente 170.66.14.13 , mas, em pelo menos trs modems da NET no dia 27082014, o endereo retornado era 37.48.81.198 , um endereo pertencente leaseweb.nl , uma empresa de hospedagem de sites, localizado na Holanda. O script retornado id.js pelo servidor holands, que o navegador acredita ser e confia no contedo como se fosse um servidor do Banco do Basil, tem o contedo alterado. O script falso inclui, no frame de gerao de boletos, contedo vindo do site httpxserver2.boletos.cc O contedo do frame includo uma rplica do formulrio de gerao de boletos que, ao ser preenchido, altera o nmero do boleto, o que leva posteriormente ao pagamento da quantia conta dos golpistas. O passo chave do ataque a resoluo de DNS errada. A primeira e mais comum causa para isso seria um virus no computador do cliente. O que faz esse ataque mais srio que isso no aconteceu a falha de DNS ocorre na infra-estrutura da NET ou no modem da NET, ou em um DNS resolver da empresa. O boleto falso, no mesmo computador, s gerado quando este se conecta Internet pela NET. Quando o computador foi conectado Internet compartilhada de um iPhone conectado Claro, no ocorreu o erro, pois a resoluo do www57.bb.com.br foi correta. A NET no a nica que falha, no entanto. Se o Banco do Brasil tivesse usado HTTPS para a transmisso de TODOS os objetos de suas pginas, inclusive o arquivo javascript mencionado acima, o ataque seria muito mais difcil , pois requereria um certificado SSL falso, ou assinado por uma Autoridade Certificadora comprometida. O problema tambm teria sido evitado com o uso de DNSSEC, ou DNS Seguro, mas sua verificao ainda no est muito difundida entre os navegadores. Detalhes Para documentar a falha de segurana gravamos, usando a ferramenta wireshark todos os pacotes Ethernet da interface usada pelo computador em questo em dois momentos o primeiro, acessando o site do banco atravs da conexo da NET, e o segundo atravs de uma conexo WiFi compartilhada por um iPhone, na rede da Claro. Em ambos os casos todos os dados do navegador foram limpos, e executamos o mesmo procedimento de gerao de boleto. Em um dado momento, ao se acessar a pgina do Banco do Brasil em comunicao com www.bb.com.br, resolvido para 170.66.11.10, o navegador envia a requisio POST portalbbhome29,116,116,1,1,1,1.bb HTTP1.1 . A resposta, que parece ser a pgina inicial do banco aps a autenticao do usurio, e inclui a linha script typetextjavascript srchttpwww57.bb.com.breniAPPSarquivosid.jsscript O navegador ento requisita a resoluo de www57.bb.com.br e recebe o endereo errado.Na rede da NET, os pacotes DNS relativos a essa resoluo so os seguintes 779 22.889060000 10.0.0.29 - 10.0.0.1 DNS 75 Standard query 0x18d8 A www57.bb.com.br780 22.907640000 10.0.0.1 - 10.0.0.29 DNS 105 Standard query response 0x18d8 A 37.48.81.198 Enquanto que na rede da Claro, a resoluo se d de forma correta 297 25.405738000 172.20.10.5 - 172.20.10.1 DNS 75 Standard query 0x53a0 A www57.bb.com.br313 26.460452000 172.20.10.1 - 172.20.10.5 DNS 91 Standard query response 0x53a0 A 170.66.14.13 Na primeira, o endereo 10.0.0.1 do roteador conectado ao modem da Net. Para eliminar a possibilidade de o roteadorestar causando a resoluo errada, conectamos o computador diretamente ao modem da net e testamos a resoluo com o comando dig dig www57.bb.com.br DiG 9.8.3-P1 www57.bb.com.br global options cmd Got answer -HEADER- opcode QUERY, status NOERROR, id 26497 flags qr aa rd ra QUERY 1, ANSWER 1, AUTHORITY 1, ADDITIONAL 0 QUESTION SECTIONwww57.bb.com.br.INA ANSWER SECTIONwww57.bb.com.br.38400INA37.48.81.198 AUTHORITY SECTIONwww57.bb.com.br.38400INNSwww57.bb.com.br. Query time 77 msec SERVER 201.17.128.7353201.17.128.73 WHEN Wed Aug 27 171138 2014 MSG SIZE rcvd 63 Note que o servidor de DNS linha SERVER acima 201.17.128.73, que um endereo da NET. host 201.17.128.7373.128.17.201.in-addr.arpa domain name pointer c9118049.virtua.com.br. O endereo 170.66.14.13 do Banco do Brasil whois 170.66.14.13... Brazilian resource whois.registro.br Copyright c Nic.br...inetnum 170.6616aut-num AS11993abuse-c BABRA22owner BANCO DO BRASIL S.A.... E de quem o endereo 37.48.81.198 whois 37.48.81.198... Information related to 37.48.64.0 - 37.48.120.255 Abuse contact for 37.48.64.0 - 37.48.120.255 is abuseleaseweb.cominetnum 37.48.64.0 - 37.48.120.255netname LEASEWEBdescr LeaseWebdescr P.O. Box 93054descr 1090BB AMSTERDAMdescr Netherlandsdescr www.leaseweb.comremarks Please send email to abuseleaseweb.com for complaintsremarks regarding portscans, DoS attacks and spam.country NLadmin-c LSW1-RIPEtech-c LSW1-RIPEstatus ASSIGNED PAmnt-by OCOM-MNTsource RIPE Filtered... www.leaseweb.com um servio de hospedagem baseado em Amsterdan, na Holanda. Abandonai toda a esperana, voz que entrai... Dante Alighieri Uma vez que o navegador enganado a achar que um servidor impostor tem o mesmo domnio que o site principal bb.com.br, toda a confiana est perdida , pois as polticas de segurana aceitam quaisquer arquivos vindos do servidor impostor como se tivessem vindo do domnio original. Ainda pior, pois o navegador pode enviar dados para o servidor remoto sem qualquer filtro. Esses dados poderiam ser, por exemplo, senhas, extratos, ou dados da seo com o banco. O ataque em questo, no entanto, mais simples. O contedo do arquivo javascript falso o seguinte incluindo o comentrio simptico var dUrl this.window.location.hreftryif dUrl.indexOfwww59.bb.com.br 0 if dUrl.indexOfboletoboletosoficialjusticaentrada, 0 dUrl.indexOfentradasecundaria 0 alertdUrl var form document.getElementByIdformulario form.actionhttpxserver2.boletos.ccoficial.jsp if dUrl.indexOfwww.bb.com.br 0 var framedocument.getElementByIdconteudoChamada if frame.src.indexOfwww63 0 frame.src.indexOfboletoboletos 0 alertaki porra frame.srchttpxserver2.boletos.cc catche O navegador ento requisita a pgina em httpxserver2.boletos.cc , que retorna um formulrio falso de gerao de boleto No momento do ataque, este servidor resolvia para o endereo 209.236.74.176 3645 39.153620000 10.0.0.29 - 10.0.0.1 DNS 79 Standard query 0xa7cd A xserver2.boletos.cc3659 39.250878000 10.0.0.1 - 10.0.0.29 DNS 238 Standard query response 0xa7cd A 209.236.74.176 Este IP, por sua vez, pertence Westhost , uma empresa de hospedagem nos EUA whois 209.236.74.176... The following results may also be obtained via httpwhois.arin.netrestnetsq209.236.74.176showDetailstrueshowARINfalseextnetref2NetRange 209.236.64.0 - 209.236.79.255CIDR 209.236.64.020OriginAS AS29854NetName WH-NET-209-236-64-0-1NetHandle NET-209-236-64-0-1Parent NET-209-0-0-0-0NetType Direct AllocationRegDate 2010-02-25Updated 2014-01-02Ref httpwhois.arin.netrestnetNET-209-236-64-0-1OrgName WestHost, Inc.OrgId WESTHOAddress 517 W 100 N STE 225City ProvidenceStateProv UTPostalCode 84332Country USRegDate 2000-03-13Updated 2014-08-20Comment Please report abuse issues to abusewesthost.comRef httpwhois.arin.netrestorgWESTHO... Infelizmente dois dias depois do ataque os dois servidores envolvidos, bem como o domnio xserver2.boletos.cc, esto desativados.As duas empresas de hospedagem podem ter informaes sobre quem contratou as hospedagens respectivas, mas aqui a investigao deixa de ser tcnica. Onde est a falha O fato demonstrado acima que h uma resoluo de DNS errada, feita pelo modem da NET. Isso chamado de DNS poisoning . O programa dig , cujo resultado da execuo no computador conectado diretamente ao modem da NET, mostrado acima, mostra inequivocamente que o modem retornou a resoluo de DNS erronea. Como isso ocorreu H duas possibilidades principais, ambas em infra-estrutura de responsabilidade da NET. 1. Modem Alterado possvel que o modem tenha sido hackeado , e que tenha sido instalado nele a entrada errada, ou trocado a configurao de DNS, apontando para um servidor de DNS malicioso. O modem em questo o Arris TG862. Um artigo de 2012 menciona vulnerabilidades bsicas deste roteador, descobertas por Chris Naegelins I basically found there was no way to secure the device other than to unplug it. Um cenrio plausvel que hackers identificaram uma vulnerabilidade em roteadores deste modelo, fizeram uma varredura do espao de endereos IP pertencentes NET, e envenenaram o DNS resolver dos modems. No seria a primeira vez um outro artigo , tambm de 2012, menciona uma apresentao do Kasperski Lab. Nestaapresentao, Fabio Assolini diz que 4,5 milhes de modems foram hackeados no Brasil desde 2011. Ele menciona 6 fabricandes de modems com vulnerabilidades,40 servidores de DNS falsos, e provedores de Internet que distribuem dispositivos com falhas de segurana. 2. Infraestrutura de DNS da NET Um ataque possvel, mas consideravelmente mais difcil para algum de fora, o comprometimento de servidores de DNS da NET, que so usados pelos modems da empresa para a resoluo de endereos. 3. Banco do Brasil O site do Banco do Brasil tambm apresenta grave falha de segurana, ao requisitar objetos associados pgina atravs de HTTP, e no de HTTPS, ou seja, via conexo segura. Conexes HTTPS se utilizam de certificados digitais para assegurar que o servidor enviando as informaes para o navegador um servidor do dono do domnio. Em outras palavras, o servidor diz que tem autoridade para falar como bb.com.br. No caso especfico deste ataque, a pgina do Banco do Brasil requisita o script httpwww57.bb.com.breniAPPSarquivosid.js de um servidor separado no domnio bb.com.br . Se essa conexo fosse por HTTPS, o servidor teria que ter acesso a um certificado pertencente ao Banco do Brasil. Embora seja possvel de se obter certificados falsos , o ataque fica consideravelmente mais difcil neste caso, e simplesmente no h motivos para que o banco no utilize HTTPS para todos os objetos associados sua pgina. Como evitar o ataque Dois dias depois da descoberta deste ataque, a NET corrigiu a resoluo do DNS erronea, e os servidores e o domnio piratas envolvidos esto fora do ar. No entanto, h vrias falhas que podem ser corrigidas, e que podem continuar a ter consequncias muito srias. A lista abaixo complementar, e no substitui as medidas de segurana que devem ser tomadas pelos usurios, como a utilizao anti-virus atualizados e a utilizao de senhas seguras . Outra medida que pode ser tomada pelos usurios de, ao invs de usar o servidor de DNS do provedor, trocar a configurao de DNS de seus computadores ou de roteadores para utilizar o servidor DNS do Google, 8.8.8.8. Substituio de modems com falhas de segurana responsabilidade do provedor de acesso Monitorao da infra-estrutura de resoluo de DNS do provedor responsabilidade do provedor de acesso Utilizao exclusiva de HTTPS como protocolo de transmisso de dados para sites que devem ser seguros Adoo de DNSSEC pelos mesmos sites embora seja necessria a implementao da tecnologia nos navegadores tambm Essas medidas no garantem 100 de segurana, mas so imprescindveis para que haja alguma chance de segurana. Quem Rodrigo Fonseca , PhD, professor e pesquisador do departamento de Cincia da Computao da Universidade de Brown , nos EUA, especializado em redes de computadores e sistemas distribudos. Imagem da placa de trnsito cortesia do usurio do Flickr joshuamckenty. Comentrios Please enable JavaScript to view the comments powered by Disqus. comments powered by Disqus Back to top Template and css from Twitter bootstrap.", "metadata": {"last_modified": "2014-09-19T18:54:22+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Gera\u00e7\u00e3o de Boletos Falsos do Banco do Brasil com acesso pela NET", "Introdu\u00e7\u00e3o", "Resumo", "Detalhes", "Onde est\u00e1 a falha?", "Como evitar o ataque", "Quem", "Coment\u00e1rios"], "word_count": 1959, "token_count_estimate": 3820}}, "https://cs.brown.edu/~pw/": {"text_content": "Peter Wegner I am the former editor-in-chief of ComputingSurveys and of The Brown Faculty Bulletin. Some of my current research interests are interaction, compound andactive document systems such as OpenDoc , JavaBeans and ActiveX ,object oriented programming, and programming languages. Here are some of my papers on Interaction Date Paper Sep. 95 OOPSLA 95Tutorial Notes Models and Paradigms of Interaction Apr 96 Coordinationas Constrained Interaction ,LNCS 1061, pp. 28-33, April 1996 May 97 Why InteractionIs More Powerful Than Algorithms , Communications of the ACM. ,May 1997 December 96 InteractiveSoftware Technology , Handbook of Computer Science and Engineering,CRC Press, 1996. May. 97 Frameworksfor Compound Active Documents , work in Progress May. 97 InteractiveFoundations of Computing, Final Draft , Theoretical Computer Science,February 1998 Jan. 98 A ResearchAgenda for Interactive Computing , work in Progress May 98 TowardsEmpirical Computer Science , The Monist, Spring 1999 July 98 Persistenceas a Form of Interaction , Brown Technical Report CS 98-07, July 1998 January 99 MathematicalModels of Interactive Computing ,Brown Technical Report CS 99-13 January 99 Interactionas a Framework for Modeling ,LNCS 1565, April 99 February 99 CoinductiveModels of Finite Computing Agents ,Electronic Notes in Theoretical Computer Science, March 1999 February 99 InteractiveVisual Programming Principles and Examples , work in Progress March99 Modeling,Formalization, and Intuition , Brown Faculty Bulletin, March 99 May 99 Modelsof Interaction , ECOOP 99 Course Notes June 99 Interaction,Computability, and Churchs Thesis ,work in Progress June 99 Draftof ECOOP99 Banquet Speech , Lisbon, Portugal Aug. 00 An InteractiveViewpoint on the Role of UML ,Book chapter, published in Unified Modeling Language Systems Analysis, Design, and Development Issues , Idea Group Publishing, 2001. May. 02 Paraconsistency of Interactive Computation ,PCL 2002 Workshop on Paraconsistent ComputationalLogic, Denmark, July 2002 Jun. 02 ComputationBeyond Turing Machines RTF, Communications of the ACM , April 2003 Jun. 03 TuringsIdeas and Models of Computation .Book chapter, in Alan Turing Life and Legacy of a Great Thinker ,ed. Christof Teuscher,Springer 2004 co-authored with Eugene Eberbach, Dina Goldin Jun. 05 The Church-Turing Thesis Breaking the Myth PDF,Presented at CiE 2005, Amsterdam LNCS 3526, Springer 2005, pp. 152-168 Mar. 06 Principlesof Problem Solving , Communications of the ACM , July 2006 Sep. 06 InteractiveComputation the New Paradigm. Published by Springer-Verlag in September2006 co-edited with Dina Goldin, Scott Smolka Jan. 08 Refutingthe Strong Church-Turing Thesis the Interactive Nature of Computing PDF,accepted for publication in Minds and Machines . co-authoredwith Dina Goldin here is herlist of paperson interaction . Peter Wegner Box 1910, Computer Science Department Brown University Providence, RI 02912 pwcs.brown.edu Finger me. 401-863-7600 voice 401-863-7657 fax", "metadata": {"last_modified": "2008-02-01T22:24:43+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Peter Wegner"], "word_count": 423, "token_count_estimate": 708}}, "https://cs.brown.edu/people/pfelzens/engn2912p/": {"text_content": "Topics in Optimization ENGN 2912P Home Assignments Lectures Lecture MWF 11am-1150am in Barus Holley 159 Instructor Pedro Felzenszwalb Email pff at brown.edu Office Barus Holley 355 Office hours Monday 2-4pm in BH355 TA Jeroen Chua Email jeroenchua at brown.edu Office hours Thursday 2-4pm in BH317 Course description This course will cover various topics in discrete and continuousoptimization. Topics include graph algorithms, dynamic programming,linear programming, convex optimization and coarse-to-fine methods. References Combinatorial Optimization. Schrijver. Springer. Introduction to Algorithms. Cormen, Leiserson, Rivest, Stein. MIT Press. The Design and Analysis of Computer Algorithms. Aho, Hopcroft, Ullman. Addison-Wesley. Algorithm Design. Kleinberg, Tardos. Addison-Wesley. Randomized Algorithms. Motwani and Raghavan. Preliminary list of topics for 2015 Shortest paths - Dijkstra, Bellman-Ford, Floyd-Warshall - Min-plus matrix multiplication - Minimum-ratio paths - String edit and time warping Flow - Max-flow Min-cut - Min-cost circulation - Bipartite matching Linear programming - Simplex - Duality Dynamic programming - Sequence labeling - Graph labeling - Piecewise quadratic fitting Approximation algorithms - Min-cover greedy - Max-cut local search - Packing rounding DP - LP relaxations Other topics - Randomized Algorithm - Branch-and-bound - Heuristic search - Local search - Convex optimization", "metadata": {"last_modified": "2016-02-20T01:48:22+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Topics in Optimization (ENGN 2912P)"], "word_count": 189, "token_count_estimate": 324}}, "https://cs.brown.edu/~seny/": {"text_content": "Home Papers Talks Lab Blog Seny Kamara Associate Professor, Brown University Lab Encrypted Systems Lab blog email senybrown.edu twitter senykam pub key B80B 84AC 9C5D 174D Overview I am an Associate Professor of Computer Science at Brown University and a Distinguished Scientist at MongoDB where I manage the Advanced CryptographyResearch Group. Before its acquisition by MongoDB, I was co-founder and ChiefScientist at Aroki Systems. Prior to that, I was a research scientist at Microsoft Research . My research is in cryptography and is driven by real-world problems fromprivacy, security and surveillance. I have worked extensively on the design andcryptanalysis of encrypted search algorithms, which are efficient algorithms tosearch on end-to-end encrypted data. I maintain interests in various aspectsof theory and systems, including applied and theoretical cryptography, datastructures and algorithms, databases, networking, game theory and technology policy. I co-direct the Encrypted Systems Lab and amaffiliated with the CAPS group, the Data ScienceInitiative , the Center for Human Rights and HumanitarianStudies and the Policy Lab . If you are interested in working in the Encrypted Systems Lab, please read this before sending me an email. In the Fall, I teach Algorithms for thePeople blog a course that surveys, critiques andaspires to address the ways in which computer science technology affectmarginalized communities. News Check out and attend the first Workshop on the Theory and Practice of Encrypted Search TPES An article on the Aroki acquisition and MongoDBs queryable encryption Wired , TechCrunch I recently did a QA with Nature My congressional testimony to the U.S. House Committee on Space, Science and Technology written , video Our report on End-to-End Encryption and Content Moderation with CDT is available blog report Check out our collaboration with Browns CSREA on Technology and Structural Inequity Our collaboration with Sen. Wyden D-OR on an encrypted gun registry appeared at Oakland 21 paper , Wired , Brown I gave a keynote at CRYPTO 2020 on Crypto for the People video , slides , Wired , Brown Check out our new blog Algorithms for the People on tech marginalized communities Thank you to Google for the Faculty Research Award My congressional testimony to the Financial Services Committee of the U.S. House of Representatives written , video Im teaching a new course this semester that explores if and how cryptography can help marginalized groups Slides for my encrypted search tutorial SAC intro , leakage attacks , leakage suppression Check out the Brown Center for Human Rights and Humanitarian Studies A few articles about MongoDBs new Field Level Encryption and how we helped review it Wired , Decipher , Brown CS Thank you to Mozilla and the Responsible CS challenge for their support Videos of the ICERM workshop on encrypted search are up Check out Archita and Tariks talks A discussion with PBSs White House Chronicle on developments in crypto and CS video Check out Pixek , our end-to-end encrypted photo app You can readhear moreabout it at Wired , BoingBoing , the CBCSpark podcast, Real-WorldCrypto and OURSA You can find our National Academies of Science report on encryption and exceptional access here Advising Postdoc Tarik Moataz 2016-2019 PhD students Marilyn George , Victor Youdom Kemmoe , Kweku Kwegyir-Aggrey ,Leah Rosenbloom co-advised with Anna Lysyanskaya, Lucy Qin , Graduated PhD students Archita Agarwal , Ghous Amjad , Sam Zhao co-advised with Stan Zdonik MSR interns Sherman Chow , Anurag Khandelwal , Xianrui Meng , Naveed Muhammad , Tarik Moataz , Olya Ohrimenko , Charalampos Papamanthou , Mariana Raykova , Ben Riva , Saeed Sadeghian ,Lei Wei Teaching CS2952-v Algorithms for the People CS2950-v Topics in Applied Cryptography Crypto for Social Good CS16 Introduction to Algorithms and Data Structures Recent Papers Full List Outside Looking In Approaches to Content Moderation in End-to-End Encrypted Systems Seny Kamara, Mallory Knodel, Emma Llans, Greg Nojeim, Lucy Qin, Dhanaraj Thakur, Caitlin Vogus Report for Center for Democracy and Technology 21 report pdf Cryptanalysis of Encrypted Search with LEAKER A framework for LEakage AttacK Evaluation on Real-world data Seny Kamara, Abdelkarim Kati, Tarik Moataz, Thomas Schneider, Amos Treiber, Michael Yonli IACR ePrint full pdf , code Structured Encryption and Dynamic Leakage Suppression Marilyn George, Seny Kamara, Tarik Moataz Eurocrypt 21 proceedings pdf A Decentralized and Encrypted National Gun Registry Seny Kamara, Tarik Moataz, Andrew Park, Lucy Qin IEEE Symposium on Security and Privacy Oakland 21 full pdf , Lucys talk video , Wired Encrypted Databases From Theory to Practice Zheguang Zhao, Seny Kamara, Tarik Moataz, Stan Zdonik Conference on Innovative Data Systems Research CIDR 21 proceedings pdf Adversarial Level Agreements for Two-Party Protocols Marilyn George, Seny Kamara IACR ePrint full pdf Encrypted Key Value Stores Archita Agarwal, Seny Kamara Indocrypt 20 proceedings pdf Encrypted Blockchain Databases Daniel Adkins, Archita Agarwal, Seny Kamara, Tarik Moataz Advances in Financial Technologies 20 full pdf , blog Towards Untrusted Social Video Verification to Combat Deepfakes via Face Geometry Consistency Eleanor Tursman, Marilyn George, Seny Kamara, James Tompkin Media Forensics CVPR Workshop 20 proceedings pdf , Eleanors Talk An Optimal Relational Database Encryption Scheme Seny Kamara, Tarik Moataz, Stan Zdonik, Zheguang Zhao IACR ePrint full pdf Encrypted Distributed Hash Tables Archita Agarwal, Seny Kamara IACR ePrint full pdf , blog , Architas talk Revisiting Leakage-Abuse Attacks Laura Blackstone, Seny Kamara, Tarik Moataz NDSS 20 full pdf Computationally Volume-Hiding Structured Encryption Seny Kamara, Tarik Moataz Eurocrypt 19 full pdf Forward and Backward Private Searchable Encryption with SGX Ghous Amjad, Seny Kamara, Tarik Moataz Eurosec 19 proceedings pdf Encrypted Databases for Differential Privacy Archita Agarwal, Maurice Herlihy, Seny Kamara, Tarik Moataz PETS 19 full pdf Breach-Resistant Structured Encryption Ghous Amjad, Seny Kamara, Tarik Moataz PETS 19 full pdf SQL on Structurally-Encrypted Databases Seny Kamara, Tarik Moataz Asiacrypt 18 full pdf 3rd most influential paper in cryptography from 2018 Structured Encryption and Leakage Suppression Seny Kamara, Tarik Moataz, Olya Ohrimenko CRYPTO 18 proceedings pdf National Academies Consensus Report Decrypting the Encryption Debate . F. Cate Chair, D. Boneh, F. Chang, S. Charney, S. Goldwasser, D. Hoffman, S. Kamara, D. Kris, S. Landau, S.Lipner, R. Littlehale, K. Martin, H. Rishikof, P. Weinberger. report , overviewLawfare Boolean Searchable Symmetric Encryption with Worst-Case Sub-Linear Complexity Seny Kamara, Tarik Moataz Eurocrypt 17 proceedings pdf Projects Pixek an end-to-end encrypted camera app Martin Zhu, Tarik Moataz, Seny Kamara overviewapp VideoRWC18 VideoOURSA Wired CBC Spark BoingBoing Clusion an open source encrypted search library Tarik Moataz, Seny Kamara overview code Signal Search Joe Engelman, Sam Zhao, Tarik Moataz, Seny Kamara overview code Essays Surveys Summer School Selected Areas in Cryptography SAC, 2019 Encrypted Search Intro and Basics Encrypted Search Leakage Attacks Encrypted Search Leakage Suppression How to Search on Encrypted Data 1 , 2 , 3 , 4 , 5 Is the NSA Metadata Program Legal Restructuring the NSA Metadata Program MIT Tech Review Are Compliance and Privacy Always at Odds Lawfare How Not to Learn Cryptography", "metadata": {"last_modified": "2022-08-11T19:33:43+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Seny Kamara", "Overview", "News", "Advising", "Teaching", "Recent Papers (", ")", "Projects", "Essays & Surveys"], "word_count": 1134, "token_count_estimate": 1749}}, "https://cs.brown.edu/~sbz/": {"text_content": "Stan Zdonik Professor of Computer Science Stan specializes in database management systems . His work addresses new applications by applying data management techniques to novel database architectures. Additional Information Research Profile Wikipedia Contact Info Email sbzcs.brown.edu Phone 401-863-7648 Fax 401-863-7657 Mailing Address Box 1910, Computer Science Department Brown University Providence, RI 02912 USA Research Interests Database Systems Alternative Database Architectures Data Streams Complex Analytics Transaction Processing Recent Projects SciDB Paradigm4 H-Store NewSQL DBMS VoltDB C-Store DBMS Vertica Co-Founder Aurora Borealis StreamBase Co-Founder Publications Research Group List DBLP Teaching Database Management Systems Fall Advanced Topics in Database Management Spring Organizations Boston Bluegrass Union Co-FounderPresident International Bluegrass Music Association President Association for Computing Machinery Fellow", "metadata": {"last_modified": "2016-12-13T20:01:51+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Stan Zdonik", "Professor of Computer Science", "Contact Info:", "Research Interests:", "Recent Projects:", "Publications:", "Teaching:", "Organizations:"], "word_count": 113, "token_count_estimate": 167}}, "https://cs.brown.edu/~seny/2950-v/": {"text_content": "Fall 2016 Fall 2017 CS 2950-v Topics in Applied Cryptography Fall 17 Meeting Time TTh 1030-1150 Location CIT 506 Instructor Seny Kamara senybrown.edu Office hours Th 330-5 Prerequisites CSCI 1660 required CSCI 1510 strongly recommended. Syllabus pdf Overview This course surveys recent developments in applied cryptography. It isstructured as a seminar where students present research papers to their peersand work on a semester-long research project. We will focus on researchmotivated by privacy and security issues that arise in practice from areas likecloud computing, databases, surveillance and finance. Topics will vary eachyear.Though the course is motivated by practicalapplied problems, some of thepapers we will study are theoretical in nature. While previous exposure to thefoundations of cryptography including, e.g., provable security, the simulationparadigm, reductions will be helpful, we will cover the necessary theory inclass. Topics tentative Encrypted systems Blockchains Surveillance Course Materials There is no textbook required for this course but students may find Introduction to Modern Cryptography by Katz and Lindell helpful to gain familiarity with cryptography. Other recommended free resources include Introduction to Modern Cryptography by Bellare and Rogaway and A Course in Cryptography by Pass and Shelat. Schedule tentative Lecture Date Topic Notes Reading 1 Th 0978 Overview 2 Tu 0912 Introduction to Cryptography pdf 3 Th 0914 Introduction to Cryptography", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["CS 2950-v: Topics in Applied Cryptography (Fall '17)", "Overview", "Topics (tentative)", "Course Materials", "Schedule (tentative)"], "word_count": 212, "token_count_estimate": 301}}, "https://cs.brown.edu/~seny/2952v/": {"text_content": "Home Papers Talks Lab Blog Algorithms for the People CS 2952V Lecture 1030-1150am, TuTh Instructor Seny Kamara senybrown.edu Office hours by appointment Teaching assistant Ghous Amjad ghousamjadbrown.edu Office hours TBD Course Description Computer science has transformed every aspect of society, including communication, transportation, commerce, finance, and health. The revolution enabled by computing has been extraordinarily valuable. The largest tech companies generate almost a trillion dollars a year and employ millions of people. But technology does not affect everyone in the same way. In this seminar, we will examine how new technologies are affecting marginalized communities. This years themes will include Protest movements Migration Geo-fencing Policing Human rights Financial technologies Syllabus pdf Pre-Requisites Graduate students none Undergrad CS concentrators either 30, 32 or 33 Undergrad non-CS concentrators email professor Course Schedule preliminary Dates Topic Speaker Scribe Readings Note Sep 10 Overview Seny Sep 15 Responsibility Seny P. Rogaway. The Moral Character of Cryptographic Work Y. Zak. Supporting unmanned aerial systems operations using ground-life visualizations make sure to watch the QA Sep 17 Protests Seny S. Biddle The Intercept. Police Surveilled George Floyd Protests with Help fom Twitter-Affiliated Startup DATAMINR R. Heilweil Vox. Members of Congress want to know more about law enforcements surveillance of protesters Sep 22 Protests Seny S. Morrison, A. Estes Vox. How protesters are turning the tables on police surveillance Project list out Sep 24 Migration S. Ghaffary Vox. The smarter wall How drones, sensors, and AI are patrolling the border B. Tau, M. Hackman WSJ. Federal Agencies Use Cellphone Location Data for Immigration Enforcement watch video Sep 29 Migration S. Chambers, G. Boyce, S. Launius, A. Dinsmore. Mortality, Surveillance and the Tertiary Funnel Effect on the US-Mexico Border Projects chosen Oct 1 Geo-Fencing SCOTUS. Carpenter v US read until p. 23 O. Kerr. Understanding the Supreme Courts Carpenter Decision Oct 6 Geo-Fencing C. Levinson Protocol. Through apps, not warrants, Locate X allows federal law enforcement to track phones C. Maloney, E. Warren, R. Wyden, M. DeSaulnier. Oversight Committee Letter to Venntel Oct 8 Geo-Fencing All Things Considered NPR. How Political Campaigns Are Using Geofencing Technology To Target Catholics At Mass podcast C. Woodward, H. Bray Boston Globe. A company sent anti-abortion ads by phone Oct 13 Policing K. Roberson, C. Khoo, Y. Song. To Surveil and Predict Oct 15 Policing Oct 20 Policing Oct 22 Human Rights K. Sandvik, N. Raymond. Beyond the Protective Effect Towards a Theory of Harm for Information Communication Technologies in Mass Atrocity Response Oct 27 Human Rights Overview of Myanmars History T. McLaughlin Wired. How Facebooks Rise Fueled Chaos and Confusion in Myanmar Oct 29 Human Rights Business for Social Responsibility. Human Rights Impact Assessment Facebook in Myanmar R. Frankel. How Facebook Is Preparing for Myanmars 2020 Election Nov 3 US Election Nov 5 TBD Nov 10 Fintech A. Katz The Intercept. The Fintech Debt Trap S. Kamara, Statement to the House Financial Services Committee Nov 12 Fintech Z. Amsden et al. The Libra Blockchain Libra Association Members. The Libra Whitepaper Nov 17 Fintech American for Financial Reform and Demand Progress. Banking on Surveillance The Libra Black Paper Nov 19 Project presentations Nov 24 Project presentations Nov 26 Thanksgiving Dec 1 Reading period Dec 3 Reading period A note on the syllabus the syllabus does not contain any work on AI and ML and, in particular, on algorithmic fairness. This is a very important subject but we will not be discussing it in 2952 because it is already covered in several Brown CS courses.", "metadata": {"last_modified": "2022-08-11T19:33:43+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Algorithms for the People (CS 2952V)", "Course Description", "Pre-Requisites", "Course Schedule (preliminary)"], "word_count": 582, "token_count_estimate": 847}}, "https://cs.brown.edu/people/rblumber/": {"text_content": "Roger B. Blumberg rbbcs.brown.edu Box1910, Computer Science Department BrownUniversity Providence,RI 02912 Curriculum Vitae I am an Adjunct Lecturer in the Department, where Ive been teaching and writing abouteducational technology, computers ethics, big data society, and other topics in thephilosophy of technology, since 1998. In Spring 2018, Ill be teaching two DataScience InitiativeDSI coursesData, Ethics and Society DATA 0080, and a Masters seminar, Data Society DATA 2080. From 1998-2006, I taught CS92, The Educational Software Seminar as well as one of the inaugural First Year Seminars at Brown, Computers and Human ValuesCS009 . Since 1999, I also have been an occasional member of the History,Philosophy and Social Science HPSS faculty at The Rhode Island School ofDesign RISD, where my courses have included Scienceand Society in 20th Century America , Technologyand Contemporary Life , and Computing andIts Consequences . At the start of 2012, I was made an alternate member ofthe Institutional Review Board IRB at Brown, because of my work in thephilosophy of technology and my evaluation experience. Before coming to the Computer Science Department, I was a Visiting Scholarat Browns Institute for Brain and Neural Systems IBNS, working on theanalysis and implementation of biologically-inspired learning algorithms. Aftercreating MendelWeb , in 1995, I becameSenior Hypermedia Researcher at Browns ScholarlyTechnology Group . At STG I worked on a variety of educational technology projects,and hosted the 1996 Conference on Hypermedia, Teaching and Technology, as partof Browns participation in the US Department of Educations RTEC for theNortheast, NetTech. Im a graduate of Columbia College, where I majored in English and ComparativeLiterature, and was a high school English teacher in New York City beforeaccepting a full-time Associate in Science position at Columbia in 1986. AtColumbia, I taught the general education science course, Theory and Practice of Science ,from 1984-1989, as well as a core curriculum Humanities course for first-yearstudents, and a science theory course for the Higher Education OpportunityProgram HEOP at Columbia. In addition to my teaching undergraduates atColumbia, Eugene Lang College, Brown and RISD, I authored and taught for 15consecutive summers a mathematics course , in theColumbia Summer Program for High School Students. I have published articles in a diverse and probably rather peculiar groupof journals and magazines, in print and online, from The Sciences andthe now defunkt New York Newsday , to The Brown Teaching Exchange and Louisiana Educational Technology Review . Most recently, I havebecome a contributor to MendelesBlog .", "metadata": {"last_modified": "2018-01-24T21:12:44+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": [], "word_count": 398, "token_count_estimate": 574}}, "https://cs.brown.edu/~sk/": {"text_content": "Shriram Krishnamurthi Professor of Computer Science Brown PLT and CS Ed Bootstrap Computer Science Department Brown University Contact with Calendar Papers Talks Teaching Service Personal I do not have a research area so much as a research vision Abstractions are essential for progress in computing. Abstractions can also be hard to understand and learn. But abstraction is also beautiful . How do we help people effectively learn about abstractions My goal is quite simply to make progress on as many angles as possibleof this vision. My work is informed by my background. I was primarily trained in programming languages , but I have since trained myself in various aspects of software engineering , formal methods , HCI , security , and networking .Over the years I have contributed to several innovative anduseful software systems JavaScript tools , Flowlog , Racket formerly DrScheme, WeScheme , Margrave , Flapjax , FrTime , Continue , FASTLINK , PerMission ,and more.Currently, I mainly work on Pyret .For more of what Ive been doing lately, please see my research groups blog . Since 2016 manifesto , I have devoted a substantial portion of my time and energy to the hardest problem Ive worked on computing education research . Its the hardest because it requires substantial work on both technical and human-factors fronts the audience is often unsophisticated and vulnerable and if you screw up, you can do real damage to not only individuals but also the field and society. The research vision above is the distillation of the direction of my computing education research. I have been doing computing outreach since 1995. You may may know me through my co-authored books like HtDP , PLAI ,or DCIC formerly PAPL .Our current outreach program, Bootstrap , is usedinternationally to integrate computing into math, physics,social studies, and other disciplines. I have been privileged to work with a group of impressive PhD students Paul Graunke , Greg Cooper , Jay McCarthy , Danny Yoo , Arjun Guha , Tim Nelson , Joe Politz , Hannah Quay-de la Vallee , Justin Pombrio , and Jack Wrenn and currently, Kuang-Chen Lu , Elijah Rivera , and Siddhartha Prasad . I have also been delighted to work with several outstanding post-docs Serge Egelman , Ben Lerner , Tim Nelson , Tess Strickland , Tristan Dyer , Ben Greenman and currently, Will Crichton . Finally, Ive equally chuffed to have done research with several excellent masters students and over 50 amazing undergraduates. Im honored to be a recipient of SIGPLANs Robin Milner Young Researcher Award , SIGPLANs Distinguished Educator Award jointly, SIGSOFTs Influential Educator Award , SIGPLANs Software Award jointly, and Brown Universitys Wriston Fellowship . Disclosure My work has been supported financially by theUS National Science Foundation,DARPA,Amazon,Bloomberg,Cisco,Code.org,CSNYC,the ESA Foundation,Fujitsu,General Motors,Google,Infosys,Jane Street Capital,Meta,RelationalAI,Roblox,the State of Rhode Island, andTripAdvisor.I believe my views have not beenswayed by this support, but I provide this information so you canjudge for yourself. My names are not spelled Sriram or Shiram or Khrishnamurthi or Krishnamurthy orKrishnamurti like the philosopher. Find me, o search engine, findme", "metadata": {"last_modified": "2023-10-08T20:07:05+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Shriram Krishnamurthi"], "word_count": 507, "token_count_estimate": 702}}, "https://cs.brown.edu/~seny/2950v/": {"text_content": "Home Papers Talks Lab Blog CS 2950-v Topics in Applied Cryptography Crypto for Social Good Fall 19 Meeting Time TTh 1030-1150 AM Location CIT 506 Instructor Seny Kamara senybrown.edu Senys office hours by appointment, CIT 507 Teaching assistant Ghous Amjad Ghous Office hours Wednesday, 230-430, CIT 423 Description This course surveys recent developments in applied cryptography. Research inthis field is motivated by privacy and security issues that arise in practicefrom areas like cloud computing, databases, surveillance and finance. Topicswill vary each year. In Fall 2019, the topic will be crypto for social good . We will learn howsurveillance has been and currently is used to suppress dissent and how newsurveillance technologies are deployed against social protest movements,intimate partners and immigrants. We will study how modern cryptography enablesnew privacy-enhancing technologies and investigate how cryptography can be usedto protect dissent and enhance the safety and welfare of marginalized groups. Prerequisites None but CS 166 recommended email instructor if not sure. Syllabus pdf Overview Topics tentative Privacy Surveillance of social movements Sexual misconduct and intimate partner abuse Human trafficking Privacy-enhancing cryptography e.g., secure multi-party computation, encrypted databases, differential privacy There is no textbook required for this course but students may find Introduction to Modern Cryptography by Katz and Lindell helpful to gainfamiliarity with cryptography. Other recommended free resources include Introduction to ModernCryptography by Bellareand Rogaway and Course inCryptography byPass and Shelat. Schedule Sept. 05 Th Introduction and Overview Sept. 10 Tu Discussion P. Rogaway. The Moral Character of Cryptographic Work . Sept. 12 Th Historical surveillance of social movements South Africa T. Jenkin. Talking with Vula historical D. Ottenheimer. RSAC TV Interview with Tim Jenkin video Sept. 17 Tu Historical surveillance of social movements The US The FBI and COINTELPRO The US Senate Church Committee. The Church ReportBook II read pages 1-20 historical The NYPD The CLEAR Project. Mapping Muslims report Judge Haight. Handschu v. Special Services Div. background Sept. 19 ThIntroduction to Cryptography Introduction to Cryptography Provable Security no summary Sept. 24 TuDifferential privacy C. Dwork, F. McSherry, K. Nissim, A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis research C. Dwork. Differential Privacy A Survey of Results optinoal C. Dwork, A. Roth. The Algorithmic Foundations of Differential Privacy optional Sept. 26 ThEncrypted databases B. Fuller, M. Varia, A. Yerukhimovich, E. Shen, A. Hamlin, V. Gadepally, R. Shay, J. Mitchell, and R. Cunningham. SoK Cryptographically Protected Database Search research Oct. 01 TuSecure multi-party computation D. Evans, V. Kolesnikov, M. Rosulek. A Pragmatic Introduction to Secure Multi-Party Computation reach Chapter 1 research Oct. 03 ThPrivate set intersection M. Ion, B. Kreuter, A. Erhan Nergiz, S. Patel, M. Raykova, S. Saxena, K. Seth, D. Shanahan, M. Yung. On Deploying Secure Computing Commercially Private Intersection-Sum Protocols and their Business Applications research Oct. 08 Tu Secure Messaging N. Unger, S. Dechand, J. Bonneau, S. Fahl, H. Perl, I. Goldberg, M. Smith. SoK Secure Messaging research Oct. 10 ThTor R. Dingledine, N. Matthewson, P. Syverson. Tor The Second-Generation Onion Router research P. Syverson, G. Tsudik, M. Reed, C. Landwehr. Towards and Analysis of Onion Router Security research Oct. 15 Tu Surveillance technologies facial recognition C. Garvie, A. M. Bedoya, J. Frankle. The Perpetual Line Up - Unregulated Police Face Recognition in America report Oct. 17 Th Surveillance technologies Drones J. Stanley and C. Crump. Protecting Privacy From Aerial Surveillance report B. Nassi, A. Shabtai, R. Masuoka, Y. Elovici. SoK - Security and Privacy in the Age of Drones Threats, Challenges, Solution Mechanisms, and Scientific Gaps research D. Gettinger, A. Holland Michel, A. Pasternack, J. Koebler, S. Musgrave, J. Rankin. The Drone Primer A Compendium of the Key Issues background Oct. 22 Tu Surveillance technologies License plate readers The EFF. Automated License Plate Readers ALPRs report Oct. 24 Th Canceled Oct. 29 Tu Surveillance technologies IMSI-Catchers aka Stingrays R. Borgaonkar, A. Martin, S. Park, A. Shaik, J.-P. Seifert. White-Stingray Evaluating IMSI Catchers Detection Applications research P. Ney, I. Smith, G. Cadamuro, and T. Kohno. SeaGlass Enabling City-Wide IMSI-Catcher Detection research The EFF Threat Lab. Gotta Catch Em All Understanding How IMSI-Catchers Exploit Cell Networks Probably background Oct. 31 Th Surveillance of social movements Black Lives Matter and Standing Rock G. Joseph Intercept. Feds Regularly Monitored Black Lives Matter Since Ferguson article A. Brown, W. Parrish, A. Speri Leaked Documents Detail Standing Rock Surveillance article Documents Shed Light on Standing Rocks Most Violent Night article Police Used Private Aircraft in Standing Rock No-Fly Zone article Nov. 05 Tu Surveillance of social movements social media F. Patel, R. Levinson-Waldman, S. DenUyl, R. Koreh. Social Media Monitoring report N. Ozer. Police use of social media surveillance software is escalating, and activists are in the digital crosshairs article L. Fang. The CIA Is Investing in Firms That Mine Your Tweets and Instagram Photos article Nov. 07 Th Surveillance databases gang databases and immigration databases Department of Homeland Security. Privacy Impact Assessment for the ICEGangs Database report The Policing in Chicago Research Group. Tracked and Targeted report M. Dumke. Chicagos Gang Database Is Full of Errors article M. Stern. Federal judge accused ICE of making up evidence to prove that Dreamer was gang-affiliated. article A. Speri. What Happened After The Bronx 120 Raid article Nov. 12 Tu Sexual misconduct A. Rajan, L. Qin, D. Archer, D. Boneh T. Lepoint, M. Varia. Callisto A Cryptographic Approach To Detect Serial Predators Of Sexual Misconduct research B. Kuykendall, H. Krawczyk, T. Rabin. Cryptography for MeToo research Nov. 14 Th Intimate partner violence D. Freed, J. Palmer, D. Minchala, K. Levy, T. Ristenpart, N. Dell. A Stalkers Paradise How Intimate Partner Abusers Exploit Technology research R. Chatterjee, P. Doerfler, H. Orgad, S. Havron, J. Palmer, D. Freed, K. Levy, N. Dell, D. McCoy, T. Ristenpart. The Spyware Used in Intimate Partner Violence research Nov. 19 Tu Human trafficking Law enforcement J. Deeb-Swihart, A. Endert, A. Bruckman. Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking research United Nations Office on Drugs and Crime. Global Report on Trafficking in Persons background M. Latonero, J. Musto, Z. Boyd, A. Bissel, K. Gibson, J. Kim. The Rise of Mobile and the Diffusion of Technology-Facilitated Trafficking background J. Musto, d. boyd. The Trafficking-Technology Nexus background Nov. 21 Th Human trafficking victim servicve providers and survivors C. Chen, N. Dell, F. Roesner. Computer Security and Privacy in the Interactions Between Victim Service Providers and Human Trafficking Survivors research Nov. 26 Tu Human trafficking Getting data J. Brunner. Getting to Good Human Trafficking Data Assessing the Landscape in Southeast Asia and Promising Practices from ASEAN Governments and Civil Society report Nov. 28 Th Thanksgiving Dec. 03 TuProject Presentations Dec. 05 ThProject Presentations Additional Resources Glencora Borradaile and Michele Gretes from Oregon State University. CS175 Communications Security and Social Movements", "metadata": {"last_modified": "2022-08-11T19:33:43+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["CS 2950-v: Topics in Applied Cryptography: Crypto for Social Good (Fall \u201819)", "Overview", "Schedule", "Additional Resources"], "word_count": 1118, "token_count_estimate": 1799}}, "https://matteo.rionda.to/": {"text_content": "Matteo Riondato Home Short Bio CV Updated Feb 22 Publications Teaching Service Software Misc Contact info E-mail riondaacm.org Office Science Center C214 Twitter teorionda Mastodon matteobsd.network GitHub rionda Group Data Mammoths I am an associate professor of computerscience at AmherstCollege , where I lead the Data Mammoths , aresearchlearning group of brilliant undergraduate students. Ialso have an appointment as visiting faculty in Computer Science at BrownUniversity . Previously, I spent some fantastic years as aresearch scientist in the Labs group at Two Sigma . My research focuses on algorithms for knowledge discovery , data mining ,and machine learning . I develop theory and methodsto extract the most information from large datasets, as fast aspossible and in a statistically sound way. The problems I studyinclude pattern extraction, graph mining, and time series analysis.My algorithms often use concepts from statistical learning theory andsampling. My research is supported, in part, by NSFCAREER Award 2238693 and by NSFAward 2006765 . My Erdsnumber is 3 Erds Suen Upfal Matteo,and I am a mathematicaldescendant of EliUpfal , EliShamir 2 nd generation, JacquesHadamard 5 th , SimonDenis Poisson 9 th , and Pierre-SimonLaplace 10 th . News Dagstuhl With Eli and Aris , Imorganizing a 5-day workshop on Statistical andProbabilistic Methods in Algorithmic Data Analysis in Dagstuhl . So glad to go back tothe beautiful Schlss KDD24 Happy to help out the organization asa Co-chair of the PhD Consortium. CogMI I am giving an invited talk on Statistically-soundKDD at this interesting conference bringing togetherresearchers from different areas. KAIS the journal version of Alice was accepted tothe KAIS special issue for the best papers of IEEE ICDM22. TenurePromotion Since July 1, I am atenured associate professor of computer science Im over the moonabout this NSF CAREER I received a 600k NSFCAREER award to work on Statistically-soundKnowledge Discovery from Data my SDM23blue-sky-idea paper has more details about what I plan to do.I am extremely thankful for the trust from the community and NSF,and excited for 5 years of work ahead DMKDDAMI ECML PKDD23 the Data Mammoths publishedanother paper Maryam and Alex introduce ROhAN , a new set ofnull models for Statistically-sound KDD. News archive", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Contact info", "News"], "word_count": 355, "token_count_estimate": 531}}, "https://cs.brown.edu/~sk/Publications/Papers/Published/fks-mod-plan-comp-studies/": {"text_content": "Modernizing Plan-Composition Studies Kathi Fisler, Shriram Krishnamurthi, Janet Siegmund ACM Technical Symposium on Computer Science Education, 2016 Abstract Plan composition is an important but under-studied topic inprogramming education. Most studies were done three decades ago,under assumptions that miss important issues that todays studentsmust confront. This paper presents rationale and details for amodernized study of plan composition that accommodates a broaderrange of programming languages and problem features. Our studydesign has two novelties the problems require students to deal withdata-processing challenges such as noisy data, and the questionsask students to not only produce but also evaluate programs. We present preliminary results from using our study in multiplecourses from different linguistic paradigms. We discuss several futurestudies that are prompted by these results. Comment The supplemental materials are here . Paper PDF These papers may differ in formatting from the versions that appear in print. They are made available only to support the rapid dissemination of results the printed versions, not these, should be considered definitive. The copyrights belong to their respective owners.", "metadata": {"last_modified": "2024-02-02T08:35:19+00:00", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Modernizing Plan-Composition Studies"], "word_count": 169, "token_count_estimate": 225}}, "https://www2.cs.arizona.edu/~pachecoj/": {"text_content": "Home Publications Courses Code Office Gould-Simpson, Rm. 724 Mailing Address University of Arizona Department of Computer Science 1040 E 4th St. Tucson, AZ 85721 Jason L. Pacheco Statistical Machine Learning and Stochastic Systems About me. I am an Assistant Professor in the Department of Computer Science at the University of Arizona in sunny Tucson Arizona. Before joining UA I completed my PhD in Computer Science at Brown University with Erik Sudderth . I also held a postdoc position at MIT CSAIL with John Fisher III . Research. My research in statistical machine learning aims to build intelligent systems for automated reasoning in stochastic systems. To achieve this requires the development of algorithms that yield efficient inferences, while remaining flexible enough to adapt to complex domains. My research interests span a variety of application domains including computer vision, signal processing, computational biology, and computational neuroscience. For more details see my CV . For more information about machine learning at UA see our website. Recent News Our paper Efficient Variational Sequential Information Control was accepted to AISTATS 2024 Our paper On Convergence of Polynomial Approximations to the Gaussian Mixture Entropy was accepted to NeurIPS 2023 Our paper Fast Variational Estimation of Mutual Information for Implicit and Explicit Likelihood Models was accepted to AISTATS 2023 Recieved the Air Force Office of Scientific Research AFOSR Young Investigator Program YIP award for Robust Maximum Entropy Planning, Learning, and Control in Uncertain Environments Interested in working with me I am happy to collaborate with motivated students If you would like to join my group, see the following items before emailing me Take my classes CSC 535 Intro. to Probabilistic Graphical Models or CSC 665 AdvancedTopics in Probabilistic Graphical Models . If you wish to work with me as a PhD student read more here . Checkout some of my recent publications for project ideas. Jason Pacheco, 2019", "metadata": {"last_modified": "N/A", "scraped_at": "2024-03-13T22:15:49+00:00", "headings": ["Jason L. Pacheco"], "word_count": 311, "token_count_estimate": 395}}}